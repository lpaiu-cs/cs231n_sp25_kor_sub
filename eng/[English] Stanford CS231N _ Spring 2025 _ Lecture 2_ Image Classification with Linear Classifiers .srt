2
00:00:05,510 --> 00:00:10,320
We will be talking today
about image classification,

3
00:00:10,320 --> 00:00:13,160
basically, continuing
our discussion

4
00:00:13,160 --> 00:00:15,290
on the topic of
image classification

5
00:00:15,290 --> 00:00:17,430
from last lecture.

6
00:00:17,430 --> 00:00:23,750
And we'll get a little bit
into some topics that gets us

7
00:00:23,750 --> 00:00:26,990
closer to neural
networks and, ultimately,

8
00:00:26,990 --> 00:00:30,020
convolutional neural
networks and so on.

9
00:00:30,020 --> 00:00:35,780
We will start with
linear classifiers.

10
00:00:35,780 --> 00:00:43,280
Moving to the next slide,
this was the syllabus

11
00:00:43,280 --> 00:00:48,350
that we've talked
about last lecture,

12
00:00:48,350 --> 00:00:52,520
in the previous
lecture, where we

13
00:00:52,520 --> 00:00:57,660
did talk about three major
categories of topics,

14
00:00:57,660 --> 00:01:02,350
deep learning basics,
perceiving and understanding

15
00:01:02,350 --> 00:01:05,620
the visual world,
reconstructing and interacting

16
00:01:05,620 --> 00:01:08,590
with the visual world as
the three major topics,

17
00:01:08,590 --> 00:01:14,540
and some subtopics that we
will be covering in the class.

18
00:01:14,540 --> 00:01:17,860
And at the end, we will
have some discussions

19
00:01:17,860 --> 00:01:21,100
around the human-centered
AI aspects.

20
00:01:21,100 --> 00:01:27,880
And today, the goal is
to cover the first three

21
00:01:27,880 --> 00:01:31,600
items, data-driven approaches,
I will try to tell you

22
00:01:31,600 --> 00:01:38,230
what this means, and linear
classification as well

23
00:01:38,230 --> 00:01:43,120
as the k-nearest
neighbor algorithm.

24
00:01:43,120 --> 00:01:48,050
So like last-- the
previous lecture,

25
00:01:48,050 --> 00:01:55,750
let's start with our core
task of image classification.

26
00:01:55,750 --> 00:01:58,930
Again, it's a core task
in computer vision.

27
00:01:58,930 --> 00:02:02,070
And we actually come
back to this task

28
00:02:02,070 --> 00:02:03,840
quite often
throughout the quarter

29
00:02:03,840 --> 00:02:05,440
because it's a very
good benchmark.

30
00:02:05,440 --> 00:02:09,030
And we have some
examples to tell you

31
00:02:09,030 --> 00:02:11,080
how the algorithms work.

32
00:02:11,080 --> 00:02:17,100
So this is one of the items that
we come back to quite often.

33
00:02:17,100 --> 00:02:21,660
We want to define that image
classification task today

34
00:02:21,660 --> 00:02:27,930
and then introduce two of the
data-driven approaches for image

35
00:02:27,930 --> 00:02:30,480
classification, one of
them, nearest neighbor,

36
00:02:30,480 --> 00:02:34,240
and one of them-- the other
one, linear classifier.

37
00:02:34,240 --> 00:02:38,580
There are some other
approaches which we have

38
00:02:38,580 --> 00:02:40,660
listed in our backup slides.

39
00:02:40,660 --> 00:02:45,120
And you're welcome to look
at them after the class.

40
00:02:45,120 --> 00:02:49,620
But this is what we
will be covering.

41
00:02:49,620 --> 00:02:53,130
So what is image classification?

42
00:02:53,130 --> 00:03:00,610
Given an image and a number
of predefined labels,

43
00:03:00,610 --> 00:03:04,110
predetermined labels, a
set of possible labels

44
00:03:04,110 --> 00:03:08,170
such as in this example, you
see dog, cat, truck, plane,

45
00:03:08,170 --> 00:03:14,880
and so on, the job of the system
is to assign one of those labels

46
00:03:14,880 --> 00:03:18,000
to this image.

47
00:03:18,000 --> 00:03:23,280
So to us, this is actually
a very, very easy task

48
00:03:23,280 --> 00:03:26,850
because our brains,
our cognitive system

49
00:03:26,850 --> 00:03:32,640
is wired to get a holistic
understanding of this image

50
00:03:32,640 --> 00:03:34,630
and assign a label to it.

51
00:03:34,630 --> 00:03:37,950
But when it comes to
coding this and looking

52
00:03:37,950 --> 00:03:41,320
at how a computer can
make sense of this image,

53
00:03:41,320 --> 00:03:45,000
that's completely
a different story.

54
00:03:45,000 --> 00:03:52,120
And we want to see how machines
can make sense of such data.

55
00:03:52,120 --> 00:03:59,930
So images are often defined
by matrices of data,

56
00:03:59,930 --> 00:04:04,430
more broadly, more
generally, tensors of data.

57
00:04:04,430 --> 00:04:06,530
And often, the numbers are--

58
00:04:06,530 --> 00:04:11,130
each of the pixel values
are between 0 and 255,

59
00:04:11,130 --> 00:04:15,030
which is an 8-bit
data structure.

60
00:04:15,030 --> 00:04:22,010
And since this is an image,
a colored image, assuming

61
00:04:22,010 --> 00:04:25,910
that it's with a
resolution of 800

62
00:04:25,910 --> 00:04:30,080
by 600, since it's
an RGB image, it

63
00:04:30,080 --> 00:04:33,000
has three channels of
red, green, and blue, RGB,

64
00:04:33,000 --> 00:04:37,850
and therefore, it's
a tensor of 800

65
00:04:37,850 --> 00:04:43,100
by 600 by 3, as you
can see on this slide.

66
00:04:43,100 --> 00:04:49,850
So as you can
probably guess, this

67
00:04:49,850 --> 00:04:54,610
is the semantic gap between
our perception of this image

68
00:04:54,610 --> 00:04:59,520
and how the machine perceives
and sees the image, right?

69
00:04:59,520 --> 00:05:04,600
And in order to be
able to even understand

70
00:05:04,600 --> 00:05:07,820
how this could be
very challenging,

71
00:05:07,820 --> 00:05:11,410
let's look at some
challenges, some variations

72
00:05:11,410 --> 00:05:14,180
in this type of imaging data.

73
00:05:14,180 --> 00:05:16,250
So let's assume, for example--

74
00:05:16,250 --> 00:05:21,070
as one example, let's assume
that we move the camera.

75
00:05:21,070 --> 00:05:23,360
If the camera is
moved, for example,

76
00:05:23,360 --> 00:05:28,660
panning the camera around,
even if the cat sits completely

77
00:05:28,660 --> 00:05:33,650
and perfectly still, all
of those pixel values,

78
00:05:33,650 --> 00:05:40,540
every single pixel value of 800
by 600 by 3 will be changed.

79
00:05:40,540 --> 00:05:44,650
So all these pixels
will have a new value.

80
00:05:44,650 --> 00:05:50,450
Again, for us humans,
it's the same object.

81
00:05:50,450 --> 00:05:52,600
There is no-- absolutely
no difference.

82
00:05:52,600 --> 00:05:54,870
But from a computer's
perspective,

83
00:05:54,870 --> 00:05:57,510
it's completely
a new data point.

84
00:05:57,510 --> 00:06:01,120
So this is one of
the challenges,

85
00:06:01,120 --> 00:06:05,920
but there are quite
a few others as well.

86
00:06:05,920 --> 00:06:12,060
For example, illumination
is another challenge.

87
00:06:12,060 --> 00:06:15,900
So if you've seen or
if you've taken courses

88
00:06:15,900 --> 00:06:20,220
in graphics or maybe
other vision courses

89
00:06:20,220 --> 00:06:23,910
and/or digital image processing
courses for engineering

90
00:06:23,910 --> 00:06:31,110
applications, you know that the
value of each RGB pixel, the RGB

91
00:06:31,110 --> 00:06:37,590
values, are a function of
the surface material, color,

92
00:06:37,590 --> 00:06:39,870
and their light source.

93
00:06:39,870 --> 00:06:46,350
And that's why same cat, same
object may look differently

94
00:06:46,350 --> 00:06:48,840
in terms of numbers
when it comes

95
00:06:48,840 --> 00:06:55,020
to being pictured in different
illumination conditions.

96
00:06:55,020 --> 00:07:00,180
With that in mind, so whether
the cat is in a dark room

97
00:07:00,180 --> 00:07:02,500
or under the sun,
still, it's the cat.

98
00:07:02,500 --> 00:07:03,910
It's one cat.

99
00:07:03,910 --> 00:07:08,440
But this is creating
challenges for the machine.

100
00:07:08,440 --> 00:07:11,490
Can you maybe name
some other challenges

101
00:07:11,490 --> 00:07:16,890
that may change the
values of the pixels

102
00:07:16,890 --> 00:07:22,440
and create problems for the
machine to recognize objects,

103
00:07:22,440 --> 00:07:24,570
other than illumination
and viewpoint changes

104
00:07:24,570 --> 00:07:26,400
that I mentioned?

105
00:07:26,400 --> 00:07:30,990
So background clutter,
background objects, yes,

106
00:07:30,990 --> 00:07:33,120
which is actually
our next slide.

107
00:07:33,120 --> 00:07:38,100
Yes, background clutter
is another challenge.

108
00:07:38,100 --> 00:07:40,590
Anything else?

109
00:07:40,590 --> 00:07:44,430
Zooming in and out,
yes, so scale basically

110
00:07:44,430 --> 00:07:46,630
of the object in the image.

111
00:07:46,630 --> 00:07:49,070
Yes, what else?

112
00:07:49,070 --> 00:07:52,100
The resolution of
the image that is--

113
00:07:52,100 --> 00:07:54,810
that could be considered as--

114
00:07:54,810 --> 00:07:56,700
that's definitely a challenge.

115
00:07:56,700 --> 00:08:01,100
But often with machine-learning
models or any model

116
00:08:01,100 --> 00:08:05,580
that you want to recognize
action objects and images,

117
00:08:05,580 --> 00:08:09,210
since we normalize
the size of the image,

118
00:08:09,210 --> 00:08:11,720
resolution may not
be that important,

119
00:08:11,720 --> 00:08:15,230
unless there is zooming
effects of the objects.

120
00:08:15,230 --> 00:08:18,120
Occlusion is one of
the major problems.

121
00:08:18,120 --> 00:08:21,960
Again, as humans, it's very
easy to say this is cat.

122
00:08:21,960 --> 00:08:23,430
These are cats.

123
00:08:23,430 --> 00:08:25,895
Even the last one, which is
actually a very challenging,

124
00:08:25,895 --> 00:08:28,050
the one on the right.

125
00:08:28,050 --> 00:08:32,179
You can only see a tail and a
little bit of probably a paw

126
00:08:32,179 --> 00:08:34,239
in the right side.

128
00:08:37,280 --> 00:08:41,690
One could say, yes, that could
be a tiger, or it could be--

129
00:08:41,690 --> 00:08:46,070
I don't know-- a raccoon
with a tiny tale.

130
00:08:46,070 --> 00:08:48,910
But because this is-- because
of the context, because we

131
00:08:48,910 --> 00:08:52,460
know this is inside a
living room on a couch,

132
00:08:52,460 --> 00:08:53,890
most probably, it's a cat.

133
00:08:53,890 --> 00:08:54,740
It's a cat.

134
00:08:54,740 --> 00:08:59,170
So again, for us humans,
it's not that hard.

135
00:08:59,170 --> 00:09:02,720
Beyond that, there are
many other problems.

136
00:09:02,720 --> 00:09:03,310
Deformation.

137
00:09:03,310 --> 00:09:05,930
Cats are very deformable.

138
00:09:05,930 --> 00:09:16,300
So they create challenges for
algorithms to be detected,

139
00:09:16,300 --> 00:09:17,890
recognized.

140
00:09:17,890 --> 00:09:19,750
I mean, not today's algorithms.

141
00:09:19,750 --> 00:09:24,910
Generally, for building
step-by-step algorithms

142
00:09:24,910 --> 00:09:26,480
that can detect objects.

143
00:09:26,480 --> 00:09:31,240
So deformation is one of
the other major challenges.

144
00:09:31,240 --> 00:09:37,000
And beyond that, the
intraclass variation

145
00:09:37,000 --> 00:09:44,220
is one more important challenge.

146
00:09:44,220 --> 00:09:48,340
We know that cats can come
in different sizes, colors,

147
00:09:48,340 --> 00:09:51,310
patterns, or even, they can--
they have different breeds.

148
00:09:51,310 --> 00:09:55,090
And all of those are still cats.

149
00:09:55,090 --> 00:09:59,340
But for the machines,
it's not that

150
00:09:59,340 --> 00:10:04,530
easy to recognize the
intraclass variations.

151
00:10:04,530 --> 00:10:09,540
One other interesting
challenge is the context,

152
00:10:09,540 --> 00:10:17,260
because if you only look at that
part, that image on the right,

153
00:10:17,260 --> 00:10:23,170
or if an algorithm looks at this
without considering the context,

154
00:10:23,170 --> 00:10:28,270
it's very easy to classify this
as a tiger or some other animal.

155
00:10:28,270 --> 00:10:31,110
But because of the
context and because we

156
00:10:31,110 --> 00:10:34,500
know that there is
the effect of shadows

157
00:10:34,500 --> 00:10:39,876
and so on, this could probably
be classified correctly.

159
00:10:45,717 --> 00:10:49,200
But the thing is that the
classifiers that we have today

160
00:10:49,200 --> 00:10:52,020
can do really great job--

161
00:10:52,020 --> 00:10:57,400
good jobs at
classifying the images,

162
00:10:57,400 --> 00:11:00,760
identifying the
objects in images,

163
00:11:00,760 --> 00:11:04,920
thanks to efforts like ImageNet,
and also all of the follow-up

164
00:11:04,920 --> 00:11:10,950
works that created larger
scale benchmarks for training

165
00:11:10,950 --> 00:11:12,640
larger scale models.

166
00:11:12,640 --> 00:11:22,050
And in this class, what we
want to do is to get to a place

167
00:11:22,050 --> 00:11:27,600
that we build models that can
recognize activity-- recognize

168
00:11:27,600 --> 00:11:32,200
objects, and also other
aspects within the image.

169
00:11:32,200 --> 00:11:34,770
For the rest of
this class, we are

170
00:11:34,770 --> 00:11:38,460
going to be working towards
building, step-by-step,

171
00:11:38,460 --> 00:11:40,460
the building blocks that
are needed for building

172
00:11:40,460 --> 00:11:42,750
those large algorithms.

173
00:11:42,750 --> 00:11:51,200
And before doing so, we have to
look at the most basic building

174
00:11:51,200 --> 00:11:58,260
block of classifying an
image, and that is building,

175
00:11:58,260 --> 00:12:01,110
implementing a
function like this.

176
00:12:01,110 --> 00:12:06,020
So if you've taken some
of the computer science

177
00:12:06,020 --> 00:12:11,000
or engineering courses
that often build frameworks

178
00:12:11,000 --> 00:12:16,130
through algorithms, like, for
example, sorting as a computer

179
00:12:16,130 --> 00:12:18,020
algorithm, it's often--

180
00:12:18,020 --> 00:12:21,200
it often comes with
some if-then-else rules

181
00:12:21,200 --> 00:12:24,000
and some for-loops and so on.

182
00:12:24,000 --> 00:12:31,770
So there is a clear
flowchart of tasks and steps,

183
00:12:31,770 --> 00:12:35,670
if-then-else steps that creates
an algorithm for sorting.

184
00:12:35,670 --> 00:12:39,160
But when it comes to
images and understanding

185
00:12:39,160 --> 00:12:45,230
the visual world, that is not
happening, that is a challenge,

186
00:12:45,230 --> 00:12:50,660
there is no way to hard code the
steps for classifying images.

187
00:12:50,660 --> 00:12:56,000
Although there has been
some efforts in this space.

188
00:12:56,000 --> 00:13:04,180
There are papers that they've
tried to come up with algorithms

189
00:13:04,180 --> 00:13:06,590
and steps to recognize objects.

190
00:13:06,590 --> 00:13:13,510
And one of those was
based on edge detectors,

191
00:13:13,510 --> 00:13:19,130
finding the edges in the
image as a first step,

192
00:13:19,130 --> 00:13:23,930
and then after creating
all of these patterns,

193
00:13:23,930 --> 00:13:29,480
look at the important
patterns, for example, corners,

194
00:13:29,480 --> 00:13:32,630
extract some features that
are around the corners,

195
00:13:32,630 --> 00:13:36,360
or counts the number of
specific types of corners,

196
00:13:36,360 --> 00:13:44,110
and based on, from those, try to
map that into the output class.

197
00:13:44,110 --> 00:13:48,840
So while this has been
an interesting effort

198
00:13:48,840 --> 00:13:55,590
and it had some success on
very limited variability type

199
00:13:55,590 --> 00:13:59,200
of images, but this is
very hard to-- first,

200
00:13:59,200 --> 00:14:01,900
it's very hard to scale
these types of algorithms.

201
00:14:01,900 --> 00:14:06,660
Even if it works, it's
very hard to scale

202
00:14:06,660 --> 00:14:09,300
because you have to
create these rules

203
00:14:09,300 --> 00:14:11,190
and everything for
every single object

204
00:14:11,190 --> 00:14:12,670
that you want to recognize.

205
00:14:12,670 --> 00:14:17,100
And second, finding the
logic for each of those

206
00:14:17,100 --> 00:14:20,920
requires a lot of effort
by itself as well.

207
00:14:20,920 --> 00:14:23,040
So because of
these challenges, I

208
00:14:23,040 --> 00:14:27,210
think these types
of algorithms, which

209
00:14:27,210 --> 00:14:34,350
are based on creating logics and
procedures for detecting objects

210
00:14:34,350 --> 00:14:38,380
or classifying images have
not been quite successful.

211
00:14:38,380 --> 00:14:42,850
And machine learning comes
with this data-driven approach.

212
00:14:42,850 --> 00:14:46,320
So with this new paradigm of--

213
00:14:46,320 --> 00:14:50,220
and another paradigm of
looking at this problem

214
00:14:50,220 --> 00:14:56,070
from a data-driven
perspective, we

215
00:14:56,070 --> 00:15:00,070
define a procedure of
a three-step process.

216
00:15:00,070 --> 00:15:06,420
And the first one is
to collect data sets

217
00:15:06,420 --> 00:15:09,400
of images and their labels.

218
00:15:09,400 --> 00:15:11,850
So there are many
different ways of if you

219
00:15:11,850 --> 00:15:17,040
want to recognize a
specific type of object

220
00:15:17,040 --> 00:15:20,550
or specific types
of objects, we can

221
00:15:20,550 --> 00:15:26,130
look for data sets or single
data points over the internet

222
00:15:26,130 --> 00:15:32,040
to create data, many samples
from each of the examples.

223
00:15:32,040 --> 00:15:35,340
We used to be doing
this 10, 20 years ago,

224
00:15:35,340 --> 00:15:41,270
using search engines and image
search engines over the internet

225
00:15:41,270 --> 00:15:44,220
to create these
types of data sets.

226
00:15:44,220 --> 00:15:47,902
Now we have all
of the data sets.

227
00:15:47,902 --> 00:15:51,350
And then the second step
is using machine learning

228
00:15:51,350 --> 00:15:53,610
algorithms to
train a classifier.

229
00:15:53,610 --> 00:15:57,680
Basically, build
a function train

230
00:15:57,680 --> 00:16:01,730
that takes the images
in the training

231
00:16:01,730 --> 00:16:04,500
data and their
associated labels,

232
00:16:04,500 --> 00:16:08,240
and builds a model
that can relate,

233
00:16:08,240 --> 00:16:10,170
associate images
with the labels.

234
00:16:10,170 --> 00:16:15,050
And then the last step
would be evaluating

235
00:16:15,050 --> 00:16:20,570
the classifier on
new images, but which

236
00:16:20,570 --> 00:16:23,630
means implementing
a function called

237
00:16:23,630 --> 00:16:28,830
predict that takes the
model and some test images,

238
00:16:28,830 --> 00:16:32,470
and for those test images that
were not part of the training

239
00:16:32,470 --> 00:16:39,080
images, predicts the labels and
returns those as the output.

240
00:16:39,080 --> 00:16:42,110
So a very simple procedure.

241
00:16:42,110 --> 00:16:46,300
But instead of
building a logic, we

242
00:16:46,300 --> 00:16:50,110
are building a data-driven
approach for it.

243
00:16:50,110 --> 00:16:55,390
As I said, we want to talk
about two popular methods

244
00:16:55,390 --> 00:16:56,570
and classifiers.

245
00:16:56,570 --> 00:16:59,080
One of them is nearest
neighbor classifier.

246
00:16:59,080 --> 00:17:03,220
This is the easiest
form of classification,

247
00:17:03,220 --> 00:17:09,579
and we specifically want
to go over this because we

248
00:17:09,579 --> 00:17:15,099
can learn some of the
concepts around building

249
00:17:15,099 --> 00:17:16,160
these classifiers.

250
00:17:16,160 --> 00:17:22,190
And it's easier to explain
some of the details.

251
00:17:22,190 --> 00:17:26,089
And then we'll move to the
topic of linear classification.

252
00:17:26,089 --> 00:17:30,870
OK to do that, what we do to
build the nearest neighbor

253
00:17:30,870 --> 00:17:31,990
classifier.

254
00:17:31,990 --> 00:17:37,720
As I said, we need to build the
train and predict functions.

255
00:17:37,720 --> 00:17:40,890
The train function
needs to just memorize

256
00:17:40,890 --> 00:17:43,270
all of the data and labels.

257
00:17:43,270 --> 00:17:44,940
So the training
function basically

258
00:17:44,940 --> 00:17:47,070
doesn't do anything other
than keeping everything

259
00:17:47,070 --> 00:17:48,130
in the memory.

260
00:17:48,130 --> 00:17:50,320
And then the
prediction function--

261
00:17:50,320 --> 00:17:56,680
the predict function looks for
the most similar training image.

262
00:17:56,680 --> 00:18:00,300
Basically, it creates a lookup
table of all of the images

263
00:18:00,300 --> 00:18:02,140
and all of their labels.

264
00:18:02,140 --> 00:18:08,070
And during the prediction or
testing time, what it does

265
00:18:08,070 --> 00:18:12,910
is tries to find the closest
one, the most similar image,

266
00:18:12,910 --> 00:18:17,620
and outputs the
label for that image.

267
00:18:17,620 --> 00:18:19,060
Let's look at an example.

268
00:18:19,060 --> 00:18:26,430
So assuming that we have these
five as in our training data,

269
00:18:26,430 --> 00:18:27,420
then--

270
00:18:27,420 --> 00:18:29,830
yes, you see my cursor.

271
00:18:29,830 --> 00:18:33,280
And then this is
the query image,

272
00:18:33,280 --> 00:18:35,830
the input image for prediction.

273
00:18:35,830 --> 00:18:39,540
What we want to do is to see
which of these training data

274
00:18:39,540 --> 00:18:43,480
and training images is the
most similar to this one.

275
00:18:43,480 --> 00:18:46,210
And for that, we need
the distance function.

276
00:18:46,210 --> 00:18:49,560
So this distance
function needs to take

277
00:18:49,560 --> 00:18:53,280
the two images, each pair of
images, each of these images

278
00:18:53,280 --> 00:18:58,950
compared to the query image,
and return a value which

279
00:18:58,950 --> 00:19:05,370
defines the similarity between
these two inputs, these two

280
00:19:05,370 --> 00:19:06,600
images.

281
00:19:06,600 --> 00:19:09,790
There are many different
ways of doing that.

282
00:19:09,790 --> 00:19:14,560
One of the most popular
ones is L1 distance,

283
00:19:14,560 --> 00:19:19,680
which is defined as the sum
over all absolute values

284
00:19:19,680 --> 00:19:25,980
of pixel differences between
the two images, Image I1 and I2.

285
00:19:25,980 --> 00:19:28,940
As an example, if this
is a testing image,

286
00:19:28,940 --> 00:19:34,460
if we want to calculate
the distance of this image

287
00:19:34,460 --> 00:19:38,450
with an image in
the training data,

288
00:19:38,450 --> 00:19:43,580
we do a pixel wise
subtraction and the difference

289
00:19:43,580 --> 00:19:46,100
between the pixel values
and then sum them up,

290
00:19:46,100 --> 00:19:54,470
which defines this new--
this value as the distance

291
00:19:54,470 --> 00:19:55,860
between these two images.

292
00:19:55,860 --> 00:20:01,710
So this is the most
basic distance function,

293
00:20:01,710 --> 00:20:06,030
but it's actually very
useful in many applications.

294
00:20:06,030 --> 00:20:10,310
We'll be coming back to
this L1 and other variations

295
00:20:10,310 --> 00:20:13,280
of distances in the
class quite often.

296
00:20:13,280 --> 00:20:15,080
With this very
simple definition,

297
00:20:15,080 --> 00:20:16,530
we want to see
how we can get it.

298
00:20:16,530 --> 00:20:17,940
Get this implemented.

299
00:20:17,940 --> 00:20:22,860
As I said, the first step is to
just memorize the training data.

300
00:20:22,860 --> 00:20:28,390
So the train function just
keeps the data in the memory.

301
00:20:28,390 --> 00:20:32,920
And then what the
predict function

302
00:20:32,920 --> 00:20:39,380
does, using actually some Python
libraries and NumPy and so on,

303
00:20:39,380 --> 00:20:42,080
we can implement this
in just four lines.

304
00:20:42,080 --> 00:20:46,720
We calculate the distances
between each of the testing

305
00:20:46,720 --> 00:20:54,760
samples and the training
data, take the minimum

306
00:20:54,760 --> 00:20:59,530
for each of the testing
samples, and then output

307
00:20:59,530 --> 00:21:05,000
the label for the
one with mean index.

308
00:21:05,000 --> 00:21:10,090
So this is going to
be the implementation

309
00:21:10,090 --> 00:21:12,370
for the predict function.

310
00:21:12,370 --> 00:21:21,160
Yeah, the pixel values, as I
explained, the simplest form,

311
00:21:21,160 --> 00:21:28,120
this is a tensor of 800 by
600 by 3 and three channels,

312
00:21:28,120 --> 00:21:32,200
and these are RGB values for
each of the pixel locations.

313
00:21:32,200 --> 00:21:35,850
So yes, I should actually
repeat the questions

314
00:21:35,850 --> 00:21:37,630
for online students too.

315
00:21:37,630 --> 00:21:41,520
And the question was the pixel
values, what do they represent?

316
00:21:41,520 --> 00:21:46,290
Yeah, so the next question is
why it's between 0 and 255.

317
00:21:46,290 --> 00:21:52,320
So there are many different
standards for storing images.

318
00:21:52,320 --> 00:21:57,690
The most popular one that
we use in almost all images

319
00:21:57,690 --> 00:22:01,920
that you see online
and here they are RGB.

320
00:22:01,920 --> 00:22:05,580
RGB is a 24-bit
format, sometimes 32

321
00:22:05,580 --> 00:22:08,070
because there's
another channel alpha.

322
00:22:08,070 --> 00:22:10,540
We don't want to get into those.

323
00:22:10,540 --> 00:22:16,000
But the 24-bit format, it means
that for each of the channels,

324
00:22:16,000 --> 00:22:19,060
for each of the three channels
of red, green, and blue,

325
00:22:19,060 --> 00:22:22,590
which creates all of
our color combinations,

326
00:22:22,590 --> 00:22:24,340
we can have 8 bits.

327
00:22:24,340 --> 00:22:27,940
So that's the standard
that is defined.

328
00:22:27,940 --> 00:22:30,220
There are some other
frameworks too,

329
00:22:30,220 --> 00:22:33,900
but this is the
most popular one.

330
00:22:33,900 --> 00:22:40,820
So with that, let me go back to
the code and ask you a question.

332
00:22:46,080 --> 00:22:53,010
So I know some of the
students, most of the students

333
00:22:53,010 --> 00:22:55,680
come with engineering
backgrounds and a little bit

334
00:22:55,680 --> 00:23:01,200
of computer science as well,
but we want to see with,

335
00:23:01,200 --> 00:23:04,380
say, n samples n examples
that we have in the training

336
00:23:04,380 --> 00:23:08,333
data how fast the training
and prediction happens.

338
00:23:11,550 --> 00:23:15,420
I'm hoping that you're familiar
with the big O notation

339
00:23:15,420 --> 00:23:21,170
that we often represents
computational and sometimes

340
00:23:21,170 --> 00:23:23,310
space complexities with.

341
00:23:23,310 --> 00:23:27,260
But here, if you look
at the algorithms,

342
00:23:27,260 --> 00:23:28,850
I'll go with the training data.

343
00:23:28,850 --> 00:23:31,790
In the training
function-- and then

344
00:23:31,790 --> 00:23:36,890
I want you to help me with
the answer for prediction.

345
00:23:36,890 --> 00:23:40,730
For the training
step, the training

346
00:23:40,730 --> 00:23:44,550
is of O1 because we are not
actually doing anything.

347
00:23:44,550 --> 00:23:46,770
We are not even moving any data.

348
00:23:46,770 --> 00:23:50,010
We are just keeping the copy
of the data in the memory.

349
00:23:50,010 --> 00:23:53,340
So no operations, it means
that without operations,

350
00:23:53,340 --> 00:23:56,600
with an operations
of order 1, we

351
00:23:56,600 --> 00:24:00,780
can complete the training step.

352
00:24:00,780 --> 00:24:03,650
What about the
prediction step for each

353
00:24:03,650 --> 00:24:12,570
of the single examples of the
training-- the testing data?

354
00:24:12,570 --> 00:24:15,590
How many operations
should we take?

355
00:24:15,590 --> 00:24:17,370
N, yes.

356
00:24:17,370 --> 00:24:19,990
If we have n training
data, it means

357
00:24:19,990 --> 00:24:23,590
that we have to calculate the
distance of every single testing

358
00:24:23,590 --> 00:24:26,960
image with all of the
images in the training data,

359
00:24:26,960 --> 00:24:33,490
so at least in the
order of n operations.

360
00:24:33,490 --> 00:24:43,480
So this is not really good
because what we often want to do

361
00:24:43,480 --> 00:24:45,890
is-- because training
is not doing anything.

362
00:24:45,890 --> 00:24:49,190
But during testing,
during prediction time,

363
00:24:49,190 --> 00:24:51,700
we are spending
so much time just

364
00:24:51,700 --> 00:24:54,220
to do comparisons
between the data

365
00:24:54,220 --> 00:25:00,010
and the single data points
and the training examples.

366
00:25:00,010 --> 00:25:03,880
This would be
similar to the fact

367
00:25:03,880 --> 00:25:07,840
that each single time that
you ask ChatGPT a question,

368
00:25:07,840 --> 00:25:11,650
it will try to see what the
answer is and compare it

369
00:25:11,650 --> 00:25:15,510
with all of the possible
answers over the internet, which

370
00:25:15,510 --> 00:25:19,270
will take years and then
return your response.

371
00:25:19,270 --> 00:25:22,710
So it wouldn't work
when it wants to scale

372
00:25:22,710 --> 00:25:24,520
for very simple problems.

373
00:25:24,520 --> 00:25:26,850
We used to be using these
types of approaches.

374
00:25:26,850 --> 00:25:34,920
So what we often want is
to build classifiers that

375
00:25:34,920 --> 00:25:37,090
are fast during prediction.

376
00:25:37,090 --> 00:25:40,860
They do it much faster, but it's
OK if they take a lot of time

377
00:25:40,860 --> 00:25:42,960
to do during the
training because that

378
00:25:42,960 --> 00:25:44,890
could be done offline.

379
00:25:44,890 --> 00:25:49,350
So with that in
mind, although there

380
00:25:49,350 --> 00:25:55,530
has been a lot of efforts
making nearest neighbor more--

381
00:25:55,530 --> 00:25:59,320
much faster using
GPUs and so on,

382
00:25:59,320 --> 00:26:01,545
which are beyond the
scope of this class,

383
00:26:01,545 --> 00:26:03,670
if you're interested, you
can take a look at those.

384
00:26:03,670 --> 00:26:08,460
But with that, I want to look
at some of the visualizations

385
00:26:08,460 --> 00:26:11,580
and how this algorithm
in general works.

386
00:26:11,580 --> 00:26:15,630
So given this space
that we have five

387
00:26:15,630 --> 00:26:19,050
classes of red, blue,
green, purple and red--

388
00:26:19,050 --> 00:26:26,880
sorry, yellow, and each dot
represents one training, sample

389
00:26:26,880 --> 00:26:32,880
in that class, if we partition
the space for every single point

390
00:26:32,880 --> 00:26:37,440
you see that we can create
these five partitions--

391
00:26:37,440 --> 00:26:41,580
let's say five or in this case
six different partitions--

392
00:26:41,580 --> 00:26:48,210
that each point, if you
have a testing sample that

393
00:26:48,210 --> 00:26:51,780
is in that specific region,
the color of that region

394
00:26:51,780 --> 00:26:57,010
shows what the nearest neighbor
for that sample will be.

395
00:26:57,010 --> 00:27:02,670
So this is going to be the
nearest neighbor algorithm, one

396
00:27:02,670 --> 00:27:04,530
nearest neighbor
algorithm partitions

397
00:27:04,530 --> 00:27:07,330
the space in this setting.

398
00:27:07,330 --> 00:27:12,500
But do you see a problem
here in this example?

399
00:27:12,500 --> 00:27:14,750
So the yellow one is exactly--

400
00:27:14,750 --> 00:27:17,220
is in the middle of
all of the greens.

401
00:27:17,220 --> 00:27:20,370
And this means that
probably that's an outlier.

402
00:27:20,370 --> 00:27:21,750
That's probably a noise.

403
00:27:21,750 --> 00:27:24,200
And this is the case
for many, many problems

404
00:27:24,200 --> 00:27:25,500
that we have to solve.

405
00:27:25,500 --> 00:27:32,300
And with that, the
reason that there

406
00:27:32,300 --> 00:27:35,090
is this big yellow
region in the middle

407
00:27:35,090 --> 00:27:38,010
is just this single point.

408
00:27:38,010 --> 00:27:41,880
And because we are only
using one nearest neighbor,

409
00:27:41,880 --> 00:27:42,600
this happens.

410
00:27:42,600 --> 00:27:44,760
So to make it a little
bit more robust,

411
00:27:44,760 --> 00:27:48,450
we can increase the number of
nearest neighbors that we take,

412
00:27:48,450 --> 00:27:50,750
which turns the nearest
neighbor algorithm

413
00:27:50,750 --> 00:27:52,650
into a k-nearest neighbor.

414
00:27:52,650 --> 00:28:00,810
And we often select more
than one point or sample.

415
00:28:00,810 --> 00:28:04,370
And we often take
the majority voting

416
00:28:04,370 --> 00:28:10,450
for identifying the label
for any given testing

417
00:28:10,450 --> 00:28:13,750
sample, testing image.

418
00:28:13,750 --> 00:28:16,840
But the problem that
you can see here

419
00:28:16,840 --> 00:28:19,970
is now we have
some white regions.

420
00:28:19,970 --> 00:28:23,480
Those white regions are areas
that we cannot make a decision,

421
00:28:23,480 --> 00:28:28,150
a complete decision because
those areas are areas that we

422
00:28:28,150 --> 00:28:34,240
have equal number of samples
from the neighbors from

423
00:28:34,240 --> 00:28:36,350
the three different classes.

424
00:28:36,350 --> 00:28:39,130
And there is no way
to identify what

425
00:28:39,130 --> 00:28:43,970
the label of that example
in the white region is.

426
00:28:43,970 --> 00:28:47,080
And for you, if you
create these types

427
00:28:47,080 --> 00:28:49,750
of spaces for your
problems, this

428
00:28:49,750 --> 00:28:52,730
means that if you
look at these spaces,

429
00:28:52,730 --> 00:28:55,540
it means that those are good
regions to go and collect

430
00:28:55,540 --> 00:28:56,600
more data for.

431
00:28:56,600 --> 00:28:59,300
So those are unclear spaces.

432
00:28:59,300 --> 00:29:01,840
So it's a good way
of finding regions

433
00:29:01,840 --> 00:29:05,380
that are important for data--

434
00:29:05,380 --> 00:29:06,650
more data collection.

435
00:29:06,650 --> 00:29:10,870
So we can go larger
on the value of the k.

436
00:29:10,870 --> 00:29:14,690
But one of the choices
that we have, one of the.

438
00:29:17,940 --> 00:29:22,270
Factors that plays an important
role is the value of k.

439
00:29:22,270 --> 00:29:25,290
But if you remember,
we had another decision

440
00:29:25,290 --> 00:29:27,960
to make which was the
distance function.

441
00:29:27,960 --> 00:29:31,290
We talked about the
L1 distance again sum

442
00:29:31,290 --> 00:29:37,320
of all of the absolute values
between pairwise differences

443
00:29:37,320 --> 00:29:41,130
of the pixels.

444
00:29:41,130 --> 00:29:47,640
And if I visualize the
L1 distance or sometimes

445
00:29:47,640 --> 00:29:52,440
in some context, we call
it Manhattan distance,

446
00:29:52,440 --> 00:29:57,090
the distance function is kind
of visualized in this way.

448
00:29:59,620 --> 00:30:05,860
If I look at this square
that I have in this space,

449
00:30:05,860 --> 00:30:10,815
all of the points
on that square are--

450
00:30:10,815 --> 00:30:13,620
they have the same
distance from the origin

451
00:30:13,620 --> 00:30:15,400
from the center point.

452
00:30:15,400 --> 00:30:19,560
So this is a good way of
visualizing and seeing

453
00:30:19,560 --> 00:30:22,930
how this L1 distance
function works.

454
00:30:22,930 --> 00:30:26,280
Another popular framework,
another popular distance

455
00:30:26,280 --> 00:30:29,040
function that we
use is L2, which

456
00:30:29,040 --> 00:30:34,050
instead of the absolute
value, calculates the square

457
00:30:34,050 --> 00:30:36,910
of the differences, sums it up.

458
00:30:36,910 --> 00:30:39,900
But because of the square,
we also do a square root.

459
00:30:39,900 --> 00:30:49,320
And visualizing that, we'll get
the circle visualization, where

460
00:30:49,320 --> 00:30:52,770
each of the points on
the circle are-- they

461
00:30:52,770 --> 00:30:56,590
have the same distance from
the center, from the origin.

462
00:30:56,590 --> 00:30:58,530
So this visualization
actually helps

463
00:30:58,530 --> 00:31:01,750
us understand the differences
between these distances too.

464
00:31:01,750 --> 00:31:04,590
And these are the most basic
and easiest distance functions

465
00:31:04,590 --> 00:31:05,370
that we can use.

466
00:31:05,370 --> 00:31:08,250
So there are, again, a lot more.

467
00:31:08,250 --> 00:31:12,710
The reason this
visualization is helpful

468
00:31:12,710 --> 00:31:16,430
is because sometimes if
you rotate the-- so x

469
00:31:16,430 --> 00:31:18,410
and y in these
two visualizations

470
00:31:18,410 --> 00:31:20,000
are basically the features.

471
00:31:20,000 --> 00:31:23,280
If you have two pixel
values, two features,

472
00:31:23,280 --> 00:31:25,140
then we have this 2D space.

473
00:31:25,140 --> 00:31:29,450
And this x and y are
often those features.

474
00:31:29,450 --> 00:31:33,830
So if I rotate these
features, meaning,

475
00:31:33,830 --> 00:31:36,210
if I use other
types of features,

476
00:31:36,210 --> 00:31:40,140
this L1 will have a different
framework, different value,

477
00:31:40,140 --> 00:31:42,330
while it's not any
different for L2.

478
00:31:42,330 --> 00:31:46,950
So that's why this is a big
difference between L1 and L2.

479
00:31:46,950 --> 00:31:50,930
And sometimes if our features
are very specific and meaningful

480
00:31:50,930 --> 00:31:53,040
and we want to preserve
their information,

481
00:31:53,040 --> 00:31:56,510
often L1 is more
important, is better

482
00:31:56,510 --> 00:32:03,020
because it has kind
of, as you can see,

483
00:32:03,020 --> 00:32:07,690
a shape that preserves
and enforces distances

484
00:32:07,690 --> 00:32:09,140
based on the features.

485
00:32:09,140 --> 00:32:12,880
But if those features
are more arbitrary,

486
00:32:12,880 --> 00:32:15,250
then L2 distance
makes more sense.

487
00:32:15,250 --> 00:32:19,250
If I want to calculate
the distance--

488
00:32:19,250 --> 00:32:22,630
so the distance of all of
the points on this shape

489
00:32:22,630 --> 00:32:29,350
from the origin are exactly the
same, if I use the L1 distance,

490
00:32:29,350 --> 00:32:34,300
but for L2 distance, the
points on this circle

491
00:32:34,300 --> 00:32:38,020
have the same distance
from the center

492
00:32:38,020 --> 00:32:43,370
or the origin of this space.

493
00:32:43,370 --> 00:32:47,003
So that's basically the main--

495
00:32:51,200 --> 00:32:52,720
what these two
images are showing.

496
00:32:52,720 --> 00:32:57,760
Any point on this shape,
when using an L1 distance,

497
00:32:57,760 --> 00:33:00,080
have the same distance
from the origin.

498
00:33:00,080 --> 00:33:03,180
And for the circle, any
point on the circle,

499
00:33:03,180 --> 00:33:05,340
if you're using L2
distance, you'll

500
00:33:05,340 --> 00:33:08,490
have the same distance
from the origin.

501
00:33:08,490 --> 00:33:11,280
Yeah, why It's important to--

502
00:33:11,280 --> 00:33:15,630
it's better to use L1 if we
want to preserve the features.

503
00:33:15,630 --> 00:33:21,210
So to answer that question,
if I rotate the feature

504
00:33:21,210 --> 00:33:24,780
axis, the distances
and this distance

505
00:33:24,780 --> 00:33:27,540
function changes completely.

506
00:33:27,540 --> 00:33:33,040
While if I do the same
here, nothing changes.

507
00:33:33,040 --> 00:33:37,404
It's the exact same
value of the features--

508
00:33:37,404 --> 00:33:38,200
distance.

509
00:33:38,200 --> 00:33:38,700
Sorry.

510
00:33:38,700 --> 00:33:44,490
So in this case, L1 is very
sensitive on the feature values,

511
00:33:44,490 --> 00:33:46,710
while L2 is not.

512
00:33:46,710 --> 00:33:49,440
If you select another feature
in the same space that

513
00:33:49,440 --> 00:33:52,920
is having a different creates
a different shape, then

514
00:33:52,920 --> 00:33:57,210
your L function, the distance
function changes as well.

515
00:33:57,210 --> 00:34:01,270
So if I draw the
lines here, again,

516
00:34:01,270 --> 00:34:05,200
the question for online students
is why it changes if you rotate.

517
00:34:05,200 --> 00:34:09,914
If I select another feature
that goes from this side,

518
00:34:09,914 --> 00:34:13,199
then the lines will
look different.

519
00:34:13,199 --> 00:34:20,559
So if you rotate this thing, but
for that shape it's not-- it's

520
00:34:20,559 --> 00:34:21,059
agnostic.

522
00:34:23,610 --> 00:34:27,370
So with these two distance
functions that we talked about,

523
00:34:27,370 --> 00:34:33,840
if I visualize
the space, you can

524
00:34:33,840 --> 00:34:38,920
see with k equals to 1 with one
nearest neighbor with L1 and L2,

525
00:34:38,920 --> 00:34:41,949
these are the space
partitionings.

526
00:34:41,949 --> 00:34:44,340
One of the interesting
things that you can see here

527
00:34:44,340 --> 00:34:51,870
is that with L1 function,
most of the boundaries

528
00:34:51,870 --> 00:34:57,180
are parallel to the two
axes, the two features,

529
00:34:57,180 --> 00:35:01,345
x1 and x2, very much
sensitive to the features.

530
00:35:01,345 --> 00:35:02,720
While there, we
have a little bit

531
00:35:02,720 --> 00:35:07,820
of more smooth
boundary separation.

532
00:35:07,820 --> 00:35:11,660
So there is a tool
online on the lab website

533
00:35:11,660 --> 00:35:16,640
that you can play around with
this, with different distance

534
00:35:16,640 --> 00:35:18,570
functions and
different number of k.

535
00:35:18,570 --> 00:35:21,630
You can see, you can
create a different setup.

536
00:35:21,630 --> 00:35:23,760
So you can play around with it.

537
00:35:23,760 --> 00:35:28,050
But why did we talk about
nearest neighbor to begin with?

538
00:35:28,050 --> 00:35:33,560
First, yes, it's the
easiest problem to solve,

539
00:35:33,560 --> 00:35:39,230
easiest solution, easiest
data-driven approach, and great

540
00:35:39,230 --> 00:35:40,080
to start with.

541
00:35:40,080 --> 00:35:45,950
But one of the main reasons that
we want to iterate and discuss

542
00:35:45,950 --> 00:35:49,250
nearest neighbor
is the fact that we

543
00:35:49,250 --> 00:35:55,080
can look into the topic
of hyperparameters.

544
00:35:55,080 --> 00:36:01,430
Hyperparameters are often
some of the variables

545
00:36:01,430 --> 00:36:03,380
that you have to
make a decision on

546
00:36:03,380 --> 00:36:05,820
to be able to run
your algorithm.

547
00:36:05,820 --> 00:36:12,320
In this case, the value of k,
the number of nearest neighbors

548
00:36:12,320 --> 00:36:14,850
is defined as-- is
a hyperparameter.

549
00:36:14,850 --> 00:36:19,770
Depending on how many number
of nearest neighbors you take,

550
00:36:19,770 --> 00:36:21,960
your outputs will be different.

551
00:36:21,960 --> 00:36:24,500
And then another choice
that you have here

552
00:36:24,500 --> 00:36:27,050
is the distance function.

553
00:36:27,050 --> 00:36:33,320
So the choice of
hyperparameters are often

554
00:36:33,320 --> 00:36:39,830
very much data set-dependent
and sometimes problem-dependent.

555
00:36:39,830 --> 00:36:43,700
And we have to have
a way to identify

556
00:36:43,700 --> 00:36:50,270
those to optimize for them
for each single problem.

557
00:36:50,270 --> 00:36:52,370
And that's what
is often referred

558
00:36:52,370 --> 00:36:56,080
to as hyperparameter tuning in
machine-learning algorithms,

559
00:36:56,080 --> 00:36:58,200
in deep learning
algorithms and so on.

560
00:36:58,200 --> 00:36:59,560
And how to do that?

561
00:36:59,560 --> 00:37:03,220
How to set the hyperparameters?

562
00:37:03,220 --> 00:37:04,720
There are different approaches.

563
00:37:04,720 --> 00:37:08,520
One of them is to choose the
hyperparameters that work

564
00:37:08,520 --> 00:37:10,980
the best for the training data.

565
00:37:10,980 --> 00:37:14,140
So you have a set
of images or data.

566
00:37:14,140 --> 00:37:19,290
In your training data,
you look for the best set

567
00:37:19,290 --> 00:37:23,940
of hyperparameters that
generates the best training

568
00:37:23,940 --> 00:37:27,700
or minimum training loss.

569
00:37:27,700 --> 00:37:30,700
While it works for
the training data,

570
00:37:30,700 --> 00:37:34,710
it's not a good idea at
all because, especially

571
00:37:34,710 --> 00:37:39,660
with nearest neighbor, k equal
to 1 is always the best value.

572
00:37:39,660 --> 00:37:43,620
Because you're memorizing
training data, so k equal to 1

573
00:37:43,620 --> 00:37:47,280
will give you, always,
the 100% accuracy.

574
00:37:47,280 --> 00:37:51,580
So we know that this
is not a great idea.

575
00:37:51,580 --> 00:37:56,520
The second one is choosing
hyperparameter that works

576
00:37:56,520 --> 00:38:00,570
best for held-out testing sets.

577
00:38:00,570 --> 00:38:05,250
While this is a little bit
better than the first one,

578
00:38:05,250 --> 00:38:07,630
there is also a
big problem here.

579
00:38:07,630 --> 00:38:11,610
Can anybody say why
this is a problem.

580
00:38:11,610 --> 00:38:15,390
Exactly, so it's kind of
cheating because you are trying

581
00:38:15,390 --> 00:38:18,910
to find the best hyperparameter
that works on the testing data,

582
00:38:18,910 --> 00:38:24,030
and you don't know how the model
will work on any other data

583
00:38:24,030 --> 00:38:26,200
points, not in the testing set.

584
00:38:26,200 --> 00:38:30,630
So yes, that is exactly right.

585
00:38:30,630 --> 00:38:33,450
It's not a good idea
because we don't know

586
00:38:33,450 --> 00:38:35,260
how the model will generalize.

587
00:38:35,260 --> 00:38:39,070
And for sure never do this.

588
00:38:39,070 --> 00:38:41,620
As we talked about,
it's kind of cheating.

589
00:38:41,620 --> 00:38:47,040
And a better idea is
to always separate,

590
00:38:47,040 --> 00:38:51,020
take some part of the training
data as validation set.

591
00:38:51,020 --> 00:38:54,530
And train your model
on the training data

592
00:38:54,530 --> 00:38:59,060
on the train portion of the
new portion that we call train.

593
00:38:59,060 --> 00:39:04,160
And then try to find or
optimize your hyperparameter

594
00:39:04,160 --> 00:39:06,230
on the validation set.

595
00:39:06,230 --> 00:39:10,710
And after you've found the
best set of hyperparameters,

596
00:39:10,710 --> 00:39:13,820
then use those
hyperparameters to replicate

597
00:39:13,820 --> 00:39:16,370
the results for the testing
set and do the predictions

598
00:39:16,370 --> 00:39:17,280
for the testing set.

599
00:39:17,280 --> 00:39:20,460
So this is a much
better approach,

600
00:39:20,460 --> 00:39:25,763
although it does have some
challenges itself because.

602
00:39:28,760 --> 00:39:32,340
Sometimes the validation
set that you've selected,

603
00:39:32,340 --> 00:39:34,220
it may not be a
good representative

604
00:39:34,220 --> 00:39:37,850
of the entire landscape
because your validation set

605
00:39:37,850 --> 00:39:40,770
is almost always much smaller.

606
00:39:40,770 --> 00:39:44,780
And that's why one of
the-- a better approach

607
00:39:44,780 --> 00:39:52,160
is to use cross-validation
for setting hyperparameters.

608
00:39:52,160 --> 00:39:54,940
Basically, you split
your training data

609
00:39:54,940 --> 00:39:59,350
into a number of folds,
a number of partitions.

610
00:39:59,350 --> 00:40:01,120
Here, in this case, five.

611
00:40:01,120 --> 00:40:08,140
And each of the folds plays
as the validation set once.

612
00:40:08,140 --> 00:40:10,660
And iteratively, you
run this five times

613
00:40:10,660 --> 00:40:12,530
for five-fold cross-validation.

614
00:40:12,530 --> 00:40:17,810
You do this five times and
average the accuracies.

615
00:40:17,810 --> 00:40:20,510
So you set a value of
the hyperparameter.

616
00:40:20,510 --> 00:40:25,460
You run this for all these
five sets, define the accuracy,

617
00:40:25,460 --> 00:40:29,690
calculate the accuracy on the
validation set, average it.

618
00:40:29,690 --> 00:40:31,600
And then you do
this multiple times

619
00:40:31,600 --> 00:40:34,250
to find the best setting
for the hyperparameter.

620
00:40:34,250 --> 00:40:36,620
After you found the
hyperparameter setting,

621
00:40:36,620 --> 00:40:39,160
you apply it to the testing set.

622
00:40:39,160 --> 00:40:41,500
This is a little
bit more reliable

623
00:40:41,500 --> 00:40:44,270
and generates much
better results,

624
00:40:44,270 --> 00:40:46,360
although in larger
scale deep learning,

625
00:40:46,360 --> 00:40:52,860
it is less practiced because
repeating this multiple times

626
00:40:52,860 --> 00:40:56,290
and five times with huge
data sets is very hard.

627
00:40:56,290 --> 00:41:00,040
So we often use intuitions
for setting hyperparameters,

628
00:41:00,040 --> 00:41:03,720
and the single validation
set is sometimes

629
00:41:03,720 --> 00:41:05,200
the approach we go with.

630
00:41:05,200 --> 00:41:09,150
But this is pretty much advised.

631
00:41:09,150 --> 00:41:13,570
Again, outside computer vision,
outside larger scale data sets,

632
00:41:13,570 --> 00:41:16,200
often research
papers require doing

633
00:41:16,200 --> 00:41:22,710
these types of cross-validation
and these types

634
00:41:22,710 --> 00:41:27,780
of statistical frameworks to
make sure your results are

635
00:41:27,780 --> 00:41:29,650
reproducible on a testing set.

636
00:41:29,650 --> 00:41:32,590
Anyways, so there are
different approaches.

637
00:41:32,590 --> 00:41:36,420
Let's finalize
the topic, wrap up

638
00:41:36,420 --> 00:41:42,720
the topic of nearest
neighbor, and look

639
00:41:42,720 --> 00:41:45,540
at some examples, some results.

640
00:41:45,540 --> 00:41:50,268
So let me introduce you
to the CIFAR10 data set.

641
00:41:50,268 --> 00:41:51,810
It's one of the data
sets that you're

642
00:41:51,810 --> 00:41:56,470
going to be using in your
assignments quite often.

643
00:41:56,470 --> 00:42:01,260
It has 10 classes with a number
of training images and testing

644
00:42:01,260 --> 00:42:02,170
images.

645
00:42:02,170 --> 00:42:03,960
The 10 classes,
some of the examples

646
00:42:03,960 --> 00:42:07,590
are shown here with
nearest neighbor

647
00:42:07,590 --> 00:42:09,580
for each of the testing images.

648
00:42:09,580 --> 00:42:14,790
If we run nearest
neighbor and select

649
00:42:14,790 --> 00:42:22,980
the top 10 nearest neighbors,
they are all visualized there.

650
00:42:22,980 --> 00:42:26,880
As you can imagine and guess,
one of the first questions

651
00:42:26,880 --> 00:42:28,260
to answer is how many--

653
00:42:31,290 --> 00:42:32,930
what should be the value for k?

654
00:42:32,930 --> 00:42:34,680
How many nearest
neighbors should we take?

655
00:42:34,680 --> 00:42:39,960
And want to study one
of the quick experiments

656
00:42:39,960 --> 00:42:42,660
with five-fold,
each of those points

657
00:42:42,660 --> 00:42:47,960
is one of the folds in five-fold
for each of the values of k,

658
00:42:47,960 --> 00:42:52,080
shows different values here.

659
00:42:52,080 --> 00:42:56,880
And as you can probably
see here, k equal to 7,

660
00:42:56,880 --> 00:43:01,440
it generates the best
results in terms of accuracy,

661
00:43:01,440 --> 00:43:03,740
which is close to 29%--

662
00:43:03,740 --> 00:43:10,190
to 28% accuracy, which
is actually not too bad

663
00:43:10,190 --> 00:43:14,700
because this is a 10-class
classification problem.

664
00:43:14,700 --> 00:43:17,190
And with a 10-class
classification problem,

665
00:43:17,190 --> 00:43:21,600
often the random guess
gets you a 10% accuracy.

666
00:43:21,600 --> 00:43:24,630
So this is much better
than random guess.

667
00:43:24,630 --> 00:43:25,680
So it's working.

668
00:43:25,680 --> 00:43:30,980
It's doing something, but there
is a lot of room to improve.

669
00:43:30,980 --> 00:43:35,700
So if we go back and
look at the examples,

670
00:43:35,700 --> 00:43:38,900
we can actually see there are
so many mistakes, especially

671
00:43:38,900 --> 00:43:41,040
with the one that is closest.

672
00:43:41,040 --> 00:43:44,150
For example, the fourth row, if
you look at that, it's a frog.

673
00:43:44,150 --> 00:43:47,690
But the first example
seems to be a cat.

674
00:43:47,690 --> 00:43:48,770
Sorry, a dog.

675
00:43:48,770 --> 00:43:54,340
And you can guess why this is
happening because the distance

676
00:43:54,340 --> 00:43:57,580
is being applied on pixels.

677
00:43:57,580 --> 00:44:01,970
And pixel wise, they
look like each other.

678
00:44:01,970 --> 00:44:05,570
They have the same type
of colors in most pixels,

679
00:44:05,570 --> 00:44:08,330
so they are much closer.

680
00:44:08,330 --> 00:44:10,390
This example and
many other examples

681
00:44:10,390 --> 00:44:15,250
show that distances that work
on pixels and pixel values

682
00:44:15,250 --> 00:44:16,880
are not the best choices.

683
00:44:16,880 --> 00:44:18,860
We never practice them.

684
00:44:18,860 --> 00:44:21,370
There are much better
approaches that we'll

685
00:44:21,370 --> 00:44:29,420
be discussing at the end of--
more in the future lectures.

686
00:44:29,420 --> 00:44:34,340
And just to wrap up the topic,
this is another example.

687
00:44:34,340 --> 00:44:37,820
If you look at this original
image, those three images,

688
00:44:37,820 --> 00:44:40,090
while they look very
much different in terms

689
00:44:40,090 --> 00:44:46,770
of color or maybe occlusion,
or the one in the third one

690
00:44:46,770 --> 00:44:51,000
from the left side is
just same pixel-- it's

691
00:44:51,000 --> 00:44:55,660
the same image with one pixel
shifting to the right, I think.

692
00:44:55,660 --> 00:44:58,590
Although from a human
eyes perspective,

693
00:44:58,590 --> 00:45:00,640
there is no-- absolutely
no difference.

694
00:45:00,640 --> 00:45:05,310
But the distance between
that and the original image

695
00:45:05,310 --> 00:45:08,590
is the same as the other two
examples that you see here.

696
00:45:08,590 --> 00:45:11,680
I'll stop for a
couple of questions,

697
00:45:11,680 --> 00:45:13,870
and this is the summary
of what we've discussed.

698
00:45:13,870 --> 00:45:16,680
So the question is, how
do we make a decision.

699
00:45:16,680 --> 00:45:20,700
In those cases, you often go
with randomly selected one

700
00:45:20,700 --> 00:45:21,750
of the tops.

701
00:45:21,750 --> 00:45:27,450
So if you are to collect
more data, if you're--

702
00:45:27,450 --> 00:45:30,180
for example, you're solving
a problem now in genetics

703
00:45:30,180 --> 00:45:33,450
or you're solving a
problem in medical imaging

704
00:45:33,450 --> 00:45:40,200
when you visualize your
examples, your features

705
00:45:40,200 --> 00:45:41,020
or whatever.

706
00:45:41,020 --> 00:45:43,570
And then in this
nearest neighbor space,

707
00:45:43,570 --> 00:45:47,610
you do see pockets of space that
you don't have any good samples

708
00:45:47,610 --> 00:45:52,920
for, or there is
ambiguity, then you often

709
00:45:52,920 --> 00:45:55,440
try to go and find
other samples that

710
00:45:55,440 --> 00:45:58,890
lie in that same
area in that space.

711
00:45:58,890 --> 00:46:03,960
OK, so summarizing
what we've talked

712
00:46:03,960 --> 00:46:06,330
about with k-nearest
neighbor, it

713
00:46:06,330 --> 00:46:12,900
was mostly about
understanding the easiest

714
00:46:12,900 --> 00:46:17,250
algorithm, data-driven
approach, and then talking

715
00:46:17,250 --> 00:46:19,080
a little bit about
hyperparameter tuning

716
00:46:19,080 --> 00:46:23,040
and how distance metrics
and the value of k

717
00:46:23,040 --> 00:46:26,070
play a very important role.

718
00:46:26,070 --> 00:46:30,570
Moving on to the next topic,
which is linear classifiers.

719
00:46:30,570 --> 00:46:35,640
25 minutes time to
cover this, I want

720
00:46:35,640 --> 00:46:40,190
to spend the remaining
time of this lecture

721
00:46:40,190 --> 00:46:43,770
to talk about this
very important topic.

722
00:46:43,770 --> 00:46:50,960
This is the most important
building block for almost.

723
00:46:50,960 --> 00:46:53,930
All of deep learning.

724
00:46:53,930 --> 00:47:04,200
And we need to see how
this approach is different.

725
00:47:04,200 --> 00:47:07,740
So first we want to see how it's
different from nearest neighbor.

726
00:47:07,740 --> 00:47:09,900
So this is a
parametric approach,

727
00:47:09,900 --> 00:47:14,180
meaning that now we are
learning we are finding

728
00:47:14,180 --> 00:47:17,900
some parameters, w,
or some weights that

729
00:47:17,900 --> 00:47:22,850
map the input image into the
output classes, the output

730
00:47:22,850 --> 00:47:23,850
numbers.

731
00:47:23,850 --> 00:47:26,720
In this case, when we
create this function

732
00:47:26,720 --> 00:47:30,290
f that maps input
to the output, often

733
00:47:30,290 --> 00:47:35,830
those outputs are kind
of membership scores

734
00:47:35,830 --> 00:47:41,900
of the image to each of those
10 output classes labels.

735
00:47:41,900 --> 00:47:49,060
So with this setup that we
build, a linear classifier

736
00:47:49,060 --> 00:47:53,830
first maps uses w
uses these parameters

737
00:47:53,830 --> 00:48:01,010
to map each of the inputs x into
a value, which is the output y.

738
00:48:01,010 --> 00:48:04,640
And how this is
done is very simple.

739
00:48:04,640 --> 00:48:10,250
This image is basically an
area of, say, 32 by 32 by 3,

740
00:48:10,250 --> 00:48:14,150
so 3,072 numbers.

741
00:48:14,150 --> 00:48:23,000
And this defines our x,
which is 3,072 by one vector.

742
00:48:23,000 --> 00:48:26,360
And we know that we
have 10 output classes.

743
00:48:26,360 --> 00:48:28,430
So we need 10 different scores.

744
00:48:28,430 --> 00:48:29,650
And the scores are--

745
00:48:29,650 --> 00:48:34,690
the output will be kind
of a vector of 10 by 1.

746
00:48:34,690 --> 00:48:38,910
And this means that we have to
identify to find a weight matrix

747
00:48:38,910 --> 00:48:47,520
w that is a 10 by 3,072 that
maps x into the output scores.

748
00:48:47,520 --> 00:48:50,020
Just to complete
this linear function,

749
00:48:50,020 --> 00:48:56,380
we often use this
bias term as well.

750
00:48:56,380 --> 00:49:01,620
It's an input-independent
value, which actually has

751
00:49:01,620 --> 00:49:03,400
a lot of different use cases.

752
00:49:03,400 --> 00:49:07,990
I can talk about it when I do
some geometric visualizations,

753
00:49:07,990 --> 00:49:13,500
but it sometimes creates a
shift for different class scores

754
00:49:13,500 --> 00:49:20,470
and helps with much better
separation of each class.

755
00:49:20,470 --> 00:49:23,730
So as I said, these
linear functions

756
00:49:23,730 --> 00:49:28,270
are actually building blocks
for building neural networks.

757
00:49:28,270 --> 00:49:32,700
Each of these linear
classifiers, linear functions

758
00:49:32,700 --> 00:49:35,170
when put together,
one after the other,

759
00:49:35,170 --> 00:49:39,240
create these large
neural networks.

760
00:49:39,240 --> 00:49:42,480
Although there are a
lot of other things

761
00:49:42,480 --> 00:49:45,720
that need to be
added here, but this

762
00:49:45,720 --> 00:49:48,190
is one of the most
important components.

763
00:49:48,190 --> 00:49:56,200
If we look at some of the
popular neural networks,

764
00:49:56,200 --> 00:50:00,570
we can see that linear
functions are everywhere

765
00:50:00,570 --> 00:50:03,600
in the architectures.

766
00:50:03,600 --> 00:50:08,040
So, to better understand what
this mapping and this function

767
00:50:08,040 --> 00:50:11,880
is doing, let's go back
to our example of CIFAR10

768
00:50:11,880 --> 00:50:15,580
and our training and
testing samples and so on,

769
00:50:15,580 --> 00:50:18,160
and even make it a
little bit simpler.

770
00:50:18,160 --> 00:50:22,120
Instead of looking at
large images of 32 by 32,

771
00:50:22,120 --> 00:50:25,680
let's look at images of
2 by 2, an input image

772
00:50:25,680 --> 00:50:27,540
that has four pixels.

773
00:50:27,540 --> 00:50:34,560
This means that the input
image is turned into a vector.

774
00:50:34,560 --> 00:50:42,260
As you can see here, we have to
find a w and the values of b.

775
00:50:42,260 --> 00:50:49,200
So the input image is mapped
into some scores as the output.

776
00:50:49,200 --> 00:50:54,710
So this is how the
linear function

777
00:50:54,710 --> 00:50:58,050
from an algebraic
viewpoint looks like.

778
00:50:58,050 --> 00:51:01,310
The output scores here, we
are considering three classes

779
00:51:01,310 --> 00:51:02,940
of cat, dog, and ship.

780
00:51:02,940 --> 00:51:10,040
And as you can
see, this function

781
00:51:10,040 --> 00:51:13,520
maps the image, the vector,
representing the image

782
00:51:13,520 --> 00:51:16,820
into those scores.

783
00:51:16,820 --> 00:51:21,780
So algebraic viewpoint
of linear classification.

784
00:51:21,780 --> 00:51:26,000
Now let's look at some
visual perspectives

785
00:51:26,000 --> 00:51:27,910
of this linear classifier.

786
00:51:27,910 --> 00:51:33,190
As you can see, we often
create each of these images,

787
00:51:33,190 --> 00:51:38,540
as we talked about
for this image.

788
00:51:38,540 --> 00:51:45,310
For each of the classes, we
define some sort of-- we have

789
00:51:45,310 --> 00:51:46,330
a row of this--

790
00:51:46,330 --> 00:51:48,506
row in the matrix w.

791
00:51:48,506 --> 00:51:51,070
So this row is
kind of a template

792
00:51:51,070 --> 00:51:52,760
for that specific class.

793
00:51:52,760 --> 00:51:57,370
If I separate it like
this, so this image

794
00:51:57,370 --> 00:52:01,030
is multiplied by w
and b, and w is--

795
00:52:01,030 --> 00:52:03,940
this is the template
from each of the three

796
00:52:03,940 --> 00:52:06,140
classes of cat, dog, and ship.

797
00:52:06,140 --> 00:52:12,740
And after training or building
the model on the CIFAR data set,

798
00:52:12,740 --> 00:52:18,880
if I look at the visual
perspective, a visual point,

799
00:52:18,880 --> 00:52:21,170
viewpoint of the
linear classifier,

800
00:52:21,170 --> 00:52:23,740
if I look at those
templates that

801
00:52:23,740 --> 00:52:26,120
are learned for each
of the 10 classes,

802
00:52:26,120 --> 00:52:27,910
you can see these templates.

803
00:52:27,910 --> 00:52:30,570
So it's very
interesting that in some

804
00:52:30,570 --> 00:52:34,360
of these cases, for example,
for the example for car,

805
00:52:34,360 --> 00:52:39,640
you do see a front of
a car template-ish,

806
00:52:39,640 --> 00:52:45,870
and although this is all done
with just one linear classifier.

807
00:52:45,870 --> 00:52:48,900
So the visual aspect,
visual viewpoint

808
00:52:48,900 --> 00:52:51,030
of the linear
classifier, and there

809
00:52:51,030 --> 00:52:55,800
is another aspect of
geometric viewpoint.

810
00:52:55,800 --> 00:53:01,290
What this linear classifier
often does is finding those

811
00:53:01,290 --> 00:53:05,910
lines if it's in 2D space,
finding those lines that

812
00:53:05,910 --> 00:53:09,240
separates each class
from the others.

813
00:53:09,240 --> 00:53:12,570
And as you can see here,
red, blue, and green

814
00:53:12,570 --> 00:53:20,260
are defining different classes,
and in higher dimensional space,

815
00:53:20,260 --> 00:53:22,990
instead of those lines,
it's these hyperplanes,

816
00:53:22,990 --> 00:53:27,450
as you can see in this
example on the left.

817
00:53:27,450 --> 00:53:33,240
So you can also see the
use of the bias term

818
00:53:33,240 --> 00:53:36,420
here, because if we didn't have
the bias, all of these lines

819
00:53:36,420 --> 00:53:38,250
should have passed
through the origin

820
00:53:38,250 --> 00:53:42,580
from the center of that space,
which doesn't really make sense.

821
00:53:42,580 --> 00:53:44,640
But with the bias,
we can actually

822
00:53:44,640 --> 00:53:53,220
create more reliable functions
and decision boundaries.

823
00:53:53,220 --> 00:53:57,190
So a linear function
is very useful.

824
00:53:57,190 --> 00:54:01,150
A linear classifier is very
useful for many applications,

825
00:54:01,150 --> 00:54:02,650
as we talked about.

826
00:54:02,650 --> 00:54:08,050
And it's a building block of
more complex neural networks.

827
00:54:08,050 --> 00:54:10,410
But it does have
its own challenges

828
00:54:10,410 --> 00:54:18,250
because it can't classify many
instances of separate data.

829
00:54:18,250 --> 00:54:20,910
For example, in this
case, if class 1

830
00:54:20,910 --> 00:54:24,200
is the first and third
quadrant and the second class

831
00:54:24,200 --> 00:54:26,100
is second and the fourth.

832
00:54:26,100 --> 00:54:28,170
There is no way to
linearly separate these.

833
00:54:28,170 --> 00:54:34,580
Another example is if we
have this type of separation

834
00:54:34,580 --> 00:54:37,970
between class 1
and class 2, that

835
00:54:37,970 --> 00:54:41,570
shows the distance from the
origin being between 1 and 2

836
00:54:41,570 --> 00:54:44,580
as class 1, and then
everything else as class 2.

837
00:54:44,580 --> 00:54:47,100
Similarly, if there
are three modes,

838
00:54:47,100 --> 00:54:50,760
three areas in the space
that are one class, and then

839
00:54:50,760 --> 00:54:52,260
the second class
is everything else.

840
00:54:52,260 --> 00:54:54,620
So in all of these cases,
it's actually very hard

841
00:54:54,620 --> 00:54:57,770
to do the separation.

842
00:54:57,770 --> 00:55:04,260
So what we should do--

843
00:55:04,260 --> 00:55:06,380
so we talked about
linear classifiers

844
00:55:06,380 --> 00:55:12,200
and how they can actually map
the input images into any form

845
00:55:12,200 --> 00:55:14,580
of labels in the output.

846
00:55:14,580 --> 00:55:20,480
But now what remains is how
to choose the value w, that

847
00:55:20,480 --> 00:55:22,690
for each of these
images maps the image

848
00:55:22,690 --> 00:55:27,130
into a score for each
single class as the output.

849
00:55:27,130 --> 00:55:31,970
And in order to do that, we
need to define a loss function,

850
00:55:31,970 --> 00:55:34,330
sometimes referred to
as objective function,

851
00:55:34,330 --> 00:55:38,960
that quantifies how
bad the classifier,

852
00:55:38,960 --> 00:55:42,140
how bad the model is working.

853
00:55:42,140 --> 00:55:45,940
So the level of
unhappiness with respect

854
00:55:45,940 --> 00:55:49,210
to the score on
the training data.

855
00:55:49,210 --> 00:55:54,700
After defining those, we need to
find a way to efficiently change

856
00:55:54,700 --> 00:56:01,730
the values of w to be able
to minimize that unhappiness,

857
00:56:01,730 --> 00:56:05,180
basically, minimize
the loss function.

858
00:56:05,180 --> 00:56:09,260
And this is the
optimization process.

859
00:56:09,260 --> 00:56:12,620
So the topic of next
class, next lecture.

860
00:56:12,620 --> 00:56:18,610
And in order to do that,
again for simplicity

861
00:56:18,610 --> 00:56:23,160
let's look at an easier
and easier example, having

862
00:56:23,160 --> 00:56:27,520
these three classes a linear
function, as you can see here,

863
00:56:27,520 --> 00:56:35,430
and the three classes
of cat, car, and frog.

864
00:56:35,430 --> 00:56:37,590
We need a loss
function that tells how

865
00:56:37,590 --> 00:56:40,270
good our current classifier is.

866
00:56:40,270 --> 00:56:45,210
And in order to do that, we need
to parameterize the problem, xi

867
00:56:45,210 --> 00:56:50,580
and yi defining the input
image, label images,

868
00:56:50,580 --> 00:56:52,900
and the corresponding labels.

869
00:56:52,900 --> 00:56:56,340
And then we need the loss
function and distance

870
00:56:56,340 --> 00:56:59,550
function that maps--

871
00:56:59,550 --> 00:57:05,190
looks at the differences and
how bad the scores are compared

872
00:57:05,190 --> 00:57:10,170
to the ones that are predicted,
the predicted scores fx and w,

873
00:57:10,170 --> 00:57:13,950
and the ground truth values, the
values that are already given,

874
00:57:13,950 --> 00:57:15,760
yi.

875
00:57:15,760 --> 00:57:19,300
We often normalize them based on
the number of samples as well,

876
00:57:19,300 --> 00:57:20,830
but it's not that important.

877
00:57:20,830 --> 00:57:23,160
So this defines
the loss function,

878
00:57:23,160 --> 00:57:26,460
the objective function.

879
00:57:26,460 --> 00:57:32,670
So how we can do
the optimization,

880
00:57:32,670 --> 00:57:40,510
and how can we
really find the w's?

881
00:57:40,510 --> 00:57:44,370
There are different ways
of defining this l--

882
00:57:44,370 --> 00:57:44,980
li.

883
00:57:44,980 --> 00:57:50,790
And I want to talk about
softmax classifier right now.

884
00:57:50,790 --> 00:57:57,030
As an example for
that cat, if you

885
00:57:57,030 --> 00:57:59,010
remember the scores
that were given

886
00:57:59,010 --> 00:58:04,710
were 3.2, 5.1, and
a minus 1.7, these

887
00:58:04,710 --> 00:58:10,530
are the scores that are the
output of the function we

888
00:58:10,530 --> 00:58:13,290
discussed, f, xi and w.

889
00:58:13,290 --> 00:58:18,570
And in order to
turn these scores--

890
00:58:18,570 --> 00:58:20,210
because these
scores are unbounded

891
00:58:20,210 --> 00:58:22,730
and the values are
often not very much

892
00:58:22,730 --> 00:58:26,870
controllable because this
is just a linear function.

893
00:58:26,870 --> 00:58:34,740
In order to turn these into some
scoring functions, the best--

894
00:58:34,740 --> 00:58:37,130
the best possible
way is to turn these

895
00:58:37,130 --> 00:58:39,080
into probabilities,
which defines

896
00:58:39,080 --> 00:58:45,050
the probability of the
class being this class

897
00:58:45,050 --> 00:58:49,320
k for each input image xi.

898
00:58:49,320 --> 00:58:53,510
And in order to do
that, we first--

899
00:58:53,510 --> 00:58:58,350
this is the function that we
use, the softmax function.

900
00:58:58,350 --> 00:59:02,900
We first exponentiate
the values of the scores

901
00:59:02,900 --> 00:59:05,580
to create these numbers.

902
00:59:05,580 --> 00:59:08,190
When we use exp
on these numbers,

903
00:59:08,190 --> 00:59:10,110
the numbers will always be--

904
00:59:10,110 --> 00:59:12,550
the outputs will
always be positive.

905
00:59:12,550 --> 00:59:15,370
And we need to make sure that
the probabilities are always

906
00:59:15,370 --> 00:59:16,220
positive.

907
00:59:16,220 --> 00:59:19,660
And after creating these
numbers, what we can do

908
00:59:19,660 --> 00:59:22,150
is just normalize them.

909
00:59:22,150 --> 00:59:24,370
So exponentiate
and then normalize

910
00:59:24,370 --> 00:59:26,690
based on the sum of
all of the samples.

911
00:59:26,690 --> 00:59:32,930
So then we normalize them
based on sum of all samples.

912
00:59:32,930 --> 00:59:37,360
And this creates a
very, very good set

913
00:59:37,360 --> 00:59:41,060
of values that define
a probability function.

914
00:59:41,060 --> 00:59:43,280
So this is a
distribution function.

915
00:59:43,280 --> 00:59:44,510
They sum to 1.

916
00:59:44,510 --> 00:59:48,580
And if I want to
interpret these,

917
00:59:48,580 --> 00:59:56,500
it's very simple to say it's
this set of w's, parameters,

918
00:59:56,500 --> 01:00:02,260
thinks that this image is
a cat with a probability

919
01:00:02,260 --> 01:00:06,224
of 13% or 0.13.

920
01:00:06,224 --> 01:00:11,440
And obviously, this is making
a mistake in this example

921
01:00:11,440 --> 01:00:14,230
because the w is
not a good setting.

922
01:00:14,230 --> 01:00:17,410
We should optimize
it and change it.

923
01:00:17,410 --> 01:00:21,120
So these probabilities
are the counterparts

924
01:00:21,120 --> 01:00:26,190
of these unnormalized log
probabilities, which are often

925
01:00:26,190 --> 01:00:27,850
referred to as logits.

926
01:00:27,850 --> 01:00:33,120
So if you've taken other
machine-learning courses,

927
01:00:33,120 --> 01:00:33,960
or if you--

928
01:00:33,960 --> 01:00:39,280
I'm sure in other fields,
you've used logistic regression,

929
01:00:39,280 --> 01:00:41,560
this is a similar
type of framework.

930
01:00:41,560 --> 01:00:45,660
This is the exact same framework
as logistic regression.

931
01:00:45,660 --> 01:00:49,200
And since we have
multiple classes here,

932
01:00:49,200 --> 01:00:54,540
it's a multinomial
logistic regression.

933
01:00:54,540 --> 01:00:57,553
How do we define the function l?

934
01:00:57,553 --> 01:00:59,220
I told you that there
are different ways

935
01:00:59,220 --> 01:01:01,980
of defining the function l.

936
01:01:01,980 --> 01:01:05,590
We want to define a
loss function that--

937
01:01:05,590 --> 01:01:06,750
what's objective here?

938
01:01:06,750 --> 01:01:13,950
We want to maximize the
probability of the sample

939
01:01:13,950 --> 01:01:15,820
belonging to the correct class.

940
01:01:15,820 --> 01:01:21,810
So we want to maximize
the value of 0.13.

941
01:01:21,810 --> 01:01:28,150
Now we have other larger
values in that set.

942
01:01:28,150 --> 01:01:34,600
So if you want to maximize this,
this is a maximization problem.

943
01:01:34,600 --> 01:01:38,100
In order to turn it--
because all of the objectives

944
01:01:38,100 --> 01:01:42,720
that we define, we try to
build a minimization objective

945
01:01:42,720 --> 01:01:49,170
function, the first step is
just to negate the values.

946
01:01:49,170 --> 01:01:52,020
We negate it so the
maximization problem turns

947
01:01:52,020 --> 01:01:53,860
into a minimization problem.

948
01:01:53,860 --> 01:01:55,980
And then we also take
the log of the value

949
01:01:55,980 --> 01:02:00,130
just to make the numbers a
little bit more manageable.

950
01:02:00,130 --> 01:02:03,570
So negative log
of that value will

951
01:02:03,570 --> 01:02:06,810
define the objective
function, the loss function

952
01:02:06,810 --> 01:02:10,050
for solving this problem.

953
01:02:10,050 --> 01:02:10,740
Very simple.

954
01:02:10,740 --> 01:02:12,440
That's the objective,
or the loss

955
01:02:12,440 --> 01:02:20,540
function for softmax and
for this logistic regression

956
01:02:20,540 --> 01:02:21,270
function.

957
01:02:21,270 --> 01:02:28,490
And if you've taken, as I said,
other classes like CS-229,

958
01:02:28,490 --> 01:02:31,550
it's often referred to as
maximum likelihood estimation

959
01:02:31,550 --> 01:02:32,160
as well.

960
01:02:32,160 --> 01:02:34,040
It's the same algorithm.

961
01:02:34,040 --> 01:02:42,540
So with that in mind, I want to
say that-- so as we discussed,

962
01:02:42,540 --> 01:02:45,140
it's the negative of the
log of that probability

963
01:02:45,140 --> 01:02:49,580
of the correct class, which
defines the objective function

964
01:02:49,580 --> 01:02:50,560
the loss function.

966
01:02:53,690 --> 01:02:56,130
And that's basically
that simple.

967
01:02:56,130 --> 01:02:59,930
But there are other types of
interpreting this framework

968
01:02:59,930 --> 01:03:00,720
as well.

969
01:03:00,720 --> 01:03:08,830
So one way of redefining
this loss function

970
01:03:08,830 --> 01:03:12,560
is saying that we have some
estimated probabilities,

971
01:03:12,560 --> 01:03:15,640
and we also have a probability
function that defines

972
01:03:15,640 --> 01:03:18,200
the correct probabilities.

973
01:03:18,200 --> 01:03:23,080
What we want to do is to match
these two probability functions.

974
01:03:23,080 --> 01:03:29,840
And in order to do that, we want
to minimize the KL divergence,

975
01:03:29,840 --> 01:03:32,210
Kullback-Leibler divergence.

976
01:03:32,210 --> 01:03:36,640
This is a information
theoretic perspective

977
01:03:36,640 --> 01:03:39,140
of looking at this
loss function.

978
01:03:39,140 --> 01:03:43,760
And again, those are
exactly the same.

979
01:03:43,760 --> 01:03:49,360
This KL divergence
in this setting

980
01:03:49,360 --> 01:03:53,290
simplifies into the same
negative log function

981
01:03:53,290 --> 01:03:54,410
that we defined.

982
01:03:54,410 --> 01:04:01,660
And even going further, this
is exactly the cross entropy

983
01:04:01,660 --> 01:04:09,750
function, because if we define
this, use this entropy of p,

984
01:04:09,750 --> 01:04:14,500
which is entropy of
the correct values,

985
01:04:14,500 --> 01:04:19,210
correct probabilities plus
that same KL divergence, again,

986
01:04:19,210 --> 01:04:22,300
this simplifies into the
same negative log function.

987
01:04:22,300 --> 01:04:26,160
And that's because when
we use one hot encoding

988
01:04:26,160 --> 01:04:29,920
setting for the classes,
the entropy is 0.

989
01:04:29,920 --> 01:04:31,920
So that's one of
the reasons that we

990
01:04:31,920 --> 01:04:34,650
call this function cross
entropy or binary cross

991
01:04:34,650 --> 01:04:36,160
entropy function.

992
01:04:36,160 --> 01:04:39,870
In all of deep learning,
you've probably--

993
01:04:39,870 --> 01:04:42,790
if you've used any of the
neural network frameworks,

994
01:04:42,790 --> 01:04:45,240
you've heard about BCE,
Binary Cross Entropy,

995
01:04:45,240 --> 01:04:47,980
or you will be hearing
about it a lot.

996
01:04:47,980 --> 01:04:50,850
So this is the same framework.

997
01:04:50,850 --> 01:04:57,600
We start very simple, but
we got to the similarities

998
01:04:57,600 --> 01:05:00,490
and differences
between each of those.

999
01:05:00,490 --> 01:05:03,810
So the objective--
sorry, the loss function

1000
01:05:03,810 --> 01:05:06,250
was defined as negative
log of this probability,

1001
01:05:06,250 --> 01:05:09,600
and the probability was
defined by the softmax, which

1002
01:05:09,600 --> 01:05:11,650
we talked about.

1003
01:05:11,650 --> 01:05:15,600
And then optimizing for this,
which is the topic of next

1004
01:05:15,600 --> 01:05:19,450
session, will give
us the right w's.

1005
01:05:19,450 --> 01:05:23,790
But before I end, I want to
ask a couple of questions

1006
01:05:23,790 --> 01:05:26,140
with this definition
that you see here.

1007
01:05:26,140 --> 01:05:29,550
What is the mean
and maximum value

1008
01:05:29,550 --> 01:05:33,450
that you can see for
the loss function li?

1009
01:05:33,450 --> 01:05:37,090
Yes, it's 0, which turns
into minus minus infinity.

1010
01:05:37,090 --> 01:05:41,470
But we have a negative negation
there, so it would be infinity.

1011
01:05:41,470 --> 01:05:42,520
That is correct.

1012
01:05:42,520 --> 01:05:44,285
But then we also have to--

1014
01:05:47,430 --> 01:05:52,240
yes, that's definitely--
that's right.

1015
01:05:52,240 --> 01:05:56,740
And let me actually look
at a second question.

1016
01:05:56,740 --> 01:05:59,850
Yes, this one.

1017
01:05:59,850 --> 01:06:05,550
So when we initialize all of
the si, so basically, the w's,

1018
01:06:05,550 --> 01:06:07,990
in the beginning,
it's almost random.

1019
01:06:07,990 --> 01:06:11,730
So the probabilities
of each of the classes

1020
01:06:11,730 --> 01:06:18,030
becomes mostly equal.

1021
01:06:18,030 --> 01:06:22,403
What is the softmax li,
assuming we have c classes?

1023
01:06:30,435 --> 01:06:31,560
And especially if it's c10.

1025
01:06:34,140 --> 01:06:37,780
So because the
probabilities are equal,

1026
01:06:37,780 --> 01:06:40,740
it means that all of the
probabilities are around 1

1027
01:06:40,740 --> 01:06:47,110
over C. And then that will
be defined as log of C.

1028
01:06:47,110 --> 01:06:49,080
And we have 10-- if
we have 10 classes,

1029
01:06:49,080 --> 01:06:54,730
then the log or ln of 10
is 2.3, which is the exp.

1030
01:06:54,730 --> 01:06:57,020
We know about it.