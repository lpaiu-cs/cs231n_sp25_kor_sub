1
00:00:05,183 --> 00:00:07,600
오늘 우리는 CNN을 이용한 이미지 분류에

2
00:00:07,600 --> 00:00:08,760
대해 이야기할 것입니다.

3
00:00:08,760 --> 00:00:11,020
그래서 여러분은 아마, 나는 누구인가 궁금할 것입니다. 저는 새로운
얼굴입니다.

4
00:00:11,020 --> 00:00:12,728
이 수업에서 저를 본 적이 없으실 겁니다.

5
00:00:12,728 --> 00:00:14,800
저는 저스틴이고, 이 수업의 네 번째 미스터리

6
00:00:14,800 --> 00:00:15,392
강사입니다.

7
00:00:15,392 --> 00:00:17,100
제 사진이 웹사이트에

8
00:00:17,100 --> 00:00:19,800
올라갔던 것 같은데, 오늘이 처음입니다.

9
00:00:19,800 --> 00:00:20,960
그리고 저에 대한 간단한 소개입니다.

10
00:00:20,960 --> 00:00:24,880
저는 2012년부터 2018년까지 스탠포드에서 박사 과정을 했고,

11
00:00:24,880 --> 00:00:26,980
[INAUDIBLE]와 함께 딥러닝,

12
00:00:26,980 --> 00:00:29,780
컴퓨터 비전, 그 시기에 컴퓨터 비전의 거의

13
00:00:29,780 --> 00:00:31,160
모든 작업을 연구했습니다.

14
00:00:31,160 --> 00:00:32,880
스탠포드에서의 시간 동안,

15
00:00:32,880 --> 00:00:36,800
저는 앙드레, [INAUDIBLE] 및 다른 사람들과

16
00:00:36,800 --> 00:00:40,360
함께 CS231N을 시작하고 가르칠 수 있는 행운이

17
00:00:40,360 --> 00:00:46,000
있었습니다. 2015년, '16, '17, '18, '19년에 여러 번
가르쳤습니다.

18
00:00:46,000 --> 00:00:49,400
그 후 스탠포드에서 페이스북 AI 연구소에서

19
00:00:49,400 --> 00:00:52,520
다양한 딥러닝 컴퓨터 비전 작업을 했습니다.

20
00:00:52,520 --> 00:00:55,760
그리고 미시간 대학교의 교수였습니다.

21
00:00:55,760 --> 00:00:58,702
거기서 비슷한 수업을 몇 번 더 가르쳤습니다.

22
00:00:58,702 --> 00:01:00,410
그래서 이 수업을 몇 번 가르쳤지만,

23
00:01:00,410 --> 00:01:02,545
여기 온 지 오래되었고, 최근에는

24
00:01:02,545 --> 00:01:04,670
[INAUDIBLE]와 함께 월드랩스라는

25
00:01:04,670 --> 00:01:06,470
스타트업을 하고 있었습니다.

26
00:01:06,470 --> 00:01:09,550
그리고 이것이 저에 대한 간단한 정보입니다.

27
00:01:09,550 --> 00:01:11,990
이제 이 수업의 진행 상황에 대해 이야기해 보겠습니다.

28
00:01:11,990 --> 00:01:14,470
현재 수업은 몇 가지 다른

29
00:01:14,470 --> 00:01:16,830
세그먼트로 나뉘어 있는 흥미로운

30
00:01:16,830 --> 00:01:18,430
지점에 있습니다.

31
00:01:18,430 --> 00:01:20,388
우리는 기본적으로 첫 번째 세그먼트를 마쳤습니다.

32
00:01:20,388 --> 00:01:23,250
첫 번째 세그먼트는 기본적으로 딥러닝 기초에 관한 것입니다.

33
00:01:23,250 --> 00:01:25,950
이것은 정말 멋진 일입니다. 왜냐하면 여러분이 네

34
00:01:25,950 --> 00:01:28,910
번의 강의에서 본 모든 것이 기본적으로 딥러닝의

35
00:01:28,910 --> 00:01:29,810
기초이기 때문입니다.

36
00:01:29,810 --> 00:01:31,910
여러분은 딥러닝 시스템을 구축하는

37
00:01:31,910 --> 00:01:34,830
데 필요한 기본 요소의 전체 파이프라인을 알고

38
00:01:34,830 --> 00:01:35,530
있습니다.

39
00:01:35,530 --> 00:01:38,238
그래서 저는 이 전환점의 시작에서 잠시

40
00:01:38,238 --> 00:01:40,950
물러나서 강의의 첫 부분에서 본 주요 주제를

41
00:01:40,950 --> 00:01:43,790
요약하는 것이 유용하다고 생각했습니다.

42
00:01:43,790 --> 00:01:46,230
첫 번째는 선형 분류기를 이용한 이미지

43
00:01:46,230 --> 00:01:47,830
분류라는 아이디어입니다.

44
00:01:47,830 --> 00:01:49,650
이것은 장난감 문제로, 딥러닝으로

45
00:01:49,650 --> 00:01:51,830
해결할 수 있는 문제의 감각을

46
00:01:51,830 --> 00:01:53,990
제공하기 위한 것이었습니다.

47
00:01:53,990 --> 00:01:55,510
일반적으로 딥러닝 문제를

48
00:01:55,510 --> 00:01:57,110
해결하는 첫 번째 단계는

49
00:01:57,110 --> 00:02:01,130
문제를 정의하는 것입니다. 입력으로는 숫자의 그리드, 텐서 등을

50
00:02:01,130 --> 00:02:02,990
사용하고, 출력으로는 텐서를

51
00:02:02,990 --> 00:02:05,250
생성하며, 이 문제를 텐서의 입력

52
00:02:05,250 --> 00:02:06,890
출력으로 공식화하고자 합니다.

53
00:02:06,890 --> 00:02:09,330
이미지 분류 설정에서는 이미지를 인간이

54
00:02:09,330 --> 00:02:11,170
이해할 수 있는 여러 카테고리로

55
00:02:11,170 --> 00:02:13,510
분류하고자 한다고 말함으로써

56
00:02:13,510 --> 00:02:16,610
이를 수행합니다. 입력은 3차원 텐서로 배열된

57
00:02:16,610 --> 00:02:18,550
픽셀 값의 그리드가 될 것입니다.

58
00:02:18,550 --> 00:02:20,290
출력은 점수로, 각 카테고리에

59
00:02:20,290 --> 00:02:22,410
대해 하나의 점수를 가지며,

60
00:02:22,410 --> 00:02:24,750
미리 정의된 카테고리 집합에 대해

61
00:02:24,750 --> 00:02:26,710
네트워크는 이미지가 속할 가능성이

62
00:02:26,710 --> 00:02:28,570
높은 카테고리에 대해 높은

63
00:02:28,570 --> 00:02:31,212
점수를 예측하고, 이미지가 속할 가능성이

64
00:02:31,212 --> 00:02:33,170
낮은 카테고리에 대해 낮은

65
00:02:33,170 --> 00:02:34,650
점수를 예측해야 합니다.

66
00:02:34,650 --> 00:02:36,290
그런 다음 우리는 문제를

67
00:02:36,290 --> 00:02:41,010
정의할 수 있습니다. 가중치 행렬을 설정하고, 이를 이미지

68
00:02:41,010 --> 00:02:43,955
픽셀에 곱하여 이러한 점수를 예측합니다.

69
00:02:43,955 --> 00:02:46,330
우리는 선형 분류기를 해석할

70
00:02:46,330 --> 00:02:48,205
수 있는 몇 가지

71
00:02:48,205 --> 00:02:50,170
다른 관점을 보았습니다.

72
00:02:50,170 --> 00:02:52,290
이것은 기본적으로 가중치 행렬 w만

73
00:02:52,290 --> 00:02:55,050
있으면 이미지에 대한 점수를 예측할 수 있다는

74
00:02:55,050 --> 00:02:56,337
기능적 형태를 설정합니다.

75
00:02:56,337 --> 00:02:58,920
그렇다면 좋은 가중치 행렬 w를 어떻게

76
00:02:58,920 --> 00:02:59,640
선택할까요?

77
00:02:59,640 --> 00:03:01,703
그에 대한 답은 손실 함수입니다.

78
00:03:01,703 --> 00:03:03,120
손실 함수는 특정 가중치

79
00:03:03,120 --> 00:03:06,880
행렬의 값과 특정 데이터 세트를 주었을 때, 이

80
00:03:06,880 --> 00:03:10,480
가중치 행렬이 이 데이터 세트에서 문제를 해결하는 데

81
00:03:10,480 --> 00:03:12,960
얼마나 잘 맞는지를 알려주는 것입니다.

82
00:03:12,960 --> 00:03:15,680
특히, 우리는 분류 문제에 일반적으로 사용되는

83
00:03:15,680 --> 00:03:18,060
손실 함수의 몇 가지 예를 보았으며,

84
00:03:18,060 --> 00:03:22,040
여기에는 소프트맥스 손실과 아마도 SVM 손실도 포함됩니다.

85
00:03:22,040 --> 00:03:25,000
그리고 이제, 좋아요, 이제 우리는 문제에서

86
00:03:25,000 --> 00:03:26,420
조금 더 나아갔습니다.

87
00:03:26,420 --> 00:03:28,600
우리는 이미지 분류 문제를 설정했습니다.

88
00:03:28,600 --> 00:03:30,520
우리는 선형 분류기를 사용하여 그 문제를

89
00:03:30,520 --> 00:03:31,740
해결할 모델을 가지고 있습니다.

90
00:03:31,740 --> 00:03:34,623
우리는 손실 함수를 사용하여 우리의 솔루션이 좋은지 판단할 수

91
00:03:34,623 --> 00:03:36,040
있는 방법이 있지만, 이제 우리는

92
00:03:36,040 --> 00:03:38,440
실제로 그 공간에서 좋은 솔루션을 찾아야 합니다.

93
00:03:38,440 --> 00:03:40,580
그리고 그게 최적화의 역할입니다.

94
00:03:40,580 --> 00:03:42,800
이제 우리는 이 최적화 경관을

95
00:03:42,800 --> 00:03:45,120
정의하는 것을 생각해 보세요.

96
00:03:45,120 --> 00:03:48,117
x축 또는 수평 평면에는 가중치 행렬의

97
00:03:48,117 --> 00:03:50,700
모든 가능한 설정이 있습니다.

98
00:03:50,700 --> 00:03:52,325
그리고 손실 함수는 기본적으로

99
00:03:52,325 --> 00:03:55,390
이 평면의 높이로, 높은 손실 함수는 나쁘기 때문에

100
00:03:55,390 --> 00:03:56,930
손실이 나쁜 것입니다.

101
00:03:56,930 --> 00:03:58,130
그래서 우리는 낮은 손실을 원합니다.

102
00:03:58,130 --> 00:03:59,670
최적화의 목적은 이 공간을

103
00:03:59,670 --> 00:04:03,490
탐색하고, 이 매니폴드 아래로 미끄러져서 매우 낮은

104
00:04:03,490 --> 00:04:06,210
손실의 바닥에 있는 점을 찾는 것입니다.

105
00:04:06,210 --> 00:04:09,090
그리고 이제 이 공간의 각 점은 가중치 행렬에 해당합니다.

106
00:04:09,090 --> 00:04:10,590
그래서 그 공간을 미끄러지듯

107
00:04:10,590 --> 00:04:13,350
내려가면서 우리는 문제를 해결하고 작업에 대한 좋은 솔루션을

108
00:04:13,350 --> 00:04:15,893
제공하는 좋은 가중치 행렬을 찾게 될 것입니다.

109
00:04:15,893 --> 00:04:17,310
특히, 우리는 딥러닝

110
00:04:17,310 --> 00:04:19,750
파이프라인에서 사용되는 몇 가지 일반적인

111
00:04:19,750 --> 00:04:22,470
최적화 알고리즘인 확률적 경량 하강법, 일반적으로

112
00:04:22,470 --> 00:04:26,070
모멘텀과 함께, RMSProp, Adam을 보았습니다.

113
00:04:26,070 --> 00:04:29,190
그리고 흥미로운 주제는 현재 가장

114
00:04:29,190 --> 00:04:32,670
큰 딥러닝 연구 회의 중 하나가

115
00:04:32,670 --> 00:04:35,390
ICLR, 국제 표현 학습

116
00:04:35,390 --> 00:04:36,990
회의라는 것입니다.

117
00:04:36,990 --> 00:04:40,070
그리고 어제, ICLR 2025에서 Adam

118
00:04:40,070 --> 00:04:42,615
논문에 테스트 오브 타임 상을 수여했습니다.

119
00:04:42,615 --> 00:04:43,990
이 Adam

120
00:04:43,990 --> 00:04:45,790
최적기를 소개한 논문이 10년

121
00:04:45,790 --> 00:04:48,830
전인 2015년에 ICLR에서 발표되었습니다.

122
00:04:48,830 --> 00:04:50,390
그래서 많은 학술 회의에서는

123
00:04:50,390 --> 00:04:52,070
10년 전의 가장 영향력

124
00:04:52,070 --> 00:04:55,420
있는 논문에 테스트 오브 타임 상을 수여하는 경향이 있습니다.

125
00:04:55,420 --> 00:04:57,003
그리고 어제, 여러분이

126
00:04:57,003 --> 00:04:59,170
배우고 있는 Adam 최적기가 ICLR

127
00:04:59,170 --> 00:05:01,740
2025에서 매우 권위 있는 테스트

128
00:05:01,740 --> 00:05:03,300
오브 타임 상을 받았습니다.

129
00:05:03,300 --> 00:05:05,320
그래서 저는 여러분이 배우고 있는

130
00:05:05,320 --> 00:05:06,820
것과 현재 머신러닝

131
00:05:06,820 --> 00:05:09,153
커뮤니티에서 일어나고 있는 일을 연결하는

132
00:05:09,153 --> 00:05:10,940
멋진 방법이라고 생각했습니다.

133
00:05:10,940 --> 00:05:13,860
그래서 이제 우리는 기본적으로-- 이 시점에서

134
00:05:13,860 --> 00:05:15,912
선형 분류기와 손실 함수를

135
00:05:15,912 --> 00:05:17,120
가지고 있습니다.

136
00:05:17,120 --> 00:05:18,320
우리는 그것들을 최적화할 수 있습니다.

137
00:05:18,320 --> 00:05:19,940
이제 거의 준비가 되었습니다.

138
00:05:19,940 --> 00:05:22,780
하지만 우리가 직면한 문제는 우리가 시작한

139
00:05:22,780 --> 00:05:25,900
선형 분류기가 실제로 그리 강력하지 않다는 것입니다.

140
00:05:25,900 --> 00:05:28,620
우리는 선형 분류기의 이러한

141
00:05:28,620 --> 00:05:32,360
결함을 해결하는 두 가지 방법을 보았습니다.

142
00:05:32,360 --> 00:05:33,980
하나는 시각적 관점에서,

143
00:05:33,980 --> 00:05:36,780
선형 분류기를 해석할 수 있는 방법으로,

144
00:05:36,780 --> 00:05:38,530
학습한 가중치 행렬을

145
00:05:38,530 --> 00:05:40,380
이미지로 생각하고, 분류하려는

146
00:05:40,380 --> 00:05:42,020
각 카테고리에 대해

147
00:05:42,020 --> 00:05:43,478
하나의 이미지 템플릿을

148
00:05:43,478 --> 00:05:44,902
학습하는 것입니다.

149
00:05:44,902 --> 00:05:46,360
그렇게 생각해보면, 선형

150
00:05:46,360 --> 00:05:49,080
분류기의 가중치, 즉 그 가중치 행렬의 각

151
00:05:49,080 --> 00:05:51,780
행은 하나의 템플릿이라는 것을 깨닫게 됩니다.

152
00:05:51,780 --> 00:05:53,240
선형 분류기는 기본적으로

153
00:05:53,240 --> 00:05:56,040
각 범주에 대한 모든 지식을 하나의 템플릿으로

154
00:05:56,040 --> 00:05:57,420
요약해야 합니다.

155
00:05:57,420 --> 00:05:59,400
그리고 그것은 어렵고, 그다지

156
00:05:59,400 --> 00:06:01,440
강력한 분류기가 아닙니다.

157
00:06:01,440 --> 00:06:04,640
그래서 이것은 학습된 선형 분류기의 시각화된

158
00:06:04,640 --> 00:06:06,360
템플릿에서 나타나며, 자동차와

159
00:06:06,360 --> 00:06:09,720
같은 범주에 대해 이 자동차가 빨간 덩어리처럼

160
00:06:09,720 --> 00:06:11,780
보인다는 것을 알 수 있습니다.

161
00:06:11,780 --> 00:06:13,580
하지만 자동차는 꼭 빨간색일 필요는 없죠?

162
00:06:13,580 --> 00:06:16,040
당신의 자동차가 파란색, 보라색, 초록색 또는 다른 색일 수도 있다면

163
00:06:16,040 --> 00:06:16,580
어떻게 될까요?

164
00:06:16,580 --> 00:06:18,580
선형 분류기가 이러한 개념, 즉

165
00:06:18,580 --> 00:06:19,480
각 범주에

166
00:06:19,480 --> 00:06:22,520
대해 객체의 다양한 외관이 있을 수 있다는 것을

167
00:06:22,520 --> 00:06:26,300
캡처할 수 있는 좋은 방법이 없습니다. 또는 기하학적

168
00:06:26,300 --> 00:06:29,200
관점에서, 데이터 세트의 각 점을 고차원 공간의

169
00:06:29,200 --> 00:06:31,143
어떤 점으로 상상한다면,

170
00:06:31,143 --> 00:06:33,560
선형 분류기는 기본적으로 하이퍼플레인으로

171
00:06:33,560 --> 00:06:35,560
그 공간을 나누는 것입니다.

172
00:06:35,560 --> 00:06:38,200
모든 범주가 실제로 선형 분리 가능한 영역에

173
00:06:38,200 --> 00:06:40,860
존재한다면 이는 매우 좋지만, 일반적으로

174
00:06:40,860 --> 00:06:43,520
그것이 사실일 것이라고 기대할 이유는 없습니다.

175
00:06:43,520 --> 00:06:45,160
이것들은 이미지 분류

176
00:06:45,160 --> 00:06:48,080
문제에 적용된 선형 분류기를 살펴볼 때

177
00:06:48,080 --> 00:06:51,030
우리가 직면한 두 가지 큰 결함입니다.

178
00:06:51,030 --> 00:06:52,622
이것은 우리가 신경망의

179
00:06:52,622 --> 00:06:54,830
개념을 정의하게 했고, 여기서

180
00:06:54,830 --> 00:06:57,750
우리는 선형 분류기를 일반화하여 하나의 가중치

181
00:06:57,750 --> 00:07:00,310
행렬만 갖는 것이 아니라 두 개의

182
00:07:00,310 --> 00:07:03,310
가중치 행렬을 쌓고 그 사이에 비선형성을

183
00:07:03,310 --> 00:07:04,310
추가하게 됩니다.

184
00:07:04,310 --> 00:07:07,030
이제 이것은 입력으로부터 점수를

185
00:07:07,030 --> 00:07:10,230
예측하는 훨씬 더 강력한 메커니즘을 제공합니다.

186
00:07:10,230 --> 00:07:12,130
기본적으로 문제는 여전히 동일합니다.

187
00:07:12,130 --> 00:07:15,270
입력 픽셀이 이 계산을 거쳐 점수를

188
00:07:15,270 --> 00:07:16,410
출력합니다.

189
00:07:16,410 --> 00:07:18,993
하지만 이제는 기본적으로 점수 함수에

190
00:07:18,993 --> 00:07:22,030
대해 다른 함수 형태를 선택했습니다.

191
00:07:22,030 --> 00:07:23,110
이것은 우리에게--

192
00:07:23,110 --> 00:07:25,330
이제 대수는 꽤 간단합니다.

193
00:07:25,330 --> 00:07:27,550
f는 wx와 같다는 것에서 시작합니다.

194
00:07:27,550 --> 00:07:30,650
여기에 추가적인 w2를 더하고 그 사이에 약간의 비선형성을 추가합니다.

195
00:07:30,650 --> 00:07:32,330
그래서 대수는 크게 변하지 않습니다.

196
00:07:32,330 --> 00:07:33,950
하지만 그렇게 함으로써,

197
00:07:33,950 --> 00:07:37,030
분류기는 이전보다 훨씬 더 강력해집니다.

198
00:07:37,030 --> 00:07:39,430
하지만 이제 다시 복잡해지는 부분이 있습니다.

199
00:07:39,430 --> 00:07:42,010
이것이 최적화와 어떻게 연결되는지입니다.

200
00:07:42,010 --> 00:07:43,810
우리는 손실 함수가 있고 모델이

201
00:07:43,810 --> 00:07:45,790
있다면, 손실을 줄이는 가중치

202
00:07:45,790 --> 00:07:48,840
행렬의 값을 찾고 싶다는 것을 알고 있습니다.

203
00:07:48,840 --> 00:07:50,835
이를 위해 우리는 기울기를 계산해야 합니다.

204
00:07:50,835 --> 00:07:52,460
모델의 모든 매개변수에 대한

205
00:07:52,460 --> 00:07:55,200
손실의 기울기를 계산할 수 있어야 합니다.

206
00:07:55,200 --> 00:07:57,460
이것이 바로 계산 그래프의 개념입니다.

207
00:07:57,460 --> 00:08:00,260
계산 그래프는 신경망의 계산을

208
00:08:00,260 --> 00:08:03,100
조직하기 위한 데이터 구조로,

209
00:08:03,100 --> 00:08:04,580
그래프의 각 노드는

210
00:08:04,580 --> 00:08:07,460
행렬 곱셈이나 ReLU와 같은

211
00:08:07,460 --> 00:08:09,340
작은 기능 원시입니다.

212
00:08:09,340 --> 00:08:11,740
그리고 데이터는 그래프에서 왼쪽에서

213
00:08:11,740 --> 00:08:13,620
오른쪽으로 흐르며, 왼쪽의

214
00:08:13,620 --> 00:08:15,258
입력과 가중치를 통해

215
00:08:15,258 --> 00:08:17,300
그래프의 모든 중간 노드를 거쳐

216
00:08:17,300 --> 00:08:19,700
오른쪽의 손실 함수를 출력합니다.

217
00:08:19,700 --> 00:08:21,320
손실을 계산한 후에는

218
00:08:21,320 --> 00:08:24,260
이 손실 그래프를 오른쪽에서

219
00:08:24,260 --> 00:08:26,860
왼쪽으로 거슬러 올라가면서

220
00:08:26,860 --> 00:08:31,540
그래프의 모든 노드에 대한 손실의 기울기를 계산합니다.

221
00:08:31,540 --> 00:08:33,620
이제 이것은 정말 멋집니다.

222
00:08:33,620 --> 00:08:36,500
왜냐하면 우리는 입력으로부터 출력을

223
00:08:36,500 --> 00:08:38,140
계산하기 위한 임의로

224
00:08:38,140 --> 00:08:40,260
복잡한 신경망과 표현을

225
00:08:40,260 --> 00:08:42,200
작성할 수 있기 때문입니다.

226
00:08:42,200 --> 00:08:45,300
하지만 우리는 이제 임의로 복잡한 신경망을 통해

227
00:08:45,300 --> 00:08:48,050
원하는 기울기를 계산하기 위한 거의 자동화된

228
00:08:48,050 --> 00:08:49,970
알고리즘을 갖게 되었습니다.

229
00:08:49,970 --> 00:08:52,970
우리가 그렇게 하는 방법은 역전파의 마법입니다.

230
00:08:52,970 --> 00:08:54,745
역전파는 정말 멋집니다.

231
00:08:54,745 --> 00:08:56,370
저는 이것이 딥러닝을

232
00:08:56,370 --> 00:08:59,250
작동하게 만드는 알고리즘 중 하나라고

233
00:08:59,250 --> 00:09:02,370
생각합니다. 왜냐하면 이것은 손실을

234
00:09:02,370 --> 00:09:04,610
계산하는 전역 문제를 지역 문제로

235
00:09:04,610 --> 00:09:06,510
변환하기 때문입니다.

236
00:09:06,510 --> 00:09:08,250
이제 각 노드는 자신이

237
00:09:08,250 --> 00:09:11,050
속한 그래프의 더 큰 맥락이나 해결하려는

238
00:09:11,050 --> 00:09:13,210
문제에 대해 아무것도 알

239
00:09:13,210 --> 00:09:14,410
필요가 없습니다.

240
00:09:14,410 --> 00:09:16,970
우리는 단지 입력으로부터 출력을 계산하는

241
00:09:16,970 --> 00:09:20,490
방법을 아는 계산 그래프 내의 작은 노드를 정의할

242
00:09:20,490 --> 00:09:23,070
수 있어야 하고, 그 다음 역방향

243
00:09:23,070 --> 00:09:26,010
패스에서는 위쪽에서 오는 기울기를 받을 수 있어야

244
00:09:26,010 --> 00:09:26,630
합니다.

245
00:09:26,630 --> 00:09:28,990
그 기울기가 어디서 오는지, 무엇이 그

246
00:09:28,990 --> 00:09:32,070
기울기를 발생시켰는지 신경 쓸 필요가 없습니다.

247
00:09:32,070 --> 00:09:34,890
저는 단지 제 입력에 대한 하류 기울기를

248
00:09:34,890 --> 00:09:38,010
계산해야 합니다, 주어진 상류 기울기를 가지고.

249
00:09:38,010 --> 00:09:40,530
다시 말해, 이것은 매우 강력합니다.

250
00:09:40,530 --> 00:09:42,530
왜냐하면 이제 우리는 출력

251
00:09:42,530 --> 00:09:45,310
계산, 지역 기울기 계산의 이 지역 API를

252
00:09:45,310 --> 00:09:49,130
따르는 다양한 유형의 노드를 정의할 수 있는 메커니즘을

253
00:09:49,130 --> 00:09:50,610
제공하기 때문입니다.

254
00:09:50,610 --> 00:09:53,522
모든 노드에 대해 이 API를 따르기만 하면,

255
00:09:53,522 --> 00:09:55,230
우리는 기본적으로 임의의

256
00:09:55,230 --> 00:09:57,910
계산을 수행할 수 있는 크고 복잡한 계산

257
00:09:57,910 --> 00:10:00,250
그래프를 함께 연결할 수 있습니다.

258
00:10:00,250 --> 00:10:01,750
그리고 기울기는 역전파

259
00:10:01,750 --> 00:10:05,590
알고리즘의 크랭크를 돌릴 때 무료로 제공됩니다.

260
00:10:05,590 --> 00:10:08,790
여러분이 지난번에 본 이 슬라이드는

261
00:10:08,790 --> 00:10:12,130
기본적으로 스칼라 값에 대한 역전파입니다.

262
00:10:12,130 --> 00:10:14,550
하지만 우리는 이것을 벡터 값,

263
00:10:14,550 --> 00:10:18,590
행렬 값 또는 텐서 값에서도 작동하도록 일반화할 수 있습니다.

264
00:10:18,590 --> 00:10:20,270
기본적으로 기억해야

265
00:10:20,270 --> 00:10:22,690
할 것은 입력이 텐서이고 출력도

266
00:10:22,690 --> 00:10:24,450
텐서라는 것입니다.

267
00:10:24,450 --> 00:10:27,070
이제 당신이 얻는 상류 그래디언트는

268
00:10:27,070 --> 00:10:30,030
출력에 대한 손실의 그래디언트입니다.

269
00:10:30,030 --> 00:10:32,610
이는 항상 출력과 같은 형태를 가집니다.

270
00:10:32,610 --> 00:10:35,110
손실이 스칼라이기 때문에,

271
00:10:35,110 --> 00:10:37,910
텐서의 각 요소를 조금

272
00:10:37,910 --> 00:10:39,630
흔들면 손실이

273
00:10:39,630 --> 00:10:42,130
얼마나 흔들리는지를

274
00:10:42,130 --> 00:10:42,900
나타냅니다.

275
00:10:42,900 --> 00:10:44,623
손실이 스칼라이기

276
00:10:44,623 --> 00:10:46,540
때문에, 우리는 각 요소를

277
00:10:46,540 --> 00:10:49,060
독립적으로 흔드는 것을

278
00:10:49,060 --> 00:10:50,140
상상하면 됩니다.

279
00:10:50,140 --> 00:10:52,098
이것이 우리의 그래디언트 정의입니다.

280
00:10:52,098 --> 00:10:53,640
그래서 이것은 기억하기 매우 쉽습니다.

281
00:10:53,640 --> 00:10:56,020
상류 그래디언트는 항상 출력과 정확히 같은

282
00:10:56,020 --> 00:10:56,955
형태를 가집니다.

283
00:10:56,955 --> 00:10:59,580
하류 그래디언트는 입력에 대한

284
00:10:59,580 --> 00:11:00,760
그래디언트입니다.

285
00:11:00,760 --> 00:11:03,700
이것도 입력과 같은 형태를 가집니다.

286
00:11:03,700 --> 00:11:05,500
그래서 역전파 알고리즘은

287
00:11:05,500 --> 00:11:07,940
기본적으로 체인 룰이며,

288
00:11:07,940 --> 00:11:10,460
상류 그래디언트를

289
00:11:10,460 --> 00:11:12,260
기반으로 하여 하류

290
00:11:12,260 --> 00:11:14,620
그래디언트를 계산해야 합니다.

291
00:11:14,620 --> 00:11:17,558
나중의 과제에서 신경망의 다양한

292
00:11:17,558 --> 00:11:19,100
연산자에 대한 그래디언트

293
00:11:19,100 --> 00:11:22,980
표현을 작성하는 연습을 하게 될 것입니다.

294
00:11:22,980 --> 00:11:25,380
기본적으로, 이것은 딥러닝의 거의

295
00:11:25,380 --> 00:11:29,113
모든 문제를 해결하기 위한 레시피를 제공합니다.

296
00:11:29,113 --> 00:11:31,780
이는 이미지 분류나 선형 분류기, 완전

297
00:11:31,780 --> 00:11:33,800
연결 네트워크보다 훨씬 더

298
00:11:33,800 --> 00:11:35,440
일반적이도록 의도되었습니다.

299
00:11:35,440 --> 00:11:38,140
이제 해결하고 싶은 문제가 있다면, 그것을

300
00:11:38,140 --> 00:11:40,360
텐서로 인코딩하고, 입력 텐서에서

301
00:11:40,360 --> 00:11:43,250
출력 텐서를 계산하는 계산 그래프를

302
00:11:43,250 --> 00:11:45,770
작성하고, 입력-출력 텐서 데이터 세트를

303
00:11:45,770 --> 00:11:47,850
수집하고, 해결하고자 하는 문제에

304
00:11:47,850 --> 00:11:50,430
대한 손실 함수를 작성하면 됩니다.

305
00:11:50,430 --> 00:11:53,850
그런 다음 역전파를 사용하여 경량 하강법으로 그

306
00:11:53,850 --> 00:11:55,570
손실 함수를 최적화합니다.

307
00:11:55,570 --> 00:11:57,090
그리고 이것은 이미지

308
00:11:57,090 --> 00:11:59,950
분류, 이미지 생성, 대형 언어 모델 등

309
00:11:59,950 --> 00:12:01,850
모든 딥 러닝 애플리케이션을

310
00:12:01,850 --> 00:12:04,970
기본적으로 지원하는 매우 강력한 레시피입니다.

311
00:12:04,970 --> 00:12:07,090
신경망과 관련된 거의 모든

312
00:12:07,090 --> 00:12:10,650
것은 이 공식을 사용하거나 이 공식의 약간의 변형을

313
00:12:10,650 --> 00:12:11,872
사용하여 훈련됩니다.

314
00:12:11,872 --> 00:12:13,330
그래서 이것은 수업의 두

315
00:12:13,330 --> 00:12:15,610
번째 부분으로 이어지며, 시각 세계를 인식하고

316
00:12:15,610 --> 00:12:16,770
이해하는 것입니다.

317
00:12:16,770 --> 00:12:19,490
여기서 우리는 좀 더 전문화된 내용을 다루고, 딥

318
00:12:19,490 --> 00:12:22,072
러닝의 일반적인 프레임워크가 아니라 컴퓨터

319
00:12:22,072 --> 00:12:23,530
비전에서 우리가 해결하고자

320
00:12:23,530 --> 00:12:26,670
하는 문제에 어떻게 적용되는지에 대해 이야기하고자 합니다.

321
00:12:26,670 --> 00:12:29,690
이미지를 처리하고, 이미지로 흥미로운 작업을 수행하는 것입니다.

322
00:12:29,690 --> 00:12:31,490
오늘은 컨볼루션 네트워크에 대해

323
00:12:31,490 --> 00:12:35,130
좀 더 이야기함으로써 그 방향으로 한 걸음 나아가겠습니다.

324
00:12:35,130 --> 00:12:38,650
컨볼루션 네트워크는 우리가 이미 정의한 이

325
00:12:38,650 --> 00:12:41,540
프레임워크 위에 추가되는 작은 변화입니다.

326
00:12:41,540 --> 00:12:43,805
우리는 이미 두 가지에 대해 이야기했습니다.

327
00:12:43,805 --> 00:12:45,680
우리는 계산 그래프 내에

328
00:12:45,680 --> 00:12:47,960
존재할 수 있는 작은 연산자들의

329
00:12:47,960 --> 00:12:50,100
일반적인 패러다임을 가지고 있습니다.

330
00:12:50,100 --> 00:12:51,707
우리는 이 아름다운 프레임워크를 가지고

331
00:12:51,707 --> 00:12:54,040
있지만, 실제로 그 프레임워크의 많은 세부 사항을

332
00:12:54,040 --> 00:12:54,980
채우지 않았습니다.

333
00:12:54,980 --> 00:12:58,000
우리는 계산 그래프 내에 존재할 수 있는

334
00:12:58,000 --> 00:13:00,900
두세 가지 다른 종류의 노드만 보았습니다.

335
00:13:00,900 --> 00:13:02,800
우리는 기본적으로 행렬 곱셈인

336
00:13:02,800 --> 00:13:04,460
완전 연결층을 보았습니다.

337
00:13:04,460 --> 00:13:06,860
우리는 ReLU와 같은 활성화

338
00:13:06,860 --> 00:13:09,280
함수와 손실 함수 자체도 보았습니다.

339
00:13:09,280 --> 00:13:13,480
그리고 이제 우리가 이미 본 것을 바탕으로 컨볼루션

340
00:13:13,480 --> 00:13:15,720
네트워크를 구축하기 위해 필요한

341
00:13:15,720 --> 00:13:19,320
것은 계산 그래프에 맞는 몇 가지 새로운 유형의

342
00:13:19,320 --> 00:13:21,160
노드를 추가하는 것입니다.

343
00:13:21,160 --> 00:13:23,400
특히, 훨씬 더 강력한 네트워크를

344
00:13:23,400 --> 00:13:24,858
구축하기 위해 이야기해야

345
00:13:24,858 --> 00:13:27,400
할 연산자는 실제로 두 가지뿐입니다. 오늘

346
00:13:27,400 --> 00:13:30,225
강의의 대부분을 차지할 컨볼루션 레이어입니다.

347
00:13:30,225 --> 00:13:31,600
그리고 이미지를

348
00:13:31,600 --> 00:13:36,360
처리할 때 자주 사용하는 또 다른 것인 풀링 레이어입니다.

349
00:13:36,360 --> 00:13:38,407
그래서 오늘의 로드맵입니다.

350
00:13:38,407 --> 00:13:40,740
일반적인 컨볼루션 네트워크에 대해 조금 이야기하고

351
00:13:40,740 --> 00:13:41,400
싶습니다.

352
00:13:41,400 --> 00:13:43,900
그 다음, 우리는 컨볼루션 네트워크를

353
00:13:43,900 --> 00:13:47,220
구축하는 데 사용할 수 있는 두 가지 특정

354
00:13:47,220 --> 00:13:50,260
계산 원시 요소에 대해 이야기할 것입니다.

355
00:13:50,260 --> 00:13:52,140
그래서 우리는 이미 이야기한 바와

356
00:13:52,140 --> 00:13:53,515
같이, 여기서 우리는 이미지

357
00:13:53,515 --> 00:13:56,005
분류 문제를 다시 한 번 생각해 보려 합니다.

358
00:13:56,005 --> 00:13:58,380
이미지 분류는 컴퓨터 비전에서

359
00:13:58,380 --> 00:14:00,660
가장 핵심적인 문제로, 입력

360
00:14:00,660 --> 00:14:03,820
이미지를 받아 그 이미지에 어떤 카테고리가 있는지를

361
00:14:03,820 --> 00:14:07,020
예측하는 것입니다. 기본적으로 k개의

362
00:14:07,020 --> 00:14:09,660
카테고리 레이블 중 하나를 예측합니다.

363
00:14:09,660 --> 00:14:11,080
그리고 이 이미지는 분명 고양이입니다.

364
00:14:11,080 --> 00:14:13,620
그래서 우리는 고양이 분류기를 예측하고자 합니다.

365
00:14:13,620 --> 00:14:16,220
우리는 기본적으로 선형 분류기를

366
00:14:16,220 --> 00:14:18,740
구축하고 완전 연결 다층 퍼셉트론

367
00:14:18,740 --> 00:14:21,780
신경망을 구축함으로써 이 문제를 어느 정도

368
00:14:21,780 --> 00:14:22,740
해결했습니다.

369
00:14:22,740 --> 00:14:26,580
하지만 이 네트워크는 기본적으로 픽셀 공간에서 작동합니다.

370
00:14:26,580 --> 00:14:29,500
입력은, 우리가 깊은 학습 문제를 해결하는 첫

371
00:14:29,500 --> 00:14:31,820
번째 단계는 입력-출력 텐서의 관점에서

372
00:14:31,820 --> 00:14:34,560
문제를 공식화하는 것이라고 말했음을 기억하세요.

373
00:14:34,560 --> 00:14:36,610
이 경우, 우리의 입력

374
00:14:36,610 --> 00:14:39,650
텐서는 이미지의 원시 픽셀 값이었습니다.

375
00:14:39,650 --> 00:14:42,710
그래서 f(x) = wx라고 쓸 때, 그

376
00:14:42,710 --> 00:14:46,170
x 입력은 모든 픽셀의 문자 그대로의 값입니다.

377
00:14:46,170 --> 00:14:47,930
그리고 우리는 그 원시 픽셀

378
00:14:47,930 --> 00:14:49,730
값에서 클래스 점수로 이동합니다.

379
00:14:49,730 --> 00:14:52,170
하지만 다른 방법도 있었는데,

380
00:14:52,170 --> 00:14:54,930
이는 신경망이 등장하기 전의 어두운

381
00:14:54,930 --> 00:14:56,850
시절에 일반적이었습니다.

382
00:14:56,850 --> 00:15:01,090
2000년대 초반부터 2010년, 2011년까지는

383
00:15:01,090 --> 00:15:03,330
특징 표현의 개념이 있었습니다.

384
00:15:03,330 --> 00:15:06,130
여기서 아이디어는 신경망에 대한 입력을

385
00:15:06,130 --> 00:15:08,790
실제로 선택할 수 있다는 것입니다.

386
00:15:08,790 --> 00:15:12,130
그래서 우리는 이미지의 원시 픽셀

387
00:15:12,130 --> 00:15:15,350
값을 신경망에 공급하는 대신, 특징을

388
00:15:15,350 --> 00:15:18,170
추출하는 다른 종류의 함수를

389
00:15:18,170 --> 00:15:20,930
정의할 수 있었습니다. 이

390
00:15:20,930 --> 00:15:23,610
함수는 이미지의 픽셀 값을 우리가

391
00:15:23,610 --> 00:15:26,930
이 시스템의 지능적인 인간 설계자로서

392
00:15:26,930 --> 00:15:28,990
중요하다고 생각하는

393
00:15:28,990 --> 00:15:32,610
다른 의미 있는 표현으로 변환합니다.

394
00:15:32,610 --> 00:15:36,000
그래서 만약 특징 표현 위에서 이미지

395
00:15:36,000 --> 00:15:38,440
분류를 하고 있다면, 첫 번째

396
00:15:38,440 --> 00:15:40,800
단계는 원시 이미지 픽셀을

397
00:15:40,800 --> 00:15:45,160
이 고차원 표현으로 변환하는 특징 표현을 정의하는

398
00:15:45,160 --> 00:15:46,220
것입니다.

399
00:15:46,220 --> 00:15:47,800
그리고 이제 그

400
00:15:47,800 --> 00:15:50,200
특징 표현은 선형 분류기에

401
00:15:50,200 --> 00:15:52,560
공급되는 x가 될 것입니다.

402
00:15:52,560 --> 00:15:55,440
2000년대부터 2010년대

403
00:15:55,440 --> 00:16:00,080
후반 또는 2010년대 초반까지 컴퓨터 비전에서 이

404
00:16:00,080 --> 00:16:03,880
특징 표현의 아이디어를 사용한 작업이

405
00:16:03,880 --> 00:16:04,920
많았습니다.

406
00:16:04,920 --> 00:16:06,960
이 특정 특징 표현에 대해 너무

407
00:16:06,960 --> 00:16:09,560
자세히 들어가는 것은 유용하지 않다고 생각합니다.

408
00:16:09,560 --> 00:16:11,780
왜냐하면 스포일러 알림, 이들은

409
00:16:11,780 --> 00:16:14,240
10년 전에 구식이 되었기 때문입니다.

410
00:16:14,240 --> 00:16:16,480
하지만 그들이 어떻게 생겼는지에 대한

411
00:16:16,480 --> 00:16:18,160
감을 가지는 것은 유용합니다.

412
00:16:18,160 --> 00:16:20,600
사람들이 가끔 사용했던 특징

413
00:16:20,600 --> 00:16:22,800
표현의 한 예는 색상

414
00:16:22,800 --> 00:16:24,200
히스토그램의 개념입니다.

415
00:16:24,200 --> 00:16:26,900
여기서 우리가 할 수 있는 것은 공간을 나누는 것입니다.

416
00:16:26,900 --> 00:16:29,800
어쩌면 우리는 이미지의 색상 분포가 분류기가

417
00:16:29,800 --> 00:16:32,710
살펴보거나 신경 써야 할 유용한 것일 수 있다고

418
00:16:32,710 --> 00:16:34,270
생각할 수 있습니다.

419
00:16:34,270 --> 00:16:36,270
왜냐하면 당신이 과일 탐지기, 사과 탐지기를 만들고

420
00:16:36,270 --> 00:16:38,770
있고, 그것이 익었는지 아닌지를 알고 싶어하기 때문입니다.

421
00:16:38,770 --> 00:16:40,450
빨간 사과와 초록 사과를 구분하는

422
00:16:40,450 --> 00:16:43,310
것, 이미지에 얼마나 많은 빨간색이나 초록색이 있는지를

423
00:16:43,310 --> 00:16:45,590
아는 것은 우리가 인간으로서 네트워크가

424
00:16:45,590 --> 00:16:48,215
분류를 하는 데 유용하다고 생각할 수 있는 것입니다.

425
00:16:48,215 --> 00:16:49,590
그래서 우리는 그 직관을

426
00:16:49,590 --> 00:16:51,390
포착하는 특징 표현을 구축하려고

427
00:16:51,390 --> 00:16:52,710
할 수 있습니다.

428
00:16:52,710 --> 00:16:54,470
여기서 우리가 할 수 있는 것은 가능한

429
00:16:54,470 --> 00:16:56,990
모든 색상의 공간을 가져와서 그 공간을 몇 개의

430
00:16:56,990 --> 00:16:58,490
버킷으로 이산화하는 것입니다.

431
00:16:58,490 --> 00:17:00,288
그리고 이제 이미지의 모든 픽셀에

432
00:17:00,288 --> 00:17:02,830
대해 그 픽셀을 색상 공간의 이산 버킷 중 하나에

433
00:17:02,830 --> 00:17:03,442
매핑합니다.

434
00:17:03,442 --> 00:17:06,109
그리고 기본적으로 우리의 특징 표현은

435
00:17:06,109 --> 00:17:08,910
이미지에서 이 색상 버킷에 해당하는 픽셀 수의

436
00:17:08,910 --> 00:17:10,550
카운트와 같은 것이 됩니다.

437
00:17:10,550 --> 00:17:13,829
이제 이것은 흥미로운 표현입니다. 왜냐하면 이미지의

438
00:17:13,829 --> 00:17:16,569
모든 공간 구조를 파괴하기 때문입니다.

439
00:17:16,569 --> 00:17:18,569
그리고 색상 분포에 대해서만 이야기합니다.

440
00:17:18,569 --> 00:17:20,990
그래서 이제 코너에 빨간색이 있든

441
00:17:20,990 --> 00:17:22,990
반대편에 빨간색이 있든, 이 색상

442
00:17:22,990 --> 00:17:25,547
히스토그램 특징에 따르면 두 이미지는

443
00:17:25,547 --> 00:17:27,589
동일하게 보이지만, 원시 픽셀

444
00:17:27,589 --> 00:17:29,910
관점에서는 매우 다르게 보일 것입니다.

445
00:17:29,910 --> 00:17:32,650
따라서 색상 히스토그램은 이미지에서

446
00:17:32,650 --> 00:17:34,960
색상만을 보고 공간 구조는

447
00:17:34,960 --> 00:17:37,210
전혀 보지 않는 기본적인

448
00:17:37,210 --> 00:17:40,130
특징 추출기 또는 특징 표현입니다.

449
00:17:40,130 --> 00:17:43,370
사람들이 사용했던 또 다른

450
00:17:43,370 --> 00:17:47,890
특징 표현 범주는 방향 기울기의

451
00:17:47,890 --> 00:17:49,790
히스토그램입니다.

452
00:17:49,790 --> 00:17:52,290
이들이 어떻게 계산되는지에 대해 너무 많이 이야기하는 것은

453
00:17:52,290 --> 00:17:53,470
유용하지 않다고 생각합니다.

454
00:17:53,470 --> 00:17:55,610
이들의 직관은 색상 정보를

455
00:17:55,610 --> 00:17:58,010
버리고 구조 정보만을 본다는

456
00:17:58,010 --> 00:17:58,910
것입니다.

457
00:17:58,910 --> 00:18:01,290
이미지의 각 지점에서 주변

458
00:18:01,290 --> 00:18:04,130
지역의 가장자리의 국소 방향이

459
00:18:04,130 --> 00:18:06,790
무엇인지 살펴보려는 것입니다.

460
00:18:06,790 --> 00:18:09,590
여기에서 이 개구리의 잎을 보면 대각선

461
00:18:09,590 --> 00:18:12,530
유형의 특징을 추출하는데, 이는

462
00:18:12,530 --> 00:18:14,610
여기의 대각선 구조와 관련이

463
00:18:14,610 --> 00:18:17,170
있습니다. 개구리의 눈 주위에서는

464
00:18:17,170 --> 00:18:20,590
구형 구조를 포착한 것을 볼 수 있습니다.

465
00:18:20,590 --> 00:18:23,270
다시 말해, 이것이 어떻게 계산되는지를 보는

466
00:18:23,270 --> 00:18:24,687
것은 그다지 유용하지

467
00:18:24,687 --> 00:18:28,250
않지만, 사람들이 10년 또는 15년 전쯤 이미지에

468
00:18:28,250 --> 00:18:31,840
대해 설계한 특징이라는 것을 아는 것은 유용합니다. 사람들은

469
00:18:31,840 --> 00:18:34,140
이를 복잡한 방식으로 결합했습니다.

470
00:18:34,140 --> 00:18:36,820
사람들은 종종 '가장 좋은 특징 표현은

471
00:18:36,820 --> 00:18:38,740
무엇인가?'라고 궁금해할 것입니다.

472
00:18:38,740 --> 00:18:41,060
일반적인 대답은 모든 것을 함께 쌓는 것이었습니다.

473
00:18:41,060 --> 00:18:42,435
상당히 일반적인 접근

474
00:18:42,435 --> 00:18:45,040
방식은 다양한 특징 표현을 가지고, 이를

475
00:18:45,040 --> 00:18:46,540
모두 이미지에서 추출한

476
00:18:46,540 --> 00:18:49,400
다음, 하나의 큰 특징 벡터로 연결하는 것입니다.

477
00:18:49,400 --> 00:18:52,355
그것이 당신의 이미지에 대한 특징 표현이 됩니다.

478
00:18:52,355 --> 00:18:54,480
이제 이 특징 표현이 생기면,

479
00:18:54,480 --> 00:18:57,760
원하는 분류기를 그 위에 붙일 수 있다고

480
00:18:57,760 --> 00:18:59,320
상상할 수 있습니다.

481
00:18:59,320 --> 00:19:03,280
그런 다음 한 걸음 물러서서 전체 시스템의 그

482
00:19:03,280 --> 00:19:07,080
그림, 관점을 대조하는 것이 흥미롭습니다.

483
00:19:07,080 --> 00:19:12,400
시스템 A는 특징 추출기와 학습된 네트워크 또는 학습된

484
00:19:12,400 --> 00:19:14,400
선형 분류기를 특징 위에

485
00:19:14,400 --> 00:19:15,860
두고 있습니다.

486
00:19:15,860 --> 00:19:18,800
그리고 시스템 B는 엔드 투 엔드 신경망입니다.

487
00:19:18,800 --> 00:19:21,640
실제로 이들은 그렇게 다르게 보이지 않습니다.

488
00:19:21,640 --> 00:19:24,480
한 걸음 물러서서 올바른 방식으로 생각해보면,

489
00:19:24,480 --> 00:19:26,510
이 두 시스템 모두

490
00:19:26,510 --> 00:19:28,830
궁극적으로 이미지의 원시 픽셀을

491
00:19:28,830 --> 00:19:32,150
입력하고 이미지에 대한 점수나 예측을 출력합니다.

492
00:19:32,150 --> 00:19:33,990
차이는 인간이 설계한

493
00:19:33,990 --> 00:19:35,670
시스템의 부분과

494
00:19:35,670 --> 00:19:38,190
경량 하강법을 통해 학습된

495
00:19:38,190 --> 00:19:39,830
부분의 차이입니다.

496
00:19:39,830 --> 00:19:42,690
특징 추출과 선형 분류기 패러다임에서 시스템의

497
00:19:42,690 --> 00:19:44,830
특징 추출 부분은 설계됩니다. 이는 복잡한

498
00:19:44,830 --> 00:19:47,190
C 코드나 복잡한 Matlab 코드일

499
00:19:47,190 --> 00:19:49,032
수 있으며, 그 내부에서 무슨

500
00:19:49,032 --> 00:19:50,990
일이 일어나는지에 대한 세부 사항을

501
00:19:50,990 --> 00:19:52,870
생각하고 싶지 않을 것입니다.

502
00:19:52,870 --> 00:19:54,470
그리고 경량 하강법을 통해

503
00:19:54,470 --> 00:19:55,910
학습하는 부분, 즉

504
00:19:55,910 --> 00:19:57,785
훈련 데이터에서 학습하는 부분은

505
00:19:57,785 --> 00:19:59,710
특징 추출기 위의 분류기뿐입니다.

506
00:19:59,710 --> 00:20:03,390
반면 신경망 접근 방식은 경량 하강법이 아마도 당신보다

507
00:20:03,390 --> 00:20:05,150
더 나은 프로그래머라는 것을

508
00:20:05,150 --> 00:20:07,750
말하고 있으며, 많은 데이터가 아마도

509
00:20:07,750 --> 00:20:10,350
당신보다 문제에 대해 더 잘 알고 있습니다.

510
00:20:10,350 --> 00:20:13,775
따라서 이러한 신경망 분류기의 직관은 궁극적으로

511
00:20:13,775 --> 00:20:15,150
원시 픽셀 값을

512
00:20:15,150 --> 00:20:17,030
입력하고 마지막에 분류 점수를

513
00:20:17,030 --> 00:20:19,070
출력하는 시스템이 될 것이라는

514
00:20:19,070 --> 00:20:19,970
것입니다.

515
00:20:19,970 --> 00:20:21,470
하지만 차이는 원시

516
00:20:21,470 --> 00:20:23,310
픽셀에서 최종 분류 점수에 이르기까지

517
00:20:23,310 --> 00:20:25,540
시스템의 모든 부분이 경량

518
00:20:25,540 --> 00:20:27,420
하강법을 통해 조정되고 훈련

519
00:20:27,420 --> 00:20:29,680
데이터 세트에서 학습된다는 것입니다.

520
00:20:29,680 --> 00:20:31,660
따라서 직관은 이 특징 추출

521
00:20:31,660 --> 00:20:33,667
패러다임에서 병목 현상이 있을

522
00:20:33,667 --> 00:20:35,000
수 있다는 것입니다.

523
00:20:35,000 --> 00:20:36,560
당신은 인간으로서 뭔가 잘못될 수 있습니다.

524
00:20:36,560 --> 00:20:39,143
문제의 어떤 부분이 중요한지, 어떤 것이

525
00:20:39,143 --> 00:20:41,120
중요하지 않은지에 대한 잘못된 직관이

526
00:20:41,120 --> 00:20:43,120
있을 수 있으며, 문제를 해결하는

527
00:20:43,120 --> 00:20:45,820
완벽한 특징 추출기를 작성하는 것이 정말 어려울

528
00:20:45,820 --> 00:20:48,240
수 있습니다. ConvNets의 이러한 종단

529
00:20:48,240 --> 00:20:50,040
간 학습 접근 방식, 그리고

530
00:20:50,040 --> 00:20:52,660
일반적으로 딥 러닝은 데이터와 계산이 인간

531
00:20:52,660 --> 00:20:56,020
설계자보다 그 문제를 더 잘 해결할 수 있다고 말하고 있습니다.

532
00:20:56,020 --> 00:20:58,860
이 패러다임은 지난 15년

533
00:20:58,860 --> 00:21:02,260
동안 많은 문제에 대해

534
00:21:02,260 --> 00:21:04,980
반복적으로 승리했습니다.

535
00:21:04,980 --> 00:21:08,620
그래서 이것은 이미지라는 특정 문제에 대해

536
00:21:08,620 --> 00:21:11,900
이러한 종단 간 시스템을 어떻게 설계해야

537
00:21:11,900 --> 00:21:14,302
하는지에 대한 직관을 제공합니다.

538
00:21:14,302 --> 00:21:16,760
완전히 연결된 네트워크가 될 수는 없습니다.

539
00:21:16,760 --> 00:21:18,135
그것은 조금 어리석을 것입니다.

540
00:21:18,135 --> 00:21:21,295
우리는 여전히 시스템에 약간의 설계를 넣어야 합니다.

541
00:21:21,295 --> 00:21:23,420
하지만 신경망을 설계하는 것과

542
00:21:23,420 --> 00:21:25,200
특징 추출기를 설계하는 것의

543
00:21:25,200 --> 00:21:26,828
차이는 신경망을 설계할 때

544
00:21:26,828 --> 00:21:29,120
특정 기능을 설계하는 것이 아니라는

545
00:21:29,120 --> 00:21:29,900
것입니다.

546
00:21:29,900 --> 00:21:32,320
당신은 기능의 전체 범주를 정의하고

547
00:21:32,320 --> 00:21:34,240
있으며, 기능의 범주는

548
00:21:34,240 --> 00:21:36,520
계산 그래프의 구조와 실행되는

549
00:21:36,520 --> 00:21:38,980
연산자의 순서에 의해 정의됩니다.

550
00:21:38,980 --> 00:21:40,560
하지만 그 시스템에는 약간의

551
00:21:40,560 --> 00:21:42,840
유연성이 있습니다. 왜냐하면 시스템의

552
00:21:42,840 --> 00:21:45,160
가중치를 데이터로부터 학습할 수 있도록 자유롭게

553
00:21:45,160 --> 00:21:46,140
두기 때문입니다.

554
00:21:46,140 --> 00:21:48,500
하지만 인간 설계자의 역할은 여전히 중요합니다.

555
00:21:48,500 --> 00:21:51,240
여전히 네트워크의 아키텍처가 무엇인지

556
00:21:51,240 --> 00:21:52,180
결정해야 합니다.

557
00:21:52,180 --> 00:21:54,120
계산 그래프에 연결되는 연산자의

558
00:21:54,120 --> 00:21:55,960
순서가 무엇인지, 처리의

559
00:21:55,960 --> 00:21:57,880
모든 단계에서 관련된 모든

560
00:21:57,880 --> 00:21:59,325
행렬의 크기가 무엇인지.

561
00:21:59,325 --> 00:22:01,200
그래서 이 딥러닝

562
00:22:01,200 --> 00:22:05,440
시대에는 문제의 일부를 설계하는 데 인간의 역할이

563
00:22:05,440 --> 00:22:09,782
여전히 많지만, 당신이 설계하는 것은 약간 다릅니다.

564
00:22:09,782 --> 00:22:11,240
그래서 이것은 우리가 지금까지

565
00:22:11,240 --> 00:22:12,740
이 문제를 해결하기 위해

566
00:22:12,740 --> 00:22:14,980
가진 도구의 결함을 보기 시작하는 지점입니다.

567
00:22:14,980 --> 00:22:17,620
왜냐하면 우리는 선형 레이어를 보았고, 완전

568
00:22:17,620 --> 00:22:19,800
연결 네트워크를 보았기 때문입니다.

569
00:22:19,800 --> 00:22:22,950
우리가 본 유일한 신경망 아키텍처는 이미지의 픽셀을

570
00:22:22,950 --> 00:22:26,330
큰 벡터로 평탄화하고, 행렬 곱셈을 하고, ReLU를 하고,

571
00:22:26,330 --> 00:22:29,570
더 많은 행렬 곱셈을 하고, 더 많은 ReLU를

572
00:22:29,570 --> 00:22:30,337
하는 것입니다.

573
00:22:30,337 --> 00:22:31,170
그게 전부입니다.

574
00:22:31,170 --> 00:22:33,163
현재 우리가 할 수 있는 것은 그것뿐입니다.

575
00:22:33,163 --> 00:22:34,830
그것의 큰 문제는 이미지의

576
00:22:34,830 --> 00:22:37,270
공간 구조를 파괴한다는 것입니다.

577
00:22:37,270 --> 00:22:39,950
이것은 큰 문제입니다.

578
00:22:39,950 --> 00:22:42,810
이미지는 실제로 일차원 객체가 아닙니다.

579
00:22:42,810 --> 00:22:44,010
이미지는 이차원입니다.

580
00:22:44,010 --> 00:22:45,610
그들은 이차원 구조를 가지고 있습니다.

581
00:22:45,610 --> 00:22:47,860
그 이차원 구조는 그 이미지의 내용에

582
00:22:47,860 --> 00:22:48,830
중요합니다.

583
00:22:48,830 --> 00:22:51,670
그리고 원시 픽셀에 대해 선형 분류기를

584
00:22:51,670 --> 00:22:53,530
구축할 때 큰 벡터로

585
00:22:53,530 --> 00:22:56,870
늘리면, 신경망 아키텍처 설계에서 입력 데이터의

586
00:22:56,870 --> 00:22:59,648
중요한 요소를 무시하는 것입니다.

587
00:22:59,648 --> 00:23:02,190
그래서 우리는 특히 이미지에

588
00:23:02,190 --> 00:23:05,590
대한 신경망 아키텍처를 설계할 때, 네트워크의

589
00:23:05,590 --> 00:23:07,590
다른 설계가 무엇인지,

590
00:23:07,590 --> 00:23:09,150
이미지의 이차원

591
00:23:09,150 --> 00:23:12,430
구조를 더 잘 존중하는 계산 원시를

592
00:23:12,430 --> 00:23:15,150
계산 그래프에 어떻게 삽입할 수

593
00:23:15,150 --> 00:23:17,110
있는지 생각하고 싶습니다.

594
00:23:17,110 --> 00:23:19,130
그리고 그것이 우리를 합성곱 네트워크로 이끕니다.

595
00:23:19,130 --> 00:23:21,100
합성곱 네트워크는

596
00:23:21,100 --> 00:23:23,060
기본적으로 선형 레이어,

597
00:23:23,060 --> 00:23:27,180
비선형성, 합성곱 레이어, 풀링

598
00:23:27,180 --> 00:23:29,783
레이어로 구성된 신경망

599
00:23:29,783 --> 00:23:31,700
아키텍처의 범주로,

600
00:23:31,700 --> 00:23:34,020
원시 픽셀 값을 입력받아

601
00:23:34,020 --> 00:23:38,843
이미지에 대한 예측이나 점수를 출력합니다.

602
00:23:38,843 --> 00:23:40,260
이들의 일반적인

603
00:23:40,260 --> 00:23:43,180
구조는 보통 어떤 접두사, 네트워크의

604
00:23:43,180 --> 00:23:45,460
본체가 있으며, 이는 합성곱

605
00:23:45,460 --> 00:23:49,060
레이어, 풀링 레이어 및 비선형성의 교차된 순서로

606
00:23:49,060 --> 00:23:51,740
유용한 특징 표현을 추출하는 것으로

607
00:23:51,740 --> 00:23:53,540
생각할 수 있습니다.

608
00:23:53,540 --> 00:23:55,340
그리고 그 위에

609
00:23:55,340 --> 00:23:59,100
보통 하나 이상의 완전 연결 레이어가

610
00:23:59,100 --> 00:24:00,740
있으며, 이는

611
00:24:00,740 --> 00:24:03,460
합성곱 부분에서 특징을 수집하는

612
00:24:03,460 --> 00:24:06,460
다층 퍼셉트론 완전 연결

613
00:24:06,460 --> 00:24:09,340
네트워크 분류기로 생각할 수

614
00:24:09,340 --> 00:24:10,300
있습니다.

615
00:24:10,300 --> 00:24:13,140
하지만 중요한 것은 이 전체 시스템이

616
00:24:13,140 --> 00:24:16,620
훈련 데이터 세트의 손실을 최소화하여 끝에서

617
00:24:16,620 --> 00:24:19,010
끝으로 조정된다는 것입니다.

618
00:24:19,010 --> 00:24:22,250
이 네트워크는 실제로 꽤 오랜 역사를 가지고 있습니다.

619
00:24:22,250 --> 00:24:25,705
그래서 이 이미지, 우리가 화면에 그린 특정

620
00:24:25,705 --> 00:24:27,330
ConvNet

621
00:24:27,330 --> 00:24:32,410
아키텍처는 실제로 1998년 Yann LeCun, Leon Bottou와

622
00:24:32,410 --> 00:24:34,523
다른 사람들이 디지털

623
00:24:34,523 --> 00:24:36,690
분류 작업을 수행하기 위해

624
00:24:36,690 --> 00:24:40,730
합성곱 신경망을 구축하던 시절의 논문에서 왔습니다.

625
00:24:40,730 --> 00:24:42,770
그리고 실제로 꽤 잘 작동했지만,

626
00:24:42,770 --> 00:24:44,230
정말 비쌌습니다.

627
00:24:44,230 --> 00:24:46,150
그들은 GPU도 없었고, TPU도

628
00:24:46,150 --> 00:24:48,970
없었으며, 오늘날 우리가 가진 컴퓨팅 자원도 없었습니다.

629
00:24:48,970 --> 00:24:51,170
하지만 기본 알고리즘,

630
00:24:51,170 --> 00:24:54,810
기본 네트워크 아키텍처는 1998년과 2010년대

631
00:24:54,810 --> 00:24:55,970
중반까지

632
00:24:55,970 --> 00:25:00,330
사람들이 사용하던 아키텍처와 꽤 비슷하게 보입니다.

633
00:25:00,330 --> 00:25:03,890
그리고 1998년부터 2012년까지, 그때

634
00:25:03,890 --> 00:25:06,070
AlexNet 아키텍처가 나왔습니다.

635
00:25:06,070 --> 00:25:09,310
그리고 이것은 딥러닝, 특히 컴퓨터

636
00:25:09,310 --> 00:25:11,310
비전의 큰 폭발이었습니다.

637
00:25:11,310 --> 00:25:13,890
우리가 이전 강의에서 이것에 대해 이야기한 것 같습니다.

638
00:25:13,890 --> 00:25:15,490
하지만 AlexNet 아키텍처는

639
00:25:15,490 --> 00:25:18,250
다시 말해 1988년의 Yann LeCun, LeNet

640
00:25:18,250 --> 00:25:20,050
아키텍처와 그렇게 다르지 않습니다.

641
00:25:20,050 --> 00:25:22,770
여러 개의 합성곱 층과 완전 연결 층이 있습니다.

642
00:25:22,770 --> 00:25:24,330
더 크고, 층이 더 많습니다.

643
00:25:24,330 --> 00:25:26,390
층에는 더 많은 유닛이 있지만,

644
00:25:26,390 --> 00:25:28,870
여전히 간단한 손실 함수를

645
00:25:28,870 --> 00:25:32,190
최소화하기 위해 역전파로 끝에서 끝까지 훈련됩니다.

646
00:25:32,190 --> 00:25:34,590
하지만 여기서, 알렉스넷처럼 진짜로 일이

647
00:25:34,590 --> 00:25:35,750
시작된 시점이었습니다.

648
00:25:35,750 --> 00:25:38,250
그리고 이 시점에서 그들은 GPU로 훈련할 수 있었습니다.

649
00:25:38,250 --> 00:25:39,510
GPU가 사용 가능했습니다.

650
00:25:39,510 --> 00:25:41,810
인터넷과 이미지넷 덕분에 더 많은

651
00:25:41,810 --> 00:25:43,470
데이터가 사용 가능해졌습니다.

652
00:25:43,470 --> 00:25:47,390
그래서 알렉스넷은 일이 정말로 시작된 시점입니다.

653
00:25:47,390 --> 00:25:52,070
그래서 2012년부터 2020년경까지의 시대는 합성곱

654
00:25:52,070 --> 00:25:54,470
네트워크가 컴퓨터 비전의 거의

655
00:25:54,470 --> 00:25:57,310
모든 문제를 지배하던 시대였습니다.

656
00:25:57,310 --> 00:26:00,030
그들은 그 시대에 이미지와 관련된 문제를 거의

657
00:26:00,030 --> 00:26:02,250
모두 해결했으며, 그 문제에서 최고의

658
00:26:02,250 --> 00:26:04,310
성능을 보이는 것은 거의 확실히

659
00:26:04,310 --> 00:26:05,790
ConvNet이었습니다.

660
00:26:05,790 --> 00:26:07,910
여기에는 왼쪽의 탐지와 같은 작업이

661
00:26:07,910 --> 00:26:11,030
포함되며, 이는 이미지를 분류하는 것뿐만 아니라

662
00:26:11,030 --> 00:26:13,342
이미지의 모든 객체 주위에 상자를

663
00:26:13,342 --> 00:26:15,300
그리고 그 상자에 카테고리 레이블을

664
00:26:15,300 --> 00:26:16,620
붙이는 작업입니다.

665
00:26:16,620 --> 00:26:19,420
세분화는 상자 수준이나 이미지 수준이

666
00:26:19,420 --> 00:26:21,560
아니라 픽셀 수준에서

667
00:26:21,560 --> 00:26:23,840
레이블을 할당하는 작업입니다.

668
00:26:23,840 --> 00:26:26,300
그래서 이제 우리는 이미지의 모든 픽셀에 독립적으로

669
00:26:26,300 --> 00:26:27,843
카테고리 레이블을 할당하고자 합니다.

670
00:26:27,843 --> 00:26:30,260
이 문제에 대한 아키텍처에 대해서는 향후 강의에서

671
00:26:30,260 --> 00:26:31,400
더 이야기할 것입니다.

672
00:26:31,400 --> 00:26:34,420
하지만 이러한 문제는 합성곱 네트워크를 사용하여

673
00:26:34,420 --> 00:26:36,780
매우 효과적으로 해결할 수 있습니다.

674
00:26:36,780 --> 00:26:39,820
사람들은 언어와 관련된 다른 문제에도 ConvNet을

675
00:26:39,820 --> 00:26:40,477
사용했습니다.

676
00:26:40,477 --> 00:26:42,060
이미지에서 자연어

677
00:26:42,060 --> 00:26:45,680
캡션을 예측하는 이미지 캡셔닝 작업입니다.

678
00:26:45,680 --> 00:26:47,860
이 문제에 대한 최초의 성공적인

679
00:26:47,860 --> 00:26:51,860
접근 방식 중 일부는 합성곱 신경망에 기반을 두었습니다.

680
00:26:51,860 --> 00:26:54,460
그리고 최근의 생성 모델링 작업에서도

681
00:26:54,460 --> 00:26:55,780
마찬가지입니다.

682
00:26:55,780 --> 00:26:57,966
텍스트에서 이미지로-- 죄송합니다,

683
00:26:57,966 --> 00:27:00,998
캡셔닝은 기본적으로 이미지에서 텍스트로의

684
00:27:00,998 --> 00:27:02,540
문제로, 이미지를 입력하고

685
00:27:02,540 --> 00:27:06,100
그 이미지를 설명하는 자연어 문장을 출력하고자 합니다.

686
00:27:06,100 --> 00:27:08,780
우리는 또한 우리가 머릿속에서

687
00:27:08,780 --> 00:27:11,700
상상하는 것에 대한 자연어 설명을

688
00:27:11,700 --> 00:27:14,630
입력하고 시스템이 우리의 입력 설명과

689
00:27:14,630 --> 00:27:18,290
일치하는 새로운 이미지를 처음부터 생성하도록

690
00:27:18,290 --> 00:27:21,050
하는 텍스트에서 이미지 생성의

691
00:27:21,050 --> 00:27:25,210
역문제를 생각할 수 있습니다. 이 문제의 최초의

692
00:27:25,210 --> 00:27:27,490
성공적인 버전도 합성곱

693
00:27:27,490 --> 00:27:29,710
신경망에 기반을 두었습니다.

694
00:27:29,710 --> 00:27:32,610
이 특정 그림은 2021년에 발표된 스테이블

695
00:27:32,610 --> 00:27:34,930
디퓨전 논문에서 가져온 것입니다.

696
00:27:34,930 --> 00:27:36,703
이 기술은 지난 몇 년

697
00:27:36,703 --> 00:27:38,870
동안 많이 발전했습니다.

698
00:27:38,870 --> 00:27:41,120
그리고 우리는 이후의 강의에서 이에 대해 더 이야기할 것입니다.

699
00:27:41,120 --> 00:27:43,370
하지만 이 문제의 최초 버전이 잘

700
00:27:43,370 --> 00:27:46,010
작동하기 시작한 것도 합성곱 신경망에 기반을

701
00:27:46,010 --> 00:27:48,670
두었다는 점을 지적하는 것이 유용합니다.

702
00:27:48,670 --> 00:27:50,170
기본적으로 합성곱

703
00:27:50,170 --> 00:27:52,730
신경망은 컴퓨터 비전 역사에서 매우 중요했으며,

704
00:27:52,730 --> 00:27:55,090
우리가 2015년에 시작한

705
00:27:55,090 --> 00:27:57,730
이 수업의 초기 버전은 실제로 시각

706
00:27:57,730 --> 00:28:00,110
인식을 위한 합성곱 신경망이라고

707
00:28:00,110 --> 00:28:02,410
불렸습니다. 당시 합성곱 신경망은

708
00:28:02,410 --> 00:28:05,010
기본적으로 컴퓨터 비전과 동의어였습니다.

709
00:28:05,010 --> 00:28:06,610
그리고 컴퓨터 비전은

710
00:28:06,610 --> 00:28:09,730
당시 딥러닝의 혜택을 가장 많이 받는

711
00:28:09,730 --> 00:28:10,970
분야였습니다.

712
00:28:10,970 --> 00:28:14,198
딥러닝에 대한 수업을 가르치기로 결정하면서 이미지

713
00:28:14,198 --> 00:28:16,240
문제에 대한 합성곱 신경망 문제에

714
00:28:16,240 --> 00:28:18,943
전적으로 집중하는 것이 매우 합리적이었습니다.

715
00:28:18,943 --> 00:28:20,360
이것이 10년 전

716
00:28:20,360 --> 00:28:22,400
이 수업의 시작입니다.

717
00:28:22,400 --> 00:28:25,580
하지만 그 이후로 이 분야는 많이 발전했습니다.

718
00:28:25,580 --> 00:28:28,060
합성곱 신경망은 실제로 대체되었습니다.

719
00:28:28,060 --> 00:28:29,120
시각 인식 외에도 이제

720
00:28:29,120 --> 00:28:31,240
해결할 수 있는 흥미로운 문제들이 많이 있습니다.

721
00:28:31,240 --> 00:28:33,032
그래서 어느 시점에서 클래스의

722
00:28:33,032 --> 00:28:35,960
이름이 변경되었고 더 이상 신경망, 특히 합성곱

723
00:28:35,960 --> 00:28:38,000
신경망에 그렇게 구체적으로 집중하지

724
00:28:38,000 --> 00:28:40,120
않게 되었다는 것을 알 수 있습니다.

725
00:28:40,120 --> 00:28:41,840
그 이유는 제가 2012년부터

726
00:28:41,840 --> 00:28:44,260
2020년까지의 시대라고 말했기 때문입니다.

727
00:28:44,260 --> 00:28:45,760
COVID 외에 2020년에

728
00:28:45,760 --> 00:28:48,320
합성곱 신경망을 대체할 수 있었던 일이

729
00:28:48,320 --> 00:28:49,840
무엇인지 궁금할 수 있습니다.

730
00:28:49,840 --> 00:28:52,438
그것은 COVID가 아니라 트랜스포머입니다.

731
00:28:52,438 --> 00:28:54,480
트랜스포머는 우리가 몇 강의

732
00:28:54,480 --> 00:28:57,120
후에 이야기할 대체 신경망 아키텍처입니다.

733
00:28:57,120 --> 00:28:59,920
기본적으로, 트랜스포머는 문서 처리, 텍스트

734
00:28:59,920 --> 00:29:03,120
문자열 처리를 위한 자연어 처리에서 시작되었습니다.

735
00:29:03,120 --> 00:29:06,378
트랜스포머 아키텍처는 2017년에 처음 발표되었습니다.

736
00:29:06,378 --> 00:29:07,920
그 후 몇 년 동안

737
00:29:07,920 --> 00:29:10,720
주로 텍스트 처리 영역에 머물렀지만,

738
00:29:10,720 --> 00:29:13,140
2021년에 발표된 매우 중요한

739
00:29:13,140 --> 00:29:15,820
논문이 있었습니다. 이 논문은 텍스트를

740
00:29:15,820 --> 00:29:18,400
처리하는 데 사용되었던 거의 동일한

741
00:29:18,400 --> 00:29:20,500
트랜스포머 아키텍처를 이미지

742
00:29:20,500 --> 00:29:23,660
처리에 거의 동일한 방식으로 적용했습니다.

743
00:29:23,660 --> 00:29:25,780
그 이후로 사람들은 우리가 방금 이야기한

744
00:29:25,780 --> 00:29:28,020
이전 문제들 중 많은 문제를 합성곱

745
00:29:28,020 --> 00:29:29,460
신경망으로 해결했던 것들을

746
00:29:29,460 --> 00:29:31,240
트랜스포머로 대체할 수 있다는

747
00:29:31,240 --> 00:29:33,740
것을 발견했습니다. 모든 것을 동일하게

748
00:29:33,740 --> 00:29:35,745
유지하고 문제를 해결하면 이러한 문제에서

749
00:29:35,745 --> 00:29:38,120
더 나은 성능을 얻는 경향이 있습니다.

750
00:29:38,120 --> 00:29:41,260
그들은 더 많은 데이터와 더 많은 컴퓨팅에 맞춰 확장됩니다.

751
00:29:41,260 --> 00:29:46,260
우리는 더 많은 데이터를 얻을 수 있고, 더 많은 컴퓨팅을 얻을 수
있습니다.

752
00:29:46,260 --> 00:29:49,140
그래서 요즘 이러한 것들은 점점 더 많은 컴퓨터

753
00:29:49,140 --> 00:29:51,620
비전 문제에 더 일반적으로 사용됩니다.

754
00:29:51,620 --> 00:29:54,120
트랜스포머에 대해서는 8강에서 더 많이

755
00:29:54,120 --> 00:29:56,980
이야기할 것이지만, 실제로 요즘은 5년 전만큼

756
00:29:56,980 --> 00:29:59,380
많이 사용되지 않는 ConvNets를

757
00:29:59,380 --> 00:30:02,560
강하게 추천하는 것이 이상할 것이라고 생각했습니다.

758
00:30:02,560 --> 00:30:04,060
하지만 여전히 합성곱

759
00:30:04,060 --> 00:30:06,360
신경망에 대해 이야기하는 것이 유용하다고

760
00:30:06,360 --> 00:30:09,010
생각합니다. 첫째, 역사적 중요성이

761
00:30:09,010 --> 00:30:12,928
많고, 둘째, 이러한 알고리즘은 여전히 실제로 많이 사용됩니다.

762
00:30:12,928 --> 00:30:14,970
셋째, 이미지에 중요한 것이 무엇인지에 대한

763
00:30:14,970 --> 00:30:17,010
직관을 구축하는 데 도움이 되며, 넷째, 실제로

764
00:30:17,010 --> 00:30:18,260
완전히 사라지지 않았습니다.

765
00:30:18,260 --> 00:30:20,510
많은 경우 우리는 실제로 하이브리드 시스템을 구축하고 있습니다.

766
00:30:20,510 --> 00:30:23,010
가끔 우리는 컨볼루션을 사용하고, 가끔은 트랜스포머를

767
00:30:23,010 --> 00:30:25,070
사용하며, 가끔은 이들을 다양한 방식으로 혼합합니다.

768
00:30:25,070 --> 00:30:28,570
그래서 이 내용을 아는 것이 여전히 매우 유용합니다.

769
00:30:28,570 --> 00:30:30,250
그럼 오늘 나머지 시간에는

770
00:30:30,250 --> 00:30:32,710
컨볼루션 신경망에 대해 더 이야기할 것입니다.

771
00:30:32,710 --> 00:30:35,890
우리는 컨볼루션 신경망이 이미지를 처리하기

772
00:30:35,890 --> 00:30:38,070
위한 계산 그래프라고 말했습니다.

773
00:30:38,070 --> 00:30:39,790
이는 몇 가지 다른 원시 요소로 구성됩니다.

774
00:30:39,790 --> 00:30:41,210
우리는 이미 완전 연결층과

775
00:30:41,210 --> 00:30:42,670
활성화 함수에 대해 다뤘습니다.

776
00:30:42,670 --> 00:30:44,795
그래서 우리는 컨볼루션 층과

777
00:30:44,795 --> 00:30:47,690
풀링 층의 두 가지 층을 더 살펴봐야 합니다.

778
00:30:47,690 --> 00:30:49,480
완전 연결층에 대한 간단한 요약입니다.

779
00:30:49,480 --> 00:30:51,730
이것은 선형 분류기의 맥락에서 이미

780
00:30:51,730 --> 00:30:53,213
이야기한 내용입니다.

781
00:30:53,213 --> 00:30:54,630
우리의 완전 연결층에서는,

782
00:30:54,630 --> 00:30:56,170
우리가 말했듯이, 기본적으로

783
00:30:56,170 --> 00:30:58,110
이미지의 픽셀을 가져옵니다.

784
00:30:58,110 --> 00:31:01,450
우리의 이미지는 32x32x3의 3차원 텐서입니다.

785
00:31:01,450 --> 00:31:04,830
32x32는 두 개의 공간 차원입니다.

786
00:31:04,830 --> 00:31:08,020
3은 RGB 색상의 세 개의 채널 차원입니다.

787
00:31:08,020 --> 00:31:10,860
그래서 우리는 32x32x3 벡터를 가져옵니다.

788
00:31:10,860 --> 00:31:13,065
이것을 3072의 긴 벡터로 펼칩니다.

789
00:31:13,065 --> 00:31:15,440
왜냐하면 머릿속으로 곱하면 그 숫자가

790
00:31:15,440 --> 00:31:16,800
나오기 때문입니다.

791
00:31:16,800 --> 00:31:21,160
그리고 나서 기본적으로 3072개의 숫자로 이루어진 이 벡터를 갖게 됩니다.

792
00:31:21,160 --> 00:31:23,040
우리는 이 경우 3072x10의 가중치 행렬을

793
00:31:23,040 --> 00:31:25,760
가지고 있습니다. 왜냐하면 10은 우리가 원하는 출력 클래스의

794
00:31:25,760 --> 00:31:26,580
수이기 때문입니다.

795
00:31:26,580 --> 00:31:28,780
행렬 벡터를 곱합니다.

796
00:31:28,780 --> 00:31:30,960
10개의 숫자로 이루어진 벡터가

797
00:31:30,960 --> 00:31:33,040
클래스 점수를 제공합니다.

798
00:31:33,040 --> 00:31:35,600
특히, 완전 연결 층에서 합성곱

799
00:31:35,600 --> 00:31:38,000
층으로 일반화하려고 할 때,

800
00:31:38,000 --> 00:31:40,577
완전 연결 층이 수행하는 구조에

801
00:31:40,577 --> 00:31:43,160
대해 조금 더 생각하는 것이

802
00:31:43,160 --> 00:31:46,780
유용합니다. 완전 연결 층의 출력 벡터는 10개의

803
00:31:46,780 --> 00:31:49,600
요소를 포함하며, 각 요소는

804
00:31:49,600 --> 00:31:50,900
하나의 숫자입니다.

805
00:31:50,900 --> 00:31:52,760
각 숫자는 가중치

806
00:31:52,760 --> 00:31:54,760
행렬의 한 행과 전체

807
00:31:54,760 --> 00:31:57,680
입력 벡터 간의 내적을 계산하여

808
00:31:57,680 --> 00:31:58,800
예측됩니다.

809
00:31:58,800 --> 00:32:00,560
각 항목은 기본적으로

810
00:32:00,560 --> 00:32:02,657
내적이라고 생각해야 하며, 내적은

811
00:32:02,657 --> 00:32:04,990
템플릿 매칭으로 생각해야 합니다.

812
00:32:04,990 --> 00:32:06,448
두 벡터 간의 내적은

813
00:32:06,448 --> 00:32:09,130
두 벡터가 같은 방향을 가리킬 때 높고,

814
00:32:09,130 --> 00:32:11,490
두 벡터가 직교할 때 0입니다.

815
00:32:11,490 --> 00:32:12,950
따라서 내적에 기반한 모든

816
00:32:12,950 --> 00:32:15,030
것은 기본적으로 템플릿 매칭입니다.

817
00:32:15,030 --> 00:32:17,630
완전 연결 층에 대해 생각할 때, 우리는

818
00:32:17,630 --> 00:32:20,670
템플릿 집합을 가지고 있으며, 각 템플릿은

819
00:32:20,670 --> 00:32:23,110
입력과 동일한 크기를 가집니다.

820
00:32:23,110 --> 00:32:26,150
그리고 출력은 각 템플릿과

821
00:32:26,150 --> 00:32:30,510
전체 입력 간의 템플릿 매칭 점수입니다.

822
00:32:30,510 --> 00:32:32,315
그렇게 생각하면, 완전

823
00:32:32,315 --> 00:32:34,190
연결 층에서 합성곱 층으로

824
00:32:34,190 --> 00:32:37,410
일반화할 수 있는 좋은 방법이 있습니다.

825
00:32:37,410 --> 00:32:39,182
그것은 여전히 템플릿 매칭 개념을

826
00:32:39,182 --> 00:32:40,890
유지할 것이라는 것입니다.

827
00:32:40,890 --> 00:32:42,432
여전히 필터 뱅크를 학습하는

828
00:32:42,432 --> 00:32:44,090
개념을 유지할 것입니다.

829
00:32:44,090 --> 00:32:46,830
하지만 우리가 변경할 것은 그 필터들이

830
00:32:46,830 --> 00:32:48,710
입력과 동일한 형태를

831
00:32:48,710 --> 00:32:50,690
갖지 않을 것이라는 점입니다.

832
00:32:50,690 --> 00:32:53,870
대신, 이제 우리의 필터는

833
00:32:53,870 --> 00:32:57,910
입력의 작은 부분 집합만을 볼 것입니다.

834
00:32:57,910 --> 00:33:00,830
더 구체적으로, 이미지를 3072개의 숫자로

835
00:33:00,830 --> 00:33:03,950
이루어진 큰 벡터로 펼치는 대신, 우리는

836
00:33:03,950 --> 00:33:07,230
이미지의 3D 공간 구조를 유지할 것입니다.

837
00:33:07,230 --> 00:33:09,730
이제는 3채널의 3차원 텐서가 될 것이며,

838
00:33:09,730 --> 00:33:12,310
때때로 깊이 또는 채널 차원이라고

839
00:33:12,310 --> 00:33:14,770
불리며, 너비 32, 높이 32입니다.

840
00:33:14,770 --> 00:33:16,530
이제 우리의 필터 중

841
00:33:16,530 --> 00:33:20,070
하나는 작은 서브 이미지, 즉 5x5

842
00:33:20,070 --> 00:33:22,730
픽셀 이미지가 될 것입니다.

843
00:33:22,730 --> 00:33:26,130
중요하게도, 그 작은 필터는 3개의 채널을

844
00:33:26,130 --> 00:33:27,430
가져야 합니다.

845
00:33:27,430 --> 00:33:29,370
채널은 항상 입력의 채널

846
00:33:29,370 --> 00:33:31,150
수와 동일하게 유지되지만,

847
00:33:31,150 --> 00:33:33,395
공간 크기는 더 작습니다.

848
00:33:33,395 --> 00:33:34,770
이제 우리가 할 것은

849
00:33:34,770 --> 00:33:36,310
내적을 계산하는 것입니다.

850
00:33:36,310 --> 00:33:38,810
그 작은 필터를 이미지 템플릿의 작은

851
00:33:38,810 --> 00:33:39,918
조각으로 생각합니다.

852
00:33:39,918 --> 00:33:42,210
그리고 우리는 그것을 이미지 전역에

853
00:33:42,210 --> 00:33:44,450
슬라이드하여 이미지의 각

854
00:33:44,450 --> 00:33:47,170
지점에서 그 서브 부분이 우리가 합성곱

855
00:33:47,170 --> 00:33:49,490
필터에서 학습하고 있는 템플릿과

856
00:33:49,490 --> 00:33:51,570
얼마나 일치하는지 확인합니다.

857
00:33:51,570 --> 00:33:53,930
그래서 우리는 이미지의 일부 조각에 그

858
00:33:53,930 --> 00:33:55,470
합성곱 필터를 놓을 것입니다.

859
00:33:55,470 --> 00:33:59,050
5x5x3 필터는 해당 공간 위치에서 이미지의

860
00:33:59,050 --> 00:34:02,400
5x5x3 조각과 정렬되어 내적을 계산하고,

861
00:34:02,400 --> 00:34:03,860
이는 그 이미지

862
00:34:03,860 --> 00:34:06,080
조각이 우리의 템플릿과 얼마나

863
00:34:06,080 --> 00:34:08,480
일치하는지를 나타내는 단일

864
00:34:08,480 --> 00:34:10,280
스칼라 숫자를 제공합니다.

865
00:34:10,280 --> 00:34:13,159
이제 우리는 그 과정을 반복하고 템플릿을

866
00:34:13,159 --> 00:34:14,900
이미지 전역에 슬라이드합니다.

867
00:34:14,900 --> 00:34:17,150
우리가 템플릿을 놓는 모든 위치에서,

868
00:34:17,150 --> 00:34:19,567
우리는 다시 템플릿 매칭 점수를 계산하여

869
00:34:19,567 --> 00:34:21,880
그 이미지 조각이 그 템플릿과 얼마나

870
00:34:21,880 --> 00:34:23,260
일치하는지를 나타냅니다.

871
00:34:23,260 --> 00:34:27,139
입력 이미지에서 필터를 슬라이드하면서, 우리는

872
00:34:27,139 --> 00:34:29,440
모든 점수, 모든 템플릿 매칭

873
00:34:29,440 --> 00:34:32,120
점수를 평면에 수집할 것입니다.

874
00:34:32,120 --> 00:34:35,040
그 평면은 이제 2차원

875
00:34:35,040 --> 00:34:37,920
평면이 되어, 평면의 각

876
00:34:37,920 --> 00:34:40,600
점은 입력 이미지의

877
00:34:40,600 --> 00:34:44,120
해당 조각이 우리의 필터와

878
00:34:44,120 --> 00:34:47,600
얼마나 일치하는지를 나타냅니다.

879
00:34:47,600 --> 00:34:50,060
하지만 물론, 이것은 딥러닝입니다.

880
00:34:50,060 --> 00:34:51,260
우리는 많은 계산을 원합니다.

881
00:34:51,260 --> 00:34:52,580
더 많은 계산을 어떻게 얻을까요?

882
00:34:52,580 --> 00:34:53,900
더 많은 필터가 있습니다.

883
00:34:53,900 --> 00:34:56,080
이제 두 번째 필터를 추가하고,

884
00:34:56,080 --> 00:34:59,080
전체 프로세스를 또 다른 필터로

885
00:34:59,080 --> 00:35:00,490
반복하겠습니다.

886
00:35:00,490 --> 00:35:03,110
우리는 5x5x3 필터를

887
00:35:03,110 --> 00:35:05,150
파란색으로 표시했습니다.

888
00:35:05,150 --> 00:35:06,750
이제 초록색으로 표시된 두

889
00:35:06,750 --> 00:35:08,470
번째 필터를 상상해 봅시다.

890
00:35:08,470 --> 00:35:11,162
두 번째 필터도 여전히 5x5x3입니다.

891
00:35:11,162 --> 00:35:12,870
우리는 그 초록색 필터를

892
00:35:12,870 --> 00:35:15,495
이미지의 모든 곳에 슬라이딩하고,

893
00:35:15,495 --> 00:35:17,870
초록색 필터와 이미지의 작은

894
00:35:17,870 --> 00:35:20,010
조각들 사이의 템플릿 매칭

895
00:35:20,010 --> 00:35:23,110
점수를 계산한 다음, 그 점수를 두 번째

896
00:35:23,110 --> 00:35:26,190
평면에 모아 이미지의 각 지점이 초록색

897
00:35:26,190 --> 00:35:28,990
필터에 얼마나 반응했는지를 알려줍니다.

898
00:35:28,990 --> 00:35:32,310
이제 우리는 기본적으로 이 과정을 반복하고 원하는 만큼 필터를

899
00:35:32,310 --> 00:35:33,670
추가할 수 있습니다.

900
00:35:33,670 --> 00:35:36,670
따라서 이 경우, 우리는 6개의

901
00:35:36,670 --> 00:35:40,350
필터를 그리며, 각각은 3x5x5

902
00:35:40,350 --> 00:35:41,030
또는

903
00:35:41,030 --> 00:35:42,343
3x5x5입니다.

904
00:35:42,343 --> 00:35:44,510
그래서 우리는 실제로 모든 필터를

905
00:35:44,510 --> 00:35:46,590
단일 4차원 텐서에 모을 수 있습니다.

906
00:35:46,590 --> 00:35:49,790
이 4차원 텐서는 이제 6개의 필터가 있기

907
00:35:49,790 --> 00:35:52,290
때문에 선행 차원으로 6을 가집니다.

908
00:35:52,290 --> 00:35:56,110
그리고 3x5x5는 우리가 배우고

909
00:35:56,110 --> 00:35:58,970
있는 이미지 템플릿입니다.

910
00:35:58,970 --> 00:36:01,970
이제 컨볼루션 레이어는 기본적으로 우리의 3차원

911
00:36:01,970 --> 00:36:04,730
입력, 즉 3차원 이미지를 입력으로

912
00:36:04,730 --> 00:36:08,112
받아 4차원 필터 뱅크를 슬라이딩하여 이미지의 모든

913
00:36:08,112 --> 00:36:09,570
곳에 필터를 적용하고

914
00:36:09,570 --> 00:36:11,530
이러한 반응 평면을 제공합니다.

915
00:36:11,530 --> 00:36:13,650
따라서 모든 반응 평면을

916
00:36:13,650 --> 00:36:15,590
수집하고 세 번째

917
00:36:15,590 --> 00:36:21,930
차원에 쌓으면 출력 크기는 6x28x28이 되며, 여기서 28x28은

918
00:36:21,930 --> 00:36:24,130
공간 차원으로

919
00:36:24,130 --> 00:36:26,850
해석되고 6은 채널 차원입니다.

920
00:36:26,850 --> 00:36:28,770
물론 선형 레이어와 마찬가지로,

921
00:36:28,770 --> 00:36:30,270
우리는 종종

922
00:36:30,270 --> 00:36:32,770
컨볼루션 레이어에도 학습 가능한 바이어스

923
00:36:32,770 --> 00:36:36,250
벡터를 추가할 것입니다. 따라서 그런 의미에서

924
00:36:36,250 --> 00:36:38,890
선형 레이어에서 바이어스는 선형

925
00:36:38,890 --> 00:36:41,680
레이어의 각 행마다 하나의 스칼라입니다.

926
00:36:41,680 --> 00:36:43,430
상응하여, 컨볼루션

927
00:36:43,430 --> 00:36:46,010
레이어에서는 일반적으로 각

928
00:36:46,010 --> 00:36:48,890
컨볼루션 필터마다 하나의 스칼라 바이어스

929
00:36:48,890 --> 00:36:50,443
값을 가집니다.

930
00:36:50,443 --> 00:36:52,610
즉, 이 설정에서는 6차원

931
00:36:52,610 --> 00:36:54,635
바이어스 벡터를 가지게 됩니다.

932
00:36:54,635 --> 00:36:56,010
네, 질문은 3이 RGB 채널이라는

933
00:36:56,010 --> 00:36:57,260
것을 명확히 하는 것이었습니다.

934
00:36:57,260 --> 00:36:58,720
네, 맞습니다.

935
00:36:58,720 --> 00:37:00,420
질문은 필터를 어떻게 얻느냐는 것입니다.

936
00:37:00,420 --> 00:37:03,740
그것이 바로 경량 하강법과 역전파의 기적입니다.

937
00:37:03,740 --> 00:37:06,220
아이디어는 이 연산자를 정의하는 것입니다.

938
00:37:06,220 --> 00:37:08,000
이 연산자는 입력 이미지와

939
00:37:08,000 --> 00:37:10,460
필터 집합을 가질 것입니다.

940
00:37:10,460 --> 00:37:12,640
하지만 어떤 인간도 그 필터가 무엇이 될지

941
00:37:12,640 --> 00:37:13,900
정의하지 않을 것입니다.

942
00:37:13,900 --> 00:37:15,900
대신, 우리는 그 필터를 무작위로 초기화할

943
00:37:15,900 --> 00:37:16,420
것입니다.

944
00:37:16,420 --> 00:37:19,040
그런 다음 그것들은 당신이 해결하려고 하는 문제에 대해 경량

945
00:37:19,040 --> 00:37:20,480
하강법을 통해 학습될 것입니다.

946
00:37:20,480 --> 00:37:22,980
그래서 이것은 실제로 염두에 두어야 할 매우 중요한 사항입니다.

947
00:37:22,980 --> 00:37:26,000
이 레이어의 힘은 우리가 상당히 계산

948
00:37:26,000 --> 00:37:28,400
비용이 많이 드는 레이어를

949
00:37:28,400 --> 00:37:30,320
정의하고 있지만, 그것이 우리의

950
00:37:30,320 --> 00:37:33,920
훈련 데이터와 계산으로 채워질 것이라고

951
00:37:33,920 --> 00:37:35,760
기대하고 있다는 것입니다.

952
00:37:35,760 --> 00:37:37,680
질문은 5를 어떻게 설정하느냐는 것입니다.

953
00:37:37,680 --> 00:37:38,880
그것은 하이퍼파라미터입니다.

954
00:37:38,880 --> 00:37:40,343
우리는 몇 강의 전에 하이퍼파라미터와

955
00:37:40,343 --> 00:37:42,260
교차 검증에 대해 이야기했습니다.

956
00:37:42,260 --> 00:37:44,218
따라서 이것들은 일반적으로 어떤 방식으로든

957
00:37:44,218 --> 00:37:46,987
교차 검증을 통해 설정하는 아키텍처 하이퍼파라미터입니다.

958
00:37:46,987 --> 00:37:47,820
네, 좋은 질문입니다.

959
00:37:47,820 --> 00:37:50,070
다양한 크기의 필터를 갖는 것이 의미가 있나요?

960
00:37:50,070 --> 00:37:52,240
다음 강의에서 CNN 아키텍처에 대해 볼

961
00:37:52,240 --> 00:37:53,640
것이므로, 사실 당신은

962
00:37:53,640 --> 00:37:56,310
inception에 대해 이야기할 것이라고 생각합니다.

963
00:37:56,310 --> 00:37:58,450
때때로 실제로 그런 경우가 있습니다.

964
00:37:58,450 --> 00:38:01,750
하지만 일반적으로는 계산 그래프에서

965
00:38:01,750 --> 00:38:03,750
원시적인 것과 원시적인

966
00:38:03,750 --> 00:38:07,003
것들로부터 만들어질 구조를 설계할 때

967
00:38:07,003 --> 00:38:09,670
좋은 API 디자인 문제에

968
00:38:09,670 --> 00:38:10,610
해당합니다.

969
00:38:10,610 --> 00:38:12,310
이 경우, 우리는 일반적으로 고정된

970
00:38:12,310 --> 00:38:14,988
필터 크기를 가진 단일 합성곱 층을 정의합니다. 이는

971
00:38:14,988 --> 00:38:17,030
계산을 더 쉽게 하고 효율적인 GPU 커널을

972
00:38:17,030 --> 00:38:18,490
작성하는 데 도움이 됩니다.

973
00:38:18,490 --> 00:38:22,630
하지만 서로 다른 필터 크기를 가진 합성곱 층을 결합하여 더 큰

974
00:38:22,630 --> 00:38:24,910
네트워크 구조에서 계산 그래프를

975
00:38:24,910 --> 00:38:27,990
연결함으로써 여러 개의 다양한 크기 필터를 효과적으로

976
00:38:27,990 --> 00:38:29,570
가질 수 있습니다.

977
00:38:29,570 --> 00:38:32,967
그래서 당신의 질문에 대한 대답은 예와 아니오입니다.

978
00:38:32,967 --> 00:38:34,550
질문은 우리가 무엇을 배우고 있는가입니다.

979
00:38:34,550 --> 00:38:37,092
그리고 이는 매개변수와 하이퍼파라미터를 구분하는

980
00:38:37,092 --> 00:38:38,350
것이 매우 중요합니다.

981
00:38:38,350 --> 00:38:40,990
하이퍼파라미터는 네트워크 훈련을 시작하기

982
00:38:40,990 --> 00:38:42,330
전에 설정하는 것입니다.

983
00:38:42,330 --> 00:38:44,190
이 경우, 하이퍼파라미터

984
00:38:44,190 --> 00:38:47,250
중 하나는 필터의 수와 필터의 크기입니다.

985
00:38:47,250 --> 00:38:49,790
이것들이 우리의 텐서 형태를 설정합니다.

986
00:38:49,790 --> 00:38:52,550
따라서 매개변수는 경량 하강

987
00:38:52,550 --> 00:38:54,140
과정에서 설정하고

988
00:38:54,140 --> 00:38:55,680
최적화할 값입니다.

989
00:38:55,680 --> 00:38:58,180
이 경우, 필터의 수, 출력 채널의 수,

990
00:38:58,180 --> 00:38:59,790
필터의 크기 등이

991
00:38:59,790 --> 00:39:01,040
하이퍼파라미터가 됩니다.

992
00:39:01,040 --> 00:39:02,907
우리는 훈련을 시작하기 전에 그것들을 한 번 설정합니다.

993
00:39:02,907 --> 00:39:04,740
훈련 시작 시, 우리는

994
00:39:04,740 --> 00:39:07,500
필터를 무작위로 초기화하고, 그 값이

995
00:39:07,500 --> 00:39:10,000
고정된 형태의 텐서를 제공합니다.

996
00:39:10,000 --> 00:39:11,820
그리고 그 텐서 내부의 값들은

997
00:39:11,820 --> 00:39:14,365
최적화 과정에서 변화하고 떠다닙니다.

998
00:39:14,365 --> 00:39:15,740
그래서 그것들은

999
00:39:15,740 --> 00:39:18,220
매개변수입니다. 왜냐하면 경량 하강을

1000
00:39:18,220 --> 00:39:19,793
통해 설정되기 때문입니다.

1001
00:39:19,793 --> 00:39:21,960
네, 질문은 우리가 어떤 그래디언트를 계산하고 있는가입니다.

1002
00:39:21,960 --> 00:39:23,860
역전파를 수행할 때마다 항상

1003
00:39:23,860 --> 00:39:26,380
네트워크 내부의 것들에 대한 손실의

1004
00:39:26,380 --> 00:39:28,160
그래디언트를 계산하고 있습니다.

1005
00:39:28,160 --> 00:39:30,580
이 경우, 우리는 개별 스칼라에 대한 손실의

1006
00:39:30,580 --> 00:39:33,420
그래디언트를 계산할 것입니다. 즉, 우리의

1007
00:39:33,420 --> 00:39:35,540
합성곱 필터 가중치에 대해 계산합니다.

1008
00:39:35,540 --> 00:39:38,140
기본적으로 이는 모든 필터

1009
00:39:38,140 --> 00:39:39,980
내부의 개별 스칼라를

1010
00:39:39,980 --> 00:39:41,608
조금 흔들면 손실이

1011
00:39:41,608 --> 00:39:43,900
얼마나 변할지를 말하는

1012
00:39:43,900 --> 00:39:45,022
것입니다.

1013
00:39:45,022 --> 00:39:46,980
그래서 손실에 대한 그래디언트를 항상

1014
00:39:46,980 --> 00:39:49,313
계산하고 있습니다. 즉, 우리의 합성곱 필터에

1015
00:39:49,313 --> 00:39:51,780
대한 손실의 그래디언트를 계산하고 있습니다.

1016
00:39:51,780 --> 00:39:54,280
질문은 기본적으로 바이어스를 어떻게 처리할 것인가입니다.

1017
00:39:54,280 --> 00:39:56,040
기본적으로 바이어스는 우리의

1018
00:39:56,040 --> 00:39:57,630
내적에 추가됩니다.

1019
00:39:57,630 --> 00:39:59,880
따라서 우리는 항상 이미지의 조각에

1020
00:39:59,880 --> 00:40:01,672
대해 필터 중 하나의 내적을

1021
00:40:01,672 --> 00:40:04,880
계산하고, 그에 해당하는 바이어스의 스칼라를 추가합니다.

1022
00:40:04,880 --> 00:40:07,960
바이어스는 벡터이지만, 벡터의 항목 수는

1023
00:40:07,960 --> 00:40:09,620
필터의 수와 같습니다.

1024
00:40:09,620 --> 00:40:13,640
따라서 바이어스의 각 항목은 출력의 전체

1025
00:40:13,640 --> 00:40:16,600
공간 차원에 걸쳐 방송됩니다.

1026
00:40:16,600 --> 00:40:18,900
하지만 각 바이어스는

1027
00:40:18,900 --> 00:40:22,160
하나의 필터에만 사용됩니다.

1028
00:40:22,160 --> 00:40:25,580
개념적으로 하나의 필터를 모든 곳에 슬라이드합니다.

1029
00:40:25,580 --> 00:40:27,860
그것은 활성화의 2차원 평면을 제공합니다.

1030
00:40:27,860 --> 00:40:29,960
그리고 두 번째 필터가 있으면 두

1031
00:40:29,960 --> 00:40:31,620
번째 활성화 평면을 얻습니다.

1032
00:40:31,620 --> 00:40:33,380
이들은 독립적인 연산자입니다.

1033
00:40:33,380 --> 00:40:36,300
첫 번째 필터를 모든 곳에 적용하는 단계입니다.

1034
00:40:36,300 --> 00:40:38,300
두 번째 필터를 모든 곳에 적용하는 단계입니다.

1035
00:40:38,300 --> 00:40:41,960
모든 필터는 평면을 생성하며, 이 평면을 우리는 활성화

1036
00:40:41,960 --> 00:40:43,383
맵이라고 부릅니다.

1037
00:40:43,383 --> 00:40:44,800
그리고 우리는 그것들을 모두 쌓습니다.

1038
00:40:44,800 --> 00:40:47,360
이것이 합성곱 층의 작업입니다.

1039
00:40:47,360 --> 00:40:50,170
질문은, 네, 기본적으로 매번 경량

1040
00:40:50,170 --> 00:40:52,110
하강을 할 때마다 필터가

1041
00:40:52,110 --> 00:40:53,790
변경된다는 것입니다.

1042
00:40:53,790 --> 00:40:56,370
신경망을 훈련한다고 상상할 때마다, 항상 '무한

1043
00:40:56,370 --> 00:40:59,932
루프'처럼 데이터 배치를 가져오고, 데이터를 네트워크를

1044
00:40:59,932 --> 00:41:01,390
통해 보내고, 순전파를 하고,

1045
00:41:01,390 --> 00:41:04,330
손실을 계산하고, 역전파를 하고, 손실에 대한

1046
00:41:04,330 --> 00:41:06,090
그래디언트를 계산한 후 최적화를

1047
00:41:06,090 --> 00:41:08,370
사용하여 그래디언트 단계를 수행합니다.

1048
00:41:08,370 --> 00:41:10,470
그래서 항상 데이터, 순전파,

1049
00:41:10,470 --> 00:41:12,170
손실, 역전파 단계가 됩니다.

1050
00:41:12,170 --> 00:41:13,610
그리고 매번 단계를

1051
00:41:13,610 --> 00:41:16,470
수행할 때마다 필터에 변화가 생깁니다.

1052
00:41:16,470 --> 00:41:17,090
좋습니다.

1053
00:41:17,090 --> 00:41:19,270
그래서 저는 반대쪽으로 갔고 질문이

1054
00:41:19,270 --> 00:41:20,630
너무 많다고 말했습니다.

1055
00:41:20,630 --> 00:41:21,490
하지만 그건 좋은 일입니다.

1056
00:41:21,490 --> 00:41:23,830
여기서 균형을 맞추겠습니다.

1057
00:41:23,830 --> 00:41:26,630
그래서 우리는 합성곱 층에 대해 이야기했습니다.

1058
00:41:26,630 --> 00:41:28,830
합성곱 층에서 배치 모드로 작업하는

1059
00:41:28,830 --> 00:41:30,610
것은 꽤 일반적입니다.

1060
00:41:30,610 --> 00:41:32,510
하나의 입력 이미지에서 작업하는 대신,

1061
00:41:32,510 --> 00:41:34,970
실제로 입력 이미지의 배치에서 작업할 것입니다.

1062
00:41:34,970 --> 00:41:37,688
이것은 모든 것을 4차원으로 만들어서 좋습니다.

1063
00:41:37,688 --> 00:41:39,230
이제 우리는 입력 이미지

1064
00:41:39,230 --> 00:41:42,095
집합인 4차원 텐서를 가지고 있습니다.

1065
00:41:42,095 --> 00:41:43,470
우리는 필터 집합인

1066
00:41:43,470 --> 00:41:46,262
4차원 텐서를 가지고 있으며, 각 필터는

1067
00:41:46,262 --> 00:41:47,970
이미지의 3차원 조각입니다.

1068
00:41:47,970 --> 00:41:50,220
그리고 출력은 4차원

1069
00:41:50,220 --> 00:41:54,000
텐서로, 출력 집합입니다.

1070
00:41:54,000 --> 00:41:56,580
각 출력은 이미지당 하나의 출력이며, 각

1071
00:41:56,580 --> 00:41:58,740
이미지의 출력은 특징 평면의 스택을

1072
00:41:58,740 --> 00:42:00,660
제공하는 3차원 텐서입니다.

1073
00:42:00,660 --> 00:42:02,893
신경망을 구축하기 시작할 때는

1074
00:42:02,893 --> 00:42:04,560
많은 차원에서 생각해야

1075
00:42:04,560 --> 00:42:07,060
하며, 이는 실제로 재미있습니다.

1076
00:42:07,060 --> 00:42:08,780
그래서 여기 합성곱 층의 일반적인

1077
00:42:08,780 --> 00:42:10,033
공식화가 있습니다.

1078
00:42:10,033 --> 00:42:11,700
일반적으로 n x cn

1079
00:42:11,700 --> 00:42:14,860
x h x w의 4차원 텐서를 입력으로 사용합니다.

1080
00:42:14,860 --> 00:42:17,600
이는 n개의 이미지 집합입니다.

1081
00:42:17,600 --> 00:42:20,460
각 n개의 이미지는 cn 채널을 가지고 있습니다.

1082
00:42:20,460 --> 00:42:22,800
RGB 이미지의 경우, 이는 3이지만

1083
00:42:22,800 --> 00:42:25,880
일반적으로 3개 이상의 채널이 있을 수 있습니다.

1084
00:42:25,880 --> 00:42:27,140
이는 임의일 수 있습니다.

1085
00:42:27,140 --> 00:42:30,340
그리고 h와 w는 입력 이미지의 공간 크기입니다.

1086
00:42:30,340 --> 00:42:33,140
우리의 합성곱 필터는 c out x

1087
00:42:33,140 --> 00:42:37,340
cn x kw x kh 형태의 4차원 텐서입니다.

1088
00:42:37,340 --> 00:42:41,420
C out은 필터의 수, 출력 채널의 수이며,

1089
00:42:41,420 --> 00:42:43,460
cn은 나머지 부분이

1090
00:42:43,460 --> 00:42:44,880
3차원 필터입니다.

1091
00:42:44,880 --> 00:42:47,090
그래서 이는 3차원 필터의 집합입니다.

1092
00:42:47,090 --> 00:42:51,050
각 3차원 필터는 cn x kw x kh 형태를 가집니다.

1093
00:42:51,050 --> 00:42:52,870
그것이 커널 너비와 커널 높이입니다.

1094
00:42:52,870 --> 00:42:55,010
그리고 우리는 c out 만큼의

1095
00:42:55,010 --> 00:42:57,388
필터가 네 차원 텐서로 모입니다.

1096
00:42:57,388 --> 00:42:59,930
그리고 출력으로 다시 네 차원 텐서를

1097
00:42:59,930 --> 00:43:03,770
생성할 것이며, 여기서 모양은 이미지 수 n에 대해

1098
00:43:03,770 --> 00:43:06,970
각 이미지당 하나의 출력, c out입니다.

1099
00:43:06,970 --> 00:43:11,370
각 출력은 필터당 하나의 c out 특성 평면으로 구성됩니다.

1100
00:43:11,370 --> 00:43:15,810
그리고 각 평면은 h 프라임과 w 프라임이 됩니다.

1101
00:43:15,810 --> 00:43:20,010
이것이 합성곱 층의 일반적인 공식입니다.

1102
00:43:20,010 --> 00:43:21,690
그리고 합성곱 네트워크는

1103
00:43:21,690 --> 00:43:23,732
여러 개의 합성곱 층을

1104
00:43:23,732 --> 00:43:25,627
포함하는 계산 그래프입니다.

1105
00:43:25,627 --> 00:43:27,210
실제로 우리는 여러 개의

1106
00:43:27,210 --> 00:43:30,130
합성곱 연산자를 차례로 쌓는 경향이 있습니다.

1107
00:43:30,130 --> 00:43:32,750
여러 개의 합성곱 연산자를 쌓으면

1108
00:43:32,750 --> 00:43:35,570
그것이 합성곱 네트워크가 됩니다.

1109
00:43:35,570 --> 00:43:37,390
이것은 간단한 ConvNet입니다.

1110
00:43:37,390 --> 00:43:40,530
3x32x32 크기의 이미지로 시작한 다음,

1111
00:43:40,530 --> 00:43:43,110
6개의 필터가 있는 합성곱 층이 있습니다.

1112
00:43:43,110 --> 00:43:45,270
각 필터는 5x5x3입니다.

1113
00:43:45,270 --> 00:43:47,710
첫 번째 합성곱을 수행한 후, 우리는

1114
00:43:47,710 --> 00:43:51,430
그 하나의 이미지에 대해 새로운 3차원 활성화 세트를

1115
00:43:51,430 --> 00:43:55,350
얻습니다. 여기서 6개의 채널이 6개의 필터와 일치하며, 공간

1116
00:43:55,350 --> 00:43:57,230
크기가 합성곱을 통해 약간

1117
00:43:57,230 --> 00:43:58,848
변경되어 28x28이 됩니다.

1118
00:43:58,848 --> 00:44:00,390
그런 다음 10개의 필터가

1119
00:44:00,390 --> 00:44:04,590
있는 또 다른 합성곱이 있습니다. 각 필터는 5x5x6입니다.

1120
00:44:04,590 --> 00:44:06,830
그래서 10은 다음 합성곱

1121
00:44:06,830 --> 00:44:09,510
층의 출력 차원을 제공합니다.

1122
00:44:09,510 --> 00:44:12,068
그리고 이 6은 합성곱의 입력

1123
00:44:12,068 --> 00:44:14,110
채널 차원과 일치해야

1124
00:44:14,110 --> 00:44:15,910
하는 채널 수입니다.

1125
00:44:15,910 --> 00:44:17,972
그래서 이러한 합성곱 층을

1126
00:44:17,972 --> 00:44:19,430
여러 개 쌓고

1127
00:44:19,430 --> 00:44:21,950
많은 계산을 수행할 수 있습니다.

1128
00:44:21,950 --> 00:44:24,510
하지만 실제로 이 네트워크 아키텍처 디자인에는

1129
00:44:24,510 --> 00:44:25,730
문제가 있습니다.

1130
00:44:25,730 --> 00:44:27,562
누군가 그것을 발견할 수 있나요?

1131
00:44:27,562 --> 00:44:28,530
그것은 크기 조정입니다.

1132
00:44:28,530 --> 00:44:31,070
그것은 제가 생각한 문제는 아닙니다.

1133
00:44:31,070 --> 00:44:32,090
진화는 지역적입니다.

1134
00:44:32,090 --> 00:44:34,430
그것도 좋은 문제지만 제가 생각한 문제는 아닙니다.

1135
00:44:34,430 --> 00:44:36,510
사실, 이 두 가지는 몇 슬라이드 안에 쉽게

1136
00:44:36,510 --> 00:44:38,590
수정할 수 있지만, 제가 생각한 문제는 다릅니다.

1137
00:44:38,590 --> 00:44:41,170
많은 메모리가 문제지만 우리가 해결할 수 있는 것은 아닙니다.

1138
00:44:41,170 --> 00:44:44,580
더 큰 GPU를 사야 합니다.

1139
00:44:44,580 --> 00:44:45,928
필터 수가 증가합니다.

1140
00:44:45,928 --> 00:44:47,720
그것은 반드시 문제가 아니라고 생각합니다.

1141
00:44:47,720 --> 00:44:49,247
괜찮습니다.

1142
00:44:49,247 --> 00:44:50,080
모든 것이 선형입니다.

1143
00:44:50,080 --> 00:44:51,720
네, 그것은 문제입니다.

1144
00:44:51,720 --> 00:44:54,480
그래서 우리는 합성곱이 내적이라고 말했습니다.

1145
00:44:54,480 --> 00:44:56,540
내적은 선형 연산자입니다.

1146
00:44:56,540 --> 00:44:58,020
두 선형 연산자의 조합은

1147
00:44:58,020 --> 00:44:59,320
여전히 선형 연산자입니다.

1148
00:44:59,320 --> 00:45:01,820
즉, 서로 직접 쌓인 두 개의 합성곱

1149
00:45:01,820 --> 00:45:03,420
층이 실제로는 단일

1150
00:45:03,420 --> 00:45:05,920
합성곱 층과 동일한 표현력을 가지게

1151
00:45:05,920 --> 00:45:09,300
됩니다. 이는 연산자의 선형성 때문입니다.

1152
00:45:09,300 --> 00:45:11,580
그에 대한 매우 간단한 해결책이 있습니다.

1153
00:45:11,580 --> 00:45:12,720
활성화 함수를 추가하세요.

1154
00:45:12,720 --> 00:45:13,233
정확히 그렇습니다.

1155
00:45:13,233 --> 00:45:14,900
우리가 다층 신경망에서

1156
00:45:14,900 --> 00:45:16,760
보았던 동일한 버그와 동일한

1157
00:45:16,760 --> 00:45:17,760
수정입니다.

1158
00:45:17,760 --> 00:45:19,820
합성곱 층 사이에 비선형 활성화

1159
00:45:19,820 --> 00:45:21,620
함수를 추가해야 합니다.

1160
00:45:21,620 --> 00:45:23,540
이는 문제에 비선형성을

1161
00:45:23,540 --> 00:45:26,913
도입하고, 네트워크 아키텍처에 비선형성을

1162
00:45:26,913 --> 00:45:28,580
추가하여 우리가 학습하는

1163
00:45:28,580 --> 00:45:30,780
네트워크의 표현력을 증가시킵니다.

1164
00:45:30,780 --> 00:45:32,900
일반적으로 ConvNet은

1165
00:45:32,900 --> 00:45:35,820
합성곱 층, 비선형성 및

1166
00:45:35,820 --> 00:45:38,715
기타 종류의 층이 쌓인 형태입니다.

1167
00:45:38,715 --> 00:45:40,340
이전에 합성곱 필터가 무엇을

1168
00:45:40,340 --> 00:45:42,290
학습하는지에 대한 질문이 있었습니다.

1169
00:45:42,290 --> 00:45:44,210
이는 기본적으로 우리가 선형

1170
00:45:44,210 --> 00:45:47,290
분류기에서 이미 했던 것과 유사하게 볼 수 있습니다.

1171
00:45:47,290 --> 00:45:49,530
선형 분류기에서는 각 행이 학습된

1172
00:45:49,530 --> 00:45:51,988
가중치 행렬의 각 행이 전체

1173
00:45:51,988 --> 00:45:53,530
입력 이미지와 동일한

1174
00:45:53,530 --> 00:45:55,113
형태의 템플릿으로

1175
00:45:55,113 --> 00:45:57,510
시각화될 수 있다는 직관이 있습니다.

1176
00:45:57,510 --> 00:45:59,250
이제 합성곱 필터와 함께,

1177
00:45:59,250 --> 00:46:02,630
이를 동일하게 생각할 수 있지만, 이제 각 필터는

1178
00:46:02,630 --> 00:46:05,290
입력 이미지의 전체 공간 크기를 넘어서는

1179
00:46:05,290 --> 00:46:07,590
것이 아니라 이미지의 작은 부분,

1180
00:46:07,590 --> 00:46:09,050
작은 조각이 될 것입니다.

1181
00:46:09,050 --> 00:46:11,770
그래서 우리는 실제로 학습된

1182
00:46:11,770 --> 00:46:15,370
신경망의 첫 번째 층 합성곱 필터를 시각화할

1183
00:46:15,370 --> 00:46:16,850
수 있습니다.

1184
00:46:16,850 --> 00:46:19,770
이것들은 이미지 분류를 위해 ImageNet에서

1185
00:46:19,770 --> 00:46:22,010
학습된 AlexNet 아키텍처가

1186
00:46:22,010 --> 00:46:24,730
학습한 첫 번째 층 합성곱 필터입니다.

1187
00:46:24,730 --> 00:46:26,450
여기 각 필터는 기본적으로 RGB

1188
00:46:26,450 --> 00:46:27,992
이미지의 작은 조각입니다.

1189
00:46:27,992 --> 00:46:29,450
이것들은 AlexNet

1190
00:46:29,450 --> 00:46:31,890
아키텍처의 첫 번째 층에서 입력 이미지 주위를

1191
00:46:31,890 --> 00:46:33,770
슬라이드하는 작은 템플릿입니다.

1192
00:46:33,770 --> 00:46:36,210
이것이 AlexNet이고,

1193
00:46:36,210 --> 00:46:37,585
ImageNet에서 학습되었으며,

1194
00:46:37,585 --> 00:46:39,720
분류 작업이었기 때문에,

1195
00:46:39,720 --> 00:46:41,440
사실상 모든 합성곱

1196
00:46:41,440 --> 00:46:42,960
네트워크는 거의 모든 문제와

1197
00:46:42,960 --> 00:46:46,560
데이터 세트, 작업에서 이러한 필터를 학습하게

1198
00:46:46,560 --> 00:46:49,800
됩니다. 단, 합리적인 작업일 경우에 한합니다.

1199
00:46:49,800 --> 00:46:52,600
우리가 보는 것은 여기에서 두 가지 종류의

1200
00:46:52,600 --> 00:46:54,440
필터를 자주 학습한다는 것입니다.

1201
00:46:54,440 --> 00:46:56,180
하나는 색상을 찾는 경향이 있으며,

1202
00:46:56,180 --> 00:46:57,780
특히 반대 색상입니다.

1203
00:46:57,780 --> 00:46:59,320
그래서 이 필터는 녹색과

1204
00:46:59,320 --> 00:47:01,260
빨간색의 대비를 찾고 있습니다.

1205
00:47:01,260 --> 00:47:04,080
우리는 또한 분홍색과 녹색의 색깔 덩어리를 봅니다.

1206
00:47:04,080 --> 00:47:06,600
우리가 자주 보는 다른 범주의

1207
00:47:06,600 --> 00:47:10,180
필터는 이미지의 공간 구조를 찾는 것입니다.

1208
00:47:10,180 --> 00:47:12,320
예를 들어, 이 필터는 수직 에지를 찾고,

1209
00:47:12,320 --> 00:47:13,560
수평 에지를 찾고 있습니다.

1210
00:47:13,560 --> 00:47:16,000
이 필터는 수직 에지를 찾고 있으며,

1211
00:47:16,000 --> 00:47:18,060
일부는 대각선 에지를 찾고 있습니다.

1212
00:47:18,060 --> 00:47:20,560
그래서 그들은 색상과 에지를 찾는 경향이 있습니다.

1213
00:47:20,560 --> 00:47:23,680
그리고 이러한 입력 이미지의

1214
00:47:23,680 --> 00:47:25,807
작은 지역 이웃에서.

1215
00:47:25,807 --> 00:47:27,640
그래서 우리는 합성곱 필터의 첫 번째

1216
00:47:27,640 --> 00:47:30,140
층에서 이 트릭을 사용하여 직접 이미지를 시각화할

1217
00:47:30,140 --> 00:47:30,820
수 있습니다.

1218
00:47:30,820 --> 00:47:33,028
네트워크의 높은 층을 시각화하는 것은 조금

1219
00:47:33,028 --> 00:47:33,960
더 복잡해집니다.

1220
00:47:33,960 --> 00:47:36,220
이 그림에 대해서는 설명하지 않겠습니다.

1221
00:47:36,220 --> 00:47:39,080
그냥 너무 많은 설명 없이 제시할 것입니다.

1222
00:47:39,080 --> 00:47:41,100
하지만 네트워크의 높은 층은 입력

1223
00:47:41,100 --> 00:47:44,260
이미지의 더 큰 공간 구조를 학습하는 경향이 있습니다.

1224
00:47:44,260 --> 00:47:47,420
여기에서 시각화는 각 행이 학습된

1225
00:47:47,420 --> 00:47:50,580
네트워크의 필터를 나타내고, 각 열은

1226
00:47:50,580 --> 00:47:53,180
해당 필터가 강하게 반응한

1227
00:47:53,180 --> 00:47:55,840
입력 이미지의 일부를 나타냅니다.

1228
00:47:55,840 --> 00:47:57,500
그래서 여기 시각화는 이전

1229
00:47:57,500 --> 00:47:59,420
슬라이드와는 약간 다릅니다.

1230
00:47:59,420 --> 00:48:01,900
이것들은 필터가 반응하는 입력

1231
00:48:01,900 --> 00:48:03,680
이미지의 조각들입니다.

1232
00:48:03,680 --> 00:48:06,140
여기서 이 6층 합성곱 필터 중

1233
00:48:06,140 --> 00:48:09,420
하나가 아마도 눈에 반응하는 것처럼 보입니다.

1234
00:48:09,420 --> 00:48:12,740
이것은 아마도 텍스트 조각에 반응하는 것처럼 보입니다.

1235
00:48:12,740 --> 00:48:15,740
이것은 아마도 바퀴나 원, 또는 원의 윗부분에

1236
00:48:15,740 --> 00:48:17,080
반응하는 것처럼 보입니다.

1237
00:48:17,080 --> 00:48:18,500
그런 것 같습니다.

1238
00:48:18,500 --> 00:48:21,660
그리고 다시 말하지만, 이것은 모두 대규모 데이터

1239
00:48:21,660 --> 00:48:24,940
세트에 대한 훈련을 통해 경량 하강법으로 구동됩니다.

1240
00:48:24,940 --> 00:48:28,020
아무도 손으로 이러한 필터를 설계하지 않습니다.

1241
00:48:28,020 --> 00:48:30,460
그리고 제가 말했듯이, 이러한 고차원 필터를

1242
00:48:30,460 --> 00:48:32,740
시각화하는 것은 약간 까다롭고 더 복잡합니다.

1243
00:48:32,740 --> 00:48:37,230
질문은 필터에 대한 모든 반응을 보면 원본 이미지를

1244
00:48:37,230 --> 00:48:39,410
재구성할 수 있는가였습니다.

1245
00:48:39,410 --> 00:48:41,110
실제로, 그렇게 할 수 있습니다.

1246
00:48:41,110 --> 00:48:42,890
그 방법과 요령도

1247
00:48:42,890 --> 00:48:45,050
경량 하강법입니다.

1248
00:48:45,050 --> 00:48:46,710
경량 하강법은 정말 강력합니다.

1249
00:48:46,710 --> 00:48:49,377
그리고 그것은 우리가 다음 몇 강의에서

1250
00:48:49,377 --> 00:48:52,025
다룰 메커니즘에 대해 이야기할 것입니다.

1251
00:48:52,025 --> 00:48:53,150
오, 좋은 질문입니다.

1252
00:48:53,150 --> 00:48:56,130
필터가 어떻게 구분되는가요?

1253
00:48:56,130 --> 00:48:58,435
그것은 실제로 무작위 초기화에 달려 있습니다.

1254
00:48:58,435 --> 00:49:00,810
그러므로 필터를 초기화하는 방식이

1255
00:49:00,810 --> 00:49:02,750
무작위인 것이 정말 중요합니다.

1256
00:49:02,750 --> 00:49:05,570
그리고 중요한 것은 네트워크 훈련을 시작할 때 각

1257
00:49:05,570 --> 00:49:07,778
필터에 대해 다른 초기화를 가져야 한다는

1258
00:49:07,778 --> 00:49:09,528
것입니다. 그래야 필터 간의

1259
00:49:09,528 --> 00:49:10,390
대칭이 깨집니다.

1260
00:49:10,390 --> 00:49:12,543
모든 필터가 정확히 동일하면

1261
00:49:12,543 --> 00:49:14,210
손실도 동일하므로 그 경량은

1262
00:49:14,210 --> 00:49:16,590
모든 필터에 동일하게 전파됩니다.

1263
00:49:16,590 --> 00:49:19,170
그래서 동일하게 초기화하면 그대로 유지됩니다.

1264
00:49:19,170 --> 00:49:20,870
하지만 다르게 초기화하면 대칭이

1265
00:49:20,870 --> 00:49:22,495
깨지고 서로 다른 특징을

1266
00:49:22,495 --> 00:49:23,770
학습할 수 있습니다.

1267
00:49:23,770 --> 00:49:23,970
네.

1268
00:49:23,970 --> 00:49:25,922
기본적으로 네트워크의 인간

1269
00:49:25,922 --> 00:49:28,130
설계자는 연산자와 채널의 순서를

1270
00:49:28,130 --> 00:49:29,590
기록해야 합니다.

1271
00:49:29,590 --> 00:49:31,530
그리고 그것이 신경망 아키텍처

1272
00:49:31,530 --> 00:49:33,447
설계의 질문이며, 다음 강의에서

1273
00:49:33,447 --> 00:49:35,280
조금 더 이야기할 것입니다.

1274
00:49:35,280 --> 00:49:38,320
세 번째 질문은 왜 더 깊은 층이 더 큰 구조를

1275
00:49:38,320 --> 00:49:40,445
시각화하는가인데, 이는 우리가 곧

1276
00:49:40,445 --> 00:49:42,278
슬라이드에서 다룰 수용 필드와

1277
00:49:42,278 --> 00:49:43,460
관련이 있습니다.

1278
00:49:43,460 --> 00:49:44,620
그래서 아마도 그곳에 도달할 것입니다.

1279
00:49:44,620 --> 00:49:46,537
그리고 몇 가지 질문이 답변될

1280
00:49:46,537 --> 00:49:47,745
것 같습니다.

1281
00:49:47,745 --> 00:49:49,120
이미 언급된 한 가지는

1282
00:49:49,120 --> 00:49:50,912
이러한 합성곱의 공간 차원을

1283
00:49:50,912 --> 00:49:52,200
어떻게 살펴보는가입니다.

1284
00:49:52,200 --> 00:49:54,232
그래서 저는 합성곱의 공간 차원을

1285
00:49:54,232 --> 00:49:56,440
정확히 어떻게 계산하는지 더 자세히

1286
00:49:56,440 --> 00:49:58,040
살펴보기를 원했습니다.

1287
00:49:58,040 --> 00:50:00,320
그래서 여기서 우리는 이

1288
00:50:00,320 --> 00:50:02,580
합성곱의 사진을 가져왔습니다.

1289
00:50:02,580 --> 00:50:05,392
우리는 그것을 90도 회전시키고 채널 차원을 제거하고 있습니다.

1290
00:50:05,392 --> 00:50:07,600
그래서 이제 채널 차원은 보드 안으로 들어갑니다.

1291
00:50:07,600 --> 00:50:10,385
그리고 우리는 7x7의 공간 차원을 가지고 있습니다.

1292
00:50:10,385 --> 00:50:11,760
여기서 우리는 공간 크기가

1293
00:50:11,760 --> 00:50:13,540
7x7인 입력을 보고 있습니다.

1294
00:50:13,540 --> 00:50:15,300
그리고 3x3의 컨볼루션 커널이 있습니다.

1295
00:50:15,300 --> 00:50:16,680
그런데 질문은 여기서

1296
00:50:16,680 --> 00:50:19,200
우리의 출력 크기가 얼마나 될 것인가입니다.

1297
00:50:19,200 --> 00:50:23,580
음, 1, 2, 3, 4, 5.

1298
00:50:23,580 --> 00:50:25,100
우리의 출력은 5x5가 될

1299
00:50:25,100 --> 00:50:27,142
것이며, 필터를 슬라이드하여 5개의 다른

1300
00:50:27,142 --> 00:50:28,560
공간에 놓을 수 있습니다.

1301
00:50:28,560 --> 00:50:30,180
그리고 우리는 이를 일반화할 수 있습니다.

1302
00:50:30,180 --> 00:50:33,710
입력이 길이 w이고, 컨볼루션 필터가 길이 k일 경우,

1303
00:50:33,710 --> 00:50:36,280
출력은 w - k + 1이 됩니다.

1304
00:50:36,280 --> 00:50:38,030
이것이 올바른 공식임을

1305
00:50:38,030 --> 00:50:39,900
스스로 확인할 수 있습니다.

1306
00:50:39,900 --> 00:50:42,150
하지만 몇몇 사람들이 이미 지적한

1307
00:50:42,150 --> 00:50:44,727
문제는 특성 맵이 이 컨볼루션을

1308
00:50:44,727 --> 00:50:46,310
거치면서 공간 크기가

1309
00:50:46,310 --> 00:50:47,670
줄어든다는 것입니다.

1310
00:50:47,670 --> 00:50:49,078
그것은 성가십니다.

1311
00:50:49,078 --> 00:50:51,370
사실, 그것을 가지고 작업할 수 있습니다.

1312
00:50:51,370 --> 00:50:53,328
그것을 다루는 신경망 아키텍처도

1313
00:50:53,328 --> 00:50:54,170
있습니다.

1314
00:50:54,170 --> 00:50:55,670
하지만 가끔 우리는 게을러서

1315
00:50:55,670 --> 00:50:59,110
모든 것이 같은 크기를 유지하기를 원합니다. 왜냐하면 그것이

1316
00:50:59,110 --> 00:51:01,870
인간 디자이너가 생각하기에 더 간단하기 때문입니다.

1317
00:51:01,870 --> 00:51:05,430
그곳에서 우리가 사용하는 한 가지 트릭은 패딩이라고 불리는 것입니다.

1318
00:51:05,430 --> 00:51:08,810
여기서는 입력 데이터 주위에 가상 데이터와 같은

1319
00:51:08,810 --> 00:51:10,830
추가 데이터를 추가하는

1320
00:51:10,830 --> 00:51:13,430
것이 일반적입니다. 즉, 컨볼루션

1321
00:51:13,430 --> 00:51:16,750
연산자를 계산하기 전에 실제 입력 데이터 주위에

1322
00:51:16,750 --> 00:51:19,150
추가적인 0을 추가하는 것입니다.

1323
00:51:19,150 --> 00:51:22,750
이제 이것은 우리가 이 특성 맵 축소 문제를 해결할 수

1324
00:51:22,750 --> 00:51:23,490
있게 해줍니다.

1325
00:51:23,490 --> 00:51:25,190
왜냐하면 이제 p의

1326
00:51:25,190 --> 00:51:28,530
패딩을 추가하면, 이 경우 p는 1입니다.

1327
00:51:28,530 --> 00:51:31,450
모든 곳에 1픽셀의 0을 추가하므로,

1328
00:51:31,450 --> 00:51:35,010
우리는 기본적으로 출력 크기에 2p를 추가합니다.

1329
00:51:35,010 --> 00:51:39,010
특히, 3x3 컨볼루션이 있고 패딩을 1로

1330
00:51:39,010 --> 00:51:41,850
추가하면, 특성 맵은 같은 크기를

1331
00:51:41,850 --> 00:51:43,230
유지합니다.

1332
00:51:43,230 --> 00:51:44,667
그것은 편리합니다.

1333
00:51:44,667 --> 00:51:46,250
이제 신호 처리에 대해 배운 적이

1334
00:51:46,250 --> 00:51:48,330
있다면, 여기에는 몇 가지 문제가 있습니다.

1335
00:51:48,330 --> 00:51:51,330
신호 처리 관점에서 이상한 현상이 발생할 수 있지만,

1336
00:51:51,330 --> 00:51:53,010
우리는 그것을 무시하고

1337
00:51:53,010 --> 00:51:55,650
텐서의 크기와 형태만 살펴보겠습니다. 왜냐하면

1338
00:51:55,650 --> 00:51:58,170
그것이 이해하기 조금 더 쉽기 때문입니다.

1339
00:51:58,170 --> 00:52:00,097
하지만 왜 0을 추가하는지 인식하세요.

1340
00:52:00,097 --> 00:52:01,430
그것이 문제를 일으킬까요?

1341
00:52:01,430 --> 00:52:03,513
네, 경계에서 문제가

1342
00:52:03,513 --> 00:52:07,030
발생할 것이지만, 많은 경우에 그렇습니다.

1343
00:52:07,030 --> 00:52:07,530
좋습니다.

1344
00:52:07,530 --> 00:52:07,830
네.

1345
00:52:07,830 --> 00:52:10,163
그래서 제가 말했듯이, 꽤 일반적인

1346
00:52:10,163 --> 00:52:12,970
설정은 p를 설정하고 k를 홀수로

1347
00:52:12,970 --> 00:52:15,670
두고 p를 (k - 1) / 2로 두는

1348
00:52:15,670 --> 00:52:18,408
것입니다. 이는 컨볼루션 후의 공간

1349
00:52:18,408 --> 00:52:20,450
크기가 컨볼루션 전의 공간

1350
00:52:20,450 --> 00:52:22,650
크기와 같다는 것을 의미합니다.

1351
00:52:22,650 --> 00:52:25,090
그 다음으로 생각할 흥미로운 것은

1352
00:52:25,090 --> 00:52:27,070
수용 필드의 개념입니다.

1353
00:52:27,070 --> 00:52:29,250
누군가 여기서 깊은 층이 더 큰

1354
00:52:29,250 --> 00:52:31,980
구조를 배우는 이유를 조금 물어보았습니다.

1355
00:52:31,980 --> 00:52:35,600
그것은 사실 컨볼루션이 구축되는 방식에 내재되어 있습니다.

1356
00:52:35,600 --> 00:52:38,440
따라서 단일 컨볼루션을 생각할 때, 각

1357
00:52:38,440 --> 00:52:41,660
출력은 입력의 이 지역을 보고 있습니다.

1358
00:52:41,660 --> 00:52:45,717
설계상, 첫 번째 레이어의 하나의 컨볼루션 출력은 학습

1359
00:52:45,717 --> 00:52:47,800
중인 컨볼루션 커널과 동일한

1360
00:52:47,800 --> 00:52:49,760
크기의 이미지 조각만을

1361
00:52:49,760 --> 00:52:51,000
볼 수 있습니다.

1362
00:52:51,000 --> 00:52:54,238
하지만 여러 개의 컨볼루션을 쌓아 올린 ConvNet을

1363
00:52:54,238 --> 00:52:56,280
구축하면, 이러한 수용 영역이

1364
00:52:56,280 --> 00:52:58,080
네트워크를 통해 확대됩니다.

1365
00:52:58,080 --> 00:53:01,840
따라서 이 경우, 우리는 세 개의 컨볼루션 레이어가 있는

1366
00:53:01,840 --> 00:53:03,460
네트워크를 보고 있습니다.

1367
00:53:03,460 --> 00:53:07,380
그리고 우리는 활성화의 마지막 레이어에서 이를 확인합니다.

1368
00:53:07,380 --> 00:53:11,640
여기 각 항목은 이전 레이어의 지역에

1369
00:53:11,640 --> 00:53:12,620
의존합니다.

1370
00:53:12,620 --> 00:53:14,440
하지만 각 항목은 차례로

1371
00:53:14,440 --> 00:53:17,580
이전 레이어의 지역에 의존하며, 이는

1372
00:53:17,580 --> 00:53:20,800
다시 이전 레이어의 지역에 의존합니다.

1373
00:53:20,800 --> 00:53:22,500
따라서 이러한 컨볼루션이

1374
00:53:22,500 --> 00:53:24,760
있을 때, 각 개별

1375
00:53:24,760 --> 00:53:26,320
컨볼루션이 이전 레이어의

1376
00:53:26,320 --> 00:53:28,470
지역을 보고 있지만,

1377
00:53:28,470 --> 00:53:31,070
여러 레이어에 걸쳐 컨볼루션을

1378
00:53:31,070 --> 00:53:33,390
쌓으면, 각 컨볼루션이 보는

1379
00:53:33,390 --> 00:53:37,630
원래 입력의 유효 크기가 네트워크를 통해 증가합니다.

1380
00:53:37,630 --> 00:53:40,470
특히 이것을 우리는 유효 수용

1381
00:53:40,470 --> 00:53:42,370
영역이라고 부릅니다.

1382
00:53:42,370 --> 00:53:44,750
컨볼루션의 유효 수용 영역은

1383
00:53:44,750 --> 00:53:47,950
기본적으로 원래 이미지의 몇 개의

1384
00:53:47,950 --> 00:53:52,430
픽셀이 나중에 네트워크의 하나의 활성화에 영향을 미칠

1385
00:53:52,430 --> 00:53:54,430
수 있는지를 나타냅니다.

1386
00:53:54,430 --> 00:53:56,670
컨볼루션이 실제로 유효 수용 영역이

1387
00:53:56,670 --> 00:53:58,390
컨볼루션 레이어의 수에

1388
00:53:58,390 --> 00:54:01,630
따라 선형적으로 증가한다는 점에 주목할 것입니다.

1389
00:54:01,630 --> 00:54:04,510
여기에는 잠재적인 문제가 있습니다. 왜냐하면

1390
00:54:04,510 --> 00:54:06,978
궁극적으로 네트워크의 끝에서 분류 결정을

1391
00:54:06,978 --> 00:54:09,270
내릴 때, 우리는 분류 결정이 전체

1392
00:54:09,270 --> 00:54:12,510
이미지에 걸쳐 글로벌 정보를 집계하기를 원하기 때문입니다.

1393
00:54:12,510 --> 00:54:14,750
하지만 이를 위해서는 많은 컨볼루션 레이어가 필요합니다.

1394
00:54:14,750 --> 00:54:18,070
따라서 여기서의 한 가지 요령은 유효 수용 영역을

1395
00:54:18,070 --> 00:54:21,310
더 빠르게 증가시키는 방법을 추가하는 것입니다.

1396
00:54:21,310 --> 00:54:23,270
컨볼루션에서 이를 수행하는 한 가지

1397
00:54:23,270 --> 00:54:25,590
방법은 스트라이드를 도입하는 것입니다.

1398
00:54:25,590 --> 00:54:27,580
따라서 여기서 우리가 말하는 것은

1399
00:54:27,580 --> 00:54:30,320
필터를 이미지의 모든 곳에 배치하는 대신 일부를

1400
00:54:30,320 --> 00:54:31,440
건너뛴다는 것입니다.

1401
00:54:31,440 --> 00:54:34,020
따라서 수용 영역을 1만큼

1402
00:54:34,020 --> 00:54:35,760
이동하는 대신

1403
00:54:35,760 --> 00:54:37,900
2만큼 스트라이드합니다.

1404
00:54:37,900 --> 00:54:41,100
따라서 이제 이 경우, 7x7 입력으로 돌아가서 3x3 컨볼루션을

1405
00:54:41,100 --> 00:54:42,180
스트라이드 2로 수행합니다.

1406
00:54:42,180 --> 00:54:43,900
이제 출력 크기는 무엇입니까?

1407
00:54:43,900 --> 00:54:45,852
1, 2, 3.

1408
00:54:45,852 --> 00:54:47,900
3x3.

1409
00:54:47,900 --> 00:54:50,700
그리고 일반적으로 입력 w 필터

1410
00:54:50,700 --> 00:54:53,420
크기 k 패딩 p 스트라이드 s가

1411
00:54:53,420 --> 00:54:57,580
있으면, 출력 크기에 대한 이 복잡한 공식을 얻습니다:

1412
00:54:57,580 --> 00:54:58,740
w - k.

1413
00:54:58,740 --> 00:55:03,460
더 큰 커널은 입력을 축소하고, 2P 패딩은 누락된 크기를

1414
00:55:03,460 --> 00:55:06,360
다시 추가하며, 스트라이드로 나눕니다.

1415
00:55:06,360 --> 00:55:09,060
스트라이드는 입력 모양을 나누고,

1416
00:55:09,060 --> 00:55:14,140
1을 더합니다. 이는 일부 울타리 기둥 수학 때문입니다.

1417
00:55:14,140 --> 00:55:16,100
좋습니다, 따라서 스트라이드 컨볼루션은

1418
00:55:16,100 --> 00:55:18,540
흥미롭습니다. 왜냐하면 이 그림으로 돌아가면,

1419
00:55:18,540 --> 00:55:20,240
이제 스트라이드 컨볼루션을 수행할 때,

1420
00:55:20,240 --> 00:55:21,940
신경망 내부에서 이미지를 효과적으로

1421
00:55:21,940 --> 00:55:23,400
다운샘플링하기 때문입니다.

1422
00:55:23,400 --> 00:55:25,460
따라서 스트라이드 컨볼루션이 있을

1423
00:55:25,460 --> 00:55:27,560
때, 각 컨볼루션 레이어는

1424
00:55:27,560 --> 00:55:30,820
일반적으로 피처 맵의 모양을 2로 나누는 것과 같습니다.

1425
00:55:30,820 --> 00:55:32,240
그리고 이를 쌓으면, 이제

1426
00:55:32,240 --> 00:55:34,115
유효 수용 영역에서 기하급수적인

1427
00:55:34,115 --> 00:55:35,660
성장을 얻을 수 있습니다.

1428
00:55:35,660 --> 00:55:37,680
따라서 각 컨볼루션 레이어가 실제로

1429
00:55:37,680 --> 00:55:40,480
2의 배수로 다운샘플링되는 경우, 유사한

1430
00:55:40,480 --> 00:55:42,272
연습을 통해 네트워크의 깊이에

1431
00:55:42,272 --> 00:55:44,438
따라 유효 수용 영역이 기하급수적으로

1432
00:55:44,438 --> 00:55:46,580
증가하는 것을 확인할 수 있습니다.

1433
00:55:46,580 --> 00:55:48,820
즉, 상대적으로 적은 레이어로도

1434
00:55:48,820 --> 00:55:51,320
전체 입력 이미지를 보는 매우

1435
00:55:51,320 --> 00:55:54,720
큰 유효 수용 영역을 구축할 수 있습니다.

1436
00:55:54,720 --> 00:55:57,640
여기서, 모두가 컨볼루션에 대해 같은 페이지에 있는지

1437
00:55:57,640 --> 00:56:00,360
확인하기 위해 하나의 예제를 살펴보겠습니다.

1438
00:56:00,360 --> 00:56:03,800
여기서, 3x32x32의 입력 볼륨을 생각해 봅시다.

1439
00:56:03,800 --> 00:56:06,220
10개의 필터가 있는 컨볼루션 레이어를 생각해

1440
00:56:06,220 --> 00:56:10,240
보겠습니다. 각 필터는 5x5이며 스트라이드는 1, 패드는 2입니다.

1441
00:56:10,240 --> 00:56:11,598
출력 크기는 얼마인가요?

1442
00:56:11,598 --> 00:56:13,640
여기 숫자가 많아서

1443
00:56:13,640 --> 00:56:15,360
색상을 구분했습니다.

1444
00:56:15,360 --> 00:56:18,760
여기서는 10 x 32 x 32입니다.

1445
00:56:18,760 --> 00:56:21,420
이 32는 사실 이 32와 다른 32입니다.

1446
00:56:21,420 --> 00:56:23,750
그래서 색상이 다른 파란색입니다.

1447
00:56:23,750 --> 00:56:26,390
하지만 이 10은 출력 채널의 수입니다.

1448
00:56:26,390 --> 00:56:29,230
출력 채널은 필터의 수와 일치해야 합니다.

1449
00:56:29,230 --> 00:56:32,390
공간 크기는 우리가 방금 본 공식을 사용하여

1450
00:56:32,390 --> 00:56:33,030
계산됩니다.

1451
00:56:33,030 --> 00:56:37,430
그래서 입력 공간 크기는 여기 아래로 내려오고 2를 더합니다-- 패딩이

1452
00:56:37,430 --> 00:56:38,890
여기 아래로 내려옵니다.

1453
00:56:38,890 --> 00:56:42,910
패딩은 공간 크기를 더하고, 5는 공간 크기를 나누는

1454
00:56:42,910 --> 00:56:45,290
합성곱 커널이며, 보폭은 1입니다.

1455
00:56:45,290 --> 00:56:46,890
그래서 이는 사소한 것이고, 1을 더합니다.

1456
00:56:46,890 --> 00:56:49,310
그리고 이것은 우연히 32가 됩니다.

1457
00:56:49,310 --> 00:56:51,270
그래서 이 경우, 이는 우리가 몇 슬라이드

1458
00:56:51,270 --> 00:56:53,733
전에 이야기한 것과 같은 패턴을 따릅니다. 즉,

1459
00:56:53,733 --> 00:56:55,650
불규칙한 형태의 합성곱 커널입니다.

1460
00:56:55,650 --> 00:56:56,650
이 경우는 5입니다.

1461
00:56:56,650 --> 00:56:57,950
패딩은 2입니다.

1462
00:56:57,950 --> 00:57:01,130
그래서 커널 크기가 2k + 1이면,

1463
00:57:01,130 --> 00:57:05,630
k의 패딩은 같은 공간 크기를 유지합니다.

1464
00:57:05,630 --> 00:57:08,487
여기에서 학습 가능한 매개변수의 수입니다.

1465
00:57:08,487 --> 00:57:11,070
아마도 저는 이것들을 살펴볼 것입니다. 왜냐하면 우리는 몇

1466
00:57:11,070 --> 00:57:12,750
개의 슬라이드를 더 지나가야 하니까요.

1467
00:57:12,750 --> 00:57:15,310
그래서 이 경우 학습 가능한

1468
00:57:15,310 --> 00:57:19,670
매개변수의 수는 760입니다. 각 필터는 기본적으로 3 x 5

1469
00:57:19,670 --> 00:57:20,830
x 5입니다.

1470
00:57:20,830 --> 00:57:22,600
그리고 우리는 바이어스 하나가 있습니다.

1471
00:57:22,600 --> 00:57:25,040
그래서 필터당 76개의 학습 가능한 매개변수가 있습니다.

1472
00:57:25,040 --> 00:57:26,000
우리는 10개의 필터가 있습니다.

1473
00:57:26,000 --> 00:57:27,740
그래서 여기에서 760개의

1474
00:57:27,740 --> 00:57:30,580
학습 가능한 매개변수가 됩니다.

1475
00:57:30,580 --> 00:57:33,083
우리는 또한 곱셈-덧셈 연산의 수를 계산할 수 있습니다.

1476
00:57:33,083 --> 00:57:35,000
이 합성곱 커널이 얼마나 많은 계산을

1477
00:57:35,000 --> 00:57:37,740
하는지, 이 합성곱 연산자가 얼마나 많은 계산을 하는지.

1478
00:57:37,740 --> 00:57:39,230
그래서 여기서는 많습니다.

1479
00:57:39,230 --> 00:57:39,980
음, 많나요?

1480
00:57:39,980 --> 00:57:40,580
모르겠습니다.

1481
00:57:40,580 --> 00:57:42,580
많은 계산이 무엇인지에 대한

1482
00:57:42,580 --> 00:57:45,040
직관이 많지 않을 수도 있습니다.

1483
00:57:45,040 --> 00:57:47,560
하지만 이 경우, 제가 생각하는 계산 방식은,

1484
00:57:47,560 --> 00:57:50,500
얼마나 많은 플롭이 있는지, 합성곱 연산자가 얼마나

1485
00:57:50,500 --> 00:57:52,620
많은 계산을 하는지, 출력 볼륨 크기가

1486
00:57:52,620 --> 00:57:54,700
10 x 32 x 32라는 것입니다.

1487
00:57:54,700 --> 00:57:56,940
그리고 우리는 그 출력 볼륨의 각

1488
00:57:56,940 --> 00:58:00,020
항목이 필터 중 하나와 입력의 조각 간의 내적을

1489
00:58:00,020 --> 00:58:02,640
통해 계산되었다는 것을 알고 있습니다.

1490
00:58:02,640 --> 00:58:05,060
그래서 이 경우, 우리는 총 플롭 수를 알고

1491
00:58:05,060 --> 00:58:08,720
있습니다. 출력 수가 10 x 32 x 32이므로 약 10,000입니다.

1492
00:58:08,720 --> 00:58:10,580
그런 다음 각 출력은

1493
00:58:10,580 --> 00:58:14,740
3x5x5 필터와 3x5x5 이미지 조각의 내적을

1494
00:58:14,740 --> 00:58:16,080
통해 계산됩니다.

1495
00:58:16,080 --> 00:58:17,840
그래서 총 75개의 요소입니다.

1496
00:58:17,840 --> 00:58:22,130
이들을 곱하면 약 768,000개의 부동

1497
00:58:22,130 --> 00:58:26,130
소수점 곱셈-덧셈 연산이 필요합니다.

1498
00:58:26,130 --> 00:58:28,130
좋습니다, 그러면 여기 컨볼루션의

1499
00:58:28,130 --> 00:58:29,932
한 줄 요약이 있습니다.

1500
00:58:29,932 --> 00:58:31,390
이 내용을 자세히 설명하지는 않을 것입니다.

1501
00:58:31,390 --> 00:58:33,170
이것은 나중에 여러분이 보도록 하기 위한 것입니다.

1502
00:58:33,170 --> 00:58:35,170
하지만 이것은 컨볼루션 레이어와

1503
00:58:35,170 --> 00:58:38,530
관련된 모든 하이퍼파라미터와 공식을 요약합니다.

1504
00:58:38,530 --> 00:58:41,690
PyTorch를 보면, PyTorch는 많은 사람들이

1505
00:58:41,690 --> 00:58:43,610
사용하는 딥러닝 프레임워크입니다.

1506
00:58:43,610 --> 00:58:45,610
이 합성곱 층에는 우리가

1507
00:58:45,610 --> 00:58:48,190
이야기했던 모든 하이퍼파라미터가 있습니다.

1508
00:58:48,190 --> 00:58:50,273
우리가 이야기하지 않은 그룹과 팽창이라는

1509
00:58:50,273 --> 00:58:52,930
몇 가지 흥미로운 하이퍼파라미터가 있습니다.

1510
00:58:52,930 --> 00:58:54,910
팽창은 요즘 그렇게 많이 사용되지 않습니다.

1511
00:58:54,910 --> 00:58:56,850
그룹은 가끔 사용됩니다.

1512
00:58:56,850 --> 00:59:00,410
하지만 아마도 나중 강의에서 그것들에 대해 이야기할 것입니다.

1513
00:59:00,410 --> 00:59:03,290
다른 종류의 합성곱도 가능합니다.

1514
00:59:03,290 --> 00:59:04,950
우리는 2D 합성곱에 대해 이야기했습니다.

1515
00:59:04,950 --> 00:59:07,930
우리는 1D 합성곱도 할 수 있습니다. 여기서는 필터를

1516
00:59:07,930 --> 00:59:10,630
슬라이드하는 2차원 신호 대신 1차원 신호를

1517
00:59:10,630 --> 00:59:13,650
가지고 있으며, 자유도가 하나 있는 필터를 슬라이드합니다.

1518
00:59:13,650 --> 00:59:15,610
또는 3차원 합성곱을 할

1519
00:59:15,610 --> 00:59:17,302
수 있습니다. 여기서는 3차원

1520
00:59:17,302 --> 00:59:19,010
신호와 3차원 필터가 있으며,

1521
00:59:19,010 --> 00:59:21,552
이제 그 필터를 3D 공간의 모든 곳에서

1522
00:59:21,552 --> 00:59:24,170
슬라이드하여 입력 신호와 합성곱할 수 있습니다.

1523
00:59:24,170 --> 00:59:25,670
그래서 컨볼루션의

1524
00:59:25,670 --> 00:59:27,430
개념은 단순히 2차원

1525
00:59:27,430 --> 00:59:29,550
이미지를 넘어 확장됩니다.

1526
00:59:29,550 --> 00:59:30,090
좋아요.

1527
00:59:30,090 --> 00:59:33,070
기본적으로 컨볼루션에 관한 모든 것입니다.

1528
00:59:33,070 --> 00:59:34,710
마지막은 풀링입니다.

1529
00:59:34,710 --> 00:59:36,950
다행히도 풀링은 꽤 간단합니다.

1530
00:59:36,950 --> 00:59:40,470
풀링 레이어는 기본적으로 신경망 내부에서 다운샘플링하는

1531
00:59:40,470 --> 00:59:41,650
또 다른 방법입니다.

1532
00:59:41,650 --> 00:59:43,310
우리는 스트라이드 컨볼루션이 신경망

1533
00:59:43,310 --> 00:59:45,190
내부에서 다운샘플링할 수 있는 한 가지

1534
00:59:45,190 --> 00:59:46,250
방법임을 보았습니다.

1535
00:59:46,250 --> 00:59:48,550
다운샘플링은 네트워크의 깊이를 거치면서

1536
00:59:48,550 --> 00:59:50,190
수용 필드를 더 빨리 구축할

1537
00:59:50,190 --> 00:59:52,550
수 있게 해주기 때문에 유용합니다.

1538
00:59:52,550 --> 00:59:54,270
하지만 합성곱은 실제로 여전히

1539
00:59:54,270 --> 00:59:55,810
상당한 계산 비용이 듭니다.

1540
00:59:55,810 --> 00:59:59,510
그래서 합성곱은 합성곱 신경망에서 대부분의 플롭스와

1541
00:59:59,510 --> 01:00:01,090
계산이 발생하는 곳입니다.

1542
01:00:01,090 --> 01:00:02,673
풀링 레이어는 기본적으로

1543
01:00:02,673 --> 01:00:04,690
매우 저렴한 다운샘플링 방법입니다.

1544
01:00:04,690 --> 01:00:06,830
많은 계산 비용이 들지 않습니다.

1545
01:00:06,830 --> 01:00:08,830
풀링 레이어의 아이디어는

1546
01:00:08,830 --> 01:00:12,270
64 x 112 x 112인 3차원 텐서를

1547
01:00:12,270 --> 01:00:13,770
주어진 것입니다.

1548
01:00:13,770 --> 01:00:15,948
이를 112 x 112의

1549
01:00:15,948 --> 01:00:17,740
공간 크기를 가진 특징의

1550
01:00:17,740 --> 01:00:20,760
3차원 볼륨으로 생각해야 하며, 64개의

1551
01:00:20,760 --> 01:00:24,220
평면, 64개의 활성화 채널이 있습니다.

1552
01:00:24,220 --> 01:00:26,660
이제 우리가 할 것은 각 평면을 112

1553
01:00:26,660 --> 01:00:29,043
x 112 이미지로 가져오는 것입니다.

1554
01:00:29,043 --> 01:00:30,460
그런 다음 각 개별

1555
01:00:30,460 --> 01:00:32,560
특징 평면을 입력 텐서에서

1556
01:00:32,560 --> 01:00:34,060
꺼내 독립적으로

1557
01:00:34,060 --> 01:00:36,260
다운샘플링하고, 다시 쌓아 출력을

1558
01:00:36,260 --> 01:00:37,520
계산하는 것입니다.

1559
01:00:37,520 --> 01:00:41,200
그러면 이 입력 64 x 224 x 224에서

1560
01:00:41,200 --> 01:00:43,860
각 224 x 224 평면을

1561
01:00:43,860 --> 01:00:45,580
독립적으로 추출하여

1562
01:00:45,580 --> 01:00:48,640
다운샘플링한 후 같은 수의 채널로 재조합하되

1563
01:00:48,640 --> 01:00:50,980
공간 크기는 변경합니다.

1564
01:00:50,980 --> 01:00:52,800
다운샘플링에 사용하는 방법은 무엇인가요?

1565
01:00:52,800 --> 01:00:54,300
좋은 질문입니다.

1566
01:00:54,300 --> 01:00:56,478
그 방법은 실제로 하이퍼파라미터이며,

1567
01:00:56,478 --> 01:00:58,020
우리가 사용하는 몇 가지 다운샘플링

1568
01:00:58,020 --> 01:00:59,402
메커니즘이 있습니다.

1569
01:00:59,402 --> 01:01:01,860
가장 일반적인 방법 중 하나는 실제로 최대

1570
01:01:01,860 --> 01:01:04,460
풀링(max pooling)이라고 불리는 것입니다.

1571
01:01:04,460 --> 01:01:06,100
최대 풀링에서는

1572
01:01:06,100 --> 01:01:08,760
단일 깊이 슬라이스를 비겹치는

1573
01:01:08,760 --> 01:01:11,400
영역으로 나누게 됩니다.

1574
01:01:11,400 --> 01:01:13,020
이 경우 두 개가 있으며,

1575
01:01:13,020 --> 01:01:15,290
우리는 이러한 것들에 대해

1576
01:01:15,290 --> 01:01:17,330
컨볼루션과 같은 용어를 사용합니다.

1577
01:01:17,330 --> 01:01:19,010
이렇게 하면 커널 크기가

1578
01:01:19,010 --> 01:01:21,890
2 x 2이고 보폭이 2인 것으로 말할

1579
01:01:21,890 --> 01:01:23,970
수 있습니다. 그러면 입력을

1580
01:01:23,970 --> 01:01:26,450
비겹치는 2 x 2 타일로 나눕니다.

1581
01:01:26,450 --> 01:01:29,350
그런 다음 각 비겹치는 2 x 2 타일 내에서

1582
01:01:29,350 --> 01:01:30,730
최대 항목을 가져옵니다.

1583
01:01:30,730 --> 01:01:33,590
이 경우 최대 값은 6, 8, 3, 4입니다.

1584
01:01:33,590 --> 01:01:36,130
따라서 각 타일 내에서 최대 항목을

1585
01:01:36,130 --> 01:01:38,490
가져오면 그것이 우리의 공간

1586
01:01:38,490 --> 01:01:40,048
압축을 제공합니다.

1587
01:01:40,048 --> 01:01:42,090
그리고 여기에 하이퍼파라미터 세트가

1588
01:01:42,090 --> 01:01:43,350
있을 수 있습니다.

1589
01:01:43,350 --> 01:01:45,655
커널 크기가 무엇인지 말할 수 있습니다.

1590
01:01:45,655 --> 01:01:47,030
커널 크기를 변경할 수 있습니다.

1591
01:01:47,030 --> 01:01:48,310
보폭을 변경할 수 있습니다.

1592
01:01:48,310 --> 01:01:51,090
다운샘플링에 사용하는 함수도 변경할 수 있습니다.

1593
01:01:51,090 --> 01:01:52,630
최대 풀링은 꽤 일반적입니다.

1594
01:01:52,630 --> 01:01:53,910
평균 풀링도 볼 수 있습니다.

1595
01:01:53,910 --> 01:01:56,463
때때로 안티 앨리어싱 다운 풀링도 볼 수 있습니다.

1596
01:01:56,463 --> 01:01:59,130
이들은 모두 이러한 특징 맵을 한 번에

1597
01:01:59,130 --> 01:02:01,127
하나씩 다운샘플링하는 방법입니다.

1598
01:02:01,127 --> 01:02:01,710
좋은 질문입니다.

1599
01:02:01,710 --> 01:02:03,090
패딩을 사용하나요?

1600
01:02:03,090 --> 01:02:06,770
일반적으로 풀링 레이어 내에서는 패딩을 사용하지 않습니다.

1601
01:02:06,770 --> 01:02:09,650
수학적으로 그렇게 하는 것을 막는 것은 없습니다.

1602
01:02:09,650 --> 01:02:12,030
하지만 최대 풀링의 경우에는 어리석습니다.

1603
01:02:12,030 --> 01:02:14,040
기본적으로 ReLU와 동등합니다.

1604
01:02:14,040 --> 01:02:15,860
따라서 최대 풀링을 사용할

1605
01:02:15,860 --> 01:02:18,160
때 ReLU도 사용하면 중복됩니다.

1606
01:02:18,160 --> 01:02:21,420
그래서 일반적으로 풀링 레이어에서는 패딩을 사용하지 않습니다.

1607
01:02:21,420 --> 01:02:22,920
PyTorch가 풀링

1608
01:02:22,920 --> 01:02:26,940
레이어에서 패딩을 위한 플래그가 있는지 확실하지 않습니다.

1609
01:02:26,940 --> 01:02:27,440
네.

1610
01:02:27,440 --> 01:02:29,080
보폭은 이러한 아키텍처

1611
01:02:29,080 --> 01:02:30,820
하이퍼파라미터 중 하나입니다.

1612
01:02:30,820 --> 01:02:32,880
하지만 일반적으로 이러한 것들을 너무 많이 조정하지는 않습니다.

1613
01:02:32,880 --> 01:02:34,800
보통 풀링 레이어의 직관은,

1614
01:02:34,800 --> 01:02:36,512
솔직히 가장 일반적인

1615
01:02:36,512 --> 01:02:38,720
것은 모든 것을 2배로 다운샘플링하고

1616
01:02:38,720 --> 01:02:42,420
싶다는 것입니다. 이는 가장 일반적인 작업입니다.

1617
01:02:42,420 --> 01:02:45,360
그래서 가장 일반적인 방법은 2x2 스트라이드 2입니다.

1618
01:02:45,360 --> 01:02:48,880
가끔 4x4 스트라이드 2를 사용할 수도 있습니다.

1619
01:02:48,880 --> 01:02:51,160
하지만 기본적으로 가장 일반적인

1620
01:02:51,160 --> 01:02:52,920
설정은 모든 것을 정확히 2배로

1621
01:02:52,920 --> 01:02:55,200
다운샘플링하고 싶다는 것입니다.

1622
01:02:55,200 --> 01:02:56,740
오, 아주 좋은 질문입니다.

1623
01:02:56,740 --> 01:02:59,680
모든 이미지가 동일한 입력 크기를 가져야 하나요?

1624
01:02:59,680 --> 01:03:02,680
지금까지 이야기한 모든 언어에서, 그렇습니다.

1625
01:03:02,680 --> 01:03:04,400
입력 이미지의 크기가

1626
01:03:04,400 --> 01:03:06,680
동일하지 않으면 큰 문제가 발생합니다.

1627
01:03:06,680 --> 01:03:08,200
그래서 이를 해결하기

1628
01:03:08,200 --> 01:03:12,020
위해 일반적으로 하는 것은, 네트워크에 배치하기 전에 모든

1629
01:03:12,020 --> 01:03:13,900
이미지를 정확히 동일한 크기로

1630
01:03:13,900 --> 01:03:15,260
조정하는 것입니다.

1631
01:03:15,260 --> 01:03:17,980
가끔 이미지를 제로 또는 다른 값으로 패딩하여

1632
01:03:17,980 --> 01:03:19,900
모두 동일한 크기로 만들기도

1633
01:03:19,900 --> 01:03:22,712
하지만, 이제는 왜곡되지 않고 패딩된 상태입니다.

1634
01:03:22,712 --> 01:03:24,420
또는 서로 다른 종횡비의 이미지에

1635
01:03:24,420 --> 01:03:27,180
대해 이러한 레이어를 독립적으로 실행해야 합니다.

1636
01:03:27,180 --> 01:03:29,420
그래서 더 정교한 훈련 설정에서

1637
01:03:29,420 --> 01:03:31,047
가끔 하는 또 다른

1638
01:03:31,047 --> 01:03:33,380
방법은 종횡비 버킷을 만드는

1639
01:03:33,380 --> 01:03:33,995
것입니다.

1640
01:03:33,995 --> 01:03:35,620
그래서 훈련 데이터에서 서로

1641
01:03:35,620 --> 01:03:37,480
다른 종횡비로 버킷을 나눕니다.

1642
01:03:37,480 --> 01:03:38,855
그런 다음 각 순전파 또는

1643
01:03:38,855 --> 01:03:40,740
역전파에서 네트워크는 동일한 해상도와

1644
01:03:40,740 --> 01:03:42,680
종횡비의 이미지 배치에서 작동합니다.

1645
01:03:42,680 --> 01:03:44,940
하지만 각 반복마다 서로 다른 해상도나

1646
01:03:44,940 --> 01:03:47,080
종횡비의 이미지를 가져올 수 있으며,

1647
01:03:47,080 --> 01:03:48,538
이는 더 일반적이고 큰

1648
01:03:48,538 --> 01:03:50,788
프로덕션 시스템에서 볼 수 있는 것입니다.

1649
01:03:50,788 --> 01:03:51,288
네.

1650
01:03:51,288 --> 01:03:53,080
그래서 질문은, 이들을 어디에 배치하느냐입니다.

1651
01:03:53,080 --> 01:03:55,600
이들은 보통 컨볼루션 레이어와 섞여 있습니다.

1652
01:03:55,600 --> 01:03:57,040
그래서 꽤 일반적인 아키텍처,

1653
01:03:57,040 --> 01:03:58,860
즉 ConvNet의 일반적인

1654
01:03:58,860 --> 01:04:01,280
패턴은 컨볼루션과 풀링을 섞는 것입니다.

1655
01:04:01,280 --> 01:04:03,820
예를 들어, com com pool, com com

1656
01:04:03,820 --> 01:04:06,860
pool, com com pool fully connected를

1657
01:04:06,860 --> 01:04:10,130
볼 수 있으며, 이는 전형적인 컨볼루션 네트워크입니다.

1658
01:04:10,130 --> 01:04:11,590
네, 아주 훌륭한 질문입니다.

1659
01:04:11,590 --> 01:04:13,150
이것이 비선형성을 도입하나요?

1660
01:04:13,150 --> 01:04:16,690
그래서 사용하는 풀링 작업의 유형에 따라

1661
01:04:16,690 --> 01:04:17,550
다릅니다.

1662
01:04:17,550 --> 01:04:20,190
최대 풀링을 사용하는 경우 비선형성입니다.

1663
01:04:20,190 --> 01:04:23,010
일부 네트워크에서는 최대 풀링이 있을 경우, 그

1664
01:04:23,010 --> 01:04:26,370
컨볼루션 주위에 ReLU를 사용하지 않을 수 있습니다. 왜냐하면

1665
01:04:26,370 --> 01:04:28,830
최대 풀링 자체가 비선형성이기 때문입니다.

1666
01:04:28,830 --> 01:04:31,633
평균 풀링이라면 그것도 선형 연산자입니다.

1667
01:04:31,633 --> 01:04:33,550
그래서 평균 풀링을 하면 선형입니다.

1668
01:04:33,550 --> 01:04:37,290
그러므로 아마도 여전히 ReLU를 원할 것입니다.

1669
01:04:37,290 --> 01:04:37,870
좋습니다.

1670
01:04:37,870 --> 01:04:39,890
그래서 풀링에 대한 간단한 한 장 요약은

1671
01:04:39,890 --> 01:04:43,123
기본적으로 컨볼루션과 동일한 하이퍼파라미터를 가지고 있다는 것입니다.

1672
01:04:43,123 --> 01:04:45,290
단, 다운샘플링을 수행하는

1673
01:04:45,290 --> 01:04:49,290
메커니즘인 추가적인 풀링 함수가 있습니다.

1674
01:04:49,290 --> 01:04:52,010
마지막으로 언급하고

1675
01:04:52,010 --> 01:04:56,110
싶은 것은 변환 동등성의 개념입니다.

1676
01:04:56,110 --> 01:04:57,690
그게 대체 뭐죠?

1677
01:04:57,690 --> 01:05:00,195
그래서 강의 시작 부분에서 우리는 이미지의

1678
01:05:00,195 --> 01:05:01,570
공간 구조를

1679
01:05:01,570 --> 01:05:03,830
존중하는 연산자가 필요하다고 말했습니다.

1680
01:05:03,830 --> 01:05:06,330
그리고 이미지를 큰 벡터로 평탄화하는

1681
01:05:06,330 --> 01:05:09,680
개념이 이미지의 공간 구조를 존중하지 않는다는

1682
01:05:09,680 --> 01:05:10,855
생각이 있었습니다.

1683
01:05:10,855 --> 01:05:13,480
그래서 합성곱과 풀링이 공유하는 정말

1684
01:05:13,480 --> 01:05:17,320
흥미로운 속성이 있는데, 이는 이들이 이미지의 2D

1685
01:05:17,320 --> 01:05:21,260
공간 구조를 존중한다는 개념을 형식화하는 한 방법입니다.

1686
01:05:21,260 --> 01:05:23,920
그것이 바로 변환 동등성이라는 개념입니다.

1687
01:05:23,920 --> 01:05:25,820
들으면 좀 미친 것 같지만,

1688
01:05:25,820 --> 01:05:29,200
두 개의 다른 연산자, 두 개의 다른 가지를

1689
01:05:29,200 --> 01:05:30,640
상상할 수 있습니다.

1690
01:05:30,640 --> 01:05:33,140
한 가지에서는 이미지를 가져와서 합성곱

1691
01:05:33,140 --> 01:05:35,000
또는 풀링 연산자를 적용하여

1692
01:05:35,000 --> 01:05:38,000
업데이트된 이미지를 얻고, 그 결과를 예를 들어 그

1693
01:05:38,000 --> 01:05:41,720
피처 맵을 옆으로 이동시켜 변환한다고 상상할 수 있습니다.

1694
01:05:41,720 --> 01:05:44,360
그런 다음 이 두 가지의 순서를 바꿀 수도

1695
01:05:44,360 --> 01:05:45,060
있습니다.

1696
01:05:45,060 --> 01:05:48,360
대신 우리가 할 수 있었던 것은 먼저 이미지를 변환한

1697
01:05:48,360 --> 01:05:50,720
다음 변환된 이미지 위에 합성곱

1698
01:05:50,720 --> 01:05:53,140
또는 풀링 연산자를 적용하는 것입니다.

1699
01:05:53,140 --> 01:05:55,140
이 경우에는 변환한 다음

1700
01:05:55,140 --> 01:05:58,780
합성곱을 하든, 합성곱을 한 다음 변환을

1701
01:05:58,780 --> 01:06:01,440
하든 순서가 중요하지 않으며,

1702
01:06:01,440 --> 01:06:04,742
특정 경계 조건에 따라 같은 결과를

1703
01:06:04,742 --> 01:06:05,700
얻습니다.

1704
01:06:05,700 --> 01:06:08,950
하지만 무한히 큰 이미지의 한계에서

1705
01:06:08,950 --> 01:06:10,510
이러한 기술적 조건을

1706
01:06:10,510 --> 01:06:12,475
무시하면, 공간에서의

1707
01:06:12,475 --> 01:06:14,350
변환 순서를 다운샘플링

1708
01:06:14,350 --> 01:06:16,710
또는 합성곱 연산자 수행과

1709
01:06:16,710 --> 01:06:19,310
바꿀 수 있다는 점이 정말

1710
01:06:19,310 --> 01:06:20,390
흥미롭습니다.

1711
01:06:20,390 --> 01:06:22,710
이것은 이미지 처리 시

1712
01:06:22,710 --> 01:06:27,350
우리가 추출하는 특징이 이미지의 내용에만

1713
01:06:27,350 --> 01:06:29,590
의존하고, 그 내용이 이미지의

1714
01:06:29,590 --> 01:06:31,830
절대 위치에서

1715
01:06:31,830 --> 01:06:34,830
어디에서 왔는지에 의존하지 않아야

1716
01:06:34,830 --> 01:06:38,110
한다는 중요한 직관을 내포합니다.

1717
01:06:38,110 --> 01:06:40,210
즉, 내가 이 방향을

1718
01:06:40,210 --> 01:06:41,390
바라보면 사람들과

1719
01:06:41,390 --> 01:06:43,010
벤치처럼 보입니다.

1720
01:06:43,010 --> 01:06:45,570
내가 이 방향을 바라보면 사람들과 벤치처럼 보입니다.

1721
01:06:45,570 --> 01:06:48,015
내 오른쪽에 있고 왼쪽에 있는 사실은 내가

1722
01:06:48,015 --> 01:06:49,390
그 데이터를 정확히

1723
01:06:49,390 --> 01:06:51,670
같은 방식으로 처리하고 싶다는 것입니다.

1724
01:06:51,670 --> 01:06:53,570
그리고 이것은 우리가

1725
01:06:53,570 --> 01:06:57,630
처리하는 2D 데이터와 이미지에 대한 중요한

1726
01:06:57,630 --> 01:06:58,970
직관과 구조입니다.

1727
01:06:58,970 --> 01:07:01,590
변환 동등성 개념은 이러한 구조가

1728
01:07:01,590 --> 01:07:03,670
이러한 연산자에 어떻게 내재되어

1729
01:07:03,670 --> 01:07:06,570
있는지를 수학적으로 설명하는 방법입니다.

1730
01:07:06,570 --> 01:07:09,610
그래서 이것은 우리가 연산자의 설계를

1731
01:07:09,610 --> 01:07:11,170
통해 이미지가

1732
01:07:11,170 --> 01:07:13,650
어떻게 처리되어야 하는지에

1733
01:07:13,650 --> 01:07:15,150
대한 직관을 내장할

1734
01:07:15,150 --> 01:07:17,525
수 있는 방법이라는 점에서

1735
01:07:17,525 --> 01:07:19,050
흥미롭습니다.

1736
01:07:19,050 --> 01:07:20,570
질문은, 왜 변환을 하느냐는 것입니다.

1737
01:07:20,570 --> 01:07:20,890
당신.

1738
01:07:20,890 --> 01:07:23,223
이건 실제로 할 일이 아닙니다.

1739
01:07:23,223 --> 01:07:26,222
이것은 기본적으로 수학적 호기심입니다.

1740
01:07:26,222 --> 01:07:27,930
신경망 내부에서 일반적으로 이렇게

1741
01:07:27,930 --> 01:07:29,850
하지 말아야 한다는 점을 분명히 하겠습니다.

1742
01:07:29,850 --> 01:07:32,370
이것은 흥미롭게도 사실이지만,

1743
01:07:32,370 --> 01:07:33,970
신경망 내부에서

1744
01:07:33,970 --> 01:07:37,090
이렇게 하지는 않을 것입니다.

1745
01:07:37,090 --> 01:07:38,690
수학자라면 이것을 가환

1746
01:07:38,690 --> 01:07:40,070
다이어그램이라고 부릅니다.

1747
01:07:40,070 --> 01:07:42,810
수학자들은 그런 것들을 좋아합니다.

1748
01:07:42,810 --> 01:07:45,410
그래서 오늘의 요약은 이렇습니다.

1749
01:07:45,410 --> 01:07:47,190
우리는 합성곱 신경망에 대해 이야기했습니다.

1750
01:07:47,190 --> 01:07:48,985
우리는 그것들이 왜 흥미로운지에 대해 이야기했습니다.

1751
01:07:48,985 --> 01:07:50,610
우리는 합성곱과 풀링이라는 두 가지

1752
01:07:50,610 --> 01:07:52,110
새로운 연산자에 대해 이야기했습니다.

1753
01:07:52,110 --> 01:07:54,652
그리고 다음 강의에서는 그것들을 CNN 아키텍처로

1754
01:07:54,652 --> 01:07:56,130
결합하는 방법을 볼 것입니다.

1755
01:07:56,130 --> 01:07:58,920
다음 시간에 뵙겠습니다.
