1
00:00:05,183 --> 00:00:07,600
오늘은 CNN을 이용한 이미지 분류에

2
00:00:07,600 --> 00:00:08,760
대해 이야기하겠습니다.

3
00:00:08,760 --> 00:00:11,020
그래서 여러분은 아마도 제가 누군지 궁금할 겁니다. 저는 새로운 얼굴입니다.

4
00:00:11,020 --> 00:00:12,728
이 수업에서 저를 본 적이 없으실 거예요.

5
00:00:12,728 --> 00:00:14,800
저는 Justin이고, 이 수업의 네 번째 미스터리

6
00:00:14,800 --> 00:00:15,392
강사입니다.

7
00:00:15,392 --> 00:00:17,100
제 사진은 웹사이트에 올라가

8
00:00:17,100 --> 00:00:19,800
있었던 것 같은데, 오늘은 처음으로 여기 왔습니다.

9
00:00:19,800 --> 00:00:20,960
그리고 저에 대해 조금 말씀드리자면,

10
00:00:20,960 --> 00:00:24,880
저는 2012년부터 2018년까지 스탠포드에서 박사 과정을 했고,

11
00:00:24,880 --> 00:00:26,980
[INAUDIBLE]와 함께 딥러닝,

12
00:00:26,980 --> 00:00:29,780
컴퓨터 비전, 그 시기 컴퓨터 비전의 거의

13
00:00:29,780 --> 00:00:31,160
모든 과제를 연구했습니다.

14
00:00:31,160 --> 00:00:32,880
스탠포드에 있는 동안,

15
00:00:32,880 --> 00:00:36,800
저는 Andre, [INAUDIBLE] 그리고

16
00:00:36,800 --> 00:00:40,360
다른 분들과 함께 CS231N을 시작하고

17
00:00:40,360 --> 00:00:46,000
2015년부터 2019년까지 여러 번 강의할 수 있는 행운을 누렸습니다.

18
00:00:46,000 --> 00:00:49,400
그 후 스탠포드에서 페이스북 AI 연구소에서

19
00:00:49,400 --> 00:00:52,520
딥러닝과 컴퓨터 비전 관련 다양한 일을 했습니다.

20
00:00:52,520 --> 00:00:55,760
그리고 미시간 대학교에서 교수로 일했습니다.

21
00:00:55,760 --> 00:00:58,702
거기서도 거의 같은 수업을 몇 번 더 가르쳤습니다.

22
00:00:58,702 --> 00:01:00,410
그래서 이 수업을 몇 번 가르쳤지만,

23
00:01:00,410 --> 00:01:02,545
여기 온 지는 좀 되었고, 최근에는

24
00:01:02,545 --> 00:01:04,670
[INAUDIBLE]와 함께 World

25
00:01:04,670 --> 00:01:06,470
Labs라는 스타트업을 하고 있습니다.

26
00:01:06,470 --> 00:01:09,550
이게 저에 대한 간단한 소개입니다.

27
00:01:09,550 --> 00:01:11,990
이제, 우리가 이 수업에서 어디쯤 왔는지 말씀드리겠습니다.

28
00:01:11,990 --> 00:01:14,470
지금 수업은 몇 가지 다른

29
00:01:14,470 --> 00:01:16,830
부분으로 나뉘어져 있어서 흥미로운

30
00:01:16,830 --> 00:01:18,430
시점에 와 있습니다.

31
00:01:18,430 --> 00:01:20,388
그리고 우리는 기본적으로 첫 번째 세그먼트를 마쳤습니다.

32
00:01:20,388 --> 00:01:23,250
첫 번째 세그먼트는 기본적으로 딥러닝 기초에 관한 내용입니다.

33
00:01:23,250 --> 00:01:25,950
이게 정말 멋진 이유는 지금까지 네 번의

34
00:01:25,950 --> 00:01:28,910
강의에서 본 모든 내용이 딥러닝의 기본 개념들이기

35
00:01:28,910 --> 00:01:29,810
때문입니다.

36
00:01:29,810 --> 00:01:31,910
여러분은 딥러닝 시스템을 구축하는 데

37
00:01:31,910 --> 00:01:34,830
필요한 기본 요소들의 전체 파이프라인을 기본적으로

38
00:01:34,830 --> 00:01:35,530
알고 계십니다.

39
00:01:35,530 --> 00:01:38,238
그래서 이 중요한 시점에서 잠시 뒤로

40
00:01:38,238 --> 00:01:40,950
물러나서 코스 초반부에서 본 주요 주제들을

41
00:01:40,950 --> 00:01:43,790
다시 정리하는 것이 유용하다고 생각했습니다.

42
00:01:43,790 --> 00:01:46,230
첫 번째는 선형 분류기를 이용한 이미지

43
00:01:46,230 --> 00:01:47,830
분류라는 개념입니다.

44
00:01:47,830 --> 00:01:49,650
이것은 딥러닝으로 해결할

45
00:01:49,650 --> 00:01:51,830
수 있는 문제의 감을

46
00:01:51,830 --> 00:01:53,990
잡게 해주기 위한 간단한

47
00:01:53,990 --> 00:01:55,510
문제로, 보통

48
00:01:55,510 --> 00:01:57,110
딥러닝 문제를 해결하는

49
00:01:57,110 --> 00:02:01,130
첫 단계는 입력을 어떤 숫자 격자, 즉 텐서로

50
00:02:01,130 --> 00:02:02,990
받고 출력도 텐서로

51
00:02:02,990 --> 00:02:05,250
내보내는 방식으로 문제를

52
00:02:05,250 --> 00:02:06,890
정의하는 것입니다.

53
00:02:06,890 --> 00:02:09,330
이미지 분류 설정에서는 이미지를

54
00:02:09,330 --> 00:02:11,170
사람이 이해할 수 있는

55
00:02:11,170 --> 00:02:13,510
여러 범주로 분류하는 문제로

56
00:02:13,510 --> 00:02:16,610
정의합니다. 입력은 3차원 텐서로 배열된

57
00:02:16,610 --> 00:02:18,550
픽셀 값의 격자이고,

58
00:02:18,550 --> 00:02:20,290
출력은 각 범주별 점수로,

59
00:02:20,290 --> 00:02:22,410
이미지가 어떤 범주에 속할

60
00:02:22,410 --> 00:02:24,750
가능성이 높은지 낮은지를

61
00:02:24,750 --> 00:02:26,710
나타냅니다. 네트워크는 이미지가

62
00:02:26,710 --> 00:02:28,570
속할 가능성이 높은 범주에

63
00:02:28,570 --> 00:02:31,212
대해 높은 점수를, 그렇지 않은

64
00:02:31,212 --> 00:02:33,170
범주에 대해서는 낮은 점수를

65
00:02:33,170 --> 00:02:34,650
예측해야 합니다.

66
00:02:34,650 --> 00:02:36,290
그 다음 문제를 설정할

67
00:02:36,290 --> 00:02:41,010
수 있는데, 가중치 행렬을 사용해 이미지 픽셀에 곱해서

68
00:02:41,010 --> 00:02:43,955
이 점수들을 예측하는 방식입니다.

69
00:02:43,955 --> 00:02:46,330
우리는 선형 분류기를 해석하는

70
00:02:46,330 --> 00:02:48,205
몇 가지 다른 관점과

71
00:02:48,205 --> 00:02:50,170
방법을 살펴봤습니다.

72
00:02:50,170 --> 00:02:52,290
이것은 기본적으로 가중치 행렬 w만

73
00:02:52,290 --> 00:02:55,050
있으면 이미지에 대한 점수를 예측할 수 있다는

74
00:02:55,050 --> 00:02:56,337
함수 형태를 설정합니다.

75
00:02:56,337 --> 00:02:58,920
그렇다면 좋은 가중치 행렬 w를 어떻게

76
00:02:58,920 --> 00:02:59,640
선택할까요?

77
00:02:59,640 --> 00:03:01,703
그 답은 손실 함수에 있습니다.

78
00:03:01,703 --> 00:03:03,120
손실 함수는 특정

79
00:03:03,120 --> 00:03:06,880
가중치 행렬 값과 주어진 데이터셋에 대해

80
00:03:06,880 --> 00:03:10,480
이 가중치 행렬이 문제를 얼마나 잘

81
00:03:10,480 --> 00:03:12,960
해결하는지 알려주는 함수입니다.

82
00:03:12,960 --> 00:03:15,680
특히 분류 문제에 자주 쓰이는

83
00:03:15,680 --> 00:03:18,060
손실 함수 예로 소프트맥스

84
00:03:18,060 --> 00:03:22,040
손실과 아마도 SVM 손실도 살펴봤습니다.

85
00:03:22,040 --> 00:03:25,000
자, 이제 문제를 좀 더 진행해

86
00:03:25,000 --> 00:03:26,420
봤습니다.

87
00:03:26,420 --> 00:03:28,600
이미지 분류 문제를 설정했습니다.

88
00:03:28,600 --> 00:03:30,520
선형 분류기를 사용해 문제를

89
00:03:30,520 --> 00:03:31,740
푸는 모델이 있습니다.

90
00:03:31,740 --> 00:03:34,623
손실 함수로 해답이 좋은지 평가할 수

91
00:03:34,623 --> 00:03:36,040
있지만, 이제 실제로

92
00:03:36,040 --> 00:03:38,440
좋은 해답을 찾아야 합니다.

93
00:03:38,440 --> 00:03:40,580
바로 그때 최적화가 필요합니다.

94
00:03:40,580 --> 00:03:42,800
이제 최적화 지형을 정의한다고

95
00:03:42,800 --> 00:03:45,120
생각해 보세요. x축,

96
00:03:45,120 --> 00:03:48,117
즉 수평면에는 가중치 행렬의

97
00:03:48,117 --> 00:03:50,700
모든 가능한 설정이 있습니다.

98
00:03:50,700 --> 00:03:52,325
손실 함수는 이

99
00:03:52,325 --> 00:03:55,390
평면의 높이와 같아서, 손실이 높으면

100
00:03:55,390 --> 00:03:56,930
안 좋습니다.

101
00:03:56,930 --> 00:03:58,130
그래서 손실이 낮아야 합니다.

102
00:03:58,130 --> 00:03:59,670
최적화의 목적은 이

103
00:03:59,670 --> 00:04:03,490
공간을 탐색하며 이 매니폴드를 따라 내려가서 매우

104
00:04:03,490 --> 00:04:06,210
낮은 손실의 지점을 찾는 것입니다.

105
00:04:06,210 --> 00:04:09,090
이 공간의 각 지점은 가중치 행렬에 대응합니다.

106
00:04:09,090 --> 00:04:10,590
그래서 이 공간을

107
00:04:10,590 --> 00:04:13,350
내려가면서 문제를 해결하고 좋은 해답을

108
00:04:13,350 --> 00:04:15,893
주는 좋은 가중치 행렬을 찾는 거죠.

109
00:04:15,893 --> 00:04:17,310
특히, 딥러닝에서

110
00:04:17,310 --> 00:04:19,750
자주 쓰이는 몇 가지 최적화 알고리즘을

111
00:04:19,750 --> 00:04:22,470
봤습니다; 모멘텀을 사용하는 확률적

112
00:04:22,470 --> 00:04:26,070
경사 하강법, RMSProp, Adam 등이죠.

113
00:04:26,070 --> 00:04:29,190
흥미로운 최신 소식으로는, 지금 가장 큰 딥러닝 연구

114
00:04:29,190 --> 00:04:32,670
학회 중 하나인 ICLR, International

115
00:04:32,670 --> 00:04:35,390
Conference on Learning

116
00:04:35,390 --> 00:04:36,990
Representations가 있습니다.

117
00:04:36,990 --> 00:04:40,070
바로 어제, 2025년에 Adam 논문이 Test

118
00:04:40,070 --> 00:04:42,615
of Time 상을 받았습니다.

119
00:04:42,615 --> 00:04:43,990
Adam 최적화 알고리즘을

120
00:04:43,990 --> 00:04:45,790
소개한 논문이 10년 전인

121
00:04:45,790 --> 00:04:48,830
2015년 ICLR에서 발표되었기 때문입니다.

122
00:04:48,830 --> 00:04:50,390
많은 학회에서는 10년

123
00:04:50,390 --> 00:04:52,070
전 가장 영향력 있는 논문에

124
00:04:52,070 --> 00:04:55,420
Test of Time 상을 주는 경향이 있습니다.

125
00:04:55,420 --> 00:04:57,003
그리고 바로 어제, 여러분이 이

126
00:04:57,003 --> 00:04:59,170
수업에서 배운 Adam 최적화 알고리즘이

127
00:04:59,170 --> 00:05:01,740
ICLR 2025에서 매우 권위 있는 Test

128
00:05:01,740 --> 00:05:03,300
of Time 상을 받았습니다.

129
00:05:03,300 --> 00:05:05,320
그래서 저는 지금까지 배우신 내용과

130
00:05:05,320 --> 00:05:06,820
현재 머신러닝 커뮤니티에서

131
00:05:06,820 --> 00:05:09,153
일어나고 있는 일들을 멋지게 연결하는

132
00:05:09,153 --> 00:05:10,940
좋은 방법이라고 생각했습니다.

133
00:05:10,940 --> 00:05:13,860
그래서 이제 기본적으로—이 시점에서 우리는

134
00:05:13,860 --> 00:05:15,912
선형 분류기와 손실 함수를

135
00:05:15,912 --> 00:05:17,120
갖추게 되었습니다.

136
00:05:17,120 --> 00:05:18,320
우리는 그것들을 최적화할 수 있습니다.

137
00:05:18,320 --> 00:05:19,940
이제 거의 준비가 된 셈입니다.

138
00:05:19,940 --> 00:05:22,780
하지만 문제에 부딪혔는데, 우리가 처음 시작한

139
00:05:22,780 --> 00:05:25,900
선형 분류기들은 사실 그렇게 강력하지 않습니다.

140
00:05:25,900 --> 00:05:28,620
그리고 우리는 선형 분류기의 이

141
00:05:28,620 --> 00:05:32,360
한계를 두 가지 다른 방식으로 살펴보았습니다.

142
00:05:32,360 --> 00:05:33,980
하나는 시각적 관점에서,

143
00:05:33,980 --> 00:05:36,780
학습된 가중치 행렬을 이미지로 생각해서

144
00:05:36,780 --> 00:05:38,530
각 분류하려는 카테고리마다

145
00:05:38,530 --> 00:05:40,380
하나의 이미지 템플릿을

146
00:05:40,380 --> 00:05:42,020
학습하는 것으로 선형

147
00:05:42,020 --> 00:05:43,478
분류기를 해석할 수

148
00:05:43,478 --> 00:05:44,902
있다는 것이었습니다.

149
00:05:44,902 --> 00:05:46,360
그렇게 생각해보면,

150
00:05:46,360 --> 00:05:49,080
선형 분류기의 가중치 행렬의 각 행이

151
00:05:49,080 --> 00:05:51,780
하나의 템플릿이라는 것을 알 수 있습니다.

152
00:05:51,780 --> 00:05:53,240
그래서 선형 분류기는

153
00:05:53,240 --> 00:05:56,040
기본적으로 각 카테고리에 대한 모든 지식을 하나의

154
00:05:56,040 --> 00:05:57,420
템플릿으로 요약해야 합니다.

155
00:05:57,420 --> 00:05:59,400
그리고 그건 어려운 일이고,

156
00:05:59,400 --> 00:06:01,440
그렇게 강력한 분류기가 아닙니다.

157
00:06:01,440 --> 00:06:04,640
그래서 이건 학습된 선형 분류기의 시각화된

158
00:06:04,640 --> 00:06:06,360
템플릿에서 나타나는데,

159
00:06:06,360 --> 00:06:09,720
자동차 같은 카테고리에서는 이 자동차가

160
00:06:09,720 --> 00:06:11,780
빨간 점처럼 보입니다.

161
00:06:11,780 --> 00:06:13,580
하지만 자동차가 꼭 빨간색일 필요는 없죠?

162
00:06:13,580 --> 00:06:16,040
만약 자동차가 파란색이나 보라색, 초록색 등 다른 색이었다면

163
00:06:16,040 --> 00:06:16,580
어떻게 할까요?

164
00:06:16,580 --> 00:06:18,580
선형 분류기는 이런 다양한

165
00:06:18,580 --> 00:06:19,480
외관을

166
00:06:19,480 --> 00:06:22,520
가진 객체의 개념을 잘 포착할 방법이

167
00:06:22,520 --> 00:06:26,300
없습니다. 기하학적 관점에서 보면, 데이터셋의

168
00:06:26,300 --> 00:06:29,200
각 점을 고차원 공간의 한

169
00:06:29,200 --> 00:06:31,143
점으로 생각할 때, 선형

170
00:06:31,143 --> 00:06:33,560
분류기는 이 공간을 초평면으로

171
00:06:33,560 --> 00:06:35,560
나누는 역할을 합니다.

172
00:06:35,560 --> 00:06:38,200
그래서 모든 카테고리가 실제로 선형적으로

173
00:06:38,200 --> 00:06:40,860
분리 가능한 영역에 있다면 아주 좋지만,

174
00:06:40,860 --> 00:06:43,520
일반적으로 그럴 거라고 기대할 이유는 없습니다.

175
00:06:43,520 --> 00:06:45,160
이 두 가지가 이미지

176
00:06:45,160 --> 00:06:48,080
분류 문제에 적용된 선형 분류기에서

177
00:06:48,080 --> 00:06:51,030
우리가 마주친 큰 한계점들입니다.

178
00:06:51,030 --> 00:06:52,622
그리고 이것이 우리를 이른바

179
00:06:52,622 --> 00:06:54,830
신경망이라는 개념을 정의하게

180
00:06:54,830 --> 00:06:57,750
만들었습니다. 여기서는 선형 분류기를 일반화해서

181
00:06:57,750 --> 00:07:00,310
하나의 가중치 행렬만 사용하는 대신, 두

182
00:07:00,310 --> 00:07:03,310
개의 가중치 행렬을 쌓고 그 사이에 비선형성을

183
00:07:03,310 --> 00:07:04,310
넣는 방식입니다.

184
00:07:04,310 --> 00:07:07,030
이제 이것은 입력으로부터 점수를

185
00:07:07,030 --> 00:07:10,230
예측하는 훨씬 더 강력한 메커니즘을 제공합니다.

186
00:07:10,230 --> 00:07:12,130
기본적으로 문제는 여전히 같습니다.

187
00:07:12,130 --> 00:07:15,270
입력 픽셀이 이 계산을 거쳐 점수를

188
00:07:15,270 --> 00:07:16,410
출력하는 것이죠.

189
00:07:16,410 --> 00:07:18,993
하지만 이제는 우리가 방금 계산한 것 대신에

190
00:07:18,993 --> 00:07:22,030
점수 함수의 다른 함수 형태를 선택한 겁니다.

191
00:07:22,030 --> 00:07:23,110
이것이 우리에게 주어진

192
00:07:23,110 --> 00:07:25,330
것이고, 이제 수학은 꽤 간단합니다.

193
00:07:25,330 --> 00:07:27,550
f = wx에서 시작해서,

194
00:07:27,550 --> 00:07:30,650
추가로 w2를 더하고 그 사이에 작은 비선형성을 넣으면 됩니다.

195
00:07:30,650 --> 00:07:32,330
그래서 수학적으로 크게 변하지는 않습니다.

196
00:07:32,330 --> 00:07:33,950
하지만 이렇게 함으로써

197
00:07:33,950 --> 00:07:37,030
분류기는 이전보다 훨씬 더 강력해집니다.

198
00:07:37,030 --> 00:07:39,430
하지만 이제 다시 조금 복잡해지는데, 이것이

199
00:07:39,430 --> 00:07:42,010
최적화에 어떻게 작용하느냐 하는 문제입니다.

200
00:07:42,010 --> 00:07:43,810
우리는 손실 함수가 있고

201
00:07:43,810 --> 00:07:45,790
모델이 있다면, 손실을 줄이는

202
00:07:45,790 --> 00:07:48,840
가중치 행렬 값을 찾아야 한다는 것을 압니다.

203
00:07:48,840 --> 00:07:50,835
그렇게 하려면, 우리는 기울기를 계산할 수 있어야 합니다.

204
00:07:50,835 --> 00:07:52,460
모델의 모든 파라미터에

205
00:07:52,460 --> 00:07:55,200
대한 손실의 기울기를 계산할 수 있어야 하죠.

206
00:07:55,200 --> 00:07:57,460
이것이 바로 계산 그래프라는 개념입니다.

207
00:07:57,460 --> 00:08:00,260
계산 그래프는 기본적으로 신경망 계산을

208
00:08:00,260 --> 00:08:03,100
조직하는 데이터 구조로, 그래프의

209
00:08:03,100 --> 00:08:04,580
각 노드는 행렬 곱셈,

210
00:08:04,580 --> 00:08:07,460
ReLU, 또는 그 밖의 다른

211
00:08:07,460 --> 00:08:09,340
작은 함수 원시 연산입니다.

212
00:08:09,340 --> 00:08:11,740
그리고 데이터는 이 그래프에서

213
00:08:11,740 --> 00:08:13,620
왼쪽에서 오른쪽으로, 왼쪽의

214
00:08:13,620 --> 00:08:15,258
입력과 가중치에서 시작해

215
00:08:15,258 --> 00:08:17,300
그래프 내 중간 노드들을 거쳐

216
00:08:17,300 --> 00:08:19,700
오른쪽의 손실 함수까지 흐릅니다.

217
00:08:19,700 --> 00:08:21,320
그리고 손실을 계산한

218
00:08:21,320 --> 00:08:24,260
후에는 이 손실, 즉 그래프를 오른쪽에서

219
00:08:24,260 --> 00:08:26,860
왼쪽으로 거슬러 올라가면서

220
00:08:26,860 --> 00:08:31,540
네트워크 내 모든 노드에 대한 손실의 기울기를 계산합니다.

221
00:08:31,540 --> 00:08:33,620
이제 정말 멋진 점은,

222
00:08:33,620 --> 00:08:36,500
임의로 복잡한 신경망이나 입력에서

223
00:08:36,500 --> 00:08:38,140
출력으로 계산하는

224
00:08:38,140 --> 00:08:40,260
임의로 복잡한 표현식을

225
00:08:40,260 --> 00:08:42,200
쓸 수 있다는 겁니다.

226
00:08:42,200 --> 00:08:45,300
하지만 이제 우리는 임의로 복잡한 신경망을 통해

227
00:08:45,300 --> 00:08:48,050
원하는 어떤 기울기든 거의 자동으로 계산할 수

228
00:08:48,050 --> 00:08:49,970
있는 알고리즘을 갖게 되었습니다.

229
00:08:49,970 --> 00:08:52,970
그 방법이 바로 역전파의 마법입니다.

230
00:08:52,970 --> 00:08:54,745
역전파는 정말 멋집니다.

231
00:08:54,745 --> 00:08:56,370
저는 이것이 딥러닝을

232
00:08:56,370 --> 00:08:59,250
가능하게 하는 알고리즘 중

233
00:08:59,250 --> 00:09:02,370
하나라고 생각하는데, 왜냐하면 손실을

234
00:09:02,370 --> 00:09:04,610
계산하는 전역 문제를 국소 문제로

235
00:09:04,610 --> 00:09:06,510
바꾸기 때문입니다.

236
00:09:06,510 --> 00:09:08,250
이제 각 노드는 자신이

237
00:09:08,250 --> 00:09:11,050
속한 그래프의 전체 맥락이나

238
00:09:11,050 --> 00:09:13,210
해결하려는 문제에 대해 알

239
00:09:13,210 --> 00:09:14,410
필요가 없습니다.

240
00:09:14,410 --> 00:09:16,970
우리는 단지 계산 그래프 내 작은

241
00:09:16,970 --> 00:09:20,490
노드들이 순전파에서는 입력으로부터 출력을

242
00:09:20,490 --> 00:09:23,070
계산하고, 역전파에서는 상류에서

243
00:09:23,070 --> 00:09:26,010
오는 기울기를 받을 수 있도록 정의하면

244
00:09:26,010 --> 00:09:26,630
됩니다.

245
00:09:26,630 --> 00:09:28,990
그 노드들은 그 기울기가 어디서

246
00:09:28,990 --> 00:09:32,070
왔는지, 왜 생겼는지 신경 쓸 필요가 없습니다.

247
00:09:32,070 --> 00:09:34,890
저는 단지 상류 기울기를 받아서 내

248
00:09:34,890 --> 00:09:38,010
입력에 대한 하류 기울기를 계산하면 됩니다.

249
00:09:38,010 --> 00:09:40,530
이것이 매우 강력한 이유는,

250
00:09:40,530 --> 00:09:42,530
이제 다양한 종류의

251
00:09:42,530 --> 00:09:45,310
노드들을 모두 출력 계산과 국소

252
00:09:45,310 --> 00:09:49,130
기울기 계산이라는 API만 따르면 정의할 수

253
00:09:49,130 --> 00:09:50,610
있기 때문입니다.

254
00:09:50,610 --> 00:09:53,522
그리고 모든 노드가 그 API를 따르면,

255
00:09:53,522 --> 00:09:55,230
우리는 이들을 연결해

256
00:09:55,230 --> 00:09:57,910
임의의 계산을 수행하는 크고 복잡한

257
00:09:57,910 --> 00:10:00,250
계산 그래프를 만들 수 있습니다.

258
00:10:00,250 --> 00:10:01,750
그리고 역전파

259
00:10:01,750 --> 00:10:05,590
알고리즘을 돌리면 기울기는 자동으로 계산됩니다.

260
00:10:05,590 --> 00:10:08,790
지난번에 보셨던 이 슬라이드는 기본적으로

261
00:10:08,790 --> 00:10:12,130
스칼라 값에 대한 역전파입니다.

262
00:10:12,130 --> 00:10:14,550
하지만 우리는 이를 벡터 값,

263
00:10:14,550 --> 00:10:18,590
행렬 값, 텐서 값에도 일반화할 수 있습니다.

264
00:10:18,590 --> 00:10:20,270
기본적으로 기억해야

265
00:10:20,270 --> 00:10:22,690
할 것은 입력은 텐서이고 출력도

266
00:10:22,690 --> 00:10:24,450
텐서라는 점입니다.

267
00:10:24,450 --> 00:10:27,070
그리고 이제 받는 상류 그래디언트는

268
00:10:27,070 --> 00:10:30,030
출력에 대한 손실의 그래디언트입니다.

269
00:10:30,030 --> 00:10:32,610
그리고 그것은 항상 출력과 같은 형태를 가집니다.

270
00:10:32,610 --> 00:10:35,110
손실은 스칼라이기 때문에, 텐서에

271
00:10:35,110 --> 00:10:37,910
대한 손실의 그래디언트는 텐서의 각

272
00:10:37,910 --> 00:10:39,630
원소를 조금씩 움직였을

273
00:10:39,630 --> 00:10:42,130
때 손실이 얼마나 변하는지를

274
00:10:42,130 --> 00:10:42,900
나타냅니다.

275
00:10:42,900 --> 00:10:44,623
손실이 스칼라이기

276
00:10:44,623 --> 00:10:46,540
때문에 텐서의 각 원소를

277
00:10:46,540 --> 00:10:49,060
독립적으로 움직인다고

278
00:10:49,060 --> 00:10:50,140
상상하면 됩니다.

279
00:10:50,140 --> 00:10:52,098
그것이 바로 그래디언트의 정의입니다.

280
00:10:52,098 --> 00:10:53,640
그래서 기억하기 아주 쉽습니다.

281
00:10:53,640 --> 00:10:56,020
상류 그래디언트는 항상 출력과 정확히 같은

282
00:10:56,020 --> 00:10:56,955
형태를 가집니다.

283
00:10:56,955 --> 00:10:59,580
여기서 downstream gradients는 제 입력에

284
00:10:59,580 --> 00:11:00,760
대한 그래디언트입니다.

285
00:11:00,760 --> 00:11:03,700
이것들도 제 입력과 같은 형태를 가집니다.

286
00:11:03,700 --> 00:11:05,500
그래서 backpropagation

287
00:11:05,500 --> 00:11:07,940
알고리즘은 기본적으로 체인 룰(chain

288
00:11:07,940 --> 00:11:10,460
rule)이고, upstream gradients와 제가

289
00:11:10,460 --> 00:11:12,260
계산하려던 함수에 따라

290
00:11:12,260 --> 00:11:14,620
downstream gradients를 계산해야 합니다.

291
00:11:14,620 --> 00:11:17,558
나중 과제에서 신경망의 다양한

292
00:11:17,558 --> 00:11:19,100
연산자에 대한 그래디언트

293
00:11:19,100 --> 00:11:22,980
표현식을 작성하는 연습을 하게 될 겁니다.

294
00:11:22,980 --> 00:11:25,380
이것이 딥러닝에서 거의

295
00:11:25,380 --> 00:11:29,113
모든 문제를 푸는 방법을 알려줍니다.

296
00:11:29,113 --> 00:11:31,780
이 방법은 단순히 이미지 분류, 선형

297
00:11:31,780 --> 00:11:33,800
분류기, 완전 연결 네트워크에

298
00:11:33,800 --> 00:11:35,440
국한된 것이 아닙니다.

299
00:11:35,440 --> 00:11:38,140
어떤 문제든 텐서로 인코딩하고,

300
00:11:38,140 --> 00:11:40,360
입력 텐서에서 출력 텐서를

301
00:11:40,360 --> 00:11:43,250
계산하는 계산 그래프를 작성하고,

302
00:11:43,250 --> 00:11:45,770
입력-출력 텐서 데이터셋을 모으고,

303
00:11:45,770 --> 00:11:47,850
해결하려는 문제에 맞는

304
00:11:47,850 --> 00:11:50,430
손실 함수를 작성하면 됩니다.

305
00:11:50,430 --> 00:11:53,850
그리고 그 손실 함수를 그래디언트 하강법과 backpropagation으로

306
00:11:53,850 --> 00:11:55,570
최적화하면 됩니다.

307
00:11:55,570 --> 00:11:57,090
이것은 이미지 분류,

308
00:11:57,090 --> 00:11:59,950
이미지 생성, 대형 언어 모델 등

309
00:11:59,950 --> 00:12:01,850
모든 딥러닝 응용 분야를

310
00:12:01,850 --> 00:12:04,970
사실상 구동하는 매우 강력한 공식입니다.

311
00:12:04,970 --> 00:12:07,090
거의 모든 신경망 관련

312
00:12:07,090 --> 00:12:10,650
문제는 이 공식이나 이 공식의 약간 변형된

313
00:12:10,650 --> 00:12:11,872
형태로 학습됩니다.

314
00:12:11,872 --> 00:12:13,330
그래서 이것이 두 번째 수업

315
00:12:13,330 --> 00:12:15,610
주제로 이어지는데, 바로 시각적 세계를

316
00:12:15,610 --> 00:12:16,770
인지하고 이해하는 것입니다.

317
00:12:16,770 --> 00:12:19,490
여기서 우리는 좀 더 전문화된 내용을 다루고,

318
00:12:19,490 --> 00:12:22,072
딥러닝의 일반적인 틀보다는 컴퓨터

319
00:12:22,072 --> 00:12:23,530
비전에서 해결하고자

320
00:12:23,530 --> 00:12:26,670
하는 문제에 어떻게 적용되는지 이야기하려고 합니다.

321
00:12:26,670 --> 00:12:29,690
이미지를 처리하고, 이미지로 흥미로운 작업을 하는 것이죠.

322
00:12:29,690 --> 00:12:31,490
오늘은 그 방향으로 한 걸음

323
00:12:31,490 --> 00:12:35,130
나아가 컨볼루션 네트워크에 대해 좀 더 이야기해보겠습니다.

324
00:12:35,130 --> 00:12:38,650
컨볼루션 네트워크는 사실 우리가 이미 정의한 이

325
00:12:38,650 --> 00:12:41,540
틀 위에 아주 작은 변화를 더한 것입니다.

326
00:12:41,540 --> 00:12:43,805
우리는 이미 두 가지를 이야기했죠.

327
00:12:43,805 --> 00:12:45,680
계산 그래프 안에 존재할

328
00:12:45,680 --> 00:12:47,960
수 있는 작은 연산자들의

329
00:12:47,960 --> 00:12:50,100
일반적인 패러다임이 있습니다.

330
00:12:50,100 --> 00:12:51,707
아름다운 틀을 가지고 있지만,

331
00:12:51,707 --> 00:12:54,040
사실 그 틀의 구체적인 내용은 많이

332
00:12:54,040 --> 00:12:54,980
채우지 않았습니다.

333
00:12:54,980 --> 00:12:58,000
계산 그래프 안에 존재할 수 있는 노드

334
00:12:58,000 --> 00:13:00,900
종류는 두세 가지 정도만 봤습니다.

335
00:13:00,900 --> 00:13:02,800
완전 연결층, 즉 기본적으로

336
00:13:02,800 --> 00:13:04,460
행렬 곱셈을 하는 층을 봤고,

337
00:13:04,460 --> 00:13:06,860
ReLU 같은 활성화 함수도

338
00:13:06,860 --> 00:13:09,280
봤으며, 손실 함수도 살펴봤습니다.

339
00:13:09,280 --> 00:13:13,480
이제 우리가 본 것들에서 출발해 컨볼루션 네트워크를

340
00:13:13,480 --> 00:13:15,720
구축하려면, 계산

341
00:13:15,720 --> 00:13:19,320
그래프에 들어갈 수 있는 새로운 노드 몇

342
00:13:19,320 --> 00:13:21,160
가지를 추가하면 됩니다.

343
00:13:21,160 --> 00:13:23,400
특히, 훨씬 더 강력한 네트워크를

344
00:13:23,400 --> 00:13:24,858
만들기 위해 이야기해야

345
00:13:24,858 --> 00:13:27,400
할 연산자는 두 가지뿐인데,

346
00:13:27,400 --> 00:13:30,225
오늘 강의 대부분을 할애할 컨볼루션 층과

347
00:13:30,225 --> 00:13:31,600
이미지 처리 시

348
00:13:31,600 --> 00:13:36,360
자주 사용하는 또 다른 연산자인 풀링 층입니다.

349
00:13:36,360 --> 00:13:38,407
오늘 강의의 로드맵은 이렇습니다.

350
00:13:38,407 --> 00:13:40,740
일반적으로 convolutional networks에 대해 조금

351
00:13:40,740 --> 00:13:41,400
이야기하고 싶습니다.

352
00:13:41,400 --> 00:13:43,900
그다음에 convolutional networks를

353
00:13:43,900 --> 00:13:47,220
우리의 계산 그래프에서 구축하는 데 사용할 수 있는

354
00:13:47,220 --> 00:13:50,260
두 가지 특정 계산 원시 연산에 대해 이야기하겠습니다.

355
00:13:50,260 --> 00:13:52,140
그래서 우리는 이미 이야기했죠--

356
00:13:52,140 --> 00:13:53,515
여기서 잠시 물러나서 이미지

357
00:13:53,515 --> 00:13:56,005
분류 문제에 대해 다시 생각해보고자 합니다.

358
00:13:56,005 --> 00:13:58,380
이미지 분류가 컴퓨터 비전에서 매우

359
00:13:58,380 --> 00:14:00,660
핵심적인 문제라는 것을 이미 이야기했는데,

360
00:14:00,660 --> 00:14:03,820
입력 이미지가 주어지면 그 이미지에 무엇이 있는지

361
00:14:03,820 --> 00:14:07,020
범주 집합으로 예측하는 문제입니다-- 기본적으로

362
00:14:07,020 --> 00:14:09,660
k개의 범주 레이블 중 하나를 예측하는 거죠.

363
00:14:09,660 --> 00:14:11,080
이 이미지는 분명히 고양이입니다.

364
00:14:11,080 --> 00:14:13,620
그래서 고양이 분류기를 예측하고 싶습니다.

365
00:14:13,620 --> 00:14:16,220
그리고 대부분의 경우-- 우리는 기본적으로

366
00:14:16,220 --> 00:14:18,740
선형 분류기를 만들고 완전 연결 다층

367
00:14:18,740 --> 00:14:21,780
퍼셉트론 신경망을 구축함으로써 이 문제를 어느

368
00:14:21,780 --> 00:14:22,740
정도 해결했습니다.

369
00:14:22,740 --> 00:14:26,580
하지만 이 네트워크들은 기본적으로 픽셀 공간에서 작동합니다.

370
00:14:26,580 --> 00:14:29,500
입력은, 기억하시죠, 딥러닝 문제를 푸는

371
00:14:29,500 --> 00:14:31,820
첫 번째 단계는 입력-출력

372
00:14:31,820 --> 00:14:34,560
텐서로 문제를 공식화하는 것이었습니다.

373
00:14:34,560 --> 00:14:36,610
이 경우 우리의 입력 텐서는

374
00:14:36,610 --> 00:14:39,650
이미지의 원시 픽셀 값들이었습니다.

375
00:14:39,650 --> 00:14:42,710
그래서 f(x) = wx라고 쓸 때,

376
00:14:42,710 --> 00:14:46,170
그 x 입력은 모든 픽셀의 실제 값들입니다.

377
00:14:46,170 --> 00:14:47,930
그리고 그 원시 픽셀 값들로부터

378
00:14:47,930 --> 00:14:49,730
클래스 점수로 넘어가는 거죠.

379
00:14:49,730 --> 00:14:52,170
하지만 다른 방법도 있습니다. 신경망이 등장하기

380
00:14:52,170 --> 00:14:54,930
전, 이 모든 TDM에서 우리를 구해준 신경망 이전의

381
00:14:54,930 --> 00:14:56,850
암흑기 때 흔히 쓰이던 방법이죠.

382
00:14:56,850 --> 00:15:01,090
아마 2000년대 초부터 2010년, 2011년쯤까지는 특징
표현(feature

383
00:15:01,090 --> 00:15:03,330
representations)이라는 아이디어가 있었습니다.

384
00:15:03,330 --> 00:15:06,130
여기서 아이디어는 신경망에 들어갈 입력을

385
00:15:06,130 --> 00:15:08,790
직접 선택할 수 있다는 겁니다.

386
00:15:08,790 --> 00:15:12,130
즉, 이미지의 원시 픽셀 값을

387
00:15:12,130 --> 00:15:15,350
신경망에 그대로 넣는 대신, 다른

388
00:15:15,350 --> 00:15:18,170
어떤 함수를 정의해서 특징을

389
00:15:18,170 --> 00:15:20,930
추출하고, 이미지의 픽셀

390
00:15:20,930 --> 00:15:23,610
값을 우리가 이 시스템의

391
00:15:23,610 --> 00:15:26,930
지능적인 설계자로서 중요하다고

392
00:15:26,930 --> 00:15:28,990
믿는 의미 있는 다른

393
00:15:28,990 --> 00:15:32,610
표현으로 변환할 수 있다는 겁니다.

394
00:15:32,610 --> 00:15:36,000
그래서 만약 이미지 분류를 feature

395
00:15:36,000 --> 00:15:38,440
representation 위에서 한다면, 첫 번째

396
00:15:38,440 --> 00:15:40,800
단계는 원시 이미지 픽셀을 더 높은

397
00:15:40,800 --> 00:15:45,160
수준의 표현으로 변환하는 feature representation을

398
00:15:45,160 --> 00:15:46,220
정의하는 것입니다.

399
00:15:46,220 --> 00:15:47,800
그리고 이제 그 feature

400
00:15:47,800 --> 00:15:50,200
representation이 x가 되어

401
00:15:50,200 --> 00:15:52,560
선형 분류기에 입력으로 들어가게 됩니다.

402
00:15:52,560 --> 00:15:55,440
2000년대부터 2010년대 초반까지

403
00:15:55,440 --> 00:16:00,080
컴퓨터 비전 분야에서는 이런 feature

404
00:16:00,080 --> 00:16:03,880
representation 아이디어를 다양한 작업에 많이

405
00:16:03,880 --> 00:16:04,920
활용했습니다.

406
00:16:04,920 --> 00:16:06,960
특정 feature representation에

407
00:16:06,960 --> 00:16:09,560
대해 자세히 설명하는 것은

408
00:16:09,560 --> 00:16:11,780
별로 유용하지 않은데, 왜냐하면 10년

409
00:16:11,780 --> 00:16:14,240
전쯤에 거의 사용되지 않게 되었기

410
00:16:14,240 --> 00:16:16,480
때문입니다. 하지만 어떤 모습이었는지 감을

411
00:16:16,480 --> 00:16:18,160
잡는 것은 도움이 됩니다.

412
00:16:18,160 --> 00:16:20,600
사람들이 가끔 사용했던 feature

413
00:16:20,600 --> 00:16:22,800
representation의 한 예는 color

414
00:16:22,800 --> 00:16:24,200
histogram 개념입니다.

415
00:16:24,200 --> 00:16:26,900
여기서 할 수 있는 것은 색 공간을 나누는 것입니다.

416
00:16:26,900 --> 00:16:29,800
이미지 내 색 분포가 분류기에

417
00:16:29,800 --> 00:16:32,710
유용할 수 있다고 생각할

418
00:16:32,710 --> 00:16:34,270
수 있겠죠.

419
00:16:34,270 --> 00:16:36,270
예를 들어 과일 감지기, 사과 감지기를 만든다고

420
00:16:36,270 --> 00:16:38,770
할 때, 사과가 익었는지 아닌지 알고 싶을 수 있습니다.

421
00:16:38,770 --> 00:16:40,450
빨간 사과와 초록 사과를

422
00:16:40,450 --> 00:16:43,310
구분하려면 이미지에 빨간색이나 초록색이 얼마나

423
00:16:43,310 --> 00:16:45,590
있는지 아는 것이 네트워크가 분류하는

424
00:16:45,590 --> 00:16:48,215
데 유용하다고 인간이 생각할 수 있습니다.

425
00:16:48,215 --> 00:16:49,590
그래서 그런 직관을 포착하는

426
00:16:49,590 --> 00:16:51,390
feature representation을

427
00:16:51,390 --> 00:16:52,710
만들어 볼 수 있습니다.

428
00:16:52,710 --> 00:16:54,470
가능한 모든 색

429
00:16:54,470 --> 00:16:56,990
공간을 일정한 구간으로

430
00:16:56,990 --> 00:16:58,490
나누는 것입니다.

431
00:16:58,490 --> 00:17:00,288
그리고 이미지의 모든 픽셀을

432
00:17:00,288 --> 00:17:02,830
색 공간 내 이산 구간 중 하나에

433
00:17:02,830 --> 00:17:03,442
매핑합니다.

434
00:17:03,442 --> 00:17:06,109
그다음 feature representation은

435
00:17:06,109 --> 00:17:08,910
이미지 내 각 색 구간에 속하는 픽셀

436
00:17:08,910 --> 00:17:10,550
수를 세는 형태가 됩니다.

437
00:17:10,550 --> 00:17:13,829
이 표현은 이미지의 공간 구조를 모두

438
00:17:13,829 --> 00:17:16,569
파괴한다는 점에서 흥미롭습니다.

439
00:17:16,569 --> 00:17:18,569
그리고 오직 색 분포에 대해서만 이야기합니다.

440
00:17:18,569 --> 00:17:20,990
그래서 만약 빨간색이 한쪽 구석에 있거나

441
00:17:20,990 --> 00:17:22,990
반대편에 있더라도, 이 color

442
00:17:22,990 --> 00:17:25,547
histogram feature는 두

443
00:17:25,547 --> 00:17:27,589
이미지를 동일하게 보지만, 원시 픽셀

444
00:17:27,589 --> 00:17:29,910
관점에서는 매우 다르게 보일 것입니다.

445
00:17:29,910 --> 00:17:32,650
컬러 히스토그램은 이미지에서 색상만

446
00:17:32,650 --> 00:17:34,960
보고 공간 구조는 전혀

447
00:17:34,960 --> 00:17:37,210
보지 않는 기본적인 특징

448
00:17:37,210 --> 00:17:40,130
추출기 또는 특징 표현 방법입니다.

449
00:17:40,130 --> 00:17:43,370
사람들이 주로 보던 또 다른 특징 표현 범주는

450
00:17:43,370 --> 00:17:47,890
방향성 히스토그램(histogram of oriented

451
00:17:47,890 --> 00:17:49,790
gradients)입니다.

452
00:17:49,790 --> 00:17:52,290
이것들이 정확히 어떻게 계산되는지 자세히 설명하는 것은 크게

453
00:17:52,290 --> 00:17:53,470
유용하지 않다고 생각합니다.

454
00:17:53,470 --> 00:17:55,610
하지만 이들의 직관은 색상

455
00:17:55,610 --> 00:17:58,010
정보를 버리고 구조 정보만 본다는

456
00:17:58,010 --> 00:17:58,910
점입니다.

457
00:17:58,910 --> 00:18:01,290
이미지의 모든 지점에서

458
00:18:01,290 --> 00:18:04,130
국소 영역 주변의 가장자리 방향이

459
00:18:04,130 --> 00:18:06,790
무엇인지 찾으려는 거죠.

460
00:18:06,790 --> 00:18:09,590
여기서 개구리와 그 잎사귀를 보면

461
00:18:09,590 --> 00:18:12,530
대각선 방향의 특징을 추출하는데, 이는

462
00:18:12,530 --> 00:18:14,610
대각선 구조와 대응됩니다.

463
00:18:14,610 --> 00:18:17,170
개구리 눈 주변에서는 구형, 즉

464
00:18:17,170 --> 00:18:20,590
원형 구조를 잘 포착한 것을 볼 수 있습니다.

465
00:18:20,590 --> 00:18:23,270
계산 방법을 자세히 보는 것은 크게 도움이

466
00:18:23,270 --> 00:18:24,687
안 되지만, 이런

467
00:18:24,687 --> 00:18:28,250
특징들이 10년에서 15년 전쯤 사람들이 이미지에 대해 설계한

468
00:18:28,250 --> 00:18:31,840
특징이라는 점은 알아두는 게 좋습니다. 그리고 사람들은

469
00:18:31,840 --> 00:18:34,140
이런 특징들을 복잡하게 조합했습니다.

470
00:18:34,140 --> 00:18:36,820
사람들은 종종 '최고의 특징 표현은

471
00:18:36,820 --> 00:18:38,740
무엇일까?' 궁금해했죠.

472
00:18:38,740 --> 00:18:41,060
보통 답은 그냥 다 합치는 것이었습니다.

473
00:18:41,060 --> 00:18:42,435
그래서 흔한 방법은 여러

474
00:18:42,435 --> 00:18:45,040
가지 특징 표현을 이미지에서 모두 추출한 뒤,

475
00:18:45,040 --> 00:18:46,540
이들을 하나의 큰 특징

476
00:18:46,540 --> 00:18:49,400
벡터로 연결(concatenate)하는 겁니다.

477
00:18:49,400 --> 00:18:52,355
그렇게 하면 그게 이미지의 특징 표현이 됩니다.

478
00:18:52,355 --> 00:18:54,480
이제 이렇게 특징 표현이

479
00:18:54,480 --> 00:18:57,760
있으면, 그 위에 원하는 분류기를

480
00:18:57,760 --> 00:18:59,320
붙일 수 있습니다.

481
00:18:59,320 --> 00:19:03,280
그리고 한 걸음 물러서서 이 전체 시스템의

482
00:19:03,280 --> 00:19:07,080
관점을 비교하는 것도 흥미롭습니다.

483
00:19:07,080 --> 00:19:12,400
시스템 A는 특징 추출기와 그 위에 학습된 네트워크

484
00:19:12,400 --> 00:19:14,400
또는 선형 분류기를

485
00:19:14,400 --> 00:19:15,860
생각하는 방식이고,

486
00:19:15,860 --> 00:19:18,800
시스템 B는 엔드 투 엔드(end-to-end) 신경망입니다.

487
00:19:18,800 --> 00:19:21,640
사실 두 방식은 그렇게 크게 다르지 않습니다.

488
00:19:21,640 --> 00:19:24,480
한 걸음 물러서서 올바른 관점에서 생각해

489
00:19:24,480 --> 00:19:26,510
보면, 이 두 시스템 모두

490
00:19:26,510 --> 00:19:28,830
궁극적으로 이미지의 원시 픽셀을

491
00:19:28,830 --> 00:19:32,150
입력받아 이미지에 대한 점수나 예측을 출력합니다.

492
00:19:32,150 --> 00:19:33,990
차이점은 시스템의 어느 부분이

493
00:19:33,990 --> 00:19:35,670
인간에 의해 설계되었고,

494
00:19:35,670 --> 00:19:38,190
어느 부분이 경사 하강법을 통해

495
00:19:38,190 --> 00:19:39,830
학습되었느냐 하는 겁니다.

496
00:19:39,830 --> 00:19:42,690
특징 추출과 선형 분류기 패러다임에서는, 특징

497
00:19:42,690 --> 00:19:44,830
추출 부분이 설계된 부분입니다—그

498
00:19:44,830 --> 00:19:47,190
부분은 복잡한 C 코드나 Matlab

499
00:19:47,190 --> 00:19:49,032
코드일 수 있고, 내부에서

500
00:19:49,032 --> 00:19:50,990
무슨 일이 일어나는지 자세히

501
00:19:50,990 --> 00:19:52,870
생각하고 싶지 않을 겁니다.

502
00:19:52,870 --> 00:19:54,470
그리고 경사 하강법으로

503
00:19:54,470 --> 00:19:55,910
학습하는 부분, 즉

504
00:19:55,910 --> 00:19:57,785
훈련 데이터로부터 학습하는

505
00:19:57,785 --> 00:19:59,710
부분은 특징 추출기 위에 있는

506
00:19:59,710 --> 00:20:03,390
분류기뿐입니다. 반면 신경망 접근법은 경사 하강법이

507
00:20:03,390 --> 00:20:05,150
아마도 당신보다 더 나은

508
00:20:05,150 --> 00:20:07,750
프로그래머이고, 많은 데이터가 당신보다

509
00:20:07,750 --> 00:20:10,350
문제를 더 잘 알고 있다고 말하는 거죠.

510
00:20:10,350 --> 00:20:13,775
그래서 이 신경망 분류기의 직관은, 결국

511
00:20:13,775 --> 00:20:15,150
원시 픽셀 값을

512
00:20:15,150 --> 00:20:17,030
입력받아 최종적으로 분류

513
00:20:17,030 --> 00:20:19,070
점수를 출력하는 시스템이라는

514
00:20:19,070 --> 00:20:19,970
겁니다.

515
00:20:19,970 --> 00:20:21,470
하지만 차이점은 원시

516
00:20:21,470 --> 00:20:23,310
픽셀부터 최종 분류 점수까지

517
00:20:23,310 --> 00:20:25,540
시스템의 모든 부분이 경사 하강법을

518
00:20:25,540 --> 00:20:27,420
통해 조정되고 훈련 데이터

519
00:20:27,420 --> 00:20:29,680
세트로부터 학습된다는 점입니다.

520
00:20:29,680 --> 00:20:31,660
그래서 직관적으로, 이 특징

521
00:20:31,660 --> 00:20:33,667
추출 패러다임에는 병목 현상이

522
00:20:33,667 --> 00:20:35,000
있을 수 있습니다.

523
00:20:35,000 --> 00:20:36,560
인간인 당신이 뭔가를 잘못 이해할 수도 있다는 겁니다.

524
00:20:36,560 --> 00:20:39,143
문제에서 어떤 부분이 중요한지, 어떤 부분이

525
00:20:39,143 --> 00:20:41,120
중요하지 않은지에 대해 잘못된 직관을

526
00:20:41,120 --> 00:20:43,120
가질 수 있고, 문제를 해결하는 완벽한

527
00:20:43,120 --> 00:20:45,820
특징 추출기를 직접 작성하는 것이 정말 어려울

528
00:20:45,820 --> 00:20:48,240
수 있습니다. ConvNets의 이 엔드 투

529
00:20:48,240 --> 00:20:50,040
엔드 학습 접근법, 그리고 더

530
00:20:50,040 --> 00:20:52,660
일반적으로 딥러닝은 데이터와 계산 능력이 인간

531
00:20:52,660 --> 00:20:56,020
디자이너보다 그 문제를 더 잘 해결할 수 있다고 말하는 겁니다.

532
00:20:56,020 --> 00:20:58,860
이 패러다임은 지난 10년

533
00:20:58,860 --> 00:21:02,260
반 동안 많은 문제들에서

534
00:21:02,260 --> 00:21:04,980
반복적으로 승리해 왔습니다.

535
00:21:04,980 --> 00:21:08,620
그래서 직관을 드리자면, 이미지라는 특정 문제에

536
00:21:08,620 --> 00:21:11,900
대해 이 엔드 투 엔드 시스템을 어떻게 설계해야

537
00:21:11,900 --> 00:21:14,302
하는가 하는 질문이 생깁니다.

538
00:21:14,302 --> 00:21:16,760
완전히 연결된 네트워크가 끝까지 이어지는 구조는 아닐 겁니다.

539
00:21:16,760 --> 00:21:18,135
그건 좀 어리석은 일이 될 겁니다.

540
00:21:18,135 --> 00:21:21,295
그래도 시스템에 약간의 설계는 여전히 필요합니다.

541
00:21:21,295 --> 00:21:23,420
하지만 신경망을 설계하는 것과 특징

542
00:21:23,420 --> 00:21:25,200
추출기를 설계하는 것의 차이는,

543
00:21:25,200 --> 00:21:26,828
신경망을 설계할 때는 특정한

544
00:21:26,828 --> 00:21:29,120
특징 추출기 함수를 설계하는 게 아니라는

545
00:21:29,120 --> 00:21:29,900
점입니다.

546
00:21:29,900 --> 00:21:32,320
계산 그래프의 구조, 즉

547
00:21:32,320 --> 00:21:34,240
실행되는 연산자들의 순서에

548
00:21:34,240 --> 00:21:36,520
의해 정의되는 함수들의

549
00:21:36,520 --> 00:21:38,980
전체 범주를 정의하는 겁니다.

550
00:21:38,980 --> 00:21:40,560
하지만 이 시스템에는 약간의

551
00:21:40,560 --> 00:21:42,840
유연성이 있습니다. 왜냐하면 시스템의

552
00:21:42,840 --> 00:21:45,160
가중치를 데이터로부터 학습하도록 자유롭게

553
00:21:45,160 --> 00:21:46,140
두기 때문입니다.

554
00:21:46,140 --> 00:21:48,500
하지만 인간 설계자의 역할은 여전히 중요합니다.

555
00:21:48,500 --> 00:21:51,240
네트워크의 아키텍처가 무엇인지

556
00:21:51,240 --> 00:21:52,180
결정해야 합니다.

557
00:21:52,180 --> 00:21:54,120
계산 그래프에 연결되는 연산자들의

558
00:21:54,120 --> 00:21:55,960
순서가 무엇인지, 처리

559
00:21:55,960 --> 00:21:57,880
단계마다 모든 행렬의 크기가

560
00:21:57,880 --> 00:21:59,325
어떻게 되는지 말이죠.

561
00:21:59,325 --> 00:22:01,200
그래서 이 딥러닝

562
00:22:01,200 --> 00:22:05,440
시대에도 문제의 일부를 설계하는 데 인간의 역할이 여전히

563
00:22:05,440 --> 00:22:09,782
큽니다. 다만 설계하는 것이 조금 다를 뿐입니다.

564
00:22:09,782 --> 00:22:11,240
이제까지 우리가

565
00:22:11,240 --> 00:22:12,740
가진 도구들의 한계가

566
00:22:12,740 --> 00:22:14,980
보이기 시작하는 지점입니다.

567
00:22:14,980 --> 00:22:17,620
우리는 선형 계층을 봤고, 완전

568
00:22:17,620 --> 00:22:19,800
연결 네트워크도 봤습니다.

569
00:22:19,800 --> 00:22:22,950
우리가 본 유일한 신경망 아키텍처는 이미지의 픽셀을

570
00:22:22,950 --> 00:22:26,330
큰 벡터로 펼쳐서 행렬 곱을 하고, ReLU를

571
00:22:26,330 --> 00:22:29,570
적용하고, 또 행렬 곱을 하고, 또 ReLU를 하는

572
00:22:29,570 --> 00:22:30,337
방식입니다.

573
00:22:30,337 --> 00:22:31,170
그게 전부입니다.

574
00:22:31,170 --> 00:22:33,163
지금까지 우리가 할 줄 아는 전부입니다.

575
00:22:33,163 --> 00:22:34,830
이 방식의 큰 문제 중 하나는

576
00:22:34,830 --> 00:22:37,270
이미지의 공간 구조를 파괴한다는 점입니다.

577
00:22:37,270 --> 00:22:39,950
이게 큰 문제입니다.

578
00:22:39,950 --> 00:22:42,810
이미지는 사실 1차원 객체가 아닙니다.

579
00:22:42,810 --> 00:22:44,010
이미지는 2차원입니다.

580
00:22:44,010 --> 00:22:45,610
2차원 구조를 가지고 있죠.

581
00:22:45,610 --> 00:22:47,860
그 2차원 구조는 이미지 내용에

582
00:22:47,860 --> 00:22:48,830
중요합니다.

583
00:22:48,830 --> 00:22:51,670
이미지의 원시 픽셀을 큰 벡터로 펼쳐서

584
00:22:51,670 --> 00:22:53,530
선형 분류기를 만들면,

585
00:22:53,530 --> 00:22:56,870
신경망 아키텍처 설계에서 입력 데이터의

586
00:22:56,870 --> 00:22:59,648
중요한 요소를 무시하는 셈입니다.

587
00:22:59,648 --> 00:23:02,190
그래서 이미지용 신경망 아키텍처를

588
00:23:02,190 --> 00:23:05,590
설계할 때는, 다른 설계 방법, 즉 계산

589
00:23:05,590 --> 00:23:07,590
그래프에 넣을 수 있는

590
00:23:07,590 --> 00:23:09,150
다른 계산 원시 연산들이

591
00:23:09,150 --> 00:23:12,430
무엇이 있을지 생각해야 합니다. 그것들이

592
00:23:12,430 --> 00:23:15,150
이미지의 2차원 구조를 더 잘

593
00:23:15,150 --> 00:23:17,110
반영할 수 있어야 합니다.

594
00:23:17,110 --> 00:23:19,130
이것이 바로 convolutional networks, 즉 합성곱 신경망으로
이어집니다.

595
00:23:19,130 --> 00:23:21,100
합성곱 신경망은 기본적으로

596
00:23:21,100 --> 00:23:23,060
선형 계층,

597
00:23:23,060 --> 00:23:27,180
비선형성, 합성곱 계층, 풀링 계층, 때로는

598
00:23:27,180 --> 00:23:29,783
몇 가지 다른 계층들이 결합되어

599
00:23:29,783 --> 00:23:31,700
원시 픽셀 값을

600
00:23:31,700 --> 00:23:34,020
입력받아 이미지에 대한

601
00:23:34,020 --> 00:23:38,843
예측이나 점수를 출력하는 신경망 아키텍처 범주입니다.

602
00:23:38,843 --> 00:23:40,260
일반적으로 이

603
00:23:40,260 --> 00:23:43,180
네트워크들은 접두부와 본체가 있는데,

604
00:23:43,180 --> 00:23:45,460
본체는 합성곱 계층, 풀링

605
00:23:45,460 --> 00:23:49,060
계층, 비선형성이 교차하는 순서로 구성되어

606
00:23:49,060 --> 00:23:51,740
이미지의 유용한 특징 표현을

607
00:23:51,740 --> 00:23:53,540
추출하는 역할을 합니다.

608
00:23:53,540 --> 00:23:55,340
그리고 그 위에는 보통

609
00:23:55,340 --> 00:23:59,100
완전 연결 계층들이 있는데, 하나일 수도

610
00:23:59,100 --> 00:24:00,740
있고 여러 개일 수도

611
00:24:00,740 --> 00:24:03,460
있습니다. 이것은 합성곱 부분에서

612
00:24:03,460 --> 00:24:06,460
추출한 특징을 입력받아 다층

613
00:24:06,460 --> 00:24:09,340
퍼셉트론 완전 연결 네트워크 분류기로

614
00:24:09,340 --> 00:24:10,300
작동합니다.

615
00:24:10,300 --> 00:24:13,140
하지만 중요한 점은 이 전체 시스템이 훈련

616
00:24:13,140 --> 00:24:16,620
데이터셋의 손실을 최소화하는 방향으로 경사 하강법을

617
00:24:16,620 --> 00:24:19,010
통해 끝에서 끝까지 조정된다는 것입니다.

618
00:24:19,010 --> 00:24:22,250
이 네트워크들은 사실 꽤 오랜 역사를 가지고 있습니다.

619
00:24:22,250 --> 00:24:25,705
화면에 그려진 이 특정 ConvNet

620
00:24:25,705 --> 00:24:27,330
아키텍처는

621
00:24:27,330 --> 00:24:32,410
1998년에 Yann LeCun, Leon

622
00:24:32,410 --> 00:24:34,523
Bottou 등 연구자들이

623
00:24:34,523 --> 00:24:36,690
당시 숫자 분류 작업을

624
00:24:36,690 --> 00:24:40,730
위해 만든 논문에서 나온 것입니다.

625
00:24:40,730 --> 00:24:42,770
실제로 꽤 잘 작동했지만, 매우

626
00:24:42,770 --> 00:24:44,230
비용이 많이 들었습니다.

627
00:24:44,230 --> 00:24:46,150
그때는 GPU도, TPU도,

628
00:24:46,150 --> 00:24:48,970
오늘날 우리가 가진 컴퓨팅 자원도 없었죠.

629
00:24:48,970 --> 00:24:51,170
하지만 기본 알고리즘과

630
00:24:51,170 --> 00:24:54,810
네트워크 아키텍처는 1998년과 2010년대까지

631
00:24:54,810 --> 00:24:55,970
사람들이

632
00:24:55,970 --> 00:25:00,330
사용한 아키텍처와 기본적으로 꽤 비슷했습니다.

633
00:25:00,330 --> 00:25:03,890
그리고 1998년부터 2012년까지를 보면, AlexNet

634
00:25:03,890 --> 00:25:06,070
아키텍처가 등장했습니다.

635
00:25:06,070 --> 00:25:09,310
이것은 딥러닝, 특히 컴퓨터 비전 분야에서

636
00:25:09,310 --> 00:25:11,310
큰 폭발적인 발전이었죠.

637
00:25:11,310 --> 00:25:13,890
이전 강의에서 이 내용을 다룬 적도 있습니다.

638
00:25:13,890 --> 00:25:15,490
하지만 AlexNet 아키텍처도

639
00:25:15,490 --> 00:25:18,250
1988년 Yann LeCun의 LeNet

640
00:25:18,250 --> 00:25:20,050
아키텍처와 크게 다르지 않습니다.

641
00:25:20,050 --> 00:25:22,770
이것은 여러 개의 convolutional layer와 fully
connected layer로 이루어져 있습니다.

642
00:25:22,770 --> 00:25:24,330
더 크고, 더 많은 층이 있습니다.

643
00:25:24,330 --> 00:25:26,390
층마다 더 많은 유닛이 있지만, 여전히

644
00:25:26,390 --> 00:25:28,870
end-to-end로 backpropagation을

645
00:25:28,870 --> 00:25:32,190
통해 꽤 단순한 손실 함수를 최소화하도록 학습됩니다.

646
00:25:32,190 --> 00:25:34,590
하지만 여기서, AlexNet처럼, 진짜로 일이

647
00:25:34,590 --> 00:25:35,750
본격적으로 시작되었죠.

648
00:25:35,750 --> 00:25:38,250
그리고 이때 GPU로 학습할 수 있었습니다.

649
00:25:38,250 --> 00:25:39,510
GPU가 사용 가능했죠.

650
00:25:39,510 --> 00:25:41,810
인터넷과 ImageNet 덕분에 더

651
00:25:41,810 --> 00:25:43,470
많은 데이터가 있었습니다.

652
00:25:43,470 --> 00:25:47,390
그래서 AlexNet이 진짜로 일이 본격적으로 시작된 시기입니다.

653
00:25:47,390 --> 00:25:52,070
그래서 2012년부터 대략 2020년까지는 convolutional

654
00:25:52,070 --> 00:25:54,470
network가 컴퓨터 비전의

655
00:25:54,470 --> 00:25:57,310
거의 모든 문제를 지배한 시대였습니다.

656
00:25:57,310 --> 00:26:00,030
그 시대에 이미지와 관련된 거의

657
00:26:00,030 --> 00:26:02,250
모든 문제는 거의 확실히

658
00:26:02,250 --> 00:26:04,310
ConvNet이 최고의

659
00:26:04,310 --> 00:26:05,790
성능을 냈습니다.

660
00:26:05,790 --> 00:26:07,910
왼쪽의 detection 같은 작업도

661
00:26:07,910 --> 00:26:11,030
포함되는데, 이는 단순히 이미지를 분류하는 것이

662
00:26:11,030 --> 00:26:13,342
아니라 이미지 내 모든 객체 주위에 박스를

663
00:26:13,342 --> 00:26:15,300
그리고 그 박스에 카테고리 레이블을

664
00:26:15,300 --> 00:26:16,620
붙이는 작업입니다.

665
00:26:16,620 --> 00:26:19,420
Segmentation은 박스나 이미지

666
00:26:19,420 --> 00:26:21,560
수준이 아니라 픽셀 단위로

667
00:26:21,560 --> 00:26:23,840
레이블을 할당하는 작업입니다.

668
00:26:23,840 --> 00:26:26,300
즉, 이제는 이미지 내 모든 픽셀에 독립적으로

669
00:26:26,300 --> 00:26:27,843
카테고리 레이블을 할당하려는 겁니다.

670
00:26:27,843 --> 00:26:30,260
이 문제들을 위한 아키텍처는 앞으로 강의에서 더

671
00:26:30,260 --> 00:26:31,400
자세히 다룰 것입니다.

672
00:26:31,400 --> 00:26:34,420
하지만 이런 문제들은 convolutional network를

673
00:26:34,420 --> 00:26:36,780
사용해 매우 효과적으로 해결할 수 있습니다.

674
00:26:36,780 --> 00:26:39,820
사람들은 언어와 관련된 다른 문제에도 ConvNet을

675
00:26:39,820 --> 00:26:40,477
사용했습니다.

676
00:26:40,477 --> 00:26:42,060
이미지 캡셔닝 작업은

677
00:26:42,060 --> 00:26:45,680
이미지에서 자연어 캡션을 예측하는 것입니다.

678
00:26:45,680 --> 00:26:47,860
이 문제에 대해 처음으로 널리

679
00:26:47,860 --> 00:26:51,860
성공한 접근법 중 일부도 컨볼루션 네트워크를 기반으로 했습니다.

680
00:26:51,860 --> 00:26:54,460
그리고 최근의 생성 모델링 작업들에도

681
00:26:54,460 --> 00:26:55,780
마찬가지입니다.

682
00:26:55,780 --> 00:26:57,966
텍스트에서 이미지로, 아니

683
00:26:57,966 --> 00:27:00,998
캡셔닝은 기본적으로 이미지에서 텍스트로의 문제로,

684
00:27:00,998 --> 00:27:02,540
이미지를 입력받아 그

685
00:27:02,540 --> 00:27:06,100
이미지를 설명하는 자연어 문장을 출력하는 겁니다.

686
00:27:06,100 --> 00:27:08,780
우리는 또한 텍스트에서 이미지

687
00:27:08,780 --> 00:27:11,700
생성이라는 역문제도 생각할 수

688
00:27:11,700 --> 00:27:14,630
있는데, 머릿속에 상상하는 것을

689
00:27:14,630 --> 00:27:18,290
자연어로 입력하면 시스템이 그 설명에

690
00:27:18,290 --> 00:27:21,050
맞는 새로운 이미지를 처음부터

691
00:27:21,050 --> 00:27:25,210
생성하는 겁니다. 이 문제의 최초로 널리 성공한

692
00:27:25,210 --> 00:27:27,490
버전들도 컨볼루션 네트워크를

693
00:27:27,490 --> 00:27:29,710
기반으로 했습니다.

694
00:27:29,710 --> 00:27:32,610
이 그림은 2021년에 나온 Stable

695
00:27:32,610 --> 00:27:34,930
Diffusion 논문에서 가져온 것입니다.

696
00:27:34,930 --> 00:27:36,703
이 기술은 지난 몇

697
00:27:36,703 --> 00:27:38,870
년간 많이 발전했습니다.

698
00:27:38,870 --> 00:27:41,120
그리고 이후 강의에서 더 자세히 다룰 예정입니다.

699
00:27:41,120 --> 00:27:43,370
하지만 기본적으로 이 문제를 처음 잘

700
00:27:43,370 --> 00:27:46,010
해결한 버전들도 컨볼루션 네트워크를 기반으로

701
00:27:46,010 --> 00:27:48,670
했다는 점을 짚고 넘어가는 게 유용합니다.

702
00:27:48,670 --> 00:27:50,170
즉, 컨볼루션 네트워크는

703
00:27:50,170 --> 00:27:52,730
컴퓨터 비전 역사에서 매우 중요해서,

704
00:27:52,730 --> 00:27:55,090
2015년에 시작한 이 강의의

705
00:27:55,090 --> 00:27:57,730
초기 버전은 '시각 인식을 위한

706
00:27:57,730 --> 00:28:00,110
컨볼루션 신경망'이라는 이름이었는데,

707
00:28:00,110 --> 00:28:02,410
당시에는 컨볼루션 네트워크가 컴퓨터

708
00:28:02,410 --> 00:28:05,010
비전과 거의 동의어였기 때문입니다.

709
00:28:05,010 --> 00:28:06,610
그리고 컴퓨터 비전은

710
00:28:06,610 --> 00:28:09,730
그 당시 딥러닝의 가장 큰 수혜

711
00:28:09,730 --> 00:28:10,970
분야였습니다.

712
00:28:10,970 --> 00:28:14,198
그래서 딥러닝 강의를 시작할 때 이미지 문제에

713
00:28:14,198 --> 00:28:16,240
대한 컨볼루션 네트워크 문제에만

714
00:28:16,240 --> 00:28:18,943
집중하는 것이 매우 합리적이었습니다.

715
00:28:18,943 --> 00:28:20,360
이것이 10년 전

716
00:28:20,360 --> 00:28:22,400
이 강의의 시작 배경입니다.

717
00:28:22,400 --> 00:28:25,580
하지만 그 이후로 분야는 많이 발전했습니다.

718
00:28:25,580 --> 00:28:28,060
컨볼루션 네트워크는 실제로 대체되었고,

719
00:28:28,060 --> 00:28:29,120
시각 인식 외에도 지금은

720
00:28:29,120 --> 00:28:31,240
해결할 수 있는 흥미로운 문제들이 많이 있습니다.

721
00:28:31,240 --> 00:28:33,032
그래서 수업 이름이 어느 시점에서

722
00:28:33,032 --> 00:28:35,960
바뀌었고, 더 이상 신경망, 특히 convolutional

723
00:28:35,960 --> 00:28:38,000
networks에만

724
00:28:38,000 --> 00:28:40,120
집중하지 않게 된 것을 알 수 있습니다.

725
00:28:40,120 --> 00:28:41,840
그 이유는 이 기간이 2012년부터

726
00:28:41,840 --> 00:28:44,260
2020년까지의 시대라고 제가 말씀드렸기 때문입니다.

727
00:28:44,260 --> 00:28:45,760
2020년에 COVID 외에

728
00:28:45,760 --> 00:28:48,320
convolutional networks를 대체한 무언가가

729
00:28:48,320 --> 00:28:49,840
있었는지 궁금할 수 있습니다.

730
00:28:49,840 --> 00:28:52,438
COVID가 아니라 transformers였습니다.

731
00:28:52,438 --> 00:28:54,480
transformers는 몇

732
00:28:54,480 --> 00:28:57,120
강의 후에 다룰 대체 신경망 아키텍처입니다.

733
00:28:57,120 --> 00:28:59,920
기본적으로 자연어 처리, 문서나

734
00:28:59,920 --> 00:29:03,120
텍스트 문자열 처리를 위해 시작되었습니다.

735
00:29:03,120 --> 00:29:06,378
transformer 아키텍처는 2017년에 처음 발표되었습니다.

736
00:29:06,378 --> 00:29:07,920
그 후 몇 년간

737
00:29:07,920 --> 00:29:10,720
주로 텍스트 처리 영역에

738
00:29:10,720 --> 00:29:13,140
머물렀지만, 2021년에

739
00:29:13,140 --> 00:29:15,820
거의 동일한 transformer

740
00:29:15,820 --> 00:29:18,400
아키텍처를 텍스트 대신

741
00:29:18,400 --> 00:29:20,500
이미지 처리에 적용한

742
00:29:20,500 --> 00:29:23,660
매우 중요한 논문이 나왔습니다.

743
00:29:23,660 --> 00:29:25,780
그리고 그 이후로, 이전에 우리가 이야기했던

744
00:29:25,780 --> 00:29:28,020
많은 문제들에 대해, 이전에는

745
00:29:28,020 --> 00:29:29,460
convolutional networks를

746
00:29:29,460 --> 00:29:31,240
사용해서 해결했지만, CNN을

747
00:29:31,240 --> 00:29:33,740
transformer로 대체하고 나머지는 그대로

748
00:29:33,740 --> 00:29:35,745
두면 그 문제들에서 더 나은 성능을

749
00:29:35,745 --> 00:29:38,120
얻는 경향이 있다는 것을 사람들이 발견했습니다.

750
00:29:38,120 --> 00:29:41,260
이들은 더 많은 데이터에 맞춰 확장할 수 있고, 더 많은 연산량에도 확장할
수 있습니다.

751
00:29:41,260 --> 00:29:46,260
즉, 우리는 더 많은 데이터를 얻을 수 있고, 더 많은 연산량도 확보할 수
있다는 겁니다.

752
00:29:46,260 --> 00:29:49,140
그래서 요즘에는 이런 것들이 점점 더 많은 컴퓨터

753
00:29:49,140 --> 00:29:51,620
비전 문제에 훨씬 더 흔히 사용되고 있습니다.

754
00:29:51,620 --> 00:29:54,120
트랜스포머에 대해서는 8강에서 더 자세히

755
00:29:54,120 --> 00:29:56,980
다룰 텐데요, 사실 요즘은 ConvNets가 5년

756
00:29:56,980 --> 00:29:59,380
전만큼 많이 사용되지는 않아서 ConvNets를

757
00:29:59,380 --> 00:30:02,560
너무 강하게 추천하는 게 이상할 것 같았습니다.

758
00:30:02,560 --> 00:30:04,060
하지만 여전히 convolutional

759
00:30:04,060 --> 00:30:06,360
networks에 대해 이야기하는 것이

760
00:30:06,360 --> 00:30:09,010
매우 유용하다고 생각하는데, 첫째로 역사적으로 매우

761
00:30:09,010 --> 00:30:12,928
중요하고, 둘째로 이 알고리즘들이 실제로도 꽤 많이 사용되고 있기
때문입니다.

762
00:30:12,928 --> 00:30:14,970
셋째로, 이미지에서 중요한 것이 무엇인지에 대한

763
00:30:14,970 --> 00:30:17,010
직관을 키우는 데 도움이 되고, 넷째로 완전히

764
00:30:17,010 --> 00:30:18,260
사라진 것은 아니기 때문입니다.

765
00:30:18,260 --> 00:30:20,510
많은 경우에 우리는 실제로 하이브리드 시스템을 구축하고 있습니다.

766
00:30:20,510 --> 00:30:23,010
가끔은 convolution을 사용하고, 가끔은 transformers를

767
00:30:23,010 --> 00:30:25,070
사용하며, 때로는 이 둘을 다양한 방식으로 섞어서 사용합니다.

768
00:30:25,070 --> 00:30:28,570
그래서 이런 것들을 여전히 아는 것이 정말 유용합니다.

769
00:30:28,570 --> 00:30:30,250
오늘 나머지 시간에는 기본적으로

770
00:30:30,250 --> 00:30:32,710
convolutional networks에 대해 더 이야기할 겁니다.

771
00:30:32,710 --> 00:30:35,890
우리는 convolutional network가 이미지를

772
00:30:35,890 --> 00:30:38,070
처리하기 위한 계산 그래프라고 말했습니다.

773
00:30:38,070 --> 00:30:39,790
이것은 몇 가지 다른 기본 요소로 구성되어 있습니다.

774
00:30:39,790 --> 00:30:41,210
우리는 이미 fully connected layer와

775
00:30:41,210 --> 00:30:42,670
activation function을 만났습니다.

776
00:30:42,670 --> 00:30:44,795
그래서 이제 convolution layer와

777
00:30:44,795 --> 00:30:47,690
pooling layer, 이 두 가지 레이어를 살펴볼 필요가 있습니다.

778
00:30:47,690 --> 00:30:49,480
fully connected layer에 대한 간단한 복습입니다.

779
00:30:49,480 --> 00:30:51,730
이것은 우리가 linear classifiers

780
00:30:51,730 --> 00:30:53,213
맥락에서 이미 이야기한 내용입니다.

781
00:30:53,213 --> 00:30:54,630
fully connected

782
00:30:54,630 --> 00:30:56,170
layer에서는, 말했듯이,

783
00:30:56,170 --> 00:30:58,110
기본적으로 이미지의 픽셀을 가져옵니다.

784
00:30:58,110 --> 00:31:01,450
우리의 이미지는 32x32x3 크기의 3차원

785
00:31:01,450 --> 00:31:04,830
텐서입니다. 32x32는 공간적 차원이고,

786
00:31:04,830 --> 00:31:08,020
3은 RGB 색상의 세 채널 차원입니다.

787
00:31:08,020 --> 00:31:10,860
그래서 32x32x3 벡터를 가져옵니다.

788
00:31:10,860 --> 00:31:13,065
이것을 길게 늘려서 3072 길이의

789
00:31:13,065 --> 00:31:15,440
벡터로 만듭니다. 머릿속으로 곱하면

790
00:31:15,440 --> 00:31:16,800
나오는 숫자입니다.

791
00:31:16,800 --> 00:31:21,160
그럼 3072개의 숫자로 이루어진 벡터가 생깁니다.

792
00:31:21,160 --> 00:31:23,040
우리는 3072x10 크기의 가중치

793
00:31:23,040 --> 00:31:25,760
행렬을 가지고 있는데, 여기서 10은 우리가 원하는 출력

794
00:31:25,760 --> 00:31:26,580
클래스 수입니다.

795
00:31:26,580 --> 00:31:28,780
두 개를 행렬-벡터 곱셈을 합니다.

796
00:31:28,780 --> 00:31:30,960
그럼 10개의 숫자로 이루어진 벡터가

797
00:31:30,960 --> 00:31:33,040
나오고, 이게 클래스 점수를 나타냅니다.

798
00:31:33,040 --> 00:31:35,600
특히, 완전 연결층에서 합성곱층으로

799
00:31:35,600 --> 00:31:38,000
일반화하려고 할 때,

800
00:31:38,000 --> 00:31:40,577
완전 연결층이 하는 일을 구조적으로

801
00:31:40,577 --> 00:31:43,160
좀 더 생각하는 게 유용합니다.

802
00:31:43,160 --> 00:31:46,780
완전 연결층의 출력 벡터는 10개의

803
00:31:46,780 --> 00:31:49,600
요소를 가지고 있고, 각 요소는

804
00:31:49,600 --> 00:31:50,900
하나의 숫자입니다.

805
00:31:50,900 --> 00:31:52,760
각 숫자는 가중치

806
00:31:52,760 --> 00:31:54,760
행렬의 한 행과 전체

807
00:31:54,760 --> 00:31:57,680
입력 벡터 사이의 내적을 계산해서

808
00:31:57,680 --> 00:31:58,800
예측합니다.

809
00:31:58,800 --> 00:32:00,560
각 항목은 기본적으로 내적, 즉

810
00:32:00,560 --> 00:32:02,657
점곱으로 생각해야 하고, 점곱은 기본적으로

811
00:32:02,657 --> 00:32:04,990
템플릿 매칭으로 생각할 수 있습니다.

812
00:32:04,990 --> 00:32:06,448
두 벡터가 같은 방향을

813
00:32:06,448 --> 00:32:09,130
가리킬 때 점곱 값이 크고, 두 벡터가

814
00:32:09,130 --> 00:32:11,490
직교하면 0이 되기 때문입니다.

815
00:32:11,490 --> 00:32:12,950
그래서 점곱을 기반으로 한

816
00:32:12,950 --> 00:32:15,030
모든 것은 기본적으로 템플릿 매칭입니다.

817
00:32:15,030 --> 00:32:17,630
완전 연결층을 생각할 때는,

818
00:32:17,630 --> 00:32:20,670
입력과 같은 크기의 템플릿 세트를

819
00:32:20,670 --> 00:32:23,110
가지고 있다고 보면 됩니다.

820
00:32:23,110 --> 00:32:26,150
출력은 각 템플릿과 전체

821
00:32:26,150 --> 00:32:30,510
입력 사이의 템플릿 매칭 점수입니다.

822
00:32:30,510 --> 00:32:32,315
이렇게 생각하면 완전

823
00:32:32,315 --> 00:32:34,190
연결층을 합성곱층으로

824
00:32:34,190 --> 00:32:37,410
일반화하는 좋은 방법이 있습니다.

825
00:32:37,410 --> 00:32:39,182
즉, 템플릿 매칭이라는

826
00:32:39,182 --> 00:32:40,890
개념은 유지합니다.

827
00:32:40,890 --> 00:32:42,432
필터 뱅크를 학습한다는

828
00:32:42,432 --> 00:32:44,090
개념도 유지합니다.

829
00:32:44,090 --> 00:32:46,830
하지만 필터, 즉 템플릿이 입력과

830
00:32:46,830 --> 00:32:48,710
같은 모양을 가지지

831
00:32:48,710 --> 00:32:50,690
않는다는 점이 달라집니다.

832
00:32:50,690 --> 00:32:53,870
대신 필터는 입력의

833
00:32:53,870 --> 00:32:57,910
작은 부분집합만을 봅니다.

834
00:32:57,910 --> 00:33:00,830
좀 더 구체적으로 말하면, 이미지를

835
00:33:00,830 --> 00:33:03,950
3072개의 숫자로 쭉 펼치는 대신,

836
00:33:03,950 --> 00:33:07,230
이미지의 3차원 공간 구조를 유지합니다.

837
00:33:07,230 --> 00:33:09,730
이제 3개의 채널(깊이 또는 채널

838
00:33:09,730 --> 00:33:12,310
차원이라고도 함), 너비 32,

839
00:33:12,310 --> 00:33:14,770
높이 32인 3차원 텐서가 됩니다.

840
00:33:14,770 --> 00:33:16,530
이제 우리의 필터 중 하나는

841
00:33:16,530 --> 00:33:20,070
아주 작은 서브 이미지, 즉 저해상도 이미지가 될

842
00:33:20,070 --> 00:33:22,730
겁니다. 이 경우 5x5 픽셀 이미지입니다.

843
00:33:22,730 --> 00:33:26,130
그리고 중요한 점은, 그 작은 필터가 세 개의 채널을

844
00:33:26,130 --> 00:33:27,430
가져야 한다는 겁니다.

845
00:33:27,430 --> 00:33:29,370
채널 수는 항상 입력의

846
00:33:29,370 --> 00:33:31,150
채널 수와 같지만, 공간적

847
00:33:31,150 --> 00:33:33,395
크기는 더 작을 겁니다.

848
00:33:33,395 --> 00:33:34,770
이제 우리가 할 일은 내적(dot

849
00:33:34,770 --> 00:33:36,310
product)을 계산하는 것입니다.

850
00:33:36,310 --> 00:33:38,810
그 작은 필터를 이미지 템플릿의 작은

851
00:33:38,810 --> 00:33:39,918
조각으로 생각합니다.

852
00:33:39,918 --> 00:33:42,210
그리고 그 필터를 이미지 전체에

853
00:33:42,210 --> 00:33:44,450
슬라이드하면서, 이미지의 각

854
00:33:44,450 --> 00:33:47,170
지점에서 그 부분 이미지가 우리가

855
00:33:47,170 --> 00:33:49,490
학습하는 컨볼루션 필터의 템플릿과

856
00:33:49,490 --> 00:33:51,570
얼마나 일치하는지 평가합니다.

857
00:33:51,570 --> 00:33:53,930
그래서 컨볼루션 필터를 이미지의

858
00:33:53,930 --> 00:33:55,470
어떤 부분에 놓습니다.

859
00:33:55,470 --> 00:33:59,050
그 5x5x3 필터가 그 공간 위치의 5x5x3

860
00:33:59,050 --> 00:34:02,400
이미지 조각과 정렬되고, 두 개의 내적을

861
00:34:02,400 --> 00:34:03,860
계산해서 하나의 스칼라

862
00:34:03,860 --> 00:34:06,080
값을 얻습니다. 이 값은 그

863
00:34:06,080 --> 00:34:08,480
이미지 조각이 템플릿과 얼마나

864
00:34:08,480 --> 00:34:10,280
일치하는지를 나타냅니다.

865
00:34:10,280 --> 00:34:13,159
이 과정을 반복해서 템플릿을 이미지

866
00:34:13,159 --> 00:34:14,900
전체에 슬라이드합니다.

867
00:34:14,900 --> 00:34:17,150
템플릿을 놓는 모든 위치에서, 우리는

868
00:34:17,150 --> 00:34:19,567
다시 그 템플릿 매칭 점수를 계산해서

869
00:34:19,567 --> 00:34:21,880
그 이미지 조각이 템플릿과 얼마나

870
00:34:21,880 --> 00:34:23,260
일치하는지 평가합니다.

871
00:34:23,260 --> 00:34:27,139
필터를 입력 이미지 전체에 슬라이드하면서,

872
00:34:27,139 --> 00:34:29,440
모든 템플릿 매칭 점수를

873
00:34:29,440 --> 00:34:32,120
모아서 평면에 저장합니다.

874
00:34:32,120 --> 00:34:35,040
그 평면은 이제 2차원

875
00:34:35,040 --> 00:34:37,920
평면이 되며, 평면의

876
00:34:37,920 --> 00:34:40,600
각 점은 입력 이미지의

877
00:34:40,600 --> 00:34:44,120
해당 부분이 필터와 얼마나

878
00:34:44,120 --> 00:34:47,600
일치하는지를 나타냅니다.

879
00:34:47,600 --> 00:34:50,060
하지만 물론, 이것은 딥러닝입니다.

880
00:34:50,060 --> 00:34:51,260
우리는 많은 연산량을 원합니다.

881
00:34:51,260 --> 00:34:52,580
그럼 어떻게 더 많은 연산량을 얻을까요?

882
00:34:52,580 --> 00:34:53,900
필터를 더 많이 사용하는 겁니다.

883
00:34:53,900 --> 00:34:56,080
이제 두 번째 필터를 추가해서,

884
00:34:56,080 --> 00:34:59,080
다시 한 번 다른 필터로 같은 과정을

885
00:34:59,080 --> 00:35:00,490
반복해 보겠습니다.

886
00:35:00,490 --> 00:35:03,110
우리는 5x5x3 크기의 필터를 가지고

887
00:35:03,110 --> 00:35:05,150
있는데, 파란색으로 표시했습니다.

888
00:35:05,150 --> 00:35:06,750
이제 두 번째 필터를

889
00:35:06,750 --> 00:35:08,470
초록색으로 상상해 봅시다.

890
00:35:08,470 --> 00:35:11,162
두 번째 필터도 여전히 5x5x3 크기입니다.

891
00:35:11,162 --> 00:35:12,870
그리고 초록색 필터를

892
00:35:12,870 --> 00:35:15,495
이미지 전체에 슬라이딩하면서, 초록색

893
00:35:15,495 --> 00:35:17,870
필터와 이미지의 작은 부분들

894
00:35:17,870 --> 00:35:20,010
간의 템플릿 매칭 점수를 계산하고,

895
00:35:20,010 --> 00:35:23,110
그 점수들을 두 번째 평면에 모읍니다.

896
00:35:23,110 --> 00:35:26,190
이 평면은 이미지의 각 지점이 초록색

897
00:35:26,190 --> 00:35:28,990
필터에 얼마나 반응했는지를 알려줍니다.

898
00:35:28,990 --> 00:35:32,310
이 과정을 반복해서 원하는 만큼 필터를

899
00:35:32,310 --> 00:35:33,670
추가할 수 있습니다.

900
00:35:33,670 --> 00:35:36,670
이 경우에는 6개의

901
00:35:36,670 --> 00:35:40,350
필터를 그리는데, 각각 3x5x5

902
00:35:40,350 --> 00:35:41,030
크

903
00:35:41,030 --> 00:35:42,343
기입니다.

904
00:35:42,343 --> 00:35:44,510
이 필터들을 모두 하나의 4차원

905
00:35:44,510 --> 00:35:46,590
텐서로 모을 수 있습니다.

906
00:35:46,590 --> 00:35:49,790
이 4차원 텐서에서 첫 번째 차원은

907
00:35:49,790 --> 00:35:52,290
6으로, 필터 개수를 나타냅니다.

908
00:35:52,290 --> 00:35:56,110
그리고 3x5x5는 우리가 학습하는 이미지

909
00:35:56,110 --> 00:35:58,970
템플릿, 즉 필터의 크기입니다.

910
00:35:58,970 --> 00:36:01,970
이제 컨볼루션 레이어는 3차원 입력

911
00:36:01,970 --> 00:36:04,730
이미지와 4차원 필터 뱅크를

912
00:36:04,730 --> 00:36:08,112
입력으로 받아, 모든 필터를 이미지 전체에

913
00:36:08,112 --> 00:36:09,570
슬라이딩하며

914
00:36:09,570 --> 00:36:11,530
반응 평면들을 생성합니다.

915
00:36:11,530 --> 00:36:13,650
이 반응 평면들을 모두

916
00:36:13,650 --> 00:36:15,590
모아서 세 번째

917
00:36:15,590 --> 00:36:21,930
차원으로 쌓으면, 출력 크기는 6x28x28이 됩니다. 여기서

918
00:36:21,930 --> 00:36:24,130
28x28은 공간적 차원이고,

919
00:36:24,130 --> 00:36:26,850
6은 채널 차원입니다.

920
00:36:26,850 --> 00:36:28,770
물론, 선형 레이어에서처럼

921
00:36:28,770 --> 00:36:30,270
컨볼루션

922
00:36:30,270 --> 00:36:32,770
레이어에도 학습 가능한 바이어스

923
00:36:32,770 --> 00:36:36,250
벡터를 추가하는 경우가 많습니다.

924
00:36:36,250 --> 00:36:38,890
선형 레이어에서는 각 행마다

925
00:36:38,890 --> 00:36:41,680
하나의 스칼라 바이어스가 있듯이,

926
00:36:41,680 --> 00:36:43,430
컨볼루션 레이어에서는

927
00:36:43,430 --> 00:36:46,010
보통 각 필터마다

928
00:36:46,010 --> 00:36:48,890
하나의 스칼라 바이어스

929
00:36:48,890 --> 00:36:50,443
값을 가집니다.

930
00:36:50,443 --> 00:36:52,610
따라서 이 설정에서는 6차원

931
00:36:52,610 --> 00:36:54,635
바이어스 벡터가 존재합니다.

932
00:36:54,635 --> 00:36:56,010
네, 질문은 3이 RGB 채널을

933
00:36:56,010 --> 00:36:57,260
의미하는지 확인하는 것이었습니다.

934
00:36:57,260 --> 00:36:58,720
네, 맞습니다.

935
00:36:58,720 --> 00:37:00,420
문제는 필터를 어떻게 얻느냐 하는 겁니다.

936
00:37:00,420 --> 00:37:03,740
그게 바로 gradient descent와 backpropagation의
기적입니다.

937
00:37:03,740 --> 00:37:06,220
즉, 우리가 이 연산자를 정의하고 있다는 거죠.

938
00:37:06,220 --> 00:37:08,000
이 연산자는 입력 이미지와

939
00:37:08,000 --> 00:37:10,460
필터 집합을 가지게 됩니다.

940
00:37:10,460 --> 00:37:12,640
하지만 사람이 직접 필터가 무엇인지

941
00:37:12,640 --> 00:37:13,900
정의하지는 않습니다.

942
00:37:13,900 --> 00:37:15,900
대신 필터를 무작위로

943
00:37:15,900 --> 00:37:16,420
초기화합니다.

944
00:37:16,420 --> 00:37:19,040
그리고 나서 해결하려는 문제에 대해 gradient

945
00:37:19,040 --> 00:37:20,480
descent를 통해 학습됩니다.

946
00:37:20,480 --> 00:37:22,980
이 점을 꼭 기억하는 게 정말 중요합니다.

947
00:37:22,980 --> 00:37:26,000
이것이 이 층들이 강력한 이유인데,

948
00:37:26,000 --> 00:37:28,400
계산 비용이 꽤 드는

949
00:37:28,400 --> 00:37:30,320
층을 정의하지만,

950
00:37:30,320 --> 00:37:33,920
훈련 데이터와 계산을 통해 채워질 것으로

951
00:37:33,920 --> 00:37:35,760
기대하는 겁니다.

952
00:37:35,760 --> 00:37:37,680
문제는 필터 크기를 어떻게 설정하느냐 하는 거죠.

953
00:37:37,680 --> 00:37:38,880
그건 하이퍼파라미터입니다.

954
00:37:38,880 --> 00:37:40,343
몇 강의 전에 하이퍼파라미터와

955
00:37:40,343 --> 00:37:42,260
교차 검증에 대해 이야기했었죠.

956
00:37:42,260 --> 00:37:44,218
이런 것들은 보통 교차 검증을

957
00:37:44,218 --> 00:37:46,987
통해 설정하는 아키텍처 하이퍼파라미터입니다.

958
00:37:46,987 --> 00:37:47,820
네, 좋은 질문입니다.

959
00:37:47,820 --> 00:37:50,070
다양한 크기의 필터를 사용하는 게 의미가 있을까요?

960
00:37:50,070 --> 00:37:52,240
다음 강의인 CNN 아키텍처 강의에서

961
00:37:52,240 --> 00:37:53,640
보시겠지만, 사실

962
00:37:53,640 --> 00:37:56,310
inception에 대해 이야기할 겁니다.

963
00:37:56,310 --> 00:37:58,450
가끔은 실제로 그런 경우가 있습니다.

964
00:37:58,450 --> 00:38:01,750
하지만 보통은 계산 그래프에서 원시 연산(primitive)으로

965
00:38:01,750 --> 00:38:03,750
정의할 것인지, 아니면 원시

966
00:38:03,750 --> 00:38:07,003
연산으로부터 만들어지는 복합 구조(emergent

967
00:38:07,003 --> 00:38:09,670
structure)로 설계할지에 관한 좋은 API

968
00:38:09,670 --> 00:38:10,610
설계 문제입니다.

969
00:38:10,610 --> 00:38:12,310
이 경우 보통 단일 컨볼루션

970
00:38:12,310 --> 00:38:14,988
레이어는 고정된 필터 크기를 갖도록 정의하는데,

971
00:38:14,988 --> 00:38:17,030
이는 계산과 효율적인 GPU 커널 작성이

972
00:38:17,030 --> 00:38:18,490
더 쉬워지기 때문입니다.

973
00:38:18,490 --> 00:38:22,630
하지만 여러 크기의 필터를 갖는 컨볼루션 레이어들을

974
00:38:22,630 --> 00:38:24,910
조합해 더 큰 네트워크 구조로

975
00:38:24,910 --> 00:38:27,990
연결하면 여러 크기의 필터를 효과적으로

976
00:38:27,990 --> 00:38:29,570
사용할 수 있습니다.

977
00:38:29,570 --> 00:38:32,967
그래서 질문에 대한 답은 예이자 아니오입니다.

978
00:38:32,967 --> 00:38:34,550
우리가 배우는 것이 무엇인가 하는 질문이죠.

979
00:38:34,550 --> 00:38:37,092
여기서 파라미터와 하이퍼파라미터를 구분하는

980
00:38:37,092 --> 00:38:38,350
것이 매우 중요합니다.

981
00:38:38,350 --> 00:38:40,990
하이퍼파라미터는 네트워크 학습을 시작하기

982
00:38:40,990 --> 00:38:42,330
전에 설정하는 것입니다.

983
00:38:42,330 --> 00:38:44,190
이 경우 하이퍼파라미터 중

984
00:38:44,190 --> 00:38:47,250
하나는 필터의 개수와 필터 크기입니다.

985
00:38:47,250 --> 00:38:49,790
왜냐하면 이들이 텐서의 형태를 결정하기 때문입니다.

986
00:38:49,790 --> 00:38:52,550
반면 파라미터는 경사 하강법

987
00:38:52,550 --> 00:38:54,140
과정에서 설정하고

988
00:38:54,140 --> 00:38:55,680
최적화하는 값입니다.

989
00:38:55,680 --> 00:38:58,180
그래서 필터 개수, 출력 채널 수,

990
00:38:58,180 --> 00:38:59,790
필터 크기 등은

991
00:38:59,790 --> 00:39:01,040
하이퍼파라미터입니다.

992
00:39:01,040 --> 00:39:02,907
학습을 시작하기 전에 한 번 설정합니다.

993
00:39:02,907 --> 00:39:04,740
학습 초기에 필터를

994
00:39:04,740 --> 00:39:07,500
무작위로 초기화하고, 그 값들이

995
00:39:07,500 --> 00:39:10,000
고정된 크기의 텐서를 만듭니다.

996
00:39:10,000 --> 00:39:11,820
그리고 그 텐서 내부의 값들은

997
00:39:11,820 --> 00:39:14,365
최적화 과정에서 계속 변하게 됩니다.

998
00:39:14,365 --> 00:39:15,740
그래서 그게 바로 파라미터인

999
00:39:15,740 --> 00:39:18,220
겁니다. 왜냐하면 그 값들이 gradient

1000
00:39:18,220 --> 00:39:19,793
descent를 통해 설정되기 때문입니다.

1001
00:39:19,793 --> 00:39:21,960
네, 질문은 우리가 어떤 gradient를 계산하는가 하는 거죠.

1002
00:39:21,960 --> 00:39:23,860
backpropagation을 할

1003
00:39:23,860 --> 00:39:26,380
때마다 항상 네트워크 내부의 것들에 대한 loss의

1004
00:39:26,380 --> 00:39:28,160
gradient를 계산합니다.

1005
00:39:28,160 --> 00:39:30,580
이 경우에는 loss의 gradient를

1006
00:39:30,580 --> 00:39:33,420
개별 스칼라, 즉 convolutional filter

1007
00:39:33,420 --> 00:39:35,540
가중치에 대해 계산하는 겁니다.

1008
00:39:35,540 --> 00:39:38,140
즉, gradient란 각 필터

1009
00:39:38,140 --> 00:39:39,980
안의 개별 스칼라를

1010
00:39:39,980 --> 00:39:41,608
조금씩 바꾸면 loss가

1011
00:39:41,608 --> 00:39:43,900
얼마나 변하는지를

1012
00:39:43,900 --> 00:39:45,022
나타내는 겁니다.

1013
00:39:45,022 --> 00:39:46,980
그래서 우리는 항상

1014
00:39:46,980 --> 00:39:49,313
convolutional filter에 대해

1015
00:39:49,313 --> 00:39:51,780
loss의 gradient를 계산하는 거죠.

1016
00:39:51,780 --> 00:39:54,280
질문은 기본적으로 bias는 어떻게 처리하느냐 하는 겁니다.

1017
00:39:54,280 --> 00:39:56,040
기본적으로 bias는 각

1018
00:39:56,040 --> 00:39:57,630
내적에 더해집니다.

1019
00:39:57,630 --> 00:39:59,880
그래서 우리는 항상 필터 하나와 이미지의

1020
00:39:59,880 --> 00:40:01,672
한 부분에 대해 내적을 계산하고,

1021
00:40:01,672 --> 00:40:04,880
거기에 bias 벡터의 해당 스칼라 값을 더하는 겁니다.

1022
00:40:04,880 --> 00:40:07,960
bias는 벡터인데, 벡터의 원소 개수는

1023
00:40:07,960 --> 00:40:09,620
필터 개수와 같습니다.

1024
00:40:09,620 --> 00:40:13,640
그래서 bias의 각 원소는 출력의 전체 공간

1025
00:40:13,640 --> 00:40:16,600
차원에 걸쳐 브로드캐스트됩니다.

1026
00:40:16,600 --> 00:40:18,900
하지만 각 bias

1027
00:40:18,900 --> 00:40:22,160
원소는 한 필터에만 사용됩니다.

1028
00:40:22,160 --> 00:40:25,580
개념적으로 보면, 한 필터를 전체 공간에 슬라이딩하는 거죠.

1029
00:40:25,580 --> 00:40:27,860
그렇게 하면 2차원 활성화 평면이 생깁니다.

1030
00:40:27,860 --> 00:40:29,960
그리고 두 번째 필터가 있으면 두

1031
00:40:29,960 --> 00:40:31,620
번째 활성화 평면이 생기고요.

1032
00:40:31,620 --> 00:40:33,380
이것들은 독립적인 연산자입니다.

1033
00:40:33,380 --> 00:40:36,300
첫 번째 단계는 첫 번째 필터를 모든 위치에 슬라이드하는 겁니다.

1034
00:40:36,300 --> 00:40:38,300
두 번째 단계는 두 번째 필터를 모든 위치에 슬라이드하는 겁니다.

1035
00:40:38,300 --> 00:40:41,960
각 필터는 평면을 만들어내는데, 이 평면을 activation

1036
00:40:41,960 --> 00:40:43,383
map이라고 부릅니다.

1037
00:40:43,383 --> 00:40:44,800
그리고 나서 이 모든 activation map을 쌓습니다.

1038
00:40:44,800 --> 00:40:47,360
이것이 바로 convolution layer의 연산입니다.

1039
00:40:47,360 --> 00:40:50,170
질문은, 네, 기본적으로 매번 gradient

1040
00:40:50,170 --> 00:40:52,110
descent를 할 때마다

1041
00:40:52,110 --> 00:40:53,790
필터가 바뀐다는 겁니다.

1042
00:40:53,790 --> 00:40:56,370
그래서 신경망을 훈련시킨다고 상상하면, 항상 이런 루프가

1043
00:40:56,370 --> 00:40:59,932
반복됩니다. while true, 데이터 배치를 가져와서 네트워크에
통과시키고,

1044
00:40:59,932 --> 00:41:01,390
forward pass,

1045
00:41:01,390 --> 00:41:04,330
손실 계산, backward pass, 손실에 대한 gradient

1046
00:41:04,330 --> 00:41:06,090
계산, 그리고 optimizer를

1047
00:41:06,090 --> 00:41:08,370
사용해 gradient step을 수행하는 거죠.

1048
00:41:08,370 --> 00:41:10,470
그래서 항상 데이터, forward, 손실,

1049
00:41:10,470 --> 00:41:12,170
backward step 순서가 됩니다.

1050
00:41:12,170 --> 00:41:13,610
그리고 매번 스텝을

1051
00:41:13,610 --> 00:41:16,470
할 때마다 필터가 변경됩니다.

1052
00:41:16,470 --> 00:41:17,090
좋습니다.

1053
00:41:17,090 --> 00:41:19,270
제가 반대로 말했죠, 질문이 더 있냐고

1054
00:41:19,270 --> 00:41:20,630
했는데 질문이 너무 많네요.

1055
00:41:20,630 --> 00:41:21,490
하지만 그건 좋은 겁니다.

1056
00:41:21,490 --> 00:41:23,830
여기서 균형을 맞출 수 있겠네요.

1057
00:41:23,830 --> 00:41:26,630
그럼 convolution layer에 대해 이야기했죠.

1058
00:41:26,630 --> 00:41:28,830
convolution layer에서는 보통

1059
00:41:28,830 --> 00:41:30,610
배치 모드로 작업하는 게 일반적입니다.

1060
00:41:30,610 --> 00:41:32,510
그래서 한 개의 입력 이미지가 아니라,

1061
00:41:32,510 --> 00:41:34,970
여러 개의 입력 이미지 배치를 처리합니다.

1062
00:41:34,970 --> 00:41:37,688
이게 좋은 점은 모든 것이 4차원이 된다는 겁니다.

1063
00:41:37,688 --> 00:41:39,230
이제 입력은 4차원 텐서가

1064
00:41:39,230 --> 00:41:42,095
되는데, 이는 여러 입력 이미지의 집합입니다.

1065
00:41:42,095 --> 00:41:43,470
필터도 4차원

1066
00:41:43,470 --> 00:41:46,262
텐서인데, 각 필터는 이미지의

1067
00:41:46,262 --> 00:41:47,970
3차원 덩어리입니다.

1068
00:41:47,970 --> 00:41:50,220
그리고 출력도 4차원

1069
00:41:50,220 --> 00:41:54,000
텐서로, 여러 출력의 집합입니다.

1070
00:41:54,000 --> 00:41:56,580
각 출력은 이미지 하나당 하나씩 있고, 각

1071
00:41:56,580 --> 00:41:58,740
이미지는 3차원 텐서로, feature

1072
00:41:58,740 --> 00:42:00,660
plane의 스택을 나타냅니다.

1073
00:42:00,660 --> 00:42:02,893
신경망을 구축할 때는 여러

1074
00:42:02,893 --> 00:42:04,560
차원을 생각해야 하는데,

1075
00:42:04,560 --> 00:42:07,060
사실 이게 재미있습니다.

1076
00:42:07,060 --> 00:42:08,780
그럼 convolution layer의

1077
00:42:08,780 --> 00:42:10,033
일반적인 수식을 보겠습니다.

1078
00:42:10,033 --> 00:42:11,700
일반적으로 입력은 n

1079
00:42:11,700 --> 00:42:14,860
by cn by h by w 형태의 4차원

1080
00:42:14,860 --> 00:42:17,600
텐서인데, 이는 n개의 이미지 집합입니다.

1081
00:42:17,600 --> 00:42:20,460
각 이미지에는 cn개의 채널이 있습니다.

1082
00:42:20,460 --> 00:42:22,800
RGB 이미지의 경우 cn은 3이지만,

1083
00:42:22,800 --> 00:42:25,880
일반적으로는 3개 이상일 수도 있습니다.

1084
00:42:25,880 --> 00:42:27,140
이 값은 임의일 수 있습니다.

1085
00:42:27,140 --> 00:42:30,340
그리고 h와 w는 입력 이미지의 공간적 크기입니다.

1086
00:42:30,340 --> 00:42:33,140
convolution 필터는 c out

1087
00:42:33,140 --> 00:42:37,340
by cn by kw by kh 형태의 4차원 텐서입니다.

1088
00:42:37,340 --> 00:42:41,420
c out은 필터 수, 즉 출력 채널 수이고, cn은

1089
00:42:41,420 --> 00:42:43,460
입력 채널 수이며, 나머지는

1090
00:42:43,460 --> 00:42:44,880
3차원 필터입니다.

1091
00:42:44,880 --> 00:42:47,090
즉, 3차원 필터 집합입니다.

1092
00:42:47,090 --> 00:42:51,050
각 3차원 필터는 cn by kw by kh 형태입니다.

1093
00:42:51,050 --> 00:42:52,870
그게 커널의 너비와 커널의 높이입니다.

1094
00:42:52,870 --> 00:42:55,010
그리고 c out 개수만큼의

1095
00:42:55,010 --> 00:42:57,388
필터들이 모여서 4차원 텐서가 됩니다.

1096
00:42:57,388 --> 00:42:59,930
출력으로는 다시 4차원 텐서를 만들

1097
00:42:59,930 --> 00:43:03,770
건데, 모양은 n으로 이미지 개수, 이미지당 하나의

1098
00:43:03,770 --> 00:43:06,970
출력, c out-- 각 출력은 c out

1099
00:43:06,970 --> 00:43:11,370
개의 피처 플레인으로 구성됩니다, 필터 하나당 하나씩이죠.

1100
00:43:11,370 --> 00:43:15,810
그리고 각 플레인은 h prime 곱하기 w prime 크기입니다.

1101
00:43:15,810 --> 00:43:20,010
이것이 컨볼루션 레이어의 일반적인 공식입니다.

1102
00:43:20,010 --> 00:43:21,690
그리고 컨볼루션 네트워크는

1103
00:43:21,690 --> 00:43:23,732
여러 컨볼루션 레이어를

1104
00:43:23,732 --> 00:43:25,627
포함하는 계산 그래프일 뿐입니다.

1105
00:43:25,627 --> 00:43:27,210
실제로는 여러 컨볼루션

1106
00:43:27,210 --> 00:43:30,130
연산자를 차례대로 쌓는 경향이 있습니다.

1107
00:43:30,130 --> 00:43:32,750
그리고 여러 컨볼루션 연산자를 쌓으면

1108
00:43:32,750 --> 00:43:35,570
그것이 컨볼루션 네트워크가 됩니다.

1109
00:43:35,570 --> 00:43:37,390
이것은 간단한 ConvNet입니다.

1110
00:43:37,390 --> 00:43:40,530
3x32x32 크기의 이미지로 시작하고, 6개의

1111
00:43:40,530 --> 00:43:43,110
필터를 가진 conv 레이어가 있습니다.

1112
00:43:43,110 --> 00:43:45,270
각 필터는 5x5x3 크기입니다.

1113
00:43:45,270 --> 00:43:47,710
첫 번째 컨볼루션을 수행하면,

1114
00:43:47,710 --> 00:43:51,430
6개의 필터에 맞는 6개의 채널을 가진 3차원 활성화

1115
00:43:51,430 --> 00:43:55,350
세트가 생성되고, 공간 크기는 컨볼루션을 거치면서

1116
00:43:55,350 --> 00:43:57,230
28x28로 약간 줄어듭니다.

1117
00:43:57,230 --> 00:43:58,848
그다음 10개의

1118
00:43:58,848 --> 00:44:00,390
필터를 가진 또

1119
00:44:00,390 --> 00:44:04,590
다른 컨볼루션이 있는데, 각 필터는 5x5x6 크기입니다.

1120
00:44:04,590 --> 00:44:06,830
그래서 10은 다음 컨볼루션

1121
00:44:06,830 --> 00:44:09,510
레이어의 출력 차원을 나타냅니다.

1122
00:44:09,510 --> 00:44:12,068
그리고 6은 컨볼루션 입력의

1123
00:44:12,068 --> 00:44:14,110
채널 차원과 일치해야

1124
00:44:14,110 --> 00:44:15,910
하는 채널 수입니다.

1125
00:44:15,910 --> 00:44:17,972
이렇게 여러 컨볼루션

1126
00:44:17,972 --> 00:44:19,430
레이어를 쌓아서 많은

1127
00:44:19,430 --> 00:44:21,950
계산을 수행할 수 있습니다.

1128
00:44:21,950 --> 00:44:24,510
하지만 이 네트워크 아키텍처 설계에는 실제로

1129
00:44:24,510 --> 00:44:25,730
문제가 있습니다.

1130
00:44:25,730 --> 00:44:27,562
누가 그것을 발견할 수 있나요?

1131
00:44:27,562 --> 00:44:28,530
그건 크기 조절 문제입니다.

1132
00:44:28,530 --> 00:44:31,070
그건 문제인데, 제가 생각한 문제는 아닙니다.

1133
00:44:31,070 --> 00:44:32,090
진화는 국소적입니다.

1134
00:44:32,090 --> 00:44:34,430
그것도 좋은 문제지만, 제가 생각한 문제는 아닙니다.

1135
00:44:34,430 --> 00:44:36,510
사실, 그 두 가지는 몇 슬라이드 안에 꽤 쉽게

1136
00:44:36,510 --> 00:44:38,590
고칠 수 있지만, 제가 생각한 문제는 다릅니다.

1137
00:44:38,590 --> 00:44:41,170
많은 메모리가 문제이긴 하지만, 우리가 고칠 수 있는 문제는 아닙니다.

1138
00:44:41,170 --> 00:44:44,580
더 큰 GPU를 사야 합니다.

1139
00:44:44,580 --> 00:44:45,928
필터 수가 증가합니다.

1140
00:44:45,928 --> 00:44:47,720
그게 꼭 문제라고 생각하지는 않습니다.

1141
00:44:47,720 --> 00:44:49,247
괜찮습니다.

1142
00:44:49,247 --> 00:44:50,080
모든 것이 선형입니다.

1143
00:44:50,080 --> 00:44:51,720
네, 그건 문제입니다.

1144
00:44:51,720 --> 00:44:54,480
그래서 우리는 컨볼루션이 내적(dot product)이라고 했습니다.

1145
00:44:54,480 --> 00:44:56,540
내적은 선형 연산자입니다.

1146
00:44:56,540 --> 00:44:58,020
두 개의 선형 연산자를 합성해도

1147
00:44:58,020 --> 00:44:59,320
여전히 선형 연산자입니다.

1148
00:44:59,320 --> 00:45:01,820
즉, 두 개의 convolution layer를

1149
00:45:01,820 --> 00:45:03,420
바로 겹쳐 쌓으면,

1150
00:45:03,420 --> 00:45:05,920
연산자의 선형성 때문에 실제로는 단일

1151
00:45:05,920 --> 00:45:09,300
convolution layer와 같은 표현력을 가진다는 뜻입니다.

1152
00:45:09,300 --> 00:45:11,580
사실 이 문제에 대한 아주 간단한 해결책이 있습니다.

1153
00:45:11,580 --> 00:45:12,720
활성화 함수를 추가하는 겁니다.

1154
00:45:12,720 --> 00:45:13,233
맞습니다.

1155
00:45:13,233 --> 00:45:14,900
이것은 우리가 다층 신경망에서

1156
00:45:14,900 --> 00:45:16,760
봤던 같은 문제이고 같은

1157
00:45:16,760 --> 00:45:17,760
해결책입니다.

1158
00:45:17,760 --> 00:45:19,820
즉, convolution layer

1159
00:45:19,820 --> 00:45:21,620
사이에 비선형 활성화

1160
00:45:21,620 --> 00:45:23,540
함수를 추가해야 하는데, 이것이

1161
00:45:23,540 --> 00:45:26,913
문제에 비선형성을 도입하고 네트워크 구조에 비선형성을

1162
00:45:26,913 --> 00:45:28,580
추가하며 우리가 학습하는

1163
00:45:28,580 --> 00:45:30,780
네트워크의 표현력을 높여줍니다.

1164
00:45:30,780 --> 00:45:32,900
일반적으로 ConvNet은

1165
00:45:32,900 --> 00:45:35,820
convolution layer, 비선형성, 그리고 다른

1166
00:45:35,820 --> 00:45:38,715
종류의 레이어들이 쌓인 계산 그래프가 됩니다.

1167
00:45:38,715 --> 00:45:40,340
앞서 convolution 필터가

1168
00:45:40,340 --> 00:45:42,290
무엇을 학습하는지에 대한 질문이 있었습니다.

1169
00:45:42,290 --> 00:45:44,210
이것은 우리가 선형 분류기에서

1170
00:45:44,210 --> 00:45:47,290
했던 것과 유사하게 볼 수 있습니다.

1171
00:45:47,290 --> 00:45:49,530
선형 분류기에서는 학습된 가중치

1172
00:45:49,530 --> 00:45:51,988
행렬의 각 행을 전체 입력

1173
00:45:51,988 --> 00:45:53,530
이미지와 같은 형태의

1174
00:45:53,530 --> 00:45:55,113
템플릿으로 시각화할

1175
00:45:55,113 --> 00:45:57,510
수 있다는 직관이 있었습니다.

1176
00:45:57,510 --> 00:45:59,250
convolution 필터도

1177
00:45:59,250 --> 00:46:02,630
마찬가지로 생각할 수 있는데, 각 필터가 입력 이미지

1178
00:46:02,630 --> 00:46:05,290
전체 공간 크기에 걸쳐 있지 않고,

1179
00:46:05,290 --> 00:46:07,590
이미지의 작은 부분, 즉 작은 조각에

1180
00:46:07,590 --> 00:46:09,050
해당한다는 점이 다릅니다.

1181
00:46:09,050 --> 00:46:11,770
그래서 우리는 실제로 학습된 신경망의

1182
00:46:11,770 --> 00:46:15,370
첫 번째 convolution layer 필터들을

1183
00:46:15,370 --> 00:46:16,850
시각화할 수 있습니다.

1184
00:46:16,850 --> 00:46:19,770
이것들은 ImageNet에서 이미지 분류를 위해

1185
00:46:19,770 --> 00:46:22,010
학습된 AlexNet 아키텍처의 첫 번째

1186
00:46:22,010 --> 00:46:24,730
convolution layer 필터들입니다.

1187
00:46:24,730 --> 00:46:26,450
여기 있는 각각은 기본적으로 RGB

1188
00:46:26,450 --> 00:46:27,992
이미지의 작은 조각들입니다.

1189
00:46:27,992 --> 00:46:29,450
이것들은 AlexNet

1190
00:46:29,450 --> 00:46:31,890
아키텍처 첫 번째 레이어에서 입력 이미지 위를

1191
00:46:31,890 --> 00:46:33,770
슬라이딩하는 작은 템플릿들입니다.

1192
00:46:33,770 --> 00:46:36,210
AlexNet이고, ImageNet에서

1193
00:46:36,210 --> 00:46:37,585
학습되었으며,

1194
00:46:37,585 --> 00:46:39,720
분류 문제였다는 점과 상관없이,

1195
00:46:39,720 --> 00:46:41,440
거의 모든 convolution

1196
00:46:41,440 --> 00:46:42,960
네트워크가 거의

1197
00:46:42,960 --> 00:46:46,560
모든 문제와 데이터셋, 합리적인 작업에서는 이런 식으로

1198
00:46:46,560 --> 00:46:49,800
보이는 필터들을 학습한다는 사실이 밝혀졌습니다.

1199
00:46:49,800 --> 00:46:52,600
우리가 보는 것은 보통 두 가지 종류의

1200
00:46:52,600 --> 00:46:54,440
필터를 학습한다는 겁니다.

1201
00:46:54,440 --> 00:46:56,180
하나는 색상을 찾는 필터로, 특히

1202
00:46:56,180 --> 00:46:57,780
반대되는 색상을 찾는 경향이 있습니다.

1203
00:46:57,780 --> 00:46:59,320
예를 들어, 이 필터는 녹색과

1204
00:46:59,320 --> 00:47:01,260
빨간색 간의 대비를 찾고 있습니다.

1205
00:47:01,260 --> 00:47:04,080
또한 분홍색과 녹색 같은 색깔 덩어리도 볼 수 있습니다.

1206
00:47:04,080 --> 00:47:06,600
다른 종류의 필터는 이미지의

1207
00:47:06,600 --> 00:47:10,180
공간적 구조를 찾는 필터입니다.

1208
00:47:10,180 --> 00:47:12,320
예를 들어, 이 필터는 수직 가장자리, 수평

1209
00:47:12,320 --> 00:47:13,560
가장자리를 찾고 있습니다.

1210
00:47:13,560 --> 00:47:16,000
이 필터는 수직 가장자리를 찾고, 일부는

1211
00:47:16,000 --> 00:47:18,060
대각선 가장자리를 찾습니다.

1212
00:47:18,060 --> 00:47:20,560
즉, 색상과 가장자리를 찾는 경향이 있습니다.

1213
00:47:20,560 --> 00:47:23,680
그리고 이것들은 입력 이미지의 작은

1214
00:47:23,680 --> 00:47:25,807
국소 영역에서 작동합니다.

1215
00:47:25,807 --> 00:47:27,640
그래서 첫 번째 convolution 필터

1216
00:47:27,640 --> 00:47:30,140
레이어에서는 이런 트릭을 써서 필터들을 직접 이미지로 시각화할

1217
00:47:30,140 --> 00:47:30,820
수 있습니다.

1218
00:47:30,820 --> 00:47:33,028
네트워크의 더 높은 레이어를 시각화하는 것은

1219
00:47:33,028 --> 00:47:33,960
좀 더 까다롭습니다.

1220
00:47:33,960 --> 00:47:36,220
이 그림에 대해서는 자세히 설명하지 않겠습니다.

1221
00:47:36,220 --> 00:47:39,080
그냥 너무 많은 설명 없이 보여드리겠습니다.

1222
00:47:39,080 --> 00:47:41,100
하지만 네트워크의 더 높은 레이어들은

1223
00:47:41,100 --> 00:47:44,260
입력 이미지의 더 큰 공간적 구조를 학습하는 경향이 있습니다.

1224
00:47:44,260 --> 00:47:47,420
여기서 시각화는 각 행이 학습된

1225
00:47:47,420 --> 00:47:50,580
네트워크의 필터를 나타내고, 각 열은

1226
00:47:50,580 --> 00:47:53,180
그 필터가 강하게 반응한 입력

1227
00:47:53,180 --> 00:47:55,840
이미지의 일부를 나타냅니다.

1228
00:47:55,840 --> 00:47:57,500
그래서 이 시각화는 이전

1229
00:47:57,500 --> 00:47:59,420
슬라이드와는 조금 다릅니다.

1230
00:47:59,420 --> 00:48:01,900
이것들은 모두 필터가 반응하는 입력

1231
00:48:01,900 --> 00:48:03,680
이미지의 일부분들입니다.

1232
00:48:03,680 --> 00:48:06,140
여기서 보시면, 6층 합성곱 신경망의

1233
00:48:06,140 --> 00:48:09,420
필터 중 하나가 아마도 눈에 반응하는 것처럼 보입니다.

1234
00:48:09,420 --> 00:48:12,740
이 필터는 아마도 텍스트 조각에 반응하는 것처럼 보입니다.

1235
00:48:12,740 --> 00:48:15,740
이 필터는 바퀴나 원, 혹은 원의 윗부분에

1236
00:48:15,740 --> 00:48:17,080
반응하는 것처럼 보입니다.

1237
00:48:17,080 --> 00:48:18,500
그런 식의 반응입니다.

1238
00:48:18,500 --> 00:48:21,660
그리고 다시 말하지만, 이 모든 것은 대규모

1239
00:48:21,660 --> 00:48:24,940
데이터셋에 대한 학습을 통해 경사 하강법으로 구동됩니다.

1240
00:48:24,940 --> 00:48:28,020
아무도 손으로 직접 필터를 설계하지 않습니다.

1241
00:48:28,020 --> 00:48:30,460
말씀드렸듯이, 고차원 필터를 시각화하는

1242
00:48:30,460 --> 00:48:32,740
것은 좀 더 까다롭고 복잡합니다.

1243
00:48:32,740 --> 00:48:37,230
질문은, 필터에 대한 모든 반응을 보면 원본 이미지를 재구성할

1244
00:48:37,230 --> 00:48:39,410
수 있느냐는 것이었습니다.

1245
00:48:39,410 --> 00:48:41,110
사실, 그게 가능합니다.

1246
00:48:41,110 --> 00:48:42,890
그 방법과 요령도 경사

1247
00:48:42,890 --> 00:48:45,050
하강법을 사용하는 겁니다.

1248
00:48:45,050 --> 00:48:46,710
경사 하강법은 정말 강력합니다.

1249
00:48:46,710 --> 00:48:49,377
그리고 그 메커니즘에 대해서는 앞으로

1250
00:48:49,377 --> 00:48:52,025
몇 강의에서 더 다룰 예정입니다.

1251
00:48:52,025 --> 00:48:53,150
아, 좋은 질문입니다.

1252
00:48:53,150 --> 00:48:56,130
필터가 어떻게 미분되는지에 관한 질문인데,

1253
00:48:56,130 --> 00:48:58,435
그것은 사실 무작위 초기화에서 시작됩니다.

1254
00:48:58,435 --> 00:49:00,810
그래서 필터를 초기화하는 방법이 무작위여야

1255
00:49:00,810 --> 00:49:02,750
한다는 것이 정말 중요합니다.

1256
00:49:02,750 --> 00:49:05,570
그리고 결정적으로, 네트워크를 훈련할 때 각

1257
00:49:05,570 --> 00:49:07,778
필터마다 다른 초기화를 해야 하는데,

1258
00:49:07,778 --> 00:49:09,528
이것이 필터 간의 대칭성을 깨뜨리기

1259
00:49:09,528 --> 00:49:10,390
때문입니다.

1260
00:49:10,390 --> 00:49:12,543
모든 필터가 똑같고 손실도 같으면,

1261
00:49:12,543 --> 00:49:14,210
그라디언트가 모든

1262
00:49:14,210 --> 00:49:16,590
필터에 똑같이 전파되어 버립니다.

1263
00:49:16,590 --> 00:49:19,170
그래서 만약 똑같이 초기화하면, 필터들도 계속 똑같이 유지됩니다.

1264
00:49:19,170 --> 00:49:20,870
하지만 다르게 초기화하면

1265
00:49:20,870 --> 00:49:22,495
대칭성이 깨지고 서로 다른 특징을

1266
00:49:22,495 --> 00:49:23,770
학습할 수 있습니다.

1267
00:49:23,770 --> 00:49:23,970
네.

1268
00:49:23,970 --> 00:49:25,922
기본적으로 네트워크 설계자는

1269
00:49:25,922 --> 00:49:28,130
연산자의 순서와 채널의

1270
00:49:28,130 --> 00:49:29,590
순서를 정해야 합니다.

1271
00:49:29,590 --> 00:49:31,530
이것이 신경망 아키텍처 설계

1272
00:49:31,530 --> 00:49:33,447
문제이고, 다음 강의에서

1273
00:49:33,447 --> 00:49:35,280
좀 더 다룰 예정입니다.

1274
00:49:35,280 --> 00:49:38,320
세 번째 질문은, 왜 더 깊은 층이 더 큰 구조를 시각화하느냐 하는 건데,

1275
00:49:38,320 --> 00:49:40,445
이건 수용 영역(receptive fields)과

1276
00:49:40,445 --> 00:49:42,278
관련이 있습니다. 이 부분은 조금 있다가

1277
00:49:42,278 --> 00:49:43,460
슬라이드에서 다룰 겁니다.

1278
00:49:43,460 --> 00:49:44,620
아마 거기까지 도달할 수 있을 겁니다.

1279
00:49:44,620 --> 00:49:46,537
그리고 몇 가지 질문들은 답이

1280
00:49:46,537 --> 00:49:47,745
나올 것 같습니다.

1281
00:49:47,745 --> 00:49:49,120
이미 나온 질문 중 하나는,

1282
00:49:49,120 --> 00:49:50,912
이 합성곱의 공간 차원을 어떻게

1283
00:49:50,912 --> 00:49:52,200
보는가 하는 것입니다.

1284
00:49:52,200 --> 00:49:54,232
그래서 합성곱의 공간 차원을

1285
00:49:54,232 --> 00:49:56,440
정확히 어떻게 계산하는지 좀 더 자세히

1286
00:49:56,440 --> 00:49:58,040
살펴보고 싶었습니다.

1287
00:49:58,040 --> 00:50:00,320
여기서는 합성곱의 그림을

1288
00:50:00,320 --> 00:50:02,580
하나 가져왔습니다.

1289
00:50:02,580 --> 00:50:05,392
이 그림을 90도 회전시키고 채널 차원을 없앴습니다.

1290
00:50:05,392 --> 00:50:07,600
그래서 이제 채널 차원은 보드 안쪽으로 들어가 있는 상태입니다.

1291
00:50:07,600 --> 00:50:10,385
그리고 7x7 공간 차원이 있습니다.

1292
00:50:10,385 --> 00:50:11,760
여기서는 공간 크기가

1293
00:50:11,760 --> 00:50:13,540
7x7인 입력을 보고 있습니다.

1294
00:50:13,540 --> 00:50:15,300
그리고 3x3 conv 커널이 있습니다.

1295
00:50:15,300 --> 00:50:16,680
그럼 출력

1296
00:50:16,680 --> 00:50:19,200
크기는 얼마나 될까요?

1297
00:50:19,200 --> 00:50:23,580
음, 1, 2, 3, 4, 5입니다.

1298
00:50:23,580 --> 00:50:25,100
그래서 출력은 5x5가

1299
00:50:25,100 --> 00:50:27,142
됩니다. 필터를 5군데에 슬라이드해서

1300
00:50:27,142 --> 00:50:28,560
놓을 수 있기 때문이죠.

1301
00:50:28,560 --> 00:50:30,180
그리고 일반화할 수 있습니다.

1302
00:50:30,180 --> 00:50:33,710
입력 길이가 w이고, conv 필터 길이가 k라면

1303
00:50:33,710 --> 00:50:36,280
출력은 w 빼기 k 더하기 1이 됩니다.

1304
00:50:36,280 --> 00:50:38,030
이 공식이 맞다는 것을

1305
00:50:38,030 --> 00:50:39,900
직접 확인할 수 있습니다.

1306
00:50:39,900 --> 00:50:42,150
하지만 문제점이 있는데, 몇몇 분들이

1307
00:50:42,150 --> 00:50:44,727
이미 지적했듯이, 합성곱을 거치면서

1308
00:50:44,727 --> 00:50:46,310
피처 맵의 공간 크기가

1309
00:50:46,310 --> 00:50:47,670
줄어든다는 겁니다.

1310
00:50:47,670 --> 00:50:49,078
이게 좀 귀찮습니다.

1311
00:50:49,078 --> 00:50:51,370
사실 이걸 감안해서 작업할 수도 있습니다.

1312
00:50:51,370 --> 00:50:53,328
그리고 그런 문제를 다루는 신경망

1313
00:50:53,328 --> 00:50:54,170
구조도 있습니다.

1314
00:50:54,170 --> 00:50:55,670
하지만 가끔은 귀찮아서

1315
00:50:55,670 --> 00:50:59,110
모든 크기를 동일하게 유지하고 싶을 때가 있는데, 그게 인간

1316
00:50:59,110 --> 00:51:01,870
설계자가 생각하기에 훨씬 간단하기 때문입니다.

1317
00:51:01,870 --> 00:51:05,430
그래서 사용하는 트릭 중 하나가 패딩입니다.

1318
00:51:05,430 --> 00:51:08,810
여기서는 입력 주변에 추가 데이터를,

1319
00:51:08,810 --> 00:51:10,830
즉 실제 입력 데이터

1320
00:51:10,830 --> 00:51:13,430
주변에 가상의 데이터를 추가하는

1321
00:51:13,430 --> 00:51:16,750
것이 일반적입니다. 합성곱 연산을 하기

1322
00:51:16,750 --> 00:51:19,150
전에 0을 추가하는 거죠.

1323
00:51:19,150 --> 00:51:22,750
이제 이 방법으로 축소되는 feature map 문제를 해결할

1324
00:51:22,750 --> 00:51:23,490
수 있습니다.

1325
00:51:23,490 --> 00:51:25,190
이제 padding p를

1326
00:51:25,190 --> 00:51:28,530
추가하면, 여기서는 padding p가 1입니다.

1327
00:51:28,530 --> 00:51:31,450
즉, 모든 가장자리에 1픽셀의 0을

1328
00:51:31,450 --> 00:51:35,010
추가하면 출력 크기에 2p가 더해집니다.

1329
00:51:35,010 --> 00:51:39,010
특히 3x3 convolution에 padding 1을

1330
00:51:39,010 --> 00:51:41,850
추가하면 feature map 크기가

1331
00:51:41,850 --> 00:51:43,230
그대로 유지됩니다.

1332
00:51:43,230 --> 00:51:44,667
이게 편리하죠.

1333
00:51:44,667 --> 00:51:46,250
신호 처리 수업을 들었다면 여기서

1334
00:51:46,250 --> 00:51:48,330
문제가 있을 수 있다는 걸 알 겁니다.

1335
00:51:48,330 --> 00:51:51,330
신호 처리 관점에서 이상한 현상이 생길 수

1336
00:51:51,330 --> 00:51:53,010
있지만, 우리는 무시하고

1337
00:51:53,010 --> 00:51:55,650
텐서의 크기와 형태만 살펴보겠습니다.

1338
00:51:55,650 --> 00:51:58,170
그게 이해하기 더 쉽기 때문입니다.

1339
00:51:58,170 --> 00:52:00,097
하지만 왜 0을 넣는지 알아두셔야 합니다.

1340
00:52:00,097 --> 00:52:01,430
그게 문제를 일으킬까요?

1341
00:52:01,430 --> 00:52:03,513
네, 경계 부분에서 문제를 일으킬

1342
00:52:03,513 --> 00:52:07,030
수 있지만, 많은 경우에는 괜찮은 것 같습니다.

1343
00:52:07,030 --> 00:52:07,530
네.

1344
00:52:07,530 --> 00:52:07,830
네.

1345
00:52:07,830 --> 00:52:10,163
그래서 제가 말했듯이, 흔한

1346
00:52:10,163 --> 00:52:12,970
설정은 k를 홀수로 하고 p를

1347
00:52:12,970 --> 00:52:15,670
(k-1)/2로 설정하는 겁니다. 이렇게

1348
00:52:15,670 --> 00:52:18,408
하면 convolution 후의

1349
00:52:18,408 --> 00:52:20,450
공간 크기가 convolution

1350
00:52:20,450 --> 00:52:22,650
전과 같아집니다.

1351
00:52:22,650 --> 00:52:25,090
그다음에 생각해볼 흥미로운 개념은

1352
00:52:25,090 --> 00:52:27,070
receptive field입니다.

1353
00:52:27,070 --> 00:52:29,250
여기서 누군가가 왜 더 깊은

1354
00:52:29,250 --> 00:52:31,980
층이 더 큰 구조를 배우는지 물었는데요.

1355
00:52:31,980 --> 00:52:35,600
그건 사실 convolution이 만들어지는 방식에 내재된 특징입니다.

1356
00:52:35,600 --> 00:52:38,440
단일 컨볼루션을 생각할 때, 각 출력은

1357
00:52:38,440 --> 00:52:41,660
입력의 이 국소 영역을 보고 있습니다.

1358
00:52:41,660 --> 00:52:45,717
설계상 첫 번째 층의 한 컨볼루션 출력은 학습하는

1359
00:52:45,717 --> 00:52:47,800
컨볼루션 커널과 같은

1360
00:52:47,800 --> 00:52:49,760
크기의 이미지 일부만 볼

1361
00:52:49,760 --> 00:52:51,000
수 있습니다.

1362
00:52:51,000 --> 00:52:54,238
하지만 여러 컨볼루션을 쌓은 ConvNet을

1363
00:52:54,238 --> 00:52:56,280
만들면, 이 수용 영역이

1364
00:52:56,280 --> 00:52:58,080
네트워크를 통해 확대됩니다.

1365
00:52:58,080 --> 00:53:01,840
이 경우, 세 개의 컨볼루션 층이 있는 네트워크를

1366
00:53:01,840 --> 00:53:03,460
보고 있습니다.

1367
00:53:03,460 --> 00:53:07,380
그리고 최종 활성화 층에서 보게 됩니다.

1368
00:53:07,380 --> 00:53:11,640
여기 각 항목은 이전 층의 국소 영역에

1369
00:53:11,640 --> 00:53:12,620
의존합니다.

1370
00:53:12,620 --> 00:53:14,440
하지만 그 각 항목도

1371
00:53:14,440 --> 00:53:17,580
다시 이전 층의 국소 영역에 의존하고, 그

1372
00:53:17,580 --> 00:53:20,800
이전 층의 국소 영역에 다시 의존합니다.

1373
00:53:20,800 --> 00:53:22,500
그래서 각 개별

1374
00:53:22,500 --> 00:53:24,760
컨볼루션은 이전 층의

1375
00:53:24,760 --> 00:53:26,320
국소 이웃만 보지만,

1376
00:53:26,320 --> 00:53:28,470
여러 층에 걸쳐

1377
00:53:28,470 --> 00:53:31,070
컨볼루션을 쌓으면 각 컨볼루션이

1378
00:53:31,070 --> 00:53:33,390
보는 원래 입력의

1379
00:53:33,390 --> 00:53:37,630
효과적인 크기가 네트워크를 따라 커집니다.

1380
00:53:37,630 --> 00:53:40,470
특히 이것을 효과적인 수용 영역(effective

1381
00:53:40,470 --> 00:53:42,370
receptive field)이라고 부릅니다.

1382
00:53:42,370 --> 00:53:44,750
컨볼루션의 효과적인 수용 영역은

1383
00:53:44,750 --> 00:53:47,950
기본적으로 원본 이미지에서 얼마나

1384
00:53:47,950 --> 00:53:52,430
많은 픽셀이 나중 네트워크 활성화 하나에 영향을 줄 기회를

1385
00:53:52,430 --> 00:53:54,430
가졌는지를 의미합니다.

1386
00:53:54,430 --> 00:53:56,670
컨볼루션 층 수에 따라 이

1387
00:53:56,670 --> 00:53:58,390
효과적인 수용 영역은 기본적으로

1388
00:53:58,390 --> 00:54:01,630
선형적으로 증가하는 것을 알 수 있습니다.

1389
00:54:01,630 --> 00:54:04,510
문제는 결국 네트워크 끝에서

1390
00:54:04,510 --> 00:54:06,978
분류 결정을 할 때, 분류

1391
00:54:06,978 --> 00:54:09,270
결정이 전체 이미지의 전역

1392
00:54:09,270 --> 00:54:12,510
정보를 집계하기를 원한다는 점입니다.

1393
00:54:12,510 --> 00:54:14,750
하지만 이를 위해서는 많은 컨볼루션 층이 필요합니다.

1394
00:54:14,750 --> 00:54:18,070
그래서 효과적인 수용 영역을 더 빠르게

1395
00:54:18,070 --> 00:54:21,310
늘리는 방법을 추가하는 트릭이 있습니다.

1396
00:54:21,310 --> 00:54:23,270
컨볼루션에서 이를 하는 한 가지 방법은

1397
00:54:23,270 --> 00:54:25,590
스트라이드(stride)를 도입하는 것입니다.

1398
00:54:25,590 --> 00:54:27,580
여기서 말하는 것은 필터를

1399
00:54:27,580 --> 00:54:30,320
이미지 전체에 놓는 대신 일부를

1400
00:54:30,320 --> 00:54:31,440
건너뛰겠다는 겁니다.

1401
00:54:31,440 --> 00:54:34,020
즉, 수용 영역을 한 칸씩

1402
00:54:34,020 --> 00:54:35,760
이동하는 대신

1403
00:54:35,760 --> 00:54:37,900
2칸씩 이동하는 겁니다.

1404
00:54:37,900 --> 00:54:41,100
이제 7x7 입력에 3x3 컨볼루션을 스트라이드

1405
00:54:41,100 --> 00:54:42,180
2로 적용해 봅시다.

1406
00:54:42,180 --> 00:54:43,900
출력 크기는 얼마일까요?

1407
00:54:43,900 --> 00:54:45,852
1, 2, 3.

1408
00:54:45,852 --> 00:54:47,900
3x3입니다.

1409
00:54:47,900 --> 00:54:50,700
일반적으로 입력 크기 w,

1410
00:54:50,700 --> 00:54:53,420
필터 크기 k, 패딩 p,

1411
00:54:53,420 --> 00:54:57,580
스트라이드 s가 있으면 출력 크기는 w에서

1412
00:54:57,580 --> 00:54:58,740
k를 빼고,

1413
00:54:58,740 --> 00:55:03,460
더 큰 커널은 입력을 줄이고, 2P 패딩은 줄어든 크기를

1414
00:55:03,460 --> 00:55:06,360
일부 보충하며, 스트라이드로 나누고,

1415
00:55:06,360 --> 00:55:09,060
마지막에 1을 더하는 복잡한

1416
00:55:09,060 --> 00:55:14,140
공식이 나옵니다. 이는 경계 계산 때문입니다.

1417
00:55:14,140 --> 00:55:16,100
스트라이드 컨볼루션은 흥미로운데,

1418
00:55:16,100 --> 00:55:18,540
이 그림으로 돌아가 보면 스트라이드

1419
00:55:18,540 --> 00:55:20,240
컨볼루션은 신경망

1420
00:55:20,240 --> 00:55:21,940
내부에서 이미지를 다운샘플링하는

1421
00:55:21,940 --> 00:55:23,400
효과가 있습니다.

1422
00:55:23,400 --> 00:55:25,460
따라서 스트라이드 컨볼루션을

1423
00:55:25,460 --> 00:55:27,560
쓰면 각 컨볼루션 층이 특징

1424
00:55:27,560 --> 00:55:30,820
맵 크기를 보통 2배씩 줄이는 것과 같습니다.

1425
00:55:30,820 --> 00:55:32,240
이걸 쌓으면

1426
00:55:32,240 --> 00:55:34,115
효과적인 수용 영역이

1427
00:55:34,115 --> 00:55:35,660
지수적으로 증가합니다.

1428
00:55:35,660 --> 00:55:37,680
즉, 여러 컨볼루션 층을

1429
00:55:37,680 --> 00:55:40,480
쌓고 각 층이 2배씩 다운샘플링하면,

1430
00:55:40,480 --> 00:55:42,272
효과적인 수용

1431
00:55:42,272 --> 00:55:44,438
영역이 네트워크 깊이에

1432
00:55:44,438 --> 00:55:46,580
따라 지수적으로 커집니다.

1433
00:55:46,580 --> 00:55:48,820
그래서 비교적 적은 층으로도

1434
00:55:48,820 --> 00:55:51,320
전체 입력 이미지를 보는 매우

1435
00:55:51,320 --> 00:55:54,720
큰 효과적인 수용 영역을 만들 수 있습니다.

1436
00:55:54,720 --> 00:55:57,640
여기서 한 가지 예제를 통해 컨볼루션에

1437
00:55:57,640 --> 00:56:00,360
대해 모두 같은 이해를 갖도록 하겠습니다.

1438
00:56:00,360 --> 00:56:03,800
입력 볼륨이 3x32x32라고 생각해 봅시다.

1439
00:56:03,800 --> 00:56:06,220
컨볼루션 층은 10개의 필터를 가지고, 각

1440
00:56:06,220 --> 00:56:10,240
필터는 5x5 크기에 스트라이드 1, 패딩 2라고 가정해 봅시다.

1441
00:56:10,240 --> 00:56:11,598
출력 크기는 얼마입니까?

1442
00:56:11,598 --> 00:56:13,640
여기 숫자가 많아서 추적하기

1443
00:56:13,640 --> 00:56:15,360
쉽게 색깔로 구분했습니다.

1444
00:56:15,360 --> 00:56:18,760
여기서는 10 곱하기 32 곱하기 32입니다.

1445
00:56:18,760 --> 00:56:21,420
이 32는 사실 이 32와 다른 32입니다.

1446
00:56:21,420 --> 00:56:23,750
그래서 파란색이 다른 색으로 표시되어 있습니다.

1447
00:56:23,750 --> 00:56:26,390
하지만 이 10은 출력 채널 수입니다.

1448
00:56:26,390 --> 00:56:29,230
출력 채널 수는 필터 수와 일치해야 합니다.

1449
00:56:29,230 --> 00:56:32,390
그리고 공간 크기는 우리가 방금 본 공식으로

1450
00:56:32,390 --> 00:56:33,030
계산합니다.

1451
00:56:33,030 --> 00:56:37,430
그래서 입력 공간 크기는 여기 아래에 있고, 패딩

1452
00:56:37,430 --> 00:56:38,890
2가 더해집니다.

1453
00:56:38,890 --> 00:56:42,910
패딩이 공간 크기를 더하고, 5는 공간 크기를 나누는 컨볼루션

1454
00:56:42,910 --> 00:56:45,290
커널 크기이며, 스트라이드는 1입니다.

1455
00:56:45,290 --> 00:56:46,890
그래서 간단하고 1을 더합니다.

1456
00:56:46,890 --> 00:56:49,310
그리고 이 값이 마침 32가 나옵니다.

1457
00:56:49,310 --> 00:56:51,270
이 경우, 몇 슬라이드 전에

1458
00:56:51,270 --> 00:56:53,733
이야기한 것과 같은 패턴을 따릅니다.

1459
00:56:53,733 --> 00:56:55,650
홀수 모양의 컨볼루션 커널입니다.

1460
00:56:55,650 --> 00:56:56,650
여기서는 5입니다.

1461
00:56:56,650 --> 00:56:57,950
패딩은 2입니다.

1462
00:56:57,950 --> 00:57:01,130
커널 크기가 2k 더하기 1이라면,

1463
00:57:01,130 --> 00:57:05,630
패딩 k는 공간 크기를 유지한다는 뜻입니다.

1464
00:57:05,630 --> 00:57:08,487
학습 가능한 파라미터 수입니다.

1465
00:57:08,487 --> 00:57:11,070
몇 개 더 슬라이드가 있으니 이 부분을

1466
00:57:11,070 --> 00:57:12,750
빠르게 살펴보겠습니다.

1467
00:57:12,750 --> 00:57:15,310
여기서는 학습 가능한 파라미터

1468
00:57:15,310 --> 00:57:19,670
수가 760입니다. 각 필터가 기본적으로 3 곱하기 5

1469
00:57:19,670 --> 00:57:20,830
곱하기 5이고,

1470
00:57:20,830 --> 00:57:22,600
바이어스가 하나 있습니다.

1471
00:57:22,600 --> 00:57:25,040
그래서 필터당 76개의 학습 가능한 파라미터가 있습니다.

1472
00:57:25,040 --> 00:57:26,000
필터가 10개 있으니,

1473
00:57:26,000 --> 00:57:27,740
총 760개의 학습

1474
00:57:27,740 --> 00:57:30,580
가능한 파라미터가 있습니다.

1475
00:57:30,580 --> 00:57:33,083
곱셈-덧셈 연산 수 또한 계산할 수 있습니다.

1476
00:57:33,083 --> 00:57:35,000
이 컨볼루션 커널, 즉 컨볼루션

1477
00:57:35,000 --> 00:57:37,740
연산자가 얼마나 많은 계산을 하는지 말이죠.

1478
00:57:37,740 --> 00:57:39,230
여기서는 꽤 많습니다.

1479
00:57:39,230 --> 00:57:39,980
음, 정말 많을까요?

1480
00:57:39,980 --> 00:57:40,580
잘 모르겠습니다.

1481
00:57:40,580 --> 00:57:42,580
계산량이 많다는 직관이

1482
00:57:42,580 --> 00:57:45,040
있을 수도, 없을 수도 있습니다.

1483
00:57:45,040 --> 00:57:47,560
하지만 제가 생각하는 계산량, 즉

1484
00:57:47,560 --> 00:57:50,500
플롭스 수를 계산하는 방법은, 출력

1485
00:57:50,500 --> 00:57:52,620
볼륨 크기가 10 곱하기 32

1486
00:57:52,620 --> 00:57:54,700
곱하기 32라는 점입니다.

1487
00:57:54,700 --> 00:57:56,940
그리고 출력 볼륨의 각 항목은 필터

1488
00:57:56,940 --> 00:58:00,020
하나와 입력의 한 부분 간의 내적(dot

1489
00:58:00,020 --> 00:58:02,640
product)으로 계산되었음을 알고 있습니다.

1490
00:58:02,640 --> 00:58:05,060
그래서 출력 수가 10 곱하기 32 곱하기

1491
00:58:05,060 --> 00:58:08,720
32, 약 만 개 정도이므로 총 플롭스 수를 알 수 있습니다.

1492
00:58:08,720 --> 00:58:10,580
그리고 각 출력값은 3x5x5

1493
00:58:10,580 --> 00:58:14,740
필터와 3x5x5 이미지 조각의 내적(dot product)으로

1494
00:58:14,740 --> 00:58:16,080
계산됩니다.

1495
00:58:16,080 --> 00:58:17,840
그래서 총 75개의 요소가 있는 거죠.

1496
00:58:17,840 --> 00:58:22,130
이걸 곱하면 약 768,000번의

1497
00:58:22,130 --> 00:58:26,130
부동소수점 곱셈-덧셈 연산이 필요합니다.

1498
00:58:26,130 --> 00:58:28,130
자, 그럼 여기서 합성곱(convolution)에

1499
00:58:28,130 --> 00:58:29,932
대한 한 줄 요약, 한 슬라이드 요약입니다.

1500
00:58:29,932 --> 00:58:31,390
이 부분은 제가 자세히 설명하지는 않을 겁니다.

1501
00:58:31,390 --> 00:58:33,170
나중에 여러분이 참고할 수 있도록 준비한 거예요.

1502
00:58:33,170 --> 00:58:35,170
이 슬라이드는 합성곱 층과

1503
00:58:35,170 --> 00:58:38,530
관련된 모든 하이퍼파라미터와 수식을 요약한 겁니다.

1504
00:58:38,530 --> 00:58:41,690
PyTorch를 보면, PyTorch는 많은 사람들이

1505
00:58:41,690 --> 00:58:43,610
사용하는 딥러닝 프레임워크입니다.

1506
00:58:43,610 --> 00:58:45,610
이 합성곱 층에는 우리가

1507
00:58:45,610 --> 00:58:48,190
이야기한 모든 하이퍼파라미터들이 있습니다.

1508
00:58:48,190 --> 00:58:50,273
우리가 이야기하지 않은 흥미로운 하이퍼파라미터가

1509
00:58:50,273 --> 00:58:52,930
두 가지 있는데, groups와 dilation입니다.

1510
00:58:52,930 --> 00:58:54,910
dilation은 요즘에는 거의 사용하지 않습니다.

1511
00:58:54,910 --> 00:58:56,850
groups는 가끔 아직도 사용됩니다.

1512
00:58:56,850 --> 00:59:00,410
하지만 아마도 나중 강의에서 다룰 수도 있습니다.

1513
00:59:00,410 --> 00:59:03,290
다른 종류의 합성곱도 있을 수 있습니다.

1514
00:59:03,290 --> 00:59:04,950
우리는 2D 합성곱에 대해 이야기했습니다.

1515
00:59:04,950 --> 00:59:07,930
1D 합성곱도 할 수 있는데, 2차원 신호

1516
00:59:07,930 --> 00:59:10,630
위에 필터를 슬라이딩하는 대신, 1차원

1517
00:59:10,630 --> 00:59:13,650
신호 위에 필터를 한 방향으로만 슬라이딩하는

1518
00:59:13,650 --> 00:59:15,610
겁니다, 또는 3D 합성곱도

1519
00:59:15,610 --> 00:59:17,302
있는데, 3차원 신호와

1520
00:59:17,302 --> 00:59:19,010
3차원 필터가 있고, 이

1521
00:59:19,010 --> 00:59:21,552
필터를 3D 공간 어디서든 슬라이딩해서

1522
00:59:21,552 --> 00:59:24,170
입력 신호와 합성곱할 수 있습니다.

1523
00:59:24,170 --> 00:59:25,670
그래서 convolution이라는

1524
00:59:25,670 --> 00:59:27,430
개념은 단순히

1525
00:59:27,430 --> 00:59:29,550
2차원 이미지에만 국한되지 않습니다.

1526
00:59:29,550 --> 00:59:30,090
네.

1527
00:59:30,090 --> 00:59:33,070
기본적으로 convolution에 관한 내용은 여기까지입니다.

1528
00:59:33,070 --> 00:59:34,710
마지막으로는 pooling입니다.

1529
00:59:34,710 --> 00:59:36,950
다행히 pooling은 꽤 간단합니다.

1530
00:59:36,950 --> 00:59:40,470
pooling 레이어는 기본적으로 신경망 내부에서 다운샘플링하는

1531
00:59:40,470 --> 00:59:41,650
또 다른 방법입니다.

1532
00:59:41,650 --> 00:59:43,310
우리는 strided convolution이

1533
00:59:43,310 --> 00:59:45,190
신경망 내부에서 다운샘플링하는 한 가지

1534
00:59:45,190 --> 00:59:46,250
방법이라는 것을 보았습니다.

1535
00:59:46,250 --> 00:59:48,550
다운샘플링은 네트워크 깊이를 따라가면서 수용

1536
00:59:48,550 --> 00:59:50,190
영역(receptive field)을

1537
00:59:50,190 --> 00:59:52,550
더 빠르게 키울 수 있기 때문에 유용합니다.

1538
00:59:52,550 --> 00:59:54,270
하지만 convolution은 여전히

1539
00:59:54,270 --> 00:59:55,810
계산 비용이 꽤 많이 듭니다.

1540
00:59:55,810 --> 00:59:59,510
convolution은 convolutional 네트워크에서 대부분의
플롭스(FLOPs),

1541
00:59:59,510 --> 01:00:01,090
즉 계산이 이루어지는 부분입니다.

1542
01:00:01,090 --> 01:00:02,673
pooling 레이어는 계산

1543
01:00:02,673 --> 01:00:04,690
비용이 매우 적은 다운샘플링 방법입니다.

1544
01:00:04,690 --> 01:00:06,830
계산 비용이 많이 들지 않습니다.

1545
01:00:06,830 --> 01:00:08,830
pooling 레이어의 아이디어는

1546
01:00:08,830 --> 01:00:12,270
3차원 텐서가 주어졌을 때, 여기서는

1547
01:00:12,270 --> 01:00:13,770
64x112x112입니다.

1548
01:00:13,770 --> 01:00:15,948
이것을 공간적으로 112x112

1549
01:00:15,948 --> 01:00:17,740
크기의 3차원

1550
01:00:17,740 --> 01:00:20,760
특징 볼륨으로 생각하면 되고, 64개의

1551
01:00:20,760 --> 01:00:24,220
평면, 즉 64개의 채널 활성화가 있습니다.

1552
01:00:24,220 --> 01:00:26,660
이제 우리가 할 것은 각 평면을

1553
01:00:26,660 --> 01:00:29,043
112x112 이미지로 보고,

1554
01:00:29,043 --> 01:00:30,460
각각의 개별 특징

1555
01:00:30,460 --> 01:00:32,560
평면을 입력 텐서에서 꺼내어

1556
01:00:32,560 --> 01:00:34,060
독립적으로 다운샘플링한

1557
01:00:34,060 --> 01:00:36,260
다음, 다시 쌓아서 출력을

1558
01:00:36,260 --> 01:00:37,520
계산하는 것입니다.

1559
01:00:37,520 --> 01:00:41,200
그래서 이 입력 64 by 224 by 224에서,

1560
01:00:41,200 --> 01:00:43,860
각 224 by 224 평면을 독립적으로

1561
01:00:43,860 --> 01:00:45,580
추출해서 다운샘플링한

1562
01:00:45,580 --> 01:00:48,640
다음, 다시 쌓아서 채널 수는 같게 유지하지만

1563
01:00:48,640 --> 01:00:50,980
공간 크기를 바꾸는 겁니다.

1564
01:00:50,980 --> 01:00:52,800
우리가 다운샘플링에 사용하는 방법은 무엇일까요?

1565
01:00:52,800 --> 01:00:54,300
좋은 질문입니다.

1566
01:00:54,300 --> 01:00:56,478
사실 그건 하이퍼파라미터인데,

1567
01:00:56,478 --> 01:00:58,020
다운샘플링에 사용하는 몇 가지

1568
01:00:58,020 --> 01:00:59,402
다른 메커니즘이 있습니다.

1569
01:00:59,402 --> 01:01:01,860
가장 흔한 방법 중 하나는 맥스 풀링(max

1570
01:01:01,860 --> 01:01:04,460
pooling)이라고 부르는 겁니다.

1571
01:01:04,460 --> 01:01:06,100
맥스 풀링에서는

1572
01:01:06,100 --> 01:01:08,760
단일 깊이 슬라이스를 겹치지

1573
01:01:08,760 --> 01:01:11,400
않는 영역으로 나누는 겁니다.

1574
01:01:11,400 --> 01:01:13,020
이 경우에는 2 by 2이고,

1575
01:01:13,020 --> 01:01:15,290
우리는 종종 컨볼루션에서 쓰는

1576
01:01:15,290 --> 01:01:17,330
것과 같은 용어를 사용합니다.

1577
01:01:17,330 --> 01:01:19,010
그래서 이 경우 커널 크기가

1578
01:01:19,010 --> 01:01:21,890
2 by 2이고 스트라이드가 2라고 말할 수

1579
01:01:21,890 --> 01:01:23,970
있는데, 이게 입력을 겹치지

1580
01:01:23,970 --> 01:01:26,450
않는 2 by 2 타일로 나누는 겁니다.

1581
01:01:26,450 --> 01:01:29,350
그 다음 각 겹치지 않는 2 by 2 타일 내에서

1582
01:01:29,350 --> 01:01:30,730
최대값을 취합니다.

1583
01:01:30,730 --> 01:01:33,590
예를 들어 6, 8, 3, 4가 있을 때,

1584
01:01:33,590 --> 01:01:36,130
각 타일 내에서 최대값을

1585
01:01:36,130 --> 01:01:38,490
취하면 공간 압축이

1586
01:01:38,490 --> 01:01:40,048
이루어집니다.

1587
01:01:40,048 --> 01:01:42,090
여기서 다양한 하이퍼파라미터를

1588
01:01:42,090 --> 01:01:43,350
생각할 수 있죠.

1589
01:01:43,350 --> 01:01:45,655
커널 크기를 무엇으로 할지,

1590
01:01:45,655 --> 01:01:47,030
커널 크기를 바꿀 수도 있고,

1591
01:01:47,030 --> 01:01:48,310
스트라이드를 바꿀 수도 있습니다.

1592
01:01:48,310 --> 01:01:51,090
또한 다운샘플링에 사용하는 함수를 바꿀 수도 있죠.

1593
01:01:51,090 --> 01:01:52,630
맥스 풀링이 꽤 흔합니다.

1594
01:01:52,630 --> 01:01:53,910
평균 풀링도 있고,

1595
01:01:53,910 --> 01:01:56,463
때로는 안티에일리어싱 다운풀링도 볼 수 있습니다.

1596
01:01:56,463 --> 01:01:59,130
이 모두가 특징 맵을 한 번에 하나씩

1597
01:01:59,130 --> 01:02:01,127
다운샘플링하는 방법들입니다.

1598
01:02:01,127 --> 01:02:01,710
좋은 질문입니다.

1599
01:02:01,710 --> 01:02:03,090
패딩을 사용하나요?

1600
01:02:03,090 --> 01:02:06,770
일반적으로 풀링 레이어에서는 패딩을 사용하지 않습니다.

1601
01:02:06,770 --> 01:02:09,650
수학적으로 막는 건 없지만,

1602
01:02:09,650 --> 01:02:12,030
맥스 풀링의 경우에는 패딩을 쓰는 게 의미가 없어요.

1603
01:02:12,030 --> 01:02:14,040
사실 ReLU와 거의 같아지기 때문입니다.

1604
01:02:14,040 --> 01:02:15,860
그래서 맥스 풀링을 쓸 때

1605
01:02:15,860 --> 01:02:18,160
ReLU도 같이 쓰면 중복이 되죠.

1606
01:02:18,160 --> 01:02:21,420
그래서 보통 풀링 레이어에서는 패딩을 사용하지 않습니다.

1607
01:02:21,420 --> 01:02:22,920
PyTorch에서

1608
01:02:22,920 --> 01:02:26,940
풀링 레이어에 패딩 옵션이 있는지는 잘 모르겠습니다.

1609
01:02:26,940 --> 01:02:27,440
네,

1610
01:02:27,440 --> 01:02:29,080
스트라이드도 이런 아키텍처

1611
01:02:29,080 --> 01:02:30,820
하이퍼파라미터 중 하나입니다.

1612
01:02:30,820 --> 01:02:32,880
하지만 보통 이런 것들을 너무 많이 튜닝하지는 않습니다.

1613
01:02:32,880 --> 01:02:34,800
보통 pooling layer의

1614
01:02:34,800 --> 01:02:36,512
직관적인 목적은, 솔직히

1615
01:02:36,512 --> 01:02:38,720
가장 흔한 것은 모든 것을

1616
01:02:38,720 --> 01:02:42,420
2배 축소하고 싶다는 겁니다. 이게 가장 흔한 연산입니다.

1617
01:02:42,420 --> 01:02:45,360
그래서 가장 흔한 방법은 2x2 크기에 stride 2를 사용하는 거죠.

1618
01:02:45,360 --> 01:02:48,880
가끔은 4x4 크기에 stride 2를 사용하기도 합니다.

1619
01:02:48,880 --> 01:02:51,160
하지만 기본적으로 가장 흔한

1620
01:02:51,160 --> 01:02:52,920
설정은 모든 것을

1621
01:02:52,920 --> 01:02:55,200
정확히 2배 축소하는 겁니다.

1622
01:02:55,200 --> 01:02:56,740
아, 아주 좋은 질문입니다.

1623
01:02:56,740 --> 01:02:59,680
모든 이미지가 같은 입력 크기여야 하나요?

1624
01:02:59,680 --> 01:03:02,680
지금까지 이야기한 모든 언어에서는 그렇습니다.

1625
01:03:02,680 --> 01:03:04,400
입력 이미지 크기가

1626
01:03:04,400 --> 01:03:06,680
다르면 큰 문제가 생깁니다.

1627
01:03:06,680 --> 01:03:08,200
그래서 보통 해결

1628
01:03:08,200 --> 01:03:12,020
방법은 첫째, 네트워크에 배치하기 전에 모든 이미지를

1629
01:03:12,020 --> 01:03:13,900
정확히 같은 크기로

1630
01:03:13,900 --> 01:03:15,260
리사이즈하는 겁니다.

1631
01:03:15,260 --> 01:03:17,980
가끔은 제로나 다른 값으로 이미지를 패딩해서 모두

1632
01:03:17,980 --> 01:03:19,900
같은 크기로 만드는 경우도 있는데,

1633
01:03:19,900 --> 01:03:22,712
이 경우에는 왜곡이 아니라 패딩을 하는 거죠.

1634
01:03:22,712 --> 01:03:24,420
또는 서로 다른 종횡비의 이미지에

1635
01:03:24,420 --> 01:03:27,180
대해 이 레이어들을 독립적으로 실행해야 합니다.

1636
01:03:27,180 --> 01:03:29,420
좀 더 정교한 학습 설정에서는 종종

1637
01:03:29,420 --> 01:03:31,047
'aspect ratio

1638
01:03:31,047 --> 01:03:33,380
bucketing'이라는 방법을 사용하기도

1639
01:03:33,380 --> 01:03:33,995
합니다.

1640
01:03:33,995 --> 01:03:35,620
즉, 학습 데이터를

1641
01:03:35,620 --> 01:03:37,480
종횡비별로 버킷에 나누는 거죠.

1642
01:03:37,480 --> 01:03:38,855
그 다음 각 순전파나 역전파

1643
01:03:38,855 --> 01:03:40,740
시에는 같은 해상도와 종횡비를

1644
01:03:40,740 --> 01:03:42,680
가진 이미지 배치로 네트워크를 돌립니다.

1645
01:03:42,680 --> 01:03:44,940
하지만 각 반복마다 다른 해상도나 종횡비의

1646
01:03:44,940 --> 01:03:47,080
이미지를 가져올 수도 있는데, 이런 방식은

1647
01:03:47,080 --> 01:03:48,538
좀 더 일반적이고 큰

1648
01:03:48,538 --> 01:03:50,788
규모의 프로덕션 시스템에서 볼 수 있습니다.

1649
01:03:50,788 --> 01:03:51,288
네.

1650
01:03:51,288 --> 01:03:53,080
그래서 질문은, 이걸 어디에 두느냐 하는 겁니다.

1651
01:03:53,080 --> 01:03:55,600
이것들은 보통 convolution 층 사이사이에 섞여 있습니다.

1652
01:03:55,600 --> 01:03:57,040
그래서 꽤 흔한 구조,

1653
01:03:57,040 --> 01:03:58,860
ConvNet에서 흔한 패턴은 convolution과

1654
01:03:58,860 --> 01:04:01,280
pooling을 번갈아 배치하는 겁니다.

1655
01:04:01,280 --> 01:04:03,820
예를 들어, com com pool, com com pool,

1656
01:04:03,820 --> 01:04:06,860
com com pool, fully connected, fully

1657
01:04:06,860 --> 01:04:10,130
connected가 전형적인 convolutional network입니다.

1658
01:04:10,130 --> 01:04:11,590
네, 아주 좋은 질문입니다.

1659
01:04:11,590 --> 01:04:13,150
이것이 비선형성을 도입하나요?

1660
01:04:13,150 --> 01:04:16,690
사용하는 pooling 연산의 종류에 따라

1661
01:04:16,690 --> 01:04:17,550
다릅니다.

1662
01:04:17,550 --> 01:04:20,190
max pooling을 한다면 그것은 비선형성입니다.

1663
01:04:20,190 --> 01:04:23,010
그래서 어떤 네트워크에서는 max pooling이 있다면

1664
01:04:23,010 --> 01:04:26,370
convolution 주변에 ReLU를 사용하지 않을 수도 있습니다.
왜냐하면

1665
01:04:26,370 --> 01:04:28,830
max pooling 자체가 비선형성이기 때문입니다.

1666
01:04:28,830 --> 01:04:31,633
평균 풀링(average pooling)은 선형 연산자입니다.

1667
01:04:31,633 --> 01:04:33,550
그래서 average pooling을 하면 선형입니다.

1668
01:04:33,550 --> 01:04:37,290
그래서 아마도 그 경우에는 여전히 ReLU를 사용하는 게 좋을 겁니다.

1669
01:04:37,290 --> 01:04:37,870
네.

1670
01:04:37,870 --> 01:04:39,890
그럼 pooling에 대한 제 간단한 한 슬라이드

1671
01:04:39,890 --> 01:04:43,123
요약은 convolution과 기본적으로 같은 하이퍼파라미터를 가진다는
겁니다.

1672
01:04:43,123 --> 01:04:45,290
다만 여기에 추가로 pooling

1673
01:04:45,290 --> 01:04:49,290
함수가 있는데, 이게 다운샘플링을 하는 메커니즘입니다.

1674
01:04:49,290 --> 01:04:52,010
마지막으로 언급하고 싶은 것은

1675
01:04:52,010 --> 01:04:56,110
translation equivariance라는 개념입니다.

1676
01:04:56,110 --> 01:04:57,690
저게 도대체 뭐죠?

1677
01:04:57,690 --> 01:05:00,195
강의 초반에 이미지의 공간 구조를

1678
01:05:00,195 --> 01:05:01,570
존중하는 연산자를

1679
01:05:01,570 --> 01:05:03,830
원한다고 말씀드렸습니다.

1680
01:05:03,830 --> 01:05:06,330
이미지를 큰 벡터로 평탄화하는 것은

1681
01:05:06,330 --> 01:05:09,680
이미지의 공간 구조를 존중하지 않는다는

1682
01:05:09,680 --> 01:05:10,855
개념도 있었습니다.

1683
01:05:10,855 --> 01:05:13,480
합성곱과 풀링이 공유하는 흥미로운

1684
01:05:13,480 --> 01:05:17,320
특성이 있는데, 이것이 이미지의 2D 공간

1685
01:05:17,320 --> 01:05:21,260
구조를 존중하는 것을 형식화하는 한 방법입니다.

1686
01:05:21,260 --> 01:05:23,920
그것이 바로 이동 등변성(translation equivariance)이라는
개념입니다.

1687
01:05:23,920 --> 01:05:25,820
좀 이상하게 들릴 수 있지만,

1688
01:05:25,820 --> 01:05:29,200
두 개의 다른 연산자, 두 개의 다른 경로를

1689
01:05:29,200 --> 01:05:30,640
상상할 수 있습니다.

1690
01:05:30,640 --> 01:05:33,140
한 경로에서는 이미지를

1691
01:05:33,140 --> 01:05:35,000
합성곱이나 풀링 연산자로

1692
01:05:35,000 --> 01:05:38,000
처리한 후, 결과 특징 맵을 옆으로

1693
01:05:38,000 --> 01:05:41,720
이동시키는 것을 상상할 수 있습니다.

1694
01:05:41,720 --> 01:05:44,360
그 대신 이 두 과정을 순서를 바꿔서 생각할

1695
01:05:44,360 --> 01:05:45,060
수도 있습니다.

1696
01:05:45,060 --> 01:05:48,360
먼저 이미지를 이동시키고 나서 그

1697
01:05:48,360 --> 01:05:50,720
위에 합성곱이나 풀링

1698
01:05:50,720 --> 01:05:53,140
연산을 수행하는 것이죠.

1699
01:05:53,140 --> 01:05:55,140
이 경우 순서가 중요하지

1700
01:05:55,140 --> 01:05:58,780
않은데, 이동 후 합성곱을 하거나 합성곱 후

1701
01:05:58,780 --> 01:06:01,440
이동을 해도 같은 결과가 나옵니다.

1702
01:06:01,440 --> 01:06:04,742
물론 경계 조건 등 몇 가지 기술적 조건은

1703
01:06:04,742 --> 01:06:05,700
있지만요.

1704
01:06:05,700 --> 01:06:08,950
무한히 큰 이미지 등 몇 가지

1705
01:06:08,950 --> 01:06:10,510
조건을 무시하면,

1706
01:06:10,510 --> 01:06:12,475
공간 이동과

1707
01:06:12,475 --> 01:06:14,350
다운샘플링 또는 합성곱

1708
01:06:14,350 --> 01:06:16,710
연산의 순서를 바꿀

1709
01:06:16,710 --> 01:06:19,310
수 있다는 점이 매우

1710
01:06:19,310 --> 01:06:20,390
흥미롭습니다.

1711
01:06:20,390 --> 01:06:22,710
이것은 이미지 처리에 중요한

1712
01:06:22,710 --> 01:06:27,350
직관을 내포하는데, 이미지에서 추출한 특징은

1713
01:06:27,350 --> 01:06:29,590
이미지 내용에만 의존해야

1714
01:06:29,590 --> 01:06:31,830
하고, 그 내용이 이미지

1715
01:06:31,830 --> 01:06:34,830
내 어디에 위치했는지 절대

1716
01:06:34,830 --> 01:06:38,110
위치에는 의존하지 않아야 한다는 겁니다.

1717
01:06:38,110 --> 01:06:40,210
즉, 이쪽을 보면

1718
01:06:40,210 --> 01:06:41,390
사람과

1719
01:06:41,390 --> 01:06:43,010
벤치가 보이고,

1720
01:06:43,010 --> 01:06:45,570
저쪽을 보면 사람과 벤치가 보입니다.

1721
01:06:45,570 --> 01:06:48,015
그것이 내 오른쪽에 있든 왼쪽에

1722
01:06:48,015 --> 01:06:49,390
있든, 그

1723
01:06:49,390 --> 01:06:51,670
데이터를 똑같이 처리해야 합니다.

1724
01:06:51,670 --> 01:06:53,570
이것이 이미지와 우리가

1725
01:06:53,570 --> 01:06:57,630
처리하는 2D 데이터에 대해 갖고 싶은 중요한

1726
01:06:57,630 --> 01:06:58,970
직관이자 구조입니다.

1727
01:06:58,970 --> 01:07:01,590
그리고 이 번역, 즉 equivariance

1728
01:07:01,590 --> 01:07:03,670
개념은 이러한 연산자에 그 구조가 어떻게

1729
01:07:03,670 --> 01:07:06,570
내재되어 있는지를 수학적으로 설명하는 방법입니다.

1730
01:07:06,570 --> 01:07:09,610
이것은 흥미로운 점인데, 이미지가 어떻게

1731
01:07:09,610 --> 01:07:11,170
처리되어야 하는지에 대한

1732
01:07:11,170 --> 01:07:13,650
우리의 직관을 특징 추출 방법의 설계가

1733
01:07:13,650 --> 01:07:15,150
아니라 연산자의 설계를

1734
01:07:15,150 --> 01:07:17,525
통해 내장할 수 있다는 겁니다,

1735
01:07:17,525 --> 01:07:19,050
처음에 봤던 것처럼요.

1736
01:07:19,050 --> 01:07:20,570
질문은, 왜 번역을 하느냐는 것입니다.

1737
01:07:20,570 --> 01:07:20,890
여러분.

1738
01:07:20,890 --> 01:07:23,223
하지 마세요. 실제로 하려는 것이 아닙니다.

1739
01:07:23,223 --> 01:07:26,222
이것은 기본적으로 수학적인 호기심일 뿐입니다.

1740
01:07:26,222 --> 01:07:27,930
명확히 하자면, 일반적으로 신경망

1741
01:07:27,930 --> 01:07:29,850
내부에서 이렇게 하면 안 됩니다.

1742
01:07:29,850 --> 01:07:32,370
이것은 단지 흥미롭게도 사실이라는

1743
01:07:32,370 --> 01:07:33,970
점을 주목하는 것이지,

1744
01:07:33,970 --> 01:07:37,090
신경망 내부에서 이렇게 하지는 않는다는 겁니다.

1745
01:07:37,090 --> 01:07:38,690
수학자라면 이것을 가환 다이어그램(commutative

1746
01:07:38,690 --> 01:07:40,070
diagram)이라고 부릅니다.

1747
01:07:40,070 --> 01:07:42,810
수학자들은 이런 걸 아주 좋아합니다.

1748
01:07:42,810 --> 01:07:45,410
이것이 오늘 강의의 요약입니다.

1749
01:07:45,410 --> 01:07:47,190
우리는 컨볼루션 신경망에 대해 이야기했습니다.

1750
01:07:47,190 --> 01:07:48,985
왜 그것들이 흥미로운지에 대해 이야기했습니다.

1751
01:07:48,985 --> 01:07:50,610
컨볼루션과 풀링이라는 두 가지 새로운

1752
01:07:50,610 --> 01:07:52,110
연산자에 대해 이야기했습니다.

1753
01:07:52,110 --> 01:07:54,652
그리고 다음 강의에서는 이들을 어떻게 결합해 CNN

1754
01:07:54,652 --> 01:07:56,130
아키텍처를 만드는지 볼 것입니다.

1755
01:07:56,130 --> 01:07:58,920
그때 뵙겠습니다.
