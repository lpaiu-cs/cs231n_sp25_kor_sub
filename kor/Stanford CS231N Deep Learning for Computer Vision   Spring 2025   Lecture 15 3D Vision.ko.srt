1
00:00:05,440 --> 00:00:08,160
다음 강연자를 발표하게 되어 정말 기쁩니다.

2
00:00:08,160 --> 00:00:11,120
과정의 강사인 자이준 우 교수입니다.

3
00:00:11,120 --> 00:00:14,597
자이준은 스탠포드 컴퓨터

4
00:00:14,597 --> 00:00:16,180
과학과의

5
00:00:16,180 --> 00:00:22,720
조교수이며, 스탠포드 비전 및 학습 연구소의

6
00:00:22,720 --> 00:00:24,040
교수진입니다.

7
00:00:24,040 --> 00:00:27,240
그의 연구는 다중 모달 인식, 로봇 공학

8
00:00:27,240 --> 00:00:31,360
및 구현된 AI, 시각적 생성 및 추론, 3D

9
00:00:31,360 --> 00:00:35,740
이해에 중점을 두고 장면 이해에 초점을 맞추고 있으며,

10
00:00:35,740 --> 00:00:38,120
이는 오늘 강의의 주제입니다.

11
00:00:38,120 --> 00:00:41,920
이제 자이준에게 오늘 강의를 시작하도록 넘기겠습니다.

12
00:00:41,920 --> 00:00:43,340
안녕하세요, 저는 자이준입니다.

13
00:00:43,340 --> 00:00:44,860
저는 여기 조교수입니다.

14
00:00:44,860 --> 00:00:46,360
몇 년 전, 저는 이

15
00:00:46,360 --> 00:00:48,840
수업을 공동으로 가르쳤던 것 같습니다.

16
00:00:48,840 --> 00:00:51,940
올해가 10주년이라고 들었습니다.

17
00:00:51,940 --> 00:00:55,360
그래서 다양한 곳에서 초청 강연자가 있습니다.

18
00:00:55,360 --> 00:00:58,520
오늘은 3D 비전에 대해 이야기할 것입니다.

19
00:00:58,520 --> 00:01:01,130
이전 몇 주 동안 우리는 합성곱

20
00:01:01,130 --> 00:01:05,938
신경망과 변환기, 아마도 비전 언어 모델과 생성

21
00:01:05,938 --> 00:01:07,730
모델에 대해 이야기했기

22
00:01:07,730 --> 00:01:09,970
때문에, 이전에 배운

23
00:01:09,970 --> 00:01:12,100
것들과는 다를 수 있습니다.

24
00:01:12,100 --> 00:01:13,730
맞습니다, 알겠습니다.

25
00:01:13,730 --> 00:01:16,690
3D에 대해 먼저 3D 표현이

26
00:01:16,690 --> 00:01:19,730
무엇인지 조금 소개할 것입니다.

27
00:01:19,730 --> 00:01:22,370
그래서 딥러닝과는 꽤 거리가 있는

28
00:01:22,370 --> 00:01:23,430
것 같습니다.

29
00:01:23,430 --> 00:01:25,850
하지만 딥러닝이나 AI가 3D 비전을 어떻게

30
00:01:25,850 --> 00:01:29,010
변화시켰는지, 그리고 그것들이 어떻게 다양한 방식으로 통합될 수 있는지에

31
00:01:29,010 --> 00:01:30,290
대해 이야기할 것입니다.

32
00:01:30,290 --> 00:01:32,930
그리고 우리는 3D 생성, 재구성 및 그와 유사한

33
00:01:32,930 --> 00:01:35,570
몇 가지 다른 응용 프로그램을 살펴볼 것입니다.

34
00:01:35,570 --> 00:01:39,050
좋습니다, 그러면 3D 객체를 표현할 수 있는

35
00:01:39,050 --> 00:01:41,070
가능한 방법을 살펴보겠습니다.

36
00:01:41,070 --> 00:01:42,755
2D에서는 매우 간단합니다.

37
00:01:42,755 --> 00:01:44,130
그냥 픽셀만 있는 것처럼 보입니다.

38
00:01:44,130 --> 00:01:47,750
PNG 파일이나 JPEG 파일을 로드하고 있습니다.

39
00:01:47,750 --> 00:01:50,130
200x200 픽셀입니다.

40
00:01:50,130 --> 00:01:51,950
그런데 3D 객체는 어떻게 표현할 수 있을까요?

41
00:01:51,950 --> 00:01:54,890
그게 우리가 먼저 살펴보고 싶은 것입니다.

42
00:01:54,890 --> 00:01:59,260
3D 객체는 다양할 수 있습니다.

43
00:01:59,260 --> 00:02:01,520
다양한 크기로 존재할 수 있습니다.

44
00:02:01,520 --> 00:02:05,580
거대한 건물과 나무, 복잡한 구조물일 수 있습니다.

45
00:02:05,580 --> 00:02:09,380
확대하면 모든 세부 사항도 볼 수 있습니다.

46
00:02:09,380 --> 00:02:11,820
다양한 크기와 다양한 특징을 가진 이러한

47
00:02:11,820 --> 00:02:14,420
다양한 유형의 3D 객체를 표현하기

48
00:02:14,420 --> 00:02:16,860
위한 최상의 3D 표현은 무엇일까요?

49
00:02:16,860 --> 00:02:20,220
모두가 픽셀을 사용하는 이미지와는 달리, 우리는

50
00:02:20,220 --> 00:02:24,260
200x200, 500x500을 가지고 있습니다.

51
00:02:24,260 --> 00:02:27,780
3D 객체를 표현하는 방법은, 객체는 기하학을 가지고

52
00:02:27,780 --> 00:02:28,650
있습니다.

53
00:02:28,650 --> 00:02:29,400
텍스처가 있습니다.

54
00:02:29,400 --> 00:02:30,320
재료가 있습니다.

55
00:02:30,320 --> 00:02:32,640
그럼 기하학을 살펴보는 것으로 시작해 보겠습니다.

56
00:02:32,640 --> 00:02:34,495
3D 객체 기하학만 해도

57
00:02:34,495 --> 00:02:36,620
표현하는 방법이 매우 다양합니다.

58
00:02:36,620 --> 00:02:39,680
기본적으로 두 가지 범주로 분류할 수 있습니다.

59
00:02:39,680 --> 00:02:41,860
하나는 명시적 표현이라고 불립니다.

60
00:02:41,860 --> 00:02:45,140
즉, 어떤 의미에서 객체의 일부를 직접적으로,

61
00:02:45,140 --> 00:02:46,700
명시적으로 표현할

62
00:02:46,700 --> 00:02:47,680
수 있습니다.

63
00:02:47,680 --> 00:02:50,160
여기에는 3D 점

64
00:02:50,160 --> 00:02:52,460
구름, 다각형 메시

65
00:02:52,460 --> 00:02:55,720
또는 우리가 이야기할 세분화와

66
00:02:55,720 --> 00:02:59,063
같은 것들이 포함됩니다.

67
00:02:59,063 --> 00:03:00,480
그리고 객체 형태 표현의

68
00:03:00,480 --> 00:03:03,550
다른 범주가 있으며, 이는 종종 암시적이라고 불립니다.

69
00:03:03,550 --> 00:03:05,300
그것들에 대해서도 이야기할 것입니다.

70
00:03:05,300 --> 00:03:07,425
조금 더 자세히 설명할 것이며,

71
00:03:07,425 --> 00:03:09,840
레벨 집합, 대수적 표면, 거리 함수 등을

72
00:03:09,840 --> 00:03:10,660
포함합니다.

73
00:03:10,660 --> 00:03:13,080
이들은 기본적으로 3D

74
00:03:13,080 --> 00:03:14,680
객체 또는 그

75
00:03:14,680 --> 00:03:17,720
기하학을 함수로 표현하는 것으로,

76
00:03:17,720 --> 00:03:19,985
직관적이지 않습니다.

77
00:03:19,985 --> 00:03:21,360
하지만 나중에

78
00:03:21,360 --> 00:03:24,280
보겠지만, 암시적 표현을 사용할 때 그들만의

79
00:03:24,280 --> 00:03:26,240
장점과 약점도 있습니다.

80
00:03:26,240 --> 00:03:29,240
모든 선택에는 적합한 작업과 기하학 유형이

81
00:03:29,240 --> 00:03:30,155
있습니다.

82
00:03:30,155 --> 00:03:32,280
특히 딥러닝의 맥락에서,

83
00:03:32,280 --> 00:03:34,488
딥러닝 방법을 적용할 때

84
00:03:34,488 --> 00:03:37,960
그들만의 강점과 약점이 있을 수 있습니다.

85
00:03:37,960 --> 00:03:41,480
언제 표현을 선택해야 할까요?

86
00:03:41,480 --> 00:03:43,480
저장해야 하므로 픽셀은

87
00:03:43,480 --> 00:03:45,640
행렬이기 때문에 저장하기 쉽습니다.

88
00:03:45,640 --> 00:03:48,620
하지만 3D 점 구름은 더 불규칙합니다.

89
00:03:48,620 --> 00:03:51,320
특히 객체를 함수로 표현하는 것과 같은

90
00:03:51,320 --> 00:03:53,340
암시적 표현을 사용할 경우,

91
00:03:53,340 --> 00:03:56,090
컴퓨터에 어떻게 저장할 수 있을까요?

92
00:03:56,090 --> 00:03:59,370
그리고 새로운 형태를 만드는 것을 어떻게 지원하나요?

93
00:03:59,370 --> 00:04:02,210
특히 입력이 사진이거나 언어

94
00:04:02,210 --> 00:04:04,770
설명이라고 가정해 봅시다.

95
00:04:04,770 --> 00:04:06,390
다양한 유형의 작업이 필요합니다.

96
00:04:06,390 --> 00:04:07,550
3D 객체가 있습니다.

97
00:04:07,550 --> 00:04:10,370
그럼 어떻게 편집하고, 단순화하고, 부드럽게 하고, 필터링하고,

98
00:04:10,370 --> 00:04:11,310
수리할 수 있을까요?

99
00:04:11,310 --> 00:04:12,850
더 많은 작업을 해야 합니다.

100
00:04:12,850 --> 00:04:14,917
이미지의 경우, 때때로 그렇게 하고 싶습니다.

101
00:04:14,917 --> 00:04:15,750
편집하고 싶습니다.

102
00:04:15,750 --> 00:04:17,208
언어를 사용하여 편집하고 싶습니다.

103
00:04:17,208 --> 00:04:19,010
스트로크를 사용하여 편집하고 싶습니다.

104
00:04:19,010 --> 00:04:22,210
3D 객체와 렌더링에 대해 어떤 작업을

105
00:04:22,210 --> 00:04:24,070
수행할 수 있을까요?

106
00:04:24,070 --> 00:04:28,112
3D 객체를 2D 픽셀로 어떻게 변환할 수 있을까요?

107
00:04:28,112 --> 00:04:29,070
어떤 의미에서는 가능합니다.

108
00:04:29,070 --> 00:04:31,210
3D 비전은 그 과정을 반전시키는 것입니다.

109
00:04:31,210 --> 00:04:35,432
2D 이미지에서 3D 객체를 재구성하는 방법은 무엇인가요?

110
00:04:35,432 --> 00:04:37,390
이 모든 것을 지원하는

111
00:04:37,390 --> 00:04:40,870
방법, 특히 3D 인간이나 동물을

112
00:04:40,870 --> 00:04:43,790
모델링하고 애니메이션화할 때 고려해야

113
00:04:43,790 --> 00:04:46,130
할 모든 요소가 있습니다.

114
00:04:46,130 --> 00:04:49,170
그리고 물론, 이 모든 것을 연결하는

115
00:04:49,170 --> 00:04:51,780
또 다른 것은 형태 편집, 렌더링,

116
00:04:51,780 --> 00:04:55,180
역 렌더링 및 애니메이션을 위한 다양한

117
00:04:55,180 --> 00:04:57,260
딥러닝 방법과의 통합입니다.

118
00:04:57,260 --> 00:04:59,380
그래서 매우 빠르게, 나는 포인트 클라우드와

119
00:04:59,380 --> 00:05:01,780
같은 이러한 표현 중 일부를 살펴볼 수 있습니다.

120
00:05:01,780 --> 00:05:05,820
포인트 클라우드는 아마도 가장 간단한 표현일 것입니다.

121
00:05:05,820 --> 00:05:07,120
나는 3D 포인트만 가지고 있습니다.

122
00:05:07,120 --> 00:05:09,508
연결성이 없기 때문에 이러한 포인트가 어떻게 연결되어

123
00:05:09,508 --> 00:05:10,800
있는지를 포착하지 않습니다.

124
00:05:10,800 --> 00:05:12,383
그래서 기본적으로

125
00:05:12,383 --> 00:05:14,260
n by [? n ?] 행렬 대신에, 이제는

126
00:05:14,260 --> 00:05:16,660
3 by n 행렬이

127
00:05:16,660 --> 00:05:20,060
있으며, 여기서 3은 이러한

128
00:05:20,060 --> 00:05:23,960
개별 포인트의 x, y, z 좌표입니다.

129
00:05:23,960 --> 00:05:26,300
그리고 포인트의 수가 있습니다.

130
00:05:26,300 --> 00:05:29,853
때때로, 포인트의 표면 법선도 표현할 수 있어, 3D

131
00:05:29,853 --> 00:05:32,020
공간에서 포인트가 어디에 있는지뿐만

132
00:05:32,020 --> 00:05:35,960
아니라 어떤 방향을 향하고 있는지도 알 수 있습니다.

133
00:05:35,960 --> 00:05:38,740
그래서 표면 법선이 있어 조금 더 많은

134
00:05:38,740 --> 00:05:40,240
정보를 제공합니다.

135
00:05:40,240 --> 00:05:42,180
때때로 사람들은 이를

136
00:05:42,180 --> 00:05:46,020
서펠(surfels)이라고 부르며, 방향을 가진 포인트입니다.

137
00:05:46,020 --> 00:05:48,322
그래서 표면 법선이 왜 필요할까요?

138
00:05:48,322 --> 00:05:49,780
객체가 어떻게

139
00:05:49,780 --> 00:05:52,430
보이는지 렌더링하려면 조명

140
00:05:52,430 --> 00:05:55,310
소스를 지정해야 하기 때문입니다.

141
00:05:55,310 --> 00:05:57,350
조명이 어디에서 오는지?

142
00:05:57,350 --> 00:05:59,430
하지만 렌더링을 현실적으로 보이게

143
00:05:59,430 --> 00:06:01,630
하려면 특정 방향에서 오는

144
00:06:01,630 --> 00:06:03,350
조명이 포인트와 어떻게

145
00:06:03,350 --> 00:06:05,090
상호작용할지를 고려해야 합니다.

146
00:06:05,090 --> 00:06:07,230
이것이 표면 법선이

147
00:06:07,230 --> 00:06:10,070
렌더링을 현실적으로 보이게 하는

148
00:06:10,070 --> 00:06:12,550
데 도움이 되는 부분입니다.

149
00:06:12,550 --> 00:06:14,590
그렇다면 포인트를 어떻게 얻을 수 있을까요?

150
00:06:14,590 --> 00:06:18,790
포인트 클라우드의 장점은 많은 3D 센서, 특히

151
00:06:18,790 --> 00:06:21,710
깊이 센서 및 일부 3D

152
00:06:21,710 --> 00:06:25,110
스캐너에서 얻는 원시 형식이라는 것입니다.

153
00:06:25,110 --> 00:06:27,970
요즘에는 아이폰을 사용할 수도 있다고 생각합니다.

154
00:06:27,970 --> 00:06:30,870
그들은 AR 키트 또는 이러한 종류의 소프트웨어를 가지고 있어

155
00:06:30,870 --> 00:06:32,230
3D 객체를 스캔할 수 있습니다.

156
00:06:32,230 --> 00:06:34,770
하지만 이러한 센서의 원시 출력은 여전히 3D

157
00:06:34,770 --> 00:06:36,050
포인트 클라우드입니다.

158
00:06:36,050 --> 00:06:37,550
물론 그 이후에는 처리하고

159
00:06:37,550 --> 00:06:40,103
융합하여 텍스처가 있는 객체처럼

160
00:06:40,103 --> 00:06:41,020
만들어야 합니다.

161
00:06:43,590 --> 00:06:45,570
그래서 그들은 종종 스캐너에서 발생합니다.

162
00:06:45,570 --> 00:06:47,185
그들은 잠재적으로 매우 시끄러울 수 있습니다.

163
00:06:47,185 --> 00:06:48,810
그리고 이런 것들이 있으며,

164
00:06:48,810 --> 00:06:52,130
이를 융합하고 병합하고 수리하고 싶습니다.

165
00:06:52,130 --> 00:06:54,650
이 부분에서는 이러한 서로 다른

166
00:06:54,650 --> 00:06:57,770
이미지가 어떻게 등록되어 공유 포인트 클라우드를

167
00:06:57,770 --> 00:07:00,810
제공할 수 있는지를 고려해야 합니다.

168
00:07:00,810 --> 00:07:04,490
그리고 그들은 매우 유연하여, 포인트를 여기저기로

169
00:07:04,490 --> 00:07:05,870
이동할 수 있습니다.

170
00:07:05,870 --> 00:07:07,850
그래서 기본적으로 모든 유형의 객체 기하학을

171
00:07:07,850 --> 00:07:09,110
표현하는 데 사용할 수 있습니다.

172
00:07:09,110 --> 00:07:11,770
토폴로지나 그런 것에 의해 제한되지 않습니다.

173
00:07:11,770 --> 00:07:14,290
대규모 데이터 세트에 유용합니다. 왜냐하면

174
00:07:14,290 --> 00:07:17,330
때때로 매우 다양한 객체 세트를 고려해야 하기 때문입니다.

175
00:07:17,330 --> 00:07:20,370
하지만 포인트는 이미 어떤 의미에서는

176
00:07:20,370 --> 00:07:23,390
미리 샘플링된 것으로 간주됩니다.

177
00:07:23,390 --> 00:07:26,830
그래서 많은 점이 있을 때, 예를 들어 객체를 표현하고

178
00:07:26,830 --> 00:07:29,342
있지만 점들이 고르게 샘플링되지

179
00:07:29,342 --> 00:07:31,050
않아서 토끼의 머리에는 많은

180
00:07:31,050 --> 00:07:34,090
점이 있지만 토끼의 꼬리에는 매우 적은 점이

181
00:07:34,090 --> 00:07:35,690
있다면, 이러한 언더샘플링된

182
00:07:35,690 --> 00:07:37,650
영역에서 샘플을 추출하는

183
00:07:37,650 --> 00:07:39,470
것이 실제로 어려울 것입니다.

184
00:07:39,470 --> 00:07:41,950
그래서 때때로 사람들이 샘플링 포인트를

185
00:07:41,950 --> 00:07:43,490
고려할 때, 객체의 다양한

186
00:07:43,490 --> 00:07:45,770
부분에서 대략 고르게 샘플링할 수

187
00:07:45,770 --> 00:07:48,020
있도록 알고리즘을 설계해야 합니다.

188
00:07:48,020 --> 00:07:50,900
그리고 다른 제한 사항이 있거나, 때때로

189
00:07:50,900 --> 00:07:52,460
이러한 객체에서 유용한

190
00:07:52,460 --> 00:07:55,340
작업인 단순화나 세분화와 같은 작업을 직접

191
00:07:55,340 --> 00:07:57,460
수행하는 것이 명확하지 않습니다.

192
00:07:57,460 --> 00:08:00,500
이것은 부드러운 렌더링을 직접 허용하지 않습니다.

193
00:08:00,500 --> 00:08:02,620
위상 정보가 없습니다.

194
00:08:02,620 --> 00:08:06,620
예를 들어, 여기에서 점의 집합을 주면, 이것이

195
00:08:06,620 --> 00:08:11,540
토러스인지 아니면 링 모양인지조차 알 수 없습니다. 왜냐하면 이

196
00:08:11,540 --> 00:08:14,588
점들이 어떻게 연결되어 있는지를 알려주지

197
00:08:14,588 --> 00:08:15,880
않기 때문입니다.

198
00:08:15,880 --> 00:08:20,220
따라서 점 구름만 있으면 객체가 무엇인지에 대한 부분적인

199
00:08:20,220 --> 00:08:21,783
정보만 있습니다.

200
00:08:21,783 --> 00:08:23,200
그래서 자연스럽게 사람들은

201
00:08:23,200 --> 00:08:25,468
OK, 이 두 개의 다른 객체를 구별할 수 있도록

202
00:08:25,468 --> 00:08:27,260
더 많은 정보를 어떻게 캡처할 수

203
00:08:27,260 --> 00:08:28,540
있을까?라고 말할 것입니다.

204
00:08:28,540 --> 00:08:32,440
그런 다음 자연스럽게 다각형 메시로 넘어갑니다.

205
00:08:32,440 --> 00:08:36,080
그래서 객체를 여전히 점의 집합으로 표현하지만, 이 점들이

206
00:08:36,080 --> 00:08:38,507
어떻게 연결되어 있는지도 포함됩니다.

207
00:08:38,507 --> 00:08:40,840
이제 점뿐만 아니라

208
00:08:40,840 --> 00:08:43,179
면과 표면도 있습니다.

209
00:08:43,179 --> 00:08:45,930
그리고 이것은 아마도 모든 그래픽 엔진과

210
00:08:45,930 --> 00:08:48,310
컴퓨터 게임에서 3D 객체를 표현하는

211
00:08:48,310 --> 00:08:51,350
가장 널리 사용되는 표현이라고 할 수 있습니다.

212
00:08:51,350 --> 00:08:54,630
기본적으로 모든 것이 다각형 메시로 표현됩니다.

213
00:08:54,630 --> 00:08:57,010
하지만 면을 표현하기 위해서는

214
00:08:57,010 --> 00:09:00,990
더 복잡합니다. 왜냐하면 종종 원시 메시를 볼 때,

215
00:09:00,990 --> 00:09:03,040
각 면이 다른 수의

216
00:09:03,040 --> 00:09:05,290
점을 가질 수 있기 때문입니다.

217
00:09:05,290 --> 00:09:07,873
세 개의 점이 있을 수도 있고, 네 개의 점이나 다섯 개의 점이 있을 수도
있습니다.

218
00:09:07,873 --> 00:09:10,310
그리고 그들의 불규칙성을 고려할 때,

219
00:09:10,310 --> 00:09:12,645
특히 초기 단계에서 사람들이 합성곱

220
00:09:12,645 --> 00:09:15,270
신경망을 시작할 때 고정된 해상도를 항상 가정했기

221
00:09:15,270 --> 00:09:17,070
때문에, 어떻게 그것들을

222
00:09:17,070 --> 00:09:18,930
표현할 수 있는지가 문제입니다.

223
00:09:18,930 --> 00:09:20,650
하지만 여기에서는 이러한

224
00:09:20,650 --> 00:09:24,730
원시 정보의 가변 차원이 있다고 말할 수 있습니다.

225
00:09:24,730 --> 00:09:26,610
그것이 딥 러닝과 어떻게 통합될까요?

226
00:09:26,610 --> 00:09:27,770
그것은 큰 도전 과제가 되었습니다.

227
00:09:27,770 --> 00:09:30,410
그래서 3D 비전과 함께하는 딥 러닝은 다소

228
00:09:30,410 --> 00:09:33,270
늦게 시작되었습니다. 왜냐하면 사람들이 이러한

229
00:09:33,270 --> 00:09:36,870
복잡한 객체 표현을 처리하기 위해 모든 딥 러닝 방법을 어떻게

230
00:09:36,870 --> 00:09:40,070
조정할 수 있을지를 고민하고 있었기 때문입니다.

231
00:09:40,070 --> 00:09:42,270
이들은 이미지만큼 통일되지 않았습니다.

232
00:09:42,270 --> 00:09:44,140
하지만 메시들은 정말 널리 사용되며,

233
00:09:44,140 --> 00:09:45,880
모든 세부 사항을 캡처하는

234
00:09:45,880 --> 00:09:47,680
매우 복잡한 메시가 될 수 있습니다.

235
00:09:47,680 --> 00:09:49,215
예를 들어, 스캐너가 있습니다.

236
00:09:49,215 --> 00:09:50,840
점들을 얻고, 그런 다음 그것들을 융합합니다.

237
00:09:50,840 --> 00:09:52,260
그리고 알고리즘을 적용합니다.

238
00:09:52,260 --> 00:09:54,860
매우 큰 메시를 얻을 수 있습니다.

239
00:09:54,860 --> 00:09:58,320
이것은 조각을 표현하기 위해 5600만

240
00:09:58,320 --> 00:10:04,200
개의 삼각형과 2800만 개의 정점을 가지고 있습니다.

241
00:10:04,200 --> 00:10:06,480
그리고 구글 어스와 같은 더 큰 것도

242
00:10:06,480 --> 00:10:07,420
있을 수 있습니다.

243
00:10:07,420 --> 00:10:08,820
그들은 수조 개의 삼각형을 가지고 있습니다.

244
00:10:08,820 --> 00:10:13,138
지구상의 모든 건물을 기본적으로 표현하려고 합니다.

245
00:10:13,138 --> 00:10:15,680
메시의 좋은 점은 세분화와 같은 많은 작업을

246
00:10:15,680 --> 00:10:16,657
지원한다는 것입니다.

247
00:10:16,657 --> 00:10:18,240
또는 더 많은 세부 사항을

248
00:10:18,240 --> 00:10:22,837
원하고, 더 많은 메시를 사용하여 형태의 세부 사항을 캡처할 수 있는 방법은
무엇인가요?

249
00:10:22,837 --> 00:10:24,420
그리고 단순화도 할 수 있습니다.

250
00:10:24,420 --> 00:10:25,962
때때로, 매우 빠르게 처리하고 싶기

251
00:10:25,962 --> 00:10:28,140
때문에 그렇게 많은 메시가 필요하지 않습니다.

252
00:10:28,140 --> 00:10:30,640
저는 단순화하고 싶습니다. 그래서

253
00:10:30,640 --> 00:10:34,520
그렇게 할 수 있는 기존 알고리즘이 있습니다.

254
00:10:34,520 --> 00:10:37,520
그리고 정규화 - 불규칙한 메쉬를 얻으면,

255
00:10:37,520 --> 00:10:39,360
때때로 모든 면이 삼각형이

256
00:10:39,360 --> 00:10:42,140
되도록 정규화하고 싶습니다. 항상 세

257
00:10:42,140 --> 00:10:43,840
개의 정점을 연결합니다.

258
00:10:43,840 --> 00:10:47,300
그들은 대략 같은 크기를 가지고 있어 처리하기가

259
00:10:47,300 --> 00:10:48,360
더 쉽습니다.

260
00:10:48,360 --> 00:10:51,100
그리고 그들은 미래의 다양한 그래픽 알고리즘과

261
00:10:51,100 --> 00:10:54,660
메쉬 처리를 지원하는 더 명확하게 좋은 특성을

262
00:10:54,660 --> 00:10:55,580
가지고 있습니다.

263
00:10:55,580 --> 00:10:58,080
이 알고리즘을 개발한 사람들이

264
00:10:58,080 --> 00:11:01,600
있어서, 기본적으로 서로 다른 영역의 점들이

265
00:11:01,600 --> 00:11:04,100
대략 고르게 샘플링되도록 보장할 수

266
00:11:04,100 --> 00:11:05,220
있습니다. 예를

267
00:11:05,220 --> 00:11:07,740
들어, 토끼의 머리 부분이

268
00:11:07,740 --> 00:11:09,620
꼬리보다 훨씬 더 밀집하게

269
00:11:09,620 --> 00:11:12,060
샘플링되는 경우는 없도록 합니다.

270
00:11:12,060 --> 00:11:14,927
좋습니다, 이것은 한 종류의 형태 표현입니다.

271
00:11:14,927 --> 00:11:16,760
그리고 파라메트릭 표현과

272
00:11:16,760 --> 00:11:20,740
같은 다른 종류의 표현이 있습니다. 왜냐하면 객체는 완전히

273
00:11:20,740 --> 00:11:22,308
불규칙하지 않기 때문입니다.

274
00:11:22,308 --> 00:11:24,100
그것은 단순히 점들의 집합이 아닙니다.

275
00:11:24,100 --> 00:11:26,000
메쉬에서는 매우 일반적입니다.

276
00:11:26,000 --> 00:11:27,920
하지만 때때로 많은 정보를 잃게 됩니다.

277
00:11:27,920 --> 00:11:30,460
예를 들어, 의자나 테이블을 보면,

278
00:11:30,460 --> 00:11:31,877
모든 직선이 있습니다.

279
00:11:31,877 --> 00:11:34,127
그렇다면 이러한 직선을 어떻게 표현할 수 있을까요?

280
00:11:34,127 --> 00:11:35,940
사람들이 그것들을 디자인할 때,

281
00:11:35,940 --> 00:11:38,700
종종 이러한 파라메트릭 표현을 사용합니다.

282
00:11:38,700 --> 00:11:41,390
그래서 형태를 함수로 표현할 수 있습니다.

283
00:11:41,390 --> 00:11:42,510
생각해 보세요.

284
00:11:42,510 --> 00:11:45,870
제가 그것들을 디자인할 때, 표면을

285
00:11:45,870 --> 00:11:48,690
표현하거나 곡선을 표현하고 싶다면,

286
00:11:48,690 --> 00:11:51,670
기본적인 자유도는 실제로 더 낮습니다.

287
00:11:51,670 --> 00:11:53,870
종종 곡선이 있다면, 기본적인

288
00:11:53,870 --> 00:11:55,683
자유도가 하나뿐입니다.

289
00:11:55,683 --> 00:11:57,350
그래서 저는 곡선을

290
00:11:57,350 --> 00:12:01,350
함수 f(x)로 표현할 수 있습니다. 저는 x를 변화시켜 y 값을 얻습니다.

291
00:12:01,350 --> 00:12:03,750
기본적으로 2D에서 이러한

292
00:12:03,750 --> 00:12:08,790
다양한 유형의 함수를 사용할 수 있지만, 더 자주 3D에서 특정

293
00:12:08,790 --> 00:12:11,390
수의 변수를 매핑하여 객체의

294
00:12:11,390 --> 00:12:13,890
기본 내재 차원, 즉 종종 2

295
00:12:13,890 --> 00:12:17,370
또는 1로 매핑하고 3D 공간으로 매핑합니다.

296
00:12:17,370 --> 00:12:19,990
그리고 이것은 기본적으로 함수 집합을 사용하여

297
00:12:19,990 --> 00:12:22,830
파라메트릭 표현을 통해 3D 객체를 표현할 수

298
00:12:22,830 --> 00:12:23,790
있게 해줍니다.

299
00:12:23,790 --> 00:12:26,970
예를 들어, 원에서 곡선에 대해 그렇게 할 수 있습니다.

300
00:12:26,970 --> 00:12:28,990
기본적으로 원을 표현하려면, 실제로

301
00:12:28,990 --> 00:12:30,950
필요하지 않습니다. 한 가지

302
00:12:30,950 --> 00:12:33,190
방법은 여러 점을 샘플링하는 것입니다.

303
00:12:33,190 --> 00:12:35,850
또는 메쉬처럼 연결할 수도 있습니다.

304
00:12:35,850 --> 00:12:37,230
선을 사용하고 있습니다.

305
00:12:37,230 --> 00:12:40,120
또 다른 방법은 원의 곡선을 이 함수로

306
00:12:40,120 --> 00:12:41,782
표현하는 것입니다.

307
00:12:41,782 --> 00:12:43,240
기본적으로 사인

308
00:12:43,240 --> 00:12:48,500
함수와 코사인 함수가 있으며, 하나의 변수 t를 변화시킵니다.

309
00:12:48,500 --> 00:12:50,700
이것을 각도나 각도로 생각할 수

310
00:12:50,700 --> 00:12:52,940
있으며, 모든 원의 점으로 매핑됩니다.

311
00:12:52,940 --> 00:12:56,560
그래서 이제 2D에서 곡선에 대한 파라메트릭 표현을

312
00:12:56,560 --> 00:12:59,100
위해 함수를 사용할 수 있습니다.

313
00:12:59,100 --> 00:13:01,580
물론 3D에서도 그렇게 할 수 있습니다.

314
00:13:01,580 --> 00:13:03,440
구를 표현하려면,

315
00:13:03,440 --> 00:13:07,382
필요한 것은 두 개의 자유도 u와 v뿐입니다.

316
00:13:07,382 --> 00:13:09,840
그런 다음 이러한 함수를

317
00:13:09,840 --> 00:13:14,200
통해 3D 공간의 모든 점에 매핑할 수 있습니다.

318
00:13:14,200 --> 00:13:15,480
사람들은 더 복잡한

319
00:13:15,480 --> 00:13:16,900
매개변수 표현을

320
00:13:16,900 --> 00:13:18,960
설계했습니다. 여기서 자세히 설명하지는

321
00:13:18,960 --> 00:13:21,280
않겠지만, 베지에 곡선과 베지에

322
00:13:21,280 --> 00:13:25,760
표면과 같은 것들이 있습니다. 이는 기본적으로 몇 개의 제어점을

323
00:13:25,760 --> 00:13:30,680
사용하여 3D에서 유연하고 매끄러운 표면을 표현할 수 있게 해줍니다.

324
00:13:30,680 --> 00:13:33,120
기본적으로 이러한 베지에 함수를

325
00:13:33,120 --> 00:13:35,520
사용하여 이러한 표면의

326
00:13:35,520 --> 00:13:37,370
기본적인 저차원성을 포착하고,

327
00:13:37,370 --> 00:13:39,370
그 다음에 이러한

328
00:13:39,370 --> 00:13:43,370
유연한 형태로 기본 저차원성을 매핑할 수 있습니다.

329
00:13:43,370 --> 00:13:46,130
또한 세분화와 같은 작업을 수행할 수

330
00:13:46,130 --> 00:13:49,570
있게 해주므로, 표면에 더 많은 세부 정보를 추가하고

331
00:13:49,570 --> 00:13:51,823
더 정밀하게 만들 수 있습니다.

332
00:13:51,823 --> 00:13:53,490
그래서 이것이 형태 표현의 두 번째

333
00:13:53,490 --> 00:13:54,550
범주가 될 것입니다.

334
00:13:54,550 --> 00:13:57,630
3D 객체를 비매개변수 방식으로 표현할 수 있습니다. 예를

335
00:13:57,630 --> 00:14:00,530
들어, 무작위 점들의 모음이나 그 연결을 메쉬로 표현할

336
00:14:00,530 --> 00:14:01,230
수 있습니다.

337
00:14:01,230 --> 00:14:04,050
또는 기본적으로 함수가 있는 매개변수 방식으로

338
00:14:04,050 --> 00:14:05,390
표현할 수 있습니다.

339
00:14:05,390 --> 00:14:08,650
객체 기하학의 진정한 자유도를 기반으로

340
00:14:08,650 --> 00:14:11,290
하는 몇 가지 매개변수를

341
00:14:11,290 --> 00:14:15,970
변경함으로써, 더 복잡한 형태로 매핑할 수 있습니다.

342
00:14:15,970 --> 00:14:18,905
기본적으로 여기서 모든 것은 제가 말했듯이,

343
00:14:18,905 --> 00:14:20,530
처음에 객체 기하학을

344
00:14:20,530 --> 00:14:21,810
표현하는 두 가지 방법이

345
00:14:21,810 --> 00:14:23,030
있다고 했습니다.

346
00:14:23,030 --> 00:14:24,390
하나는 명시적입니다.

347
00:14:24,390 --> 00:14:25,590
더 많은 것은 암시적입니다.

348
00:14:25,590 --> 00:14:27,570
모두 이 명시적

349
00:14:27,570 --> 00:14:29,070
범주에 속합니다.

350
00:14:29,070 --> 00:14:30,790
그래서 저는 점들이 있습니다.

351
00:14:30,790 --> 00:14:33,550
점들은 객체 위의 직접적인 점입니다.

352
00:14:33,550 --> 00:14:36,510
표면이나 매개변수 곡선의

353
00:14:36,510 --> 00:14:41,670
경우에도, 그것들은 객체 위의 점으로 직접 매핑됩니다.

354
00:14:41,670 --> 00:14:43,650
그래서 명시적 표현이 있습니다.

355
00:14:43,650 --> 00:14:45,830
그들은 많은 이점이 있습니다.

356
00:14:45,830 --> 00:14:49,950
첫째, 모든 점을 직접 매핑하므로, 이 모든

357
00:14:49,950 --> 00:14:51,990
점을 얻을 수 있습니다.

358
00:14:51,990 --> 00:14:55,970
일반적으로, 제가 예를 들어 샘플에서 가진 모든 점은

359
00:14:55,970 --> 00:14:58,810
베지에 표면 표현을 가지고 있습니다.

360
00:14:58,810 --> 00:15:02,230
기본적으로 이 저차원 공간에서 두 점과 UV를 샘플링한

361
00:15:02,230 --> 00:15:04,990
다음, 그 함수로 들어가서 3D 공간의

362
00:15:04,990 --> 00:15:06,850
점으로 매핑할 수 있습니다.

363
00:15:06,850 --> 00:15:10,968
그래서 저는 3D 공간에서 직접 점을 얻습니다.

364
00:15:10,968 --> 00:15:13,510
모든 점이 주어지므로, 어떤 의미에서는 직접적으로 말할 수 있습니다.

365
00:15:13,510 --> 00:15:15,430
저는 다른 점을 직접적으로 얻을 수 있습니다.

366
00:15:15,430 --> 00:15:17,810
그래서 점을 샘플링하는 것이 매우 쉽습니다.

367
00:15:17,810 --> 00:15:20,910
예를 들어, 제가 이 토러스가 있고, 이 f

368
00:15:20,910 --> 00:15:22,450
함수로 표현했습니다.

369
00:15:22,450 --> 00:15:24,830
그래서 이제 제 질문은, 객체의 표면에서 몇

370
00:15:24,830 --> 00:15:26,850
개의 점을 샘플링해 줄 수 있나요?

371
00:15:26,850 --> 00:15:29,230
이것은 매우 쉽습니다. 왜냐하면 저는 무작위로 몇 개의 u와 v

372
00:15:29,230 --> 00:15:30,530
값을 넣기만 하면 되기 때문입니다.

373
00:15:30,530 --> 00:15:33,320
저는 그 u와 v 값을 무작위로

374
00:15:33,320 --> 00:15:37,240
샘플링한 다음, 이 함수를 통과시켜서 객체의

375
00:15:37,240 --> 00:15:40,840
표면에 보장된 몇 개의 3D 점을 계산하고

376
00:15:40,840 --> 00:15:41,960
얻을 것입니다.

377
00:15:41,960 --> 00:15:44,640
그래서 샘플링이 훨씬 더 쉽습니다.

378
00:15:44,640 --> 00:15:48,440
그렇다면 이러한 명시적 표현의 어려운 점은 무엇인가요?

379
00:15:48,440 --> 00:15:51,880
어려운 점은 어떤 의미에서는 점이 객체 내부에

380
00:15:51,880 --> 00:15:56,400
있는지 외부에 있는지를 테스트하기가 매우 어렵다는 것입니다.

381
00:15:56,400 --> 00:15:59,560
유사하게, 제가 이 함수를 사용하여 구를

382
00:15:59,560 --> 00:16:03,480
표현하면, 구 위의 점을 샘플링하는 것은 쉽습니다.

383
00:16:03,480 --> 00:16:05,520
하지만 이제 다른 쿼리가 생겼을 때,

384
00:16:05,520 --> 00:16:07,360
그것을 말하는 것은 어렵습니다.

385
00:16:07,360 --> 00:16:10,520
나는 지금 이 시점에서 3분의 4, 2분의 1, 4분의 1이라고 말합니다.

386
00:16:10,520 --> 00:16:13,120
3D 공간의 이 지점에서,

387
00:16:13,120 --> 00:16:16,720
내부 객체인지 외부 객체인지입니다.

388
00:16:16,720 --> 00:16:18,440
어쩌면 우리는--

389
00:16:18,440 --> 00:16:21,360
사실, 그에 대해 확신이 없습니다.

390
00:16:21,360 --> 00:16:24,760
따라서 특정 점이 객체 내부인지 외부인지

391
00:16:24,760 --> 00:16:27,000
테스트하기가 실제로 어렵습니다.

392
00:16:27,000 --> 00:16:31,557
명시적 표현은-- 이러한 모든 표현은 각자의

393
00:16:31,557 --> 00:16:33,890
강점과 약점이

394
00:16:33,890 --> 00:16:34,655
있습니다.

395
00:16:34,655 --> 00:16:36,030
명시적 표현의 경우, 샘플링

396
00:16:36,030 --> 00:16:38,290
포인트를 얻는 것이 꽤 쉽습니다.

397
00:16:38,290 --> 00:16:39,450
이는 때때로 포인트

398
00:16:39,450 --> 00:16:41,590
모음으로 변환하고 싶기 때문에 유용합니다.

399
00:16:41,590 --> 00:16:43,310
그런 다음, 당신의 포인트에 대해

400
00:16:43,310 --> 00:16:44,490
신경망을 적용하고 싶습니다.

401
00:16:44,490 --> 00:16:47,410
하지만 특정 점이 객체 내부인지 외부인지 테스트하기가 어렵고,

402
00:16:47,410 --> 00:16:49,850
이는 몇 가지 문제를 일으킬 수 있습니다.

403
00:16:49,850 --> 00:16:52,533
예를 들어, 신경 렌더링 방법을 사용하고 싶다고

404
00:16:52,533 --> 00:16:54,950
가정해 보겠습니다. 현재 많은 신경 렌더링 방법이

405
00:16:54,950 --> 00:16:56,450
있으며, 객체 내부 또는

406
00:16:56,450 --> 00:16:59,070
외부에 점이 있는지에 대한 많은 쿼리가 필요합니다.

407
00:16:59,070 --> 00:17:01,330
특정 지점에서 객체의 기하학 또는

408
00:17:01,330 --> 00:17:02,430
밀도는 무엇일까요?

409
00:17:02,430 --> 00:17:03,390
재료는 무엇일까요?

410
00:17:03,390 --> 00:17:05,609
특정 지점에서 객체의 방사선 또는

411
00:17:05,609 --> 00:17:06,930
색상은 무엇일까요?

412
00:17:06,930 --> 00:17:11,170
본질적으로, 표현은 이러한 명시적 표현에서

413
00:17:11,170 --> 00:17:12,849
이러한 작업을

414
00:17:12,849 --> 00:17:15,740
수행하기가 쉽지 않습니다.

415
00:17:15,740 --> 00:17:17,490
따라서 자연스럽게 사람들은 기하학을

416
00:17:17,490 --> 00:17:19,157
표현하는 다른 방법을 생각할

417
00:17:19,157 --> 00:17:20,329
수 있다고 생각했습니다.

418
00:17:20,329 --> 00:17:23,030
여기서 나는 기하학을 위한 '암시적' 표현이라고 말합니다.

419
00:17:23,030 --> 00:17:25,694
하지만 나중에 보시다시피, 많은 신경 렌더링

420
00:17:25,694 --> 00:17:27,069
방법이나 딥 러닝

421
00:17:27,069 --> 00:17:29,569
방법에서, 이들은 기하학뿐만 아니라

422
00:17:29,569 --> 00:17:33,100
3D 객체의 색상과 외관을 위한 암시적 표현을 확장합니다.

423
00:17:33,100 --> 00:17:36,180
이 암시적 표현의 아이디어는 이제 이

424
00:17:36,180 --> 00:17:39,160
점들을 분류하고 싶다는 것입니다.

425
00:17:39,160 --> 00:17:42,540
따라서 점들이 객체 위에 있다면, 객체의

426
00:17:42,540 --> 00:17:44,080
표면에 있다면,

427
00:17:44,080 --> 00:17:46,740
특정 관계를 만족한다고 가정합니다.

428
00:17:46,740 --> 00:17:48,820
예를 들어, 구의 경우,

429
00:17:48,820 --> 00:17:51,980
단위 구 위의 점들은 무엇일까요?

430
00:17:51,980 --> 00:17:54,580
그들이 만족하는 제약 조건은 x의

431
00:17:54,580 --> 00:17:57,340
제곱과 y의 제곱, z의 제곱입니다.

432
00:17:57,340 --> 00:17:59,280
이들을 합치면 1이 됩니다.

433
00:17:59,280 --> 00:18:03,540
따라서 이것은 구 위의 모든 점들이 만족하는

434
00:18:03,540 --> 00:18:05,285
제약 조건입니다.

435
00:18:05,285 --> 00:18:06,660
좋습니다, 좀 더

436
00:18:06,660 --> 00:18:09,740
일반적으로, 제약 조건은 x와 y와 z의 어떤

437
00:18:09,740 --> 00:18:12,310
함수가 0과 같다고 쓸 수 있습니다.

438
00:18:12,310 --> 00:18:14,060
이 경우, f, x, y의

439
00:18:14,060 --> 00:18:17,680
함수는 x 제곱 더하기 y 제곱 더하기 z 제곱 빼기 1입니다.

440
00:18:17,680 --> 00:18:19,160
그래서 여기서의 함수는 그것입니다.

441
00:18:19,160 --> 00:18:20,910
하지만 더 일반적으로, 복잡한

442
00:18:20,910 --> 00:18:23,652
형태에 대해서도 생각할 수 있습니다. 때때로

443
00:18:23,652 --> 00:18:25,860
이러한 함수는 너무 복잡해서 닫힌

444
00:18:25,860 --> 00:18:27,320
형태가 없을 수 있습니다.

445
00:18:27,320 --> 00:18:28,700
그렇다면 f를 어떻게 표현할 수 있을까요?

446
00:18:28,700 --> 00:18:30,860
나는 그것을 신경망으로 작성합니다.

447
00:18:30,860 --> 00:18:33,680
내 희망은 신경망이 그것을 표현할 수 있을 것이라는 것입니다.

448
00:18:33,680 --> 00:18:35,600
하지만 일반적으로, 아이디어는

449
00:18:35,600 --> 00:18:38,480
특정 객체 위의 점들이 만족할 어떤

450
00:18:38,480 --> 00:18:41,360
함수나 제약 조건이 있다는 것입니다.

451
00:18:41,360 --> 00:18:43,460
그리고 이것이 객체를 표현하는 방법입니다.

452
00:18:43,460 --> 00:18:45,380
이것은 기하학에서 시작된

453
00:18:45,380 --> 00:18:47,100
암시적 표현이라고 불립니다.

454
00:18:47,100 --> 00:18:49,480
하지만 제가 말했듯이, 이제 여러분은 질감,

455
00:18:49,480 --> 00:18:51,920
재료, 외관 등을 나타내는 다양한 방법을

456
00:18:51,920 --> 00:18:52,817
사용하고 있습니다.

457
00:18:52,817 --> 00:18:55,400
암시적 표현의 좋은 점은-- 죄송합니다, 나쁜 점부터

458
00:18:55,400 --> 00:18:56,380
시작하겠습니다.

459
00:18:56,380 --> 00:18:58,172
암시적 표현의 나쁜 점은 이제 실제로

460
00:18:58,172 --> 00:19:00,380
점을 샘플링하는 것이 훨씬 더 어렵다는 것입니다.

461
00:19:00,380 --> 00:19:02,540
제가 말하죠, OK, 이것은 제약 조건입니다, 이

462
00:19:02,540 --> 00:19:04,160
토러스가 만족해야 한다고 가정해봅시다.

463
00:19:04,160 --> 00:19:09,160
맞아요, OK, 모든 x, y, z에 대해 이 함수를 넣었을 때 출력이

464
00:19:09,160 --> 00:19:11,440
0이면, 네, 그들은 이

465
00:19:11,440 --> 00:19:13,460
객체의 표면에 있어야 합니다.

466
00:19:13,460 --> 00:19:17,398
하지만 그러면 이 x, y, z 튜플을 몇 개 얻을 수 있을까요?

467
00:19:17,398 --> 00:19:19,440
그것은 이 함수를 해결해야 하기 때문에

468
00:19:19,440 --> 00:19:20,540
매우 어려울 것입니다.

469
00:19:20,540 --> 00:19:22,720
그리고 이 함수는 아마도 해결하기 그렇게 어렵지 않을 것입니다.

470
00:19:22,720 --> 00:19:25,330
어쩌면 여러분은 고등학교 수학을 사용하여 여전히 해결할 수 있습니다.

471
00:19:25,330 --> 00:19:29,650
하지만 함수가 임의의 형태에 대해 정말 복잡해지면, 이러한 함수들을

472
00:19:29,650 --> 00:19:32,310
해결하는 것이 훨씬 더 어려워집니다.

473
00:19:32,310 --> 00:19:34,850
따라서 객체를 암시적으로 표현할

474
00:19:34,850 --> 00:19:38,010
경우 객체의 표면에서 점을 샘플링하는 것이

475
00:19:38,010 --> 00:19:39,330
쉽지 않습니다.

476
00:19:39,330 --> 00:19:40,715
하지만 그 이점, 강점은

477
00:19:40,715 --> 00:19:42,090
이제 점이 객체

478
00:19:42,090 --> 00:19:44,170
내부인지 외부인지 테스트하는 것이 꽤

479
00:19:44,170 --> 00:19:45,290
쉽다는 것입니다.

480
00:19:45,290 --> 00:19:48,610
테스트를 하고 싶다면, 쿼리만 있으면 되므로, 내부인지

481
00:19:48,610 --> 00:19:50,910
외부인지 확인하는 것이 매우 쉽습니다.

482
00:19:50,910 --> 00:19:52,550
그냥 그 함수를 통해 보냅니다.

483
00:19:52,550 --> 00:19:55,510
값을 얻을 것이고, 그 값은 -1/8입니다.

484
00:19:55,510 --> 00:19:56,810
0보다 작습니다.

485
00:19:56,810 --> 00:20:02,170
그래서 저는 객체가 이 함수로 표현된다고 가정합니다.

486
00:20:02,170 --> 00:20:03,930
그리고 객체의 모든 표면 점은

487
00:20:03,930 --> 00:20:05,870
그 함수가 0과 같아야 합니다.

488
00:20:05,870 --> 00:20:07,870
무엇이든, [? 모르겠습니다, ?] 저는 0보다 낮은 것은 음수라고

489
00:20:07,870 --> 00:20:08,950
말할 것입니다.

490
00:20:08,950 --> 00:20:11,490
출력 값이 음수이면, 그 점은 객체

491
00:20:11,490 --> 00:20:12,910
내부에 있어야 합니다.

492
00:20:12,910 --> 00:20:14,710
출력 값이 양수이면, 그

493
00:20:14,710 --> 00:20:17,490
점은 객체 외부에 있어야 합니다.

494
00:20:17,490 --> 00:20:20,730
그래서 이제 특정 점이 객체 내부인지 외부인지 테스트하는

495
00:20:20,730 --> 00:20:22,850
것이 훨씬 쉬워지지만, 객체의

496
00:20:22,850 --> 00:20:24,740
표면에서 여러 점을 샘플링하는

497
00:20:24,740 --> 00:20:26,460
것은 훨씬 더 어려워집니다.

498
00:20:26,460 --> 00:20:28,700
그래서 이제 암시적 표현과 명시적 표현

499
00:20:28,700 --> 00:20:31,500
사이에 명확한 트레이드오프가 있음을 알 수 있습니다.

500
00:20:31,500 --> 00:20:33,500
여기서 다시 우리는 기하학에 대해 이야기합니다.

501
00:20:33,500 --> 00:20:36,020
하지만 명시적 표현과 암시적 표현

502
00:20:36,020 --> 00:20:38,620
간의 이 구분과 대조는 매우 중요하고

503
00:20:38,620 --> 00:20:40,120
근본적이라고 생각합니다.

504
00:20:40,120 --> 00:20:44,060
이는 나중에 볼 것처럼 3D 데이터에 적용될

505
00:20:44,060 --> 00:20:48,060
때 심층 신경망의 발전 뒤에 있습니다.

506
00:20:48,060 --> 00:20:50,800
그래서 우리가-- 잠시만요, [? 보세요, 저는 ?] 25분이 지났습니다.

507
00:20:50,800 --> 00:20:52,758
그래서 제가 5분 이상 사용하지 않겠다고 약속했으니,

508
00:20:52,758 --> 00:20:54,592
이제 심층 학습에 대해 이야기하겠습니다.

509
00:20:54,592 --> 00:20:57,380
그래서 딥러닝이 일반적으로 3D 표현에

510
00:20:57,380 --> 00:21:00,420
어떻게 적용될 수 있는지 이야기하기 전에, 암묵적

511
00:21:00,420 --> 00:21:02,140
표현에 대한 몇 가지

512
00:21:02,140 --> 00:21:04,480
추가 사항은-- 암묵적 표현의 다른

513
00:21:04,480 --> 00:21:08,183
특징들, 그들의 장점은 쉽게 조합할 수 있다는 것입니다.

514
00:21:08,183 --> 00:21:10,100
그래서 가끔은 모든 것을 함수로

515
00:21:10,100 --> 00:21:14,060
표현하면 좋겠다고 느끼지만, 닫힌 형태가 있다면 좋지만,

516
00:21:14,060 --> 00:21:15,980
모든 닫힌 형태는 내가 쓸

517
00:21:15,980 --> 00:21:18,800
수 있기 때문에 매우 제한적일 것 같습니다.

518
00:21:18,800 --> 00:21:21,400
기하학은 매우 규칙적으로 보입니다.

519
00:21:21,400 --> 00:21:24,285
그래서 소의 형태를 표현하고 싶다면, 어떻게

520
00:21:24,285 --> 00:21:25,410
표현할 수 있을까요?

521
00:21:25,410 --> 00:21:27,370
소의 형태를 위해 쓸 수 있는 함수는 무엇일까요?

522
00:21:27,370 --> 00:21:28,430
그건 명확하지 않습니다.

523
00:21:28,430 --> 00:21:30,430
하지만 암묵적 표현의 좋은 점은 모든 것을 한

524
00:21:30,430 --> 00:21:32,513
번에 쓸 필요가 없다는 것입니다. 왜냐하면 그것들을

525
00:21:32,513 --> 00:21:34,190
조합하는 것이 매우 쉽기 때문입니다.

526
00:21:34,190 --> 00:21:36,310
실제로 이러한 암묵적 함수에 대해 논리 연산을

527
00:21:36,310 --> 00:21:37,490
수행할 수 있습니다.

528
00:21:37,490 --> 00:21:39,190
두 개의 객체가 있다고

529
00:21:39,190 --> 00:21:42,070
가정하고, 합집합, 교집합 또는 차집합을 찾습니다.

530
00:21:42,070 --> 00:21:43,670
다시 말해, 그들은 단순히 값입니다.

531
00:21:43,670 --> 00:21:45,583
x, y, z를 이 함수에 넣습니다.

532
00:21:45,583 --> 00:21:46,250
값을 얻습니다.

533
00:21:46,250 --> 00:21:47,570
x, y, z를 저 함수에 넣습니다.

534
00:21:47,570 --> 00:21:48,290
값을 얻습니다.

535
00:21:48,290 --> 00:21:50,645
이 값들 위에서 산술 연산을 수행할 수

536
00:21:50,645 --> 00:21:52,270
있으며, 이는 이러한 객체

537
00:21:52,270 --> 00:21:54,645
간의 합집합이나 교집합 또는 차집합을

538
00:21:54,645 --> 00:21:56,110
계산할 수 있게 해줍니다.

539
00:21:56,110 --> 00:21:59,110
결국, 이를 조합하여 꽤 복잡한 형태를

540
00:21:59,110 --> 00:22:00,670
나눌 수 있습니다.

541
00:22:00,670 --> 00:22:04,055
이것은 사람들이 복잡한 부품을 설계할

542
00:22:04,055 --> 00:22:05,430
때 많은 산업

543
00:22:05,430 --> 00:22:10,788
디자인을 지원하는 실제 배경입니다. 제가 말하자면, 잘 모르겠어요.

544
00:22:10,788 --> 00:22:11,330
디자인을 지원하는 실제 배경입니다. 제가 말하자면, 잘 모르겠어요.

545
00:22:11,330 --> 00:22:14,550
제조를 할 때 복잡한 형태를

546
00:22:14,550 --> 00:22:17,077
제작해야 합니다.

547
00:22:17,077 --> 00:22:18,910
이러한 디자인의 많은 부분은 CAD 모델, 즉

548
00:22:18,910 --> 00:22:20,210
컴퓨터 지원 설계로 이루어집니다.

549
00:22:20,210 --> 00:22:22,970
그들은 간단한 논리 연산을 사용하여

550
00:22:22,970 --> 00:22:25,650
이러한 암묵적 함수를 조합하고 있습니다.

551
00:22:25,650 --> 00:22:29,827
또한 단순한 논리를 넘어서는 작업도 할 수 있습니다.

552
00:22:29,827 --> 00:22:31,410
특히 거리 함수가 있는

553
00:22:31,410 --> 00:22:34,290
경우, 모든 점은 긍정적인 값과 부정적인

554
00:22:34,290 --> 00:22:36,995
값처럼, 값은 실제로 의미가 있습니다.

555
00:22:36,995 --> 00:22:38,370
왜냐하면 그것들이 객체의

556
00:22:38,370 --> 00:22:40,010
표면까지 얼마나 먼지를

557
00:22:40,010 --> 00:22:41,590
나타내기 때문입니다.

558
00:22:41,590 --> 00:22:43,650
그래서 이들을 더할 수도 있고,

559
00:22:43,650 --> 00:22:46,756
이는 형태를 부드럽게 혼합할 수 있게 해줍니다.

560
00:22:46,756 --> 00:22:49,590
여기서 거리 함수가 있고, 여기서 수직선을

561
00:22:49,590 --> 00:22:51,810
표현하고 싶다면, 알겠습니다,

562
00:22:51,810 --> 00:22:52,830
여기에 있습니다.

563
00:22:52,830 --> 00:22:55,710
그리고 마이너스 0인 것은 선의 왼쪽에 있습니다.

564
00:22:55,710 --> 00:22:58,258
양수인 것은 선의 오른쪽에 있습니다.

565
00:22:58,258 --> 00:23:00,050
그리고 다른 함수를 사용하여 또

566
00:23:00,050 --> 00:23:01,490
다른 선을 나타냅니다.

567
00:23:01,490 --> 00:23:03,130
그럼 더하면 어떻게 될까요?

568
00:23:03,130 --> 00:23:05,610
더하면 자연스럽게 이 두

569
00:23:05,610 --> 00:23:07,750
형태 간의 보간이 됩니다.

570
00:23:07,750 --> 00:23:10,370
이것은 1D에서 작업하는 예입니다.

571
00:23:10,370 --> 00:23:13,210
하지만 비슷하게 3D에서도 작업할 수 있다고 상상할 수

572
00:23:13,210 --> 00:23:15,610
있습니다. 알겠습니다, 이제 이러한 다양한 형태를

573
00:23:15,610 --> 00:23:16,770
혼합할 수 있습니다.

574
00:23:16,770 --> 00:23:19,620
이 거리 함수는 임의로 조합될 수 있으며, 실제로

575
00:23:19,620 --> 00:23:22,060
꽤 복잡한 세계를 만들 수 있게 해줍니다,

576
00:23:22,060 --> 00:23:22,560
이렇게.

577
00:23:22,560 --> 00:23:25,620
이것은 쉽지 않지만, 생각해볼 수 있습니다.

578
00:23:25,620 --> 00:23:28,300
복잡한 세계를 구성할 수

579
00:23:28,300 --> 00:23:31,220
있습니다. 단순히 -- 단순하지

580
00:23:31,220 --> 00:23:34,077
않지만, 이러한 다양한 함수를

581
00:23:34,077 --> 00:23:35,160
조합하여.

582
00:23:35,160 --> 00:23:37,118
하지만 정말 잘하면

583
00:23:37,118 --> 00:23:39,820
매우 표현력이 뛰어납니다.

584
00:23:39,820 --> 00:23:44,087
좋습니다, 우리는 매개변수 표현이 명시적일 수 있다고 말했습니다.

585
00:23:44,087 --> 00:23:46,420
3D 표면의 점을 직접

586
00:23:46,420 --> 00:23:47,120
제공합니다.

587
00:23:47,120 --> 00:23:48,620
또는 이러한 함수와 같은 매개변수

588
00:23:48,620 --> 00:23:49,540
표현을 가질 수 있습니다.

589
00:23:49,540 --> 00:23:50,660
하지만 그것들은 암묵적입니다.

590
00:23:50,660 --> 00:23:52,660
그래서 이제는 점이 객체 내부에 있는지

591
00:23:52,660 --> 00:23:55,240
외부에 있는지 확인하려고만 할 수 있습니다.

592
00:23:55,240 --> 00:23:56,657
그러나 그것들을 조합하여 더

593
00:23:56,657 --> 00:23:58,260
복잡한 형태를 만들 수도 있습니다.

594
00:23:58,260 --> 00:24:00,500
우리가 암묵적 표현과 비매개변수 표현을

595
00:24:00,500 --> 00:24:02,460
가질 수 있을까요? 그런 점

596
00:24:02,460 --> 00:24:05,207
스타일처럼, 하지만 쿼리 함수도 있습니까?

597
00:24:05,207 --> 00:24:07,540
실제로 그런 것들이 있을 때도 있습니다.

598
00:24:07,540 --> 00:24:10,080
결국 이는 레벨 세트 방법과 같은 방법으로 이어집니다.

599
00:24:10,080 --> 00:24:13,460
암묵적 표면은 매우 좋습니다. 왜냐하면 우리가 말했듯이, 쉽게

600
00:24:13,460 --> 00:24:14,800
병합할 수 있기 때문입니다.

601
00:24:14,800 --> 00:24:16,100
쉽게 분할할 수 있습니다.

602
00:24:16,100 --> 00:24:18,690
하지만 때때로, 복잡한 형태를 닫힌 형태로

603
00:24:18,690 --> 00:24:20,050
설명하기는 어렵습니다.

604
00:24:20,050 --> 00:24:21,245
당신은 소가 있습니다.

605
00:24:21,245 --> 00:24:22,370
어떻게 표현하시겠습니까?

606
00:24:22,370 --> 00:24:23,850
그것들을 조합할 수 있습니다.

607
00:24:23,850 --> 00:24:27,390
하지만 매번 특정 점이 소 안에 있는지 쿼리해야 한다면,

608
00:24:27,390 --> 00:24:30,030
수백 개의 함수를 가져야 합니다.

609
00:24:30,030 --> 00:24:32,550
그리고 모든 이러한 더하기 및 또는, 그리고/또는,

610
00:24:32,550 --> 00:24:33,970
더하기/빼기 연산을 수행합니다.

611
00:24:33,970 --> 00:24:35,230
그러면 시간이 오래 걸립니다.

612
00:24:35,230 --> 00:24:37,410
그렇다면 미리 쿼리하면 어떨까요?

613
00:24:37,410 --> 00:24:41,030
3D 공간이 있고, 100 x 100 x 100 그리드를

614
00:24:41,030 --> 00:24:43,110
샘플링한다고 가정해 보겠습니다.

615
00:24:43,110 --> 00:24:45,887
이제 백만 개의 점이 샘플링되었습니다.

616
00:24:45,887 --> 00:24:47,470
이 백만 개의 점에

617
00:24:47,470 --> 00:24:50,190
대해, 객체 내부에 있는지

618
00:24:50,190 --> 00:24:52,150
외부에 있는지, 복잡한

619
00:24:52,150 --> 00:24:55,883
형태의 표면까지의 거리를 미리 계산합니다.

620
00:24:55,883 --> 00:24:57,550
그래서 그것들을 미리 계산하고,

621
00:24:57,550 --> 00:25:00,090
모든 값을 행렬에 저장할 수 있습니다.

622
00:25:00,090 --> 00:25:00,890
이것은 2D입니다.

623
00:25:00,890 --> 00:25:04,070
하지만 이는 시각화를 위한 것입니다.

624
00:25:04,070 --> 00:25:05,890
실제로는 3D입니다.

625
00:25:05,890 --> 00:25:09,190
그래서 모든 미리 계산된 거리 함수 값을 저장하는

626
00:25:09,190 --> 00:25:10,950
3D 행렬이 있습니다.

627
00:25:10,950 --> 00:25:13,930
이제 어떤 의미에서는 여전히 암묵적 표현이 있습니다.

628
00:25:13,930 --> 00:25:16,260
하지만 미리 쿼리했기

629
00:25:16,260 --> 00:25:20,280
때문에 비매개변수 표현으로 바뀌었습니다.

630
00:25:20,280 --> 00:25:23,740
2D에서 이 행렬을 보기만 해도 경계가

631
00:25:23,740 --> 00:25:26,373
어디인지 찾을 수 있습니다.

632
00:25:26,373 --> 00:25:27,540
그래서 경계는 어디에 있나요?

633
00:25:27,540 --> 00:25:30,460
기본적으로 인접한 두 값이 있는 곳입니다.

634
00:25:30,460 --> 00:25:32,480
하나는 양수이고, 하나는 음수입니다.

635
00:25:32,480 --> 00:25:34,840
즉, 그 사이 어딘가에 있어야 합니다.

636
00:25:34,840 --> 00:25:37,340
여기가 핵심입니다.

637
00:25:37,340 --> 00:25:39,320
그들은 함수 f(x) =

638
00:25:39,320 --> 00:25:42,860
0을 만족하므로, 그 점은 표면 위에 있어야 합니다.

639
00:25:42,860 --> 00:25:46,280
그런 의미에서, 많은 이러한 점들을 함수들을

640
00:25:46,280 --> 00:25:48,640
사용하여 미리 쿼리함으로써

641
00:25:48,640 --> 00:25:50,560
매개변수 표현 또는

642
00:25:50,560 --> 00:25:54,760
암묵적 표현을 비매개변수 표현으로 전환하고 있습니다.

643
00:25:54,760 --> 00:25:57,480
이렇게 하면 실제로 더 명시적인 제어가

644
00:25:57,480 --> 00:26:00,447
가능해지며, 이제 이를 시각화할 수 있습니다.

645
00:26:00,447 --> 00:26:01,780
나는 이 행렬을 가지고 있습니다.

646
00:26:01,780 --> 00:26:03,900
그리고 나는 그들의 값을 기반으로 시각화할 수 있습니다.

647
00:26:03,900 --> 00:26:08,240
이것은 CT, MRI 및 모든 의료 데이터와 같은

648
00:26:08,240 --> 00:26:09,920
것들에서 많이 사용됩니다.

649
00:26:09,920 --> 00:26:12,052
관련된 것은 사람들이 이렇게 말할 수 있습니다. '좋아요,

650
00:26:12,052 --> 00:26:14,260
모든 거리 값에 신경 쓰지 않으면 어떻게 되나요?'

651
00:26:14,260 --> 00:26:17,203
나는 모든 이러한 점에서 무슨 일이 일어나고 있는지를 미리 쿼리할 수

652
00:26:17,203 --> 00:26:18,620
있지만, 그럼 모든 값을 계산합니다.

653
00:26:18,620 --> 00:26:20,560
나는 플러스 5, 마이너스 5라고 말합니다.

654
00:26:20,560 --> 00:26:23,900
하지만 내가 신경 쓰는 것은 이것이 객체 내부인지

655
00:26:23,900 --> 00:26:24,578
외부인지입니다.

656
00:26:24,578 --> 00:26:26,620
그래서 긍정적이면 하나로 취급합니다.

657
00:26:26,620 --> 00:26:29,120
부정적이면, 즉 객체 내부를 의미하므로, 0으로

658
00:26:29,120 --> 00:26:30,420
취급한다고 가정합시다.

659
00:26:30,420 --> 00:26:32,700
그래서 이들을 이진화하면, 최종

660
00:26:32,700 --> 00:26:34,900
표현이 주어지며, 이는 이해하기

661
00:26:34,900 --> 00:26:39,000
가장 쉬운 것으로 주장할 수 있는 복셀이라고 불립니다.

662
00:26:39,000 --> 00:26:42,900
그래서 암묵적 함수가 어디에 있는지를 미리 쿼리할 수 있고, 그런

663
00:26:42,900 --> 00:26:45,560
다음 모든 밀도 샘플링 그리드가 있습니다.

664
00:26:45,560 --> 00:26:47,980
하지만 이제 거리 함수를 저장하는 대신,

665
00:26:47,980 --> 00:26:49,940
표면에서 얼마나 멀리 떨어져 있는지를

666
00:26:49,940 --> 00:26:52,660
함수들을 통해 계산하여 플러스 5, 마이너스 5를

667
00:26:52,660 --> 00:26:54,160
주는 대신, 그냥 이진화합니다.

668
00:26:54,160 --> 00:26:57,580
당신은 특정 점이 객체 내부인지 외부인지에만

669
00:26:57,580 --> 00:26:59,060
신경 씁니다.

670
00:26:59,060 --> 00:27:00,880
그럼 당신은 복셀 표현을 가지게

671
00:27:00,880 --> 00:27:04,980
되며, 이는 다시 3D 행렬과 같고, 100 x 100 x 100일 수
있습니다.

672
00:27:04,980 --> 00:27:07,820
하지만 모든 점에 대해 이 함수를 통해

673
00:27:07,820 --> 00:27:10,320
객체 내부와 외부인지 쿼리해야 합니다.

674
00:27:10,320 --> 00:27:12,910
당신은 1 또는 0을 가지며, 이진화된 방식으로 객체를

675
00:27:12,910 --> 00:27:14,010
표현할 수 있습니다.

676
00:27:14,010 --> 00:27:16,510
그래서 이것은 내가 3D 객체에

677
00:27:16,510 --> 00:27:19,670
대해 이야기할 최종 표현을 제공합니다.

678
00:27:19,670 --> 00:27:23,028
그래서 나는 복셀을 복잡한 방식으로 소개했습니다.

679
00:27:23,028 --> 00:27:25,070
하지만 다른 관점에서 보면, 사람들은 이렇게 말할

680
00:27:25,070 --> 00:27:27,190
수 있습니다. '사실 이것은 이해하기 매우 쉽습니다.

681
00:27:27,190 --> 00:27:29,530
' 왜냐하면 어떤 의미에서 복셀은 픽셀과 많은 유사성을

682
00:27:29,530 --> 00:27:31,470
가지기 때문입니다. 픽셀은 2D 행렬입니다.

683
00:27:31,470 --> 00:27:34,630
그리고 이제 3D 행렬이 있으며, 복셀은

684
00:27:34,630 --> 00:27:37,002
기본적으로 3D 행렬입니다.

685
00:27:37,002 --> 00:27:39,630
그래서 그들이 우리가 형태를 표현할 수 있는

686
00:27:39,630 --> 00:27:41,630
다른 모든 방법과 연결되어 있다는

687
00:27:41,630 --> 00:27:43,150
것을 볼 수 있습니다.

688
00:27:43,150 --> 00:27:46,880
내가 이렇게 소개하는 방식은, 사실 딥러닝이 들어올 때--

689
00:27:46,880 --> 00:27:49,130
그래서 먼저, 딥러닝은 언제

690
00:27:49,130 --> 00:27:49,880
시작되었나요?

691
00:27:49,880 --> 00:27:51,215
2010년입니다.

692
00:27:51,215 --> 00:27:53,090
딥러닝은 오랫동안

693
00:27:53,090 --> 00:27:56,690
존재했지만, 현대 딥러닝은 2010년입니다.

694
00:27:56,690 --> 00:27:59,210
Geoff Hinton은 음성 인식에서 그렇게 시작했습니다.

695
00:27:59,210 --> 00:28:02,345
그리고 2012년에 AlexNet이 등장했는데, 이는 ImageNet에서
작성되었습니다.

696
00:28:02,345 --> 00:28:04,470
그래서 여러분은 이 모든 것을 배웠고, 모두 2D입니다.

697
00:28:04,470 --> 00:28:07,370
좋아요, 이제 사람들은 3D에서 하고 싶다면 어떻게 할까요?

698
00:28:07,370 --> 00:28:08,750
이것은 매우 자연스러운 생각입니다.

699
00:28:08,750 --> 00:28:11,360
그래서 저는 2D 합성곱 신경망에서 3D로

700
00:28:11,360 --> 00:28:14,067
가고 싶습니다. 2012년에는 변환기가 없습니다.

701
00:28:14,067 --> 00:28:16,400
그렇다면 3D 데이터에 2D 합성곱 신경망을 어떻게 적용할

702
00:28:16,400 --> 00:28:17,120
수 있을까요?

703
00:28:17,120 --> 00:28:19,640
모두가 다양한 3D 표현이 있다는

704
00:28:19,640 --> 00:28:21,280
것을 알고 있습니다.

705
00:28:21,280 --> 00:28:23,912
하지만 어떤 것부터 시작해야 할까요?

706
00:28:23,912 --> 00:28:26,390
사람들은 3D 데이터에서 딥러닝을

707
00:28:26,390 --> 00:28:28,922
시작한 사람들이 컴퓨터 비전 사람들이라고

708
00:28:28,922 --> 00:28:30,380
말할 것입니다.

709
00:28:30,380 --> 00:28:31,540
그들은 그래픽 사람들과는 다릅니다.

710
00:28:31,540 --> 00:28:33,540
그들은 '나는 픽셀로 작업해왔어'라고 말합니다.

711
00:28:33,540 --> 00:28:36,600
그리고 내가 할 수 있는 가장 쉬운 일은 그냥 스케일을 키우는 것입니다.

712
00:28:36,600 --> 00:28:38,260
2D 행렬 대신 3D

713
00:28:38,260 --> 00:28:40,300
행렬에서 작업하도록 만들면 됩니다.

714
00:28:40,300 --> 00:28:41,540
그래서 그것이 제가 할 수 있는 가장 간단한 일입니다.

715
00:28:41,540 --> 00:28:43,248
2D 합성곱 네트워크 대신

716
00:28:43,248 --> 00:28:45,280
볼륨 합성곱 신경망을 갖게 됩니다.

717
00:28:45,280 --> 00:28:47,240
그렇다면, 이러한 표현 중 어떤

718
00:28:47,240 --> 00:28:50,023
것이 볼륨 합성을 가능하게 하거나 지원합니까?

719
00:28:50,023 --> 00:28:51,940
결국 이 복셀 표현이 되었습니다.

720
00:28:51,940 --> 00:28:55,603
기본적으로 상상할 수 있는 가장 쉬운 것입니다.

721
00:28:55,603 --> 00:28:57,520
하지만 그래픽 사람들은 그렇게 생각하지 않습니다.

722
00:28:57,520 --> 00:28:58,900
왜냐하면 그래픽 사람들은 이 복셀이

723
00:28:58,900 --> 00:29:00,358
정말 나쁘다고 생각하기 때문입니다. 표현은 정말 나쁘다고 생각합니다.

724
00:29:00,358 --> 00:29:02,760
계산 속도가 매우 느리기 때문입니다.

725
00:29:02,760 --> 00:29:04,920
우리가 이야기한 것처럼, 우리는 이 [INAUDIBLE]

726
00:29:04,920 --> 00:29:05,900
샘플을 모두 가져와야 합니다.

727
00:29:05,900 --> 00:29:08,130
그곳에서 품질을 확인할 수 있습니다.

728
00:29:08,130 --> 00:29:10,378
메시나 포인트 클라우드와 비교했을 때 정말 나쁩니다.

729
00:29:10,378 --> 00:29:12,670
그래서 사람들은 왜 그걸로 시작하고 싶어하는지 궁금해합니다.

730
00:29:12,670 --> 00:29:14,920
하지만 사람들이 복셀로 3D 데이터에서

731
00:29:14,920 --> 00:29:17,356
딥러닝을 시작한 이유는 픽셀과

732
00:29:17,356 --> 00:29:20,550
복셀 사이의 유사성을 그리기 쉽기 때문입니다. 코드

733
00:29:20,550 --> 00:29:22,470
중 하나만 변경하면 됩니다.

734
00:29:22,470 --> 00:29:24,178
즉, 2D 합성 대신 이제 3D

735
00:29:24,178 --> 00:29:25,730
합성을 수행하는 것입니다.

736
00:29:25,730 --> 00:29:28,570
그래서 어떤 의미에서는 그렇게 시작됩니다.

737
00:29:28,570 --> 00:29:32,090
하지만 3D 데이터에 대한 딥러닝 방법에 대해 이야기하기 전에, 또 다른

738
00:29:32,090 --> 00:29:34,490
중요한 측면은 데이터입니다. 3D 데이터에 대해

739
00:29:34,490 --> 00:29:35,370
말씀드리겠습니다.

740
00:29:35,370 --> 00:29:38,030
방법 외에도 데이터 세트도 매우 중요합니다.

741
00:29:38,030 --> 00:29:41,270
ImageNet은 실제로 AlexNet과 같은 것들을 촉발했습니다.

742
00:29:41,270 --> 00:29:44,650
3D의 경우에도 많은 데이터를 수집해야 합니다.

743
00:29:44,650 --> 00:29:48,708
3D 이전, 딥러닝 이전에 사람들이 자주 사용하는 일반 데이터 세트는

744
00:29:48,708 --> 00:29:51,250
프린스턴 데이터 형태 벤치마크라고 불리는

745
00:29:51,250 --> 00:29:55,070
것으로, 1,800개의 모델과 180개의 카테고리가 있습니다.

746
00:29:55,070 --> 00:29:57,570
실제로 180개의 카테고리가 꽤 많다는

747
00:29:57,570 --> 00:29:58,910
것을 알 수 있습니다.

748
00:29:58,910 --> 00:30:01,770
하지만 모델은 1,800개뿐이어서 기본적으로 연도당

749
00:30:01,770 --> 00:30:04,130
10개의 모델에 불과합니다. 이는 매우 적습니다.

750
00:30:04,130 --> 00:30:06,522
하지만 그 당시에는 꽤 큰 것으로 여겨졌습니다.

751
00:30:06,522 --> 00:30:08,230
사람들은 이미 충분하다고 느꼈습니다.

752
00:30:08,230 --> 00:30:10,605
왜냐하면 그들로는 정말 잘 작동하는

753
00:30:10,605 --> 00:30:12,350
것을 만들 수 없었기 때문입니다.

754
00:30:12,350 --> 00:30:15,230
거기에는 기계 학습이 거의 없었습니다.

755
00:30:15,230 --> 00:30:20,430
2014년 이전에는 이러한 데이터 세트가 대체로 작았습니다.

756
00:30:20,430 --> 00:30:23,630
그들은 특정 수의 모델을 가질 수 있으며, 최대 10,000개,
9,000개,

757
00:30:23,630 --> 00:30:25,070
10,000개까지 가능합니다.

758
00:30:25,070 --> 00:30:27,810
하지만 그들은 또한 매우 다양한 클래스들로 나뉘어 있습니다.

759
00:30:27,810 --> 00:30:31,250
그래서 각 클래스마다 모델이 10개 이하 또는 100개

760
00:30:31,250 --> 00:30:32,790
이하라고 할 수 있습니다.

761
00:30:32,790 --> 00:30:36,130
그래서 그 이후에 사람들은 '좋아, 우리가 ImageNet이 있다면, 형태에

762
00:30:36,130 --> 00:30:38,870
대한 3D 데이터 세트도 가질 수 있을까?'라고 말하기 시작했습니다.

763
00:30:38,870 --> 00:30:42,010
그래서 이것은 몇 가지 동시 작업의 노력 뒤에 있습니다.

764
00:30:42,010 --> 00:30:43,510
하지만 정말로, 결국 그들은

765
00:30:43,510 --> 00:30:44,968
ShapeNet이라고 불리는

766
00:30:44,968 --> 00:30:46,670
것으로 통합되었고, 그 중 많은 부분이

767
00:30:46,670 --> 00:30:48,030
스탠포드에서 주도했습니다.

768
00:30:48,030 --> 00:30:52,070
레오 기바스와 실비오 사바레세가 있습니다.

769
00:30:52,070 --> 00:30:55,050
그래서 그들은 300만 개의 모델을 가진

770
00:30:55,050 --> 00:30:57,922
ShapeNet이라는 대규모 데이터 세트를 이끌었습니다.

771
00:30:57,922 --> 00:31:00,750
하지만 실제로는 ImageNet만으로도 이 큰 이미지가 있습니다.

772
00:31:00,750 --> 00:31:03,010
그리고 사람들이 자주 사용하는 더 작은 데이터 세트가 있습니다.

773
00:31:03,010 --> 00:31:05,427
ShapeNet의 경우, 기본적으로 55개

774
00:31:05,427 --> 00:31:09,440
카테고리에 50,000개의 모델이 있는 ShapeNet 코어 데이터

775
00:31:09,440 --> 00:31:10,600
세트가 있습니다.

776
00:31:10,600 --> 00:31:12,100
이제 각 카테고리마다 평균 1,000개의

777
00:31:12,100 --> 00:31:13,720
모델이 있다는 것을 알 수 있습니다.

778
00:31:13,720 --> 00:31:15,460
하지만 실제로는 균형이 맞지 않습니다.

779
00:31:15,460 --> 00:31:17,780
의자의 경우, 실제로는 훨씬 더 많습니다.

780
00:31:17,780 --> 00:31:19,240
그래서 사람들이 이제 드디어 의자에

781
00:31:19,240 --> 00:31:21,300
대한 수천 개의 모델을 갖게 되었다고 말하는 이유입니다.

782
00:31:21,300 --> 00:31:22,760
그것으로 딥 네트워크를 훈련할 수 있습니다.

783
00:31:22,760 --> 00:31:24,385
이전에는 10개의 모델만 있을 수 있었습니다.

784
00:31:24,385 --> 00:31:25,600
아무것도 할 수 없습니다.

785
00:31:25,600 --> 00:31:28,520
이것이 시작된 방식이며, 몇 년 동안 이러한 발전과

786
00:31:28,520 --> 00:31:31,520
모든 결과가 의자와 자동차에만 제시되었습니다.

787
00:31:31,520 --> 00:31:33,620
이는 ShapeNet에서 가장 큰

788
00:31:33,620 --> 00:31:36,115
카테고리이기 때문입니다. 사람들은 '좋아,

789
00:31:36,115 --> 00:31:37,740
그거 좋다'고 느낍니다.

790
00:31:37,740 --> 00:31:38,980
하지만 그건 충분하지 않습니다.

791
00:31:38,980 --> 00:31:41,960
그래서 우리는 더 큰 것으로 나아가야 합니다.

792
00:31:41,960 --> 00:31:45,140
지난 몇 년 동안, 이것은 시애틀의 앨런 연구소 AI2에서

793
00:31:45,140 --> 00:31:47,662
진행된 작업으로, 그들이 한 일은 Objaverse와

794
00:31:47,662 --> 00:31:50,120
Objaverse Extra Large라는

795
00:31:50,120 --> 00:31:52,880
훨씬 더 큰 데이터 세트를 수집한 것입니다. 이 데이터

796
00:31:52,880 --> 00:31:57,100
세트에는 약 100만 또는 1000만 개의 다양한 3D 자산 모델이
있습니다.

797
00:31:57,100 --> 00:32:00,240
그리고 그들은 훨씬 더 많은 카테고리를 가지고 있습니다.

798
00:32:00,240 --> 00:32:03,330
이 모델들은 평균적으로 질감이 있는 더

799
00:32:03,330 --> 00:32:05,730
높은 품질을 가지고 있습니다.

800
00:32:05,730 --> 00:32:07,190
이것들은 합성 데이터 세트입니다.

801
00:32:07,190 --> 00:32:09,648
하지만 3D 스캔에서 나온

802
00:32:09,648 --> 00:32:12,130
실제 데이터 세트도 있습니다.

803
00:32:12,130 --> 00:32:15,470
3D 스캐너를 사용하면 됩니다.

804
00:32:15,470 --> 00:32:17,630
2016년에는 사람들이 이 작업을 하고 있었습니다.

805
00:32:17,630 --> 00:32:19,750
이 데이터 세트는 레드우드 데이터

806
00:32:19,750 --> 00:32:21,270
세트라고 생각합니다.

807
00:32:21,270 --> 00:32:24,810
실제 물체의 스캔이 10,000개 있습니다.

808
00:32:24,810 --> 00:32:28,890
최근에는 사람들이 더 큰 데이터 세트를 구축하고 있으며,

809
00:32:28,890 --> 00:32:30,850
사람들을 독려하고 있습니다.

810
00:32:30,850 --> 00:32:35,250
이것은 메타와 옥스포드가 공동 주도하는 노력이라고 생각합니다.

811
00:32:35,250 --> 00:32:37,598
그들은 사람들이 그들을 위해 데이터를 수집하도록 장려합니다.

812
00:32:37,598 --> 00:32:39,390
그들은 또한 사람들에게 데이터를 수집하도록 보수를 지급합니다.

813
00:32:39,390 --> 00:32:41,630
사람들은 아이폰을 사용하여 물체를 촬영합니다.

814
00:32:41,630 --> 00:32:42,310
물체를 테이블에 놓습니다.

815
00:32:42,310 --> 00:32:43,060
아이폰을 사용합니다.

816
00:32:43,060 --> 00:32:44,890
물체 주위에서 360도

817
00:32:44,890 --> 00:32:47,370
비디오를 촬영하면 $1 정도를 받습니다.

818
00:32:47,370 --> 00:32:49,987
그들은 사람들이 그들을 위해 데이터를 수집하도록 장려합니다.

819
00:32:49,987 --> 00:32:51,070
이것은 첫 번째 버전입니다.

820
00:32:51,070 --> 00:32:53,050
그들은 물체의 비디오가 19,000개 있습니다.

821
00:32:53,050 --> 00:32:55,565
이것들은 실제 물체입니다. 실제 물체를 캡처하는 것은 훨씬

822
00:32:55,565 --> 00:32:56,190
더 어렵습니다.

823
00:32:56,190 --> 00:32:57,250
이전의 물체 버전과

824
00:32:57,250 --> 00:32:59,590
제가 이야기한 모든 것은 합성 물체였습니다.

825
00:32:59,590 --> 00:33:01,260
하지만 이것들은 실제 물체입니다.

826
00:33:01,260 --> 00:33:04,780
또한 3D 비전 알고리즘의 많은 개발 덕분에,

827
00:33:04,780 --> 00:33:07,220
이 360도 비디오를 사용하여

828
00:33:07,220 --> 00:33:09,680
3D 물체를 재구성할 수 있습니다.

829
00:33:09,680 --> 00:33:13,400
이제 물체의 비디오 또는 이미지와 그들의 3D 기하학 및

830
00:33:13,400 --> 00:33:15,510
텍스처의 쌍 데이터가 있습니다.

831
00:33:27,380 --> 00:33:28,480
이것은 첫 번째 버전입니다.

832
00:33:28,480 --> 00:33:31,020
그들은 더 최근의 버전인 V2 또는 아마도 V3를

833
00:33:31,020 --> 00:33:33,880
가지고 있다고 생각합니다. 이는 조금 더 큽니다.

834
00:33:33,880 --> 00:33:35,535
하지만 여전히 확장하기 어렵습니다.

835
00:33:35,535 --> 00:33:36,160
생각해 보세요.

836
00:33:36,160 --> 00:33:39,580
현재 90,000개의 비디오 또는 기본적으로 90,000개의

837
00:33:39,580 --> 00:33:40,360
물체가 있습니다.

838
00:33:40,360 --> 00:33:42,200
그들은 확장하고 있다고 생각하지만

839
00:33:42,200 --> 00:33:44,440
100,000개를 넘지 않는 것 같습니다.

840
00:33:44,440 --> 00:33:47,000
기본적으로 실제 물체에 대해 100,000개의

841
00:33:47,000 --> 00:33:48,900
모델이 있다고 생각할 수 있습니다.

842
00:33:48,900 --> 00:33:52,660
하지만 이미지의 데이터 세트 크기는 무엇인지 살펴보세요.

843
00:33:52,660 --> 00:33:54,880
그래서 그것은 [? 에서 ?] 5B 또는 그와 비슷한 숫자를 입력하세요.

844
00:33:54,880 --> 00:33:56,280
그건 약 50억 개의 이미지와 같습니다.

845
00:33:56,280 --> 00:33:59,240
구글과 오픈AI는 훨씬 더 큰 데이터 세트를 가지고 있을 것입니다.

846
00:33:59,240 --> 00:34:02,160
따라서 2D 이미지나 비디오에 비해 3D

847
00:34:02,160 --> 00:34:05,520
객체에 대한 데이터 포인트 수에는 여전히 큰

848
00:34:05,520 --> 00:34:06,860
차이가 있습니다.

849
00:34:06,860 --> 00:34:08,400
그래서 3D 비전을 어떻게

850
00:34:08,400 --> 00:34:10,500
발전시킬 수 있을지가 큰 도전이라고 생각합니다.

851
00:34:10,500 --> 00:34:12,360
사람들은 다양한 아이디어를 가지고 있습니다.

852
00:34:12,360 --> 00:34:15,060
하지만 여전히, 이것은 우리가 이전에 가졌던 것보다 훨씬 더 큽니다.

853
00:34:15,060 --> 00:34:15,962
적어도 당신은 할 수 있습니다.

854
00:34:15,962 --> 00:34:17,920
현재 이러한 데이터 세트에서

855
00:34:17,920 --> 00:34:22,108
어느 정도 딥러닝 모델을 훈련할 수 있을 가능성이 있습니다.

856
00:34:22,108 --> 00:34:24,400
그리고 빠르게, 사람들에 의해 부품에 대한 다른

857
00:34:24,400 --> 00:34:25,760
데이터 세트도 구축되고 있습니다.

858
00:34:25,760 --> 00:34:27,528
이것은 스탠포드에서 나온 것으로,

859
00:34:27,528 --> 00:34:29,320
객체 부품과 그에 대한

860
00:34:29,320 --> 00:34:31,760
대응 및 계층을 조금 주석 달려고 합니다.

861
00:34:35,320 --> 00:34:38,719
또한 PartNet이라는 데이터 세트가 있어, 부품과

862
00:34:38,719 --> 00:34:40,518
의미뿐만 아니라 어떻게

863
00:34:40,518 --> 00:34:42,060
움직일 수 있는지도 주석

864
00:34:42,060 --> 00:34:43,280
달고 싶어합니다.

865
00:34:43,280 --> 00:34:46,100
그래서 다양한 부품의 약간의 이동성 정보입니다.

866
00:34:46,100 --> 00:34:48,239
예를 들어, 노트북은 열고 닫을 수 있습니다.

867
00:34:48,239 --> 00:34:50,241
그리고 3D 장면에 대한 데이터 세트도 있으므로, 단순히

868
00:34:50,241 --> 00:34:51,699
객체와 부품만 있는 것이 아닙니다.

869
00:34:51,699 --> 00:34:53,600
방도 있습니다.

870
00:34:53,600 --> 00:34:57,200
스캔 데이터 세트와 같은 것들이 있었습니다.

871
00:34:57,200 --> 00:34:59,450
이들은 실제로 당신의 집 안이나 사무실

872
00:34:59,450 --> 00:35:01,990
안으로 들어가서 스캔하는 사람들입니다.

873
00:35:01,990 --> 00:35:04,630
그들은 들어와서 3D 스캐너를 가지고 있습니다.

874
00:35:04,630 --> 00:35:07,130
그들은 집을 스캔하고 주석을 달았습니다.

875
00:35:07,130 --> 00:35:11,850
그래서 여기서도 최근에는 지금 당신의 아이폰으로도

876
00:35:11,850 --> 00:35:14,090
그렇게 할 수 있습니다.

877
00:35:14,090 --> 00:35:17,150
하지만 여전히 이러한 종류의 데이터 세트는 훨씬 작습니다.

878
00:35:17,150 --> 00:35:20,945
여기 첫 번째 버전 스캐너는 1,500개입니다.

879
00:35:20,945 --> 00:35:23,070
그들은 두 번째 버전에서 대략 같은 크기로

880
00:35:23,070 --> 00:35:26,710
++가 있다고 생각합니다. 아마도 2,000 또는 3,000개의 방입니다.

881
00:35:26,710 --> 00:35:29,170
따라서 3D 데이터, 특히 3D

882
00:35:29,170 --> 00:35:32,250
장면에 대한 데이터 양은 3D 객체에

883
00:35:32,250 --> 00:35:34,703
대한 데이터 양보다 훨씬 작습니다.

884
00:35:34,703 --> 00:35:36,370
그래서 이러한 제약을

885
00:35:36,370 --> 00:35:38,453
넘어 어떻게 나아갈 수 있을지

886
00:35:38,453 --> 00:35:40,010
명확하지 않습니다.

887
00:35:40,010 --> 00:35:41,410
왜냐하면 스캔을 직접

888
00:35:41,410 --> 00:35:45,250
해야 한다면 항상 시간과 인원에 의해 제한되기 때문입니다.

889
00:35:45,250 --> 00:35:47,850
어쨌든 데이터 수집을

890
00:35:47,850 --> 00:35:52,010
시도하는 노력이 있습니다.

891
00:35:52,010 --> 00:35:56,220
마지막으로, 3D 비전에 딥러닝을 적용하고 싶다면,

892
00:35:56,220 --> 00:35:59,085
우리가 관심 있는 작업은 무엇인가요?

893
00:35:59,085 --> 00:36:00,460
생성 모델링이

894
00:36:00,460 --> 00:36:03,000
있습니다. 저스틴이 말한 것처럼.

895
00:36:03,000 --> 00:36:05,700
2D 이미지나 비디오를 생성할 수 있습니다.

896
00:36:05,700 --> 00:36:07,080
3D 형태를 생성할 수도 있습니다.

897
00:36:07,080 --> 00:36:08,240
3D 장면을 생성할 수 있습니다.

898
00:36:08,240 --> 00:36:09,980
조건을 설정할 수 있습니다.

899
00:36:09,980 --> 00:36:13,560
조건은 언어에 대한 조건, 이미지에 대한 조건이 될 수 있습니다.

900
00:36:13,560 --> 00:36:14,600
입력 이미지가 있습니다.

901
00:36:14,600 --> 00:36:16,940
3D 객체를 어떻게 재구성할 수 있을까요?

902
00:36:16,940 --> 00:36:19,000
형태 우선 사항을 배워야 합니다.

903
00:36:19,000 --> 00:36:21,320
형태 생성 및 완성을 해야 합니다.

904
00:36:21,320 --> 00:36:23,220
때때로 부분 객체가 있고,

905
00:36:23,220 --> 00:36:25,280
이를 수리하고 싶습니다.

906
00:36:25,280 --> 00:36:26,080
수리하고 싶습니다.

907
00:36:26,080 --> 00:36:28,580
따라서 기하학적 데이터 처리도 있습니다.

908
00:36:28,580 --> 00:36:31,425
판별 모델을 포함한 다른 작업들.

909
00:36:31,425 --> 00:36:32,800
예를 들어, 3D 형태가 있습니다.

910
00:36:32,800 --> 00:36:35,700
그것이 어떤 객체의 범주에 속하는지 어떻게 분류할

911
00:36:35,700 --> 00:36:36,480
수 있을까요?

912
00:36:36,480 --> 00:36:38,380
의자인가요, 테이블인가요?

913
00:36:38,380 --> 00:36:39,940
현재 많은 작업이 픽셀로

914
00:36:39,940 --> 00:36:41,820
렌더링하여 수행됩니다. 매우

915
00:36:41,820 --> 00:36:44,500
좋은 이미지 인식 모델이 있기 때문입니다,

916
00:36:44,500 --> 00:36:46,000
예를 들어 GPT와 같은.

917
00:36:46,000 --> 00:36:47,502
그래서 3D 객체를 가져옵니다.

918
00:36:47,502 --> 00:36:48,960
그것을 그림으로 렌더링할 수 있습니다.

919
00:36:48,960 --> 00:36:51,160
GPT에 그림을 업로드하면, 그들이 대신 해줄 수 있습니다.

920
00:36:51,160 --> 00:36:52,820
어떤 면에서는 이러한

921
00:36:52,820 --> 00:36:55,670
판별 문제를 해결하는 한 방법입니다.

922
00:36:55,670 --> 00:36:57,550
하지만 해결하기 쉽지 않은 더

923
00:36:57,550 --> 00:36:59,430
구체적인 것들도 있습니다.

924
00:36:59,430 --> 00:37:02,070
예를 들어, 다른 유형의 세포가 있습니다.

925
00:37:02,070 --> 00:37:03,570
그리고 3D 스캔이 있습니다.

926
00:37:03,570 --> 00:37:05,750
세포를 어떻게 분류할 수 있을까요?

927
00:37:05,750 --> 00:37:08,083
데이터가 많지 않은 이러한 전문 분야에서.

928
00:37:08,083 --> 00:37:11,950
이러한 판별 문제를 어떻게 해결할 수 있을까요?

929
00:37:11,950 --> 00:37:13,965
2D 및 3D 데이터의 공동 모델링은

930
00:37:13,965 --> 00:37:16,590
점점 더 중요해지고 있습니다. 두 데이터가 훨씬

931
00:37:16,590 --> 00:37:17,650
더 많기 때문입니다.

932
00:37:17,650 --> 00:37:19,188
우리는 많은 이미지와 비디오를 가지고 있습니다.

933
00:37:19,188 --> 00:37:21,730
그들에 대해 훈련된 매우 좋은 기초 모델이 있습니다.

934
00:37:21,730 --> 00:37:24,670
우리의 2D 기초 모델에서 우선 사항을 어떻게 활용할 수

935
00:37:24,670 --> 00:37:25,190
있을까요?

936
00:37:25,190 --> 00:37:26,607
이미지가 어떻게 보이는지,

937
00:37:26,607 --> 00:37:28,950
이미지를 어떻게 현실적으로 만드는지, 비디오를 어떻게

938
00:37:28,950 --> 00:37:29,730
현실적으로 만드는지.

939
00:37:29,730 --> 00:37:32,590
그 정보를 사용하여 3D 재구성이 더 현실적으로

940
00:37:32,590 --> 00:37:34,270
되도록 어떻게 도울 수 있을까요?

941
00:37:34,270 --> 00:37:36,490
2D 및 3D 데이터의 공동 모델링 -

942
00:37:36,490 --> 00:37:38,950
대규모 2D 데이터 세트와 매우 좋은 사전 훈련된

943
00:37:38,950 --> 00:37:40,450
모델이 많기 때문입니다.

944
00:37:40,450 --> 00:37:43,377
또한 3D 세계와 2D 세계를 연결하는 신경

945
00:37:43,377 --> 00:37:45,710
렌더링 또는 미분 렌더링 방법에서 많은

946
00:37:45,710 --> 00:37:46,927
발전이 있었습니다.

947
00:37:46,927 --> 00:37:48,010
3D 세계가 있기 때문입니다.

948
00:37:48,010 --> 00:37:48,760
당신은 3D 모델을 가지고 있습니다.

949
00:37:48,760 --> 00:37:49,970
당신은 그것들을 2D로 렌더링할 수 있습니다.

950
00:37:49,970 --> 00:37:52,500
렌더링 과정은 미분 가능하게 만들거나

951
00:37:52,500 --> 00:37:54,460
신경망으로 근사할 수 있습니다.

952
00:37:54,460 --> 00:37:56,680
그럼 이제 미분 가능한 신경망을

953
00:37:56,680 --> 00:37:58,763
통해 다양한 모달리티의 모든 데이터를

954
00:37:58,763 --> 00:38:02,920
연결할 수 있으며, 이를 통해 2D 데이터나 2D 기초 모델에서

955
00:38:02,920 --> 00:38:06,360
가진 선험적 지식을 3D 세계로 연결할 수 있습니다.

956
00:38:06,360 --> 00:38:09,113
네, 그리고 때때로 시각적 데이터를 넘어 텍스트 데이터를 포함한

957
00:38:09,113 --> 00:38:10,780
공동 다중 모달 작업을 하고 싶습니다.

958
00:38:10,780 --> 00:38:12,238
하지만 때때로 다른 데이터가 있습니다.

959
00:38:12,238 --> 00:38:14,660
로봇 공학에서는 종종 촉각 데이터를 가지고 있다고 가정해 봅시다.

960
00:38:14,660 --> 00:38:16,280
그렇다면 그것들을 어떻게 융합할까요?

961
00:38:16,280 --> 00:38:18,360
그리고 때때로 자율 주행을 위해 LiDAR

962
00:38:18,360 --> 00:38:20,380
데이터나 깊이 데이터를 가질 수 있습니다.

963
00:38:20,380 --> 00:38:22,760
그것들을 어떻게 융합할 수 있을까요?

964
00:38:22,760 --> 00:38:25,480
그래서 저는 3D 데이터에 딥러닝을 사용하여 이러한 다양한

965
00:38:25,480 --> 00:38:26,878
문제를 해결하고 싶습니다.

966
00:38:26,878 --> 00:38:29,170
우리는 표현에 대해 많은 시간을 이야기합니다.

967
00:38:29,170 --> 00:38:30,640
그럼 우리는 어떻게 시작할까요?

968
00:38:30,640 --> 00:38:33,898
제가 제안한 대로, 처음에 이를 수행하는 사람들은 픽셀

969
00:38:33,898 --> 00:38:35,940
작업을 하는 컴퓨터 비전 사람들입니다.

970
00:38:35,940 --> 00:38:36,900
그들은 이미지 작업을 합니다.

971
00:38:36,900 --> 00:38:39,420
그래서 자연스럽게 그들은 왜 복셀로 시작하지 않냐고 말합니다.

972
00:38:39,420 --> 00:38:42,858
하지만 그 이전에, 그들은 이렇게 말합니다. 좋아요, 이것은 오래된
아이디어입니다.

973
00:38:42,858 --> 00:38:45,400
그리고 이것은 사람들이 딥러닝을 3D 비전에 적용하려고

974
00:38:45,400 --> 00:38:46,900
시도한 첫 번째 아이디어입니다.

975
00:38:46,900 --> 00:38:48,643
그리고 이제 어떤 의미에서는 다시 돌아오고 있습니다.

976
00:38:48,643 --> 00:38:50,060
하지만 그들이 시도한 첫 번째 아이디어는,

977
00:38:50,060 --> 00:38:52,080
이제는 복셀에 대해 걱정하지 말자는 것입니다.

978
00:38:52,080 --> 00:38:53,700
그냥 3D 형태가 있다고 가정합시다.

979
00:38:53,700 --> 00:38:54,320
그것은 메시입니다.

980
00:38:54,320 --> 00:38:55,700
복셀이든, 무엇이든요.

981
00:38:55,700 --> 00:38:59,200
그리고 나는 당신이 물체를 인식하는 것을 배우기를 원합니다.

982
00:38:59,200 --> 00:39:00,280
여기서 물체는 무엇인가요?

983
00:39:00,280 --> 00:39:01,600
의자입니다.

984
00:39:01,600 --> 00:39:03,120
하지만 입력이 3D 데이터라면 어떻게 될까요?

985
00:39:03,120 --> 00:39:04,820
우리는 그것을 어떻게 처리할 수 있을까요?

986
00:39:04,820 --> 00:39:07,320
3D 딥러닝 방법이 있기 전에, 내가 아주 좋은

987
00:39:07,320 --> 00:39:10,140
이미지 모델이 있기 때문에 그냥 이미지를 렌더링하면

988
00:39:10,140 --> 00:39:10,790
어떨까요?

989
00:39:13,620 --> 00:39:14,960
나는 3D 물체를 가져옵니다.

990
00:39:14,960 --> 00:39:16,480
나는 카메라를 다른 위치에 두겠습니다.

991
00:39:16,480 --> 00:39:18,230
나는 다양한 시점에서 물체의 모든

992
00:39:18,230 --> 00:39:19,540
이미지를 렌더링할 수 있습니다.

993
00:39:19,540 --> 00:39:22,120
그럼 이제 이것은 2D 문제로 바뀝니다.

994
00:39:22,120 --> 00:39:24,180
저는 이 각 뷰에 합성곱 신경망을

995
00:39:24,180 --> 00:39:27,560
적용할 것이고, 이를 융합할 방법이 있습니다.

996
00:39:27,560 --> 00:39:29,580
그래서 저는 풀링을 사용합니다, 뭐든지요.

997
00:39:29,580 --> 00:39:32,500
그리고 저는 이미지 분류를 수행합니다.

998
00:39:32,500 --> 00:39:34,860
그래서 이것은 이미지 분류 문제로 바뀝니다.

999
00:39:34,860 --> 00:39:37,722
유일한 차이점은 이제 여러 개의 뷰가 있다는 것입니다.

1000
00:39:37,722 --> 00:39:40,180
이것은 어떤 면에서 사람들이 3D 비전에 처음

1001
00:39:40,180 --> 00:39:41,700
적용한 아이디어 중 하나입니다.

1002
00:39:41,700 --> 00:39:43,375
그들은 2D 네트워크를 사용했습니다.

1003
00:39:43,375 --> 00:39:45,000
왜 2D 네트워크를 사용하고 싶어하나요?

1004
00:39:45,000 --> 00:39:47,042
그 당시에는 ImageNet에 집중하고 있었기 때문입니다.

1005
00:39:47,042 --> 00:39:48,150
그리고 그들은 매우 좋습니다.

1006
00:39:48,150 --> 00:39:51,535
ImageNet은 3D 데이터 세트보다 훨씬 큽니다.

1007
00:39:51,535 --> 00:39:53,410
그래서 ImageNet에서 사전 훈련된

1008
00:39:53,410 --> 00:39:54,743
모델은 성능이 매우 좋습니다.

1009
00:39:54,743 --> 00:39:57,190
이 3D 인식 문제를 해결하는 가장 쉬운

1010
00:39:57,190 --> 00:39:59,670
방법은 먼저 2D로 렌더링하는 것입니다.

1011
00:39:59,670 --> 00:40:02,790
나중에 사람들은 더 많은 3D 데이터가 생기면서 이를

1012
00:40:02,790 --> 00:40:04,010
벗어나기 시작했습니다.

1013
00:40:04,010 --> 00:40:05,550
우리는 3D 네이티브

1014
00:40:05,550 --> 00:40:07,390
방법을 시도해야 합니다.

1015
00:40:07,390 --> 00:40:10,310
사람들은 신경 렌더링을 통해 3D와 2D를 연결하는

1016
00:40:10,310 --> 00:40:11,715
아이디어를 내기도 합니다.

1017
00:40:11,715 --> 00:40:13,590
하지만 지금 이 트렌드가 다시 돌아오는 것 같아요.

1018
00:40:13,590 --> 00:40:15,815
왜냐하면 모든 이미지와 비디오 모델이 정말 훌륭해지고

1019
00:40:15,815 --> 00:40:16,690
있기 때문입니다.

1020
00:40:16,690 --> 00:40:18,790
여러분 중 많은 분들이 어제

1021
00:40:18,790 --> 00:40:21,070
발표된 VL3를 보셨는지 모르겠네요?

1022
00:40:21,070 --> 00:40:21,570
맞아요.

1023
00:40:21,570 --> 00:40:24,470
그들이 그렇게 훌륭하다면, 아마도 우리는 이미지와

1024
00:40:24,470 --> 00:40:26,770
비디오 기반 모델에 좀 더 의존해야 할 것

1025
00:40:26,770 --> 00:40:29,853
같습니다. 왜냐하면 그들은 3D 데이터보다 천 배, 만

1026
00:40:29,853 --> 00:40:31,770
배, 아니면 그 이상, 아마도 백만

1027
00:40:31,770 --> 00:40:34,310
배 더 많은 데이터로 훈련되었기 때문입니다.

1028
00:40:34,310 --> 00:40:36,090
그렇다면 우리는 어떻게 그것을 통합할 수 있을까요?

1029
00:40:36,090 --> 00:40:39,430
하지만 돌아가서, 이제 이것이 첫 번째 방법입니다.

1030
00:40:39,430 --> 00:40:43,030
어떤 의미에서는 사람들은 3D 데이터를 2D로 변환하여

1031
00:40:43,030 --> 00:40:45,270
딥 러닝을 적용하려고 합니다.

1032
00:40:45,270 --> 00:40:48,122
그들은 형태 분류에서 매우 잘 작동합니다.

1033
00:40:48,122 --> 00:40:50,080
그들은 형태를 가지고 있고, 여러분은 그것들을 다른

1034
00:40:50,080 --> 00:40:51,163
카테고리로 분류하고 싶어합니다.

1035
00:40:51,163 --> 00:40:54,280
그리고 그들은 매우 좋은 성능을 보입니다.

1036
00:40:54,280 --> 00:40:58,440
그래서 여러분은 2D 이미지 사전 훈련 모델에 대한 많은

1037
00:40:58,440 --> 00:41:00,120
문헌을 활용할 수 있습니다.

1038
00:41:00,120 --> 00:41:02,680
하지만 문제는 몇 가지 투영이 필요하다는 것입니다.

1039
00:41:02,680 --> 00:41:05,140
하지만 때때로 입력이 매우 시끄러울 수 있습니다.

1040
00:41:05,140 --> 00:41:07,243
사람들은 '내 입력이 너무 시끄럽다면 어떻게 하지?'라고 생각합니다.

1041
00:41:07,243 --> 00:41:09,660
포인트 클라우드 등은 그리 좋지 않습니다.

1042
00:41:09,660 --> 00:41:11,760
렌더링하면 좀 안 좋아 보입니다.

1043
00:41:11,760 --> 00:41:15,680
그렇다면 더 많은 3D 네이티브 방법을 생각해낼 수 있을까요?

1044
00:41:15,680 --> 00:41:20,000
그래서 나중에 사람들은 3D 데이터에 딥 러닝을 직접 적용하는 여러

1045
00:41:20,000 --> 00:41:22,040
3D 네이티브 방법을 시도했습니다.

1046
00:41:22,040 --> 00:41:24,280
제가 말했듯이, 가장 쉬운

1047
00:41:24,280 --> 00:41:27,640
방법은 픽셀 합성곱 신경망을 복셀, 볼륨

1048
00:41:27,640 --> 00:41:30,440
합성곱 신경망에 적용하는 것입니다.

1049
00:41:30,440 --> 00:41:33,360
이것은 실제로 생성 네트워크인 딥

1050
00:41:33,360 --> 00:41:34,880
빌리프 네트워크입니다.

1051
00:41:34,880 --> 00:41:38,060
하지만 여전히 3D 합성곱 필터가 있습니다.

1052
00:41:38,060 --> 00:41:41,280
이것은 2015년 프린스턴에서 나온 것입니다.

1053
00:41:41,280 --> 00:41:43,640
그들의 생성 모델에서

1054
00:41:43,640 --> 00:41:48,330
상대적으로 낮은 해상도의 3D 복셀 형태로 3D 형태를

1055
00:41:48,330 --> 00:41:50,370
합성할 수 있습니다.

1056
00:41:50,370 --> 00:41:52,430
하지만 이것은 이제 10년 전입니다.

1057
00:41:52,430 --> 00:41:56,090
그 당시에는 꽤 인상적이라고 여겨졌습니다.

1058
00:41:56,090 --> 00:41:58,470
모든 조건 생성, 조건부 의미

1059
00:41:58,470 --> 00:42:02,750
레이블을 배트와 책상, 테이블에서 생성할 수 있습니다.

1060
00:42:02,750 --> 00:42:04,582
이 다양한 형태를 합성할 수 있습니다.

1061
00:42:04,582 --> 00:42:06,290
그리고 이것이 생성 네트워크이기

1062
00:42:06,290 --> 00:42:08,730
때문에 분류에도 사용할 수 있습니다.

1063
00:42:08,730 --> 00:42:12,890
이미지 형태 분류도 할 수 있습니다.

1064
00:42:12,890 --> 00:42:16,890
그리고 나중에 우리가 실제로 한 것은 GAN,

1065
00:42:16,890 --> 00:42:19,330
즉 생성적 적대 신경망을

1066
00:42:19,330 --> 00:42:20,830
적용하면 어떨까요?

1067
00:42:20,830 --> 00:42:22,510
GAN을 사용하여 2D 픽셀을 생성할 수 있습니다.

1068
00:42:22,510 --> 00:42:25,090
3D 복셀을 생성하는 데 GAN을 사용할 수 없는 이유는 없습니다.

1069
00:42:25,090 --> 00:42:27,450
그래서 우리는 아주 간단한 작업을

1070
00:42:27,450 --> 00:42:30,690
했고, 그것은 GAN을 3D 복셀에 적용하여

1071
00:42:30,690 --> 00:42:33,830
실제로 3D 객체의 꽤 좋은 생성을 제공합니다.

1072
00:42:33,830 --> 00:42:36,450
이것은 8, 9년 전입니다.

1073
00:42:36,450 --> 00:42:39,410
네, 알겠습니다.

1074
00:42:39,410 --> 00:42:44,490
그리고 나중에 CMU의 훈련으로 우리는 확장을 했습니다.

1075
00:42:44,490 --> 00:42:48,130
즉, GAN을 사용하여 3D 형태를 생성할 뿐만 아니라

1076
00:42:48,130 --> 00:42:50,330
2D로 렌더링할 수도 있습니다.

1077
00:42:50,330 --> 00:42:53,470
생성한 3D 객체의 깊이 맵을 얻기

1078
00:42:53,470 --> 00:42:57,130
위해 2D 표면으로 투영할 수 있습니다.

1079
00:42:57,130 --> 00:42:59,950
그런 다음 사이클GAN을 사용하여 이 깊이

1080
00:42:59,950 --> 00:43:02,273
맵을 컬러 이미지로 변환할 수 있습니다.

1081
00:43:02,273 --> 00:43:04,690
이제 3D 형태뿐만 아니라 2D 이미지에서도 적대적

1082
00:43:04,690 --> 00:43:05,830
손실을 가질 수 있습니다.

1083
00:43:05,830 --> 00:43:08,270
3D 형태가 현실적으로 보이도록 하여

1084
00:43:08,270 --> 00:43:12,270
가지고 있는 3D 객체 데이터와 구별할 수 없도록 하고 싶습니다.

1085
00:43:12,270 --> 00:43:14,710
2D 이미지도 현실적으로 보이도록

1086
00:43:14,710 --> 00:43:18,470
하여 실제 자동차 이미지와 구별할 수 없도록 하고 싶습니다.

1087
00:43:18,470 --> 00:43:20,270
그래서 동시에 3D 생성과

1088
00:43:20,270 --> 00:43:22,630
2D 생성을 할 수 있습니다.

1089
00:43:22,630 --> 00:43:27,210
형태, 시점 및 질감에 대해 서로 다른 잠재 벡터가

1090
00:43:27,210 --> 00:43:29,330
있기 때문에 어느 정도의

1091
00:43:29,330 --> 00:43:31,352
제어 가능성도 있습니다.

1092
00:43:31,352 --> 00:43:32,810
예를 들어, 시점을 변경할 수 있습니다.

1093
00:43:32,810 --> 00:43:34,310
질감을 변경할 수 있습니다.

1094
00:43:34,310 --> 00:43:36,270
보간을 할 수 있습니다.

1095
00:43:36,270 --> 00:43:39,750
한 자동차의 텍스처를 다른 자동차의

1096
00:43:39,750 --> 00:43:42,260
형태에 전이할 수 있습니다.

1097
00:43:42,260 --> 00:43:45,200
이것은 2018년입니다.

1098
00:43:45,200 --> 00:43:47,480
그래서 사람들은 2D 픽셀 대신 3D

1099
00:43:47,480 --> 00:43:48,980
복셀에 합성곱 신경망,

1100
00:43:48,980 --> 00:43:51,920
생성적 적대 신경망과 같은 딥 네트워크를 적용하려고

1101
00:43:51,920 --> 00:43:52,863
했습니다.

1102
00:43:52,863 --> 00:43:54,780
그렇다면 복셀로 좀 더 나은 결과를 얻을 수 있을까요?

1103
00:43:54,780 --> 00:43:57,200
사람들이 복셀에 대해 불만을 제기한 한 가지는

1104
00:43:57,200 --> 00:43:59,240
복셀의 속도가 정말 느리다는 것입니다.

1105
00:43:59,240 --> 00:44:00,420
미리 샘플링해야 합니다.

1106
00:44:00,420 --> 00:44:01,920
많은 샘플 포인트가 빈

1107
00:44:01,920 --> 00:44:04,880
공간과 같기 때문에 많은 노력이 낭비됩니다.

1108
00:44:04,880 --> 00:44:08,125
또는 물체 내부에 있어서 아무 정보도 제공하지 않습니다.

1109
00:44:08,125 --> 00:44:09,500
그래서 자연스럽게 사람들은, 좋습니다,

1110
00:44:09,500 --> 00:44:10,792
실제로 개선할 수 있을까요?

1111
00:44:10,792 --> 00:44:14,120
복셀에 대한 개선 사항으로 옥타브 트리가 있습니다.

1112
00:44:14,120 --> 00:44:16,160
옥타브 트리의 아이디어는 여전히 명시적

1113
00:44:16,160 --> 00:44:18,093
표현을 가지고 있다는 것입니다.

1114
00:44:18,093 --> 00:44:19,760
어떤 의미에서는 그것이 암시적 표현이라고

1115
00:44:19,760 --> 00:44:20,885
주장할 수 있습니다.

1116
00:44:20,885 --> 00:44:24,400
하지만 비모수적 암시적 표현과 같습니다.

1117
00:44:24,400 --> 00:44:26,520
그러나 공간의 모든 점을

1118
00:44:26,520 --> 00:44:31,848
균일한 스케일로 표현하는 대신, 실제로 복셀이나, 네,

1119
00:44:31,848 --> 00:44:34,780
기본적으로 복셀이 서로 다른 크기를

1120
00:44:34,780 --> 00:44:37,840
가질 수 있다고 가정하고, 공간을

1121
00:44:37,840 --> 00:44:40,230
서로 다른 영역으로 나눕니다.

1122
00:44:40,230 --> 00:44:41,490
그리고 훨씬 더 많은 비용을 지출합니다.

1123
00:44:41,490 --> 00:44:43,810
물체의 표면에 정말 가까이 있다고

1124
00:44:43,810 --> 00:44:47,110
느낄 때, 훨씬 더 세밀한 스케일로 물체를 표현합니다.

1125
00:44:47,110 --> 00:44:49,890
그리고 이 빈 공간이나 물체 내부에 있을 때, 그곳에서

1126
00:44:49,890 --> 00:44:52,690
무슨 일이 일어나고 있는지 별로 신경 쓰지 않는다면,

1127
00:44:52,690 --> 00:44:54,990
어떤 의미에서는 큰 복셀을 가질 수 있습니다.

1128
00:44:54,990 --> 00:44:57,690
그래서 공간을 재귀적으로 분할할 수 있으며,

1129
00:44:57,690 --> 00:45:02,070
서로 다른 공간에서 서로 다른 크기의 복셀을 가질 수 있습니다.

1130
00:45:02,070 --> 00:45:04,730
이것은 실제로 확장할 수 있게 해줍니다.

1131
00:45:04,730 --> 00:45:07,870
그래서 단순히 복셀을 직접 사용하는 것과 비교했을

1132
00:45:07,870 --> 00:45:10,130
때, 이것은 2019년 경입니다.

1133
00:45:10,130 --> 00:45:12,890
사람들은 옥타브 트리가 훌륭하다고 말합니다. 왜냐하면 낮은

1134
00:45:12,890 --> 00:45:14,950
해상도에서 높게 갈 수 있게 해주기 때문입니다.

1135
00:45:14,950 --> 00:45:17,770
그것이 GPU 메모리에 얼마나 많이 들어갈 수 있는지입니다.

1136
00:45:17,770 --> 00:45:20,150
복셀로 64x64를 할 수 있습니다.

1137
00:45:20,150 --> 00:45:23,956
하지만 옥타브 트리로는 256을 할 수 있습니다.

1138
00:45:23,956 --> 00:45:26,230
그리고 그것을 생성에도 사용할 수 있습니다.

1139
00:45:26,230 --> 00:45:28,530
물체를 생성할 수도 있습니다.

1140
00:45:28,530 --> 00:45:31,330
그들은 복셀처럼 보이지만, 공간을 표현하는

1141
00:45:31,330 --> 00:45:34,490
데 더 효율적이기 때문에 해상도가 더 높습니다.

1142
00:45:34,490 --> 00:45:37,260
그래서 이것들은 3D 공간에 딥 러닝을 적용하려는

1143
00:45:37,260 --> 00:45:38,620
초기 시도들입니다.

1144
00:45:38,620 --> 00:45:41,406
그리고 당신은, 좋습니다, 왜 복셀을 시도하지 않습니까?

1145
00:45:41,406 --> 00:45:44,300
그때 사람들이 그래픽 전문가들이

1146
00:45:44,300 --> 00:45:46,640
'당신은 모든

1147
00:45:46,640 --> 00:45:50,740
것을 잘못하고 있다'고 느끼기 시작한

1148
00:45:50,740 --> 00:45:51,700
순간입니다.

1149
00:45:51,700 --> 00:45:54,460
왜 이런 비효율적이고 보기 흉한 표현,

1150
00:45:54,460 --> 00:45:56,540
즉 복셀이나 옥타브 트리를

1151
00:45:56,540 --> 00:45:58,067
사용하고 싶어할까요?

1152
00:45:58,067 --> 00:45:59,900
이제 우리는 모든 좋은 표현을 가지고

1153
00:45:59,900 --> 00:46:01,820
있습니다. 포인트 클라우드, 메쉬, 스플라인.

1154
00:46:01,820 --> 00:46:03,880
왜 이러한 표현을 사용하지 않나요?

1155
00:46:03,880 --> 00:46:06,652
하지만 우리가 말했듯이, 문제는 점들이 여기저기 있다는 것입니다.

1156
00:46:06,652 --> 00:46:08,860
어떻게 컨볼루션 포인트와 그런 것들을 적용할

1157
00:46:08,860 --> 00:46:09,360
수 있죠?

1158
00:46:09,360 --> 00:46:10,540
그건 그리 명확하지 않습니다.

1159
00:46:10,540 --> 00:46:12,420
하지만 사람들은 그것을 살펴보기 시작합니다.

1160
00:46:12,420 --> 00:46:15,860
그래서 자연스럽게 사람들은 3D 데이터뿐만 아니라 포인트

1161
00:46:15,860 --> 00:46:19,302
클라우드와 같은 다양한 3D 표현에 직접 작용하는

1162
00:46:19,302 --> 00:46:21,260
새로운 딥러닝 방법을 적용하거나

1163
00:46:21,260 --> 00:46:23,060
개발하는 쪽으로 나아갑니다.

1164
00:46:23,060 --> 00:46:26,380
그래서 PointNet에서는 이것이 스탠포드의

1165
00:46:26,380 --> 00:46:29,620
레오 팀에서 나온 중요한 작업이라고 생각합니다.

1166
00:46:29,620 --> 00:46:32,300
여기서 일어나는 것은 3D 포인트 클라우드와 직접 작동하는

1167
00:46:32,300 --> 00:46:34,660
새로운 유형의 딥 네트워크를 개발하는 것입니다.

1168
00:46:34,660 --> 00:46:37,520
그래서 이것을 PointNet이라고 부릅니다.

1169
00:46:37,520 --> 00:46:42,440
아이디어는 포인트에 대해 순열 불변성을 가져야 한다는 것입니다. 왜냐하면
내가 포인트 1과

1170
00:46:42,440 --> 00:46:45,840
포인트 2가 있다고 가정할 때, 포인트 1은 여기 있고 포인트

1171
00:46:45,840 --> 00:46:47,170
2는 여기 있기 때문입니다.

1172
00:46:47,170 --> 00:46:49,300
이제 다른 입력이 있습니다.

1173
00:46:49,300 --> 00:46:52,000
나는 포인트 1이 여기 있고 포인트 2가 저기 있다고 말할 것입니다.

1174
00:46:52,000 --> 00:46:55,080
그러면 당신의 네트워크는 이러한 두 가지 입력 유형에 대해

1175
00:46:55,080 --> 00:46:58,880
불변해야 합니다. 즉, 내가 이 하나를 포인트 1이라고 부르든, 저

1176
00:46:58,880 --> 00:47:02,060
하나를 포인트 2라고 부르든, 또는 이 하나를 포인트 1이라고

1177
00:47:02,060 --> 00:47:03,920
부르고 저 하나를 포인트 2라고

1178
00:47:03,920 --> 00:47:05,900
부르든, 당신의 출력은 동일해야 합니다.

1179
00:47:05,900 --> 00:47:08,488
왜냐하면 그곳의 점들은 순서가 없기 때문입니다.

1180
00:47:08,488 --> 00:47:10,280
우리의 왼쪽 상단이 1,

1181
00:47:10,280 --> 00:47:11,680
1이라는 보장이 없습니다.

1182
00:47:11,680 --> 00:47:14,660
오른쪽 하단은 100, 100입니다.

1183
00:47:14,660 --> 00:47:17,500
그래서 순서가 있다면, 점들이 순서가 없다면,

1184
00:47:17,500 --> 00:47:19,880
당신은 순열 불변성을 가져야 합니다.

1185
00:47:19,880 --> 00:47:22,560
그럼 우리는 어떻게 할 수 있을까요?

1186
00:47:22,560 --> 00:47:25,400
두 번째는 샘플링 불변성을 가져야 한다는 것입니다.

1187
00:47:25,400 --> 00:47:28,200
때때로, 토끼의 머리에서 10개의

1188
00:47:28,200 --> 00:47:31,320
점을 샘플링하고 토끼의 꼬리에서

1189
00:47:31,320 --> 00:47:33,380
5개의 점을 샘플링합니다.

1190
00:47:33,380 --> 00:47:34,970
때때로, 토끼의 꼬리에서 10개의

1191
00:47:34,970 --> 00:47:36,690
점을 샘플링하고 토끼의 머리에서

1192
00:47:36,690 --> 00:47:38,082
5개의 점만 샘플링합니다.

1193
00:47:38,082 --> 00:47:39,790
그럼 어떻게 그것에 대해서도 불변성을 가질 수 있을까요?

1194
00:47:39,790 --> 00:47:42,710
샘플링 포인트에 대한 보장이 없기 때문입니다.

1195
00:47:42,710 --> 00:47:45,730
여기저기 약간의 문제가 있지만, 그들이 암시하는

1196
00:47:45,730 --> 00:47:50,250
한 가지 아이디어는, 그들이 사용한 것이고, 아마도 가장 중요한 점이라고

1197
00:47:50,250 --> 00:47:52,970
생각하는 것은, 그들은 단순히-- 나는

1198
00:47:52,970 --> 00:47:53,830
단순히

1199
00:47:53,830 --> 00:47:55,910
적용합니다-- 그것이 매우 간단합니다.

1200
00:47:55,910 --> 00:47:57,450
나는 단순히 점들의 임베딩에

1201
00:47:57,450 --> 00:47:59,190
대해 대칭 함수를 적용합니다.

1202
00:47:59,190 --> 00:48:01,930
기본적으로 모든 점에 대해 먼저 그들의

1203
00:48:01,930 --> 00:48:04,270
임베딩을 계산합니다. 마치 이미지의

1204
00:48:04,270 --> 00:48:07,010
서로 다른 영역이나 서로 다른 창에 대한

1205
00:48:07,010 --> 00:48:08,810
임베딩을 계산하는 것처럼.

1206
00:48:08,810 --> 00:48:11,370
각 점에 대한 특징을 계산합니다.

1207
00:48:11,370 --> 00:48:13,310
그리고 나서 나는 그것들을 융합해야 합니다.

1208
00:48:13,310 --> 00:48:16,150
하지만 나는 그것들이 순열 불변성을 가지기를

1209
00:48:16,150 --> 00:48:18,890
원하기 때문에, 예를 들어, 최대 함수와

1210
00:48:18,890 --> 00:48:21,070
같은 대칭 함수를 사용합니다.

1211
00:48:21,070 --> 00:48:23,410
나는 최대값, 소프트맥스를 취합니다.

1212
00:48:23,410 --> 00:48:24,670
또한 합 함수일 수도 있습니다.

1213
00:48:24,670 --> 00:48:26,850
나는 그것들을 더합니다.

1214
00:48:26,850 --> 00:48:27,990
그래서 그런 일이 일어나고 있습니다.

1215
00:48:27,990 --> 00:48:28,790
이것은 매우 간단합니다.

1216
00:48:28,790 --> 00:48:31,583
여러 점이 있습니다, 1, 2, 3 또는 1, 뭐든지요.

1217
00:48:31,583 --> 00:48:33,500
그런 다음 이 점들에 대한 임베딩을

1218
00:48:33,500 --> 00:48:34,640
계산하고, 이를 집계합니다.

1219
00:48:34,640 --> 00:48:36,440
각 차원에 대해 최대값을 계산할 수 있습니다.

1220
00:48:36,440 --> 00:48:38,340
이들을 합산하거나 그런 식으로 할 수 있습니다.

1221
00:48:38,340 --> 00:48:39,560
그리고 네.

1222
00:48:39,560 --> 00:48:42,870
모든 점에 대한 집계된 임베딩이 있습니다.

1223
00:48:42,870 --> 00:48:44,620
그런 다음 완전 연결 네트워크의

1224
00:48:44,620 --> 00:48:46,760
몇 개 층을 거칠 수 있습니다.

1225
00:48:46,760 --> 00:48:50,380
그리고 나서 이 점들이 정말 의자나

1226
00:48:50,380 --> 00:48:55,380
테이블을 나타내는지 분류하는 데 사용합니다.

1227
00:48:55,380 --> 00:48:57,440
기본적으로 이렇게 진행되며,

1228
00:48:57,440 --> 00:49:00,200
꽤 강력한 결과를 가져왔습니다.

1229
00:49:00,200 --> 00:49:03,735
물론 그 위에 많은 개선이 있었습니다.

1230
00:49:03,735 --> 00:49:04,360
물론 그 위에 많은 개선이 있었습니다.

1231
00:49:04,360 --> 00:49:06,360
사람들은 PointNet을 개선하는

1232
00:49:06,360 --> 00:49:07,756
새로운 방법을 제안해왔습니다.

1233
00:49:07,756 --> 00:49:09,335
그들은 PointNet++을 가지고 있습니다.

1234
00:49:09,335 --> 00:49:11,460
사람들이 시도해온 것 중

1235
00:49:11,460 --> 00:49:14,940
하나는 그래프 신경망입니다. 왜냐하면 점을

1236
00:49:14,940 --> 00:49:19,440
그래프의 노드로 쉽게 변환할 수 있고, 이 점들을 연결하는

1237
00:49:19,440 --> 00:49:22,100
엣지로서 이웃과 근접성을 고려할 수

1238
00:49:22,100 --> 00:49:23,320
있기 때문입니다.

1239
00:49:23,320 --> 00:49:24,820
그래서 그래프

1240
00:49:24,820 --> 00:49:26,362
신경망과 이러한 점

1241
00:49:26,362 --> 00:49:30,150
구름 처리를 위한 다른 방법들이 개발되었습니다.

1242
00:49:30,150 --> 00:49:34,410
하지만 PointNet 논문의 원래 아이디어는 매우 간단하며,

1243
00:49:34,410 --> 00:49:36,990
또한 매우 강력한 결과를 가져왔습니다.

1244
00:49:36,990 --> 00:49:38,510
고려해야 할 또 다른 것은

1245
00:49:38,510 --> 00:49:40,350
측정도 해야 한다는 것입니다.

1246
00:49:40,350 --> 00:49:41,410
픽셀의 경우, 쉽습니다.

1247
00:49:41,410 --> 00:49:42,650
출력 이미지가 있습니다.

1248
00:49:42,650 --> 00:49:44,170
정답 이미지가 있습니다.

1249
00:49:44,170 --> 00:49:46,128
두 이미지 간의 차이를 계산하면 됩니다.

1250
00:49:46,128 --> 00:49:48,070
두 개의 손실이 있거나 그와 비슷한 것입니다.

1251
00:49:48,070 --> 00:49:50,950
점의 경우, 출력 점 구름과 입력 점 구름을

1252
00:49:50,950 --> 00:49:52,910
어떻게 비교할까요, 특히 생성 작업에

1253
00:49:52,910 --> 00:49:54,035
관심이 있다면?

1254
00:49:54,035 --> 00:49:55,702
분류를 한다면 괜찮습니다.

1255
00:49:55,702 --> 00:49:57,350
입력 점 구름이 있고,

1256
00:49:57,350 --> 00:49:59,350
출력은 의자, 테이블 등입니다.

1257
00:49:59,350 --> 00:50:00,850
교차 엔트로피 손실이 있습니다.

1258
00:50:00,850 --> 00:50:02,110
그게 전부입니다.

1259
00:50:02,110 --> 00:50:04,670
하지만 생성 작업을 하고 있고, 복셀을

1260
00:50:04,670 --> 00:50:06,270
출력한다면, 그것도 쉽습니다.

1261
00:50:06,270 --> 00:50:08,510
100 x 100 x 100 복셀 그리드의

1262
00:50:08,510 --> 00:50:10,630
교차 엔트로피 손실을 계산하면 됩니다.

1263
00:50:10,630 --> 00:50:13,230
하지만 출력이 점이고 100개의 점이라면,

1264
00:50:13,230 --> 00:50:16,150
출력 점 구름과 정답 점 구름을 어떻게

1265
00:50:16,150 --> 00:50:16,810
비교할까요?

1266
00:50:16,810 --> 00:50:19,270
거리 메트릭도 설계해야 합니다.

1267
00:50:19,270 --> 00:50:22,992
사람들이 사용한 두 가지 일반적인 거리 메트릭 중 하나는

1268
00:50:22,992 --> 00:50:24,450
챔퍼 거리라고 불립니다.

1269
00:50:24,450 --> 00:50:26,210
샴퍼 거리(Chamfer distance)는 이해하기 쉽습니다.

1270
00:50:26,210 --> 00:50:27,790
즉, 두 개의 점 집합이 있습니다.

1271
00:50:27,790 --> 00:50:31,370
각 점에 대해, 각 집합의 각 점에 대해 가장

1272
00:50:31,370 --> 00:50:33,485
가까운 이웃을 찾습니다.

1273
00:50:33,485 --> 00:50:35,110
그래서 빨간 점들의 모음이 있습니다.

1274
00:50:35,110 --> 00:50:36,630
파란 점들의 모음이 있습니다.

1275
00:50:36,630 --> 00:50:38,150
빨간 점에 대해, 각 빨간

1276
00:50:38,150 --> 00:50:40,590
점의 가장 가까운 이웃을 파란 집합에서 찾습니다.

1277
00:50:40,590 --> 00:50:41,930
각 파란 점에 대해서도 빨간 집합에서

1278
00:50:41,930 --> 00:50:43,130
가장 가까운 이웃을 찾습니다.

1279
00:50:43,130 --> 00:50:44,850
그리고 거리를 최소화하고 싶습니다,

1280
00:50:44,850 --> 00:50:46,850
각 점이 다른 집합의 가장 가까운

1281
00:50:46,850 --> 00:50:49,170
이웃까지의 거리를 최소화하고 싶습니다.

1282
00:50:49,170 --> 00:50:51,770
사람들이 사용할 수 있는 두 번째 아이디어, 손실 함수는 지구 이동
거리(Earth

1283
00:50:51,770 --> 00:50:53,270
Mover distance)라고 불립니다.

1284
00:50:53,270 --> 00:50:55,770
여기서 두 점 집합 간의 이분 매칭을

1285
00:50:55,770 --> 00:50:58,107
수행하고, 이 점들 간에 일대일

1286
00:50:58,107 --> 00:50:59,690
쌍 매칭을 하며, 이

1287
00:50:59,690 --> 00:51:02,672
모든 쌍 간의 거리를 최소화하고 싶습니다.

1288
00:51:02,672 --> 00:51:04,130
이것들은 점 구름 간의 거리를

1289
00:51:04,130 --> 00:51:05,930
비교할 때 사람들이 사용하는 두

1290
00:51:05,930 --> 00:51:07,170
가지 일반적인 메트릭입니다.

1291
00:51:07,170 --> 00:51:08,470
이들은 미분 가능하게

1292
00:51:08,470 --> 00:51:10,345
만들 수 있으며, 이는 이제

1293
00:51:10,345 --> 00:51:12,530
기울기를 계산하고 신경망을 최적화하는 데

1294
00:51:12,530 --> 00:51:14,530
사용할 수 있음을 의미합니다. 그러면

1295
00:51:14,530 --> 00:51:19,330
점 구름 생성 문제에 관심이 있다면 출력이 더 나은 점 구름이 되기를
바랍니다.

1296
00:51:19,330 --> 00:51:23,050
우리는 복셀에서 점 구름으로 이동했습니다.

1297
00:51:23,050 --> 00:51:24,950
사람들은 '좋아, 이거 좋다'고 말했습니다.

1298
00:51:24,950 --> 00:51:28,080
이제 나는 점을 처리할 수 있고, 점을 출력할 수 있습니다.

1299
00:51:28,080 --> 00:51:31,900
하지만 우리는 스플라인과 같은 다른 아름다운 분할도 가지고 있습니다.

1300
00:51:31,900 --> 00:51:34,320
그들은 물체의 표면을 포착하는 데 매우 능숙합니다.

1301
00:51:34,320 --> 00:51:36,340
어떤 종류의 신경망을 사용하여 복셀을

1302
00:51:36,340 --> 00:51:38,200
생성하거나 포인트 클라우드를 생성하면

1303
00:51:38,200 --> 00:51:39,880
항상 매우 보기 흉하게 보입니다.

1304
00:51:39,880 --> 00:51:42,400
그래서 매끄러운 표면 같은 것이 없습니다.

1305
00:51:42,400 --> 00:51:43,858
그렇다면 객체를 출력하거나

1306
00:51:43,858 --> 00:51:46,900
이해할 수 있는 신경망을 어떻게 만들 수 있을까요?

1307
00:51:46,900 --> 00:51:48,940
아름다운 표면도 표현할 수 있도록.

1308
00:51:48,940 --> 00:51:51,772
사람들은 신경망을 스플라인이나 그런

1309
00:51:51,772 --> 00:51:53,980
함수와 통합할 수 있는 방법에

1310
00:51:53,980 --> 00:51:56,340
대해 조금 더 생각합니다.

1311
00:51:56,340 --> 00:51:58,220
주목할 만한 예시로, 여기

1312
00:51:58,220 --> 00:52:00,400
AtlasNet이라는 것이 있습니다.

1313
00:52:00,400 --> 00:52:04,060
여기서 일어나는 일은 그들이 딥러닝을 사용하려고 한다는 것입니다.

1314
00:52:04,060 --> 00:52:06,940
하지만 3D 포인트 클라우드 집합을

1315
00:52:06,940 --> 00:52:10,940
직접 출력하는 대신, 변환 함수를 학습했습니다.

1316
00:52:10,940 --> 00:52:13,420
저는 잠재적인 형태 표현을 가지고 있습니다.

1317
00:52:13,420 --> 00:52:16,940
그리고 우리가 물체 형태의 매개변수 표현이

1318
00:52:16,940 --> 00:52:19,680
있다고 말할 때, 기본적으로 u와

1319
00:52:19,680 --> 00:52:25,030
v의 2D 공간을 구와 같은 3D 공간으로 변환하고 있습니다.

1320
00:52:25,030 --> 00:52:27,353
구와 같은 간단한 것들은 쉽습니다.

1321
00:52:27,353 --> 00:52:28,270
그것을 적어낼 수 있습니다.

1322
00:52:28,270 --> 00:52:32,088
그 함수는 사인과 코사인 또는 다른 것들로 무엇인가요?

1323
00:52:32,088 --> 00:52:34,630
하지만 복잡한 객체의 경우 함수 작성이 매우 어렵습니다.

1324
00:52:34,630 --> 00:52:36,470
종종 닫힌 형태가 없습니다.

1325
00:52:36,470 --> 00:52:39,158
그래서 여기서의 아이디어는, 닫힌 형태가 없다면,

1326
00:52:39,158 --> 00:52:40,950
왜 신경망을 사용하여 그것을

1327
00:52:40,950 --> 00:52:42,210
표현하지 않겠습니까?

1328
00:52:42,210 --> 00:52:44,390
여기에서 이 신경망이

1329
00:52:44,390 --> 00:52:49,210
MLP로 구현되어 함수 f를 학습하는 모습을 볼 수 있습니다.

1330
00:52:49,210 --> 00:52:51,750
u와 v 두 값을 함수 f의 입력으로

1331
00:52:51,750 --> 00:52:53,110
사용할 수 있습니다.

1332
00:52:53,110 --> 00:52:55,510
신경망은 함수 f와 u, v의

1333
00:52:55,510 --> 00:52:59,470
계산을 수행하고 3D 공간의 한 점을 출력합니다.

1334
00:52:59,470 --> 00:53:04,070
기본적으로 2D 공간을 3D 공간으로 변환하는 방법을

1335
00:53:04,070 --> 00:53:09,070
학습하고 있으며, 단일 변환으로 전체 객체를 표현하기는

1336
00:53:09,070 --> 00:53:11,920
너무 어려울 수 있습니다.

1337
00:53:11,920 --> 00:53:13,670
그래서 사람들은 몇 개의 작은 신경망을

1338
00:53:13,670 --> 00:53:14,885
사용할 수 있다고 생각했습니다.

1339
00:53:14,885 --> 00:53:17,010
이제 종이 한 장이 있다고 생각해 보세요.

1340
00:53:17,010 --> 00:53:18,450
여러 가지 방법으로 접을 수 있습니다.

1341
00:53:18,450 --> 00:53:20,010
여러 번 접을 수 있습니다.

1342
00:53:20,010 --> 00:53:21,750
이 모든 것이 모여서

1343
00:53:21,750 --> 00:53:25,920
당신이 원하는 최종 형태를 형성합니다.

1344
00:53:25,920 --> 00:53:29,007
이것은 세 가지 서로 다른 표현 간의 차이를

1345
00:53:29,007 --> 00:53:30,340
볼 수 있습니다.

1346
00:53:30,340 --> 00:53:31,480
입력 이미지가 있습니다.

1347
00:53:31,480 --> 00:53:34,440
복셀을 사용하여 재구성하려면 무언가를

1348
00:53:34,440 --> 00:53:36,680
하고 있는 것을 볼 수 있습니다.

1349
00:53:36,680 --> 00:53:40,400
하지만 제한된 해상도의 복셀에 의해 정말로 제한됩니다.

1350
00:53:40,400 --> 00:53:42,440
포인트 클라우드의 경우, 더 이상 해상도에

1351
00:53:42,440 --> 00:53:43,860
의해 제한되지 않습니다.

1352
00:53:43,860 --> 00:53:46,260
그리고 아마도 좀 더 많은 세부 정보를 제공합니다.

1353
00:53:46,260 --> 00:53:48,020
하지만 점들은 정말로 무질서합니다.

1354
00:53:48,020 --> 00:53:50,720
포인트 클라우드에서 매끄러운 표면을 얻을

1355
00:53:50,720 --> 00:53:51,560
수 없습니다.

1356
00:53:51,560 --> 00:53:54,063
AtlasNet이라고 불리는 이 것은 기본적으로

1357
00:53:54,063 --> 00:53:55,480
조각을 변환하는 것을

1358
00:53:55,480 --> 00:53:58,160
학습하며, 실제로 더 매끄러운 표면을 가지고 있습니다.

1359
00:53:58,160 --> 00:54:00,160
신경망을 사용하여 저차원

1360
00:54:00,160 --> 00:54:02,240
공간에서 고차원 공간으로 매개변수

1361
00:54:02,240 --> 00:54:05,320
표현을 매핑하는 방법을 나타내고, 이러한

1362
00:54:05,320 --> 00:54:07,340
매핑을 여러 개 학습합니다.

1363
00:54:07,340 --> 00:54:10,080
이들이 결합되면 2D 이미지에 조건화된 최종

1364
00:54:10,080 --> 00:54:11,610
출력 기하학을 제공합니다.

1365
00:54:16,200 --> 00:54:30,020
좋습니다, 그래서 결국 어떤 의미에서 이렇게 표현할 수 있습니다.

1366
00:54:30,020 --> 00:54:32,660
딥 네트워크가 ImageNet 분류를 할

1367
00:54:32,660 --> 00:54:34,380
때 무엇을 하고 있나요?

1368
00:54:34,380 --> 00:54:36,980
기본적으로 입력 이미지를 픽셀 형태로

1369
00:54:36,980 --> 00:54:40,220
최종 카테고리 레이블로 매핑하는 매우 복잡한

1370
00:54:40,220 --> 00:54:42,040
함수를 학습하고 있습니다.

1371
00:54:42,040 --> 00:54:45,060
고양이인가 개인가 사람인가 또는 무엇이든요?

1372
00:54:45,060 --> 00:54:47,500
그 함수는 정말 복잡하고 출력 공간은

1373
00:54:47,500 --> 00:54:48,240
정말 작습니다.

1374
00:54:48,240 --> 00:54:50,620
출력 공간은 1,000 차원입니다.

1375
00:54:50,620 --> 00:54:52,200
그래서 고양이인지 개인지?

1376
00:54:52,200 --> 00:54:53,617
1,000가지 분류가 있습니다.

1377
00:54:53,617 --> 00:54:54,680
출력 공간은 매우 작습니다.

1378
00:54:54,680 --> 00:54:57,260
입력 공간은 훨씬 더 큽니다. 왜냐하면 500 x 500

1379
00:54:57,260 --> 00:54:58,480
픽셀이 있기 때문입니다.

1380
00:54:58,480 --> 00:55:00,935
그래서 250,000 정도입니다.

1381
00:55:00,935 --> 00:55:02,060
입력 공간은 훨씬 더 큽니다.

1382
00:55:02,060 --> 00:55:03,268
출력 공간이 정말 작습니다.

1383
00:55:03,268 --> 00:55:07,340
함수를 작성하는 것이 정말 어렵습니다.

1384
00:55:07,340 --> 00:55:09,500
입력 이미지를 분류하기 위해 몇

1385
00:55:09,500 --> 00:55:13,540
가지 공식을 적을 수 있을까요? 특정 값을 계산하고

1386
00:55:13,540 --> 00:55:15,640
이것이 고양이인지 개인지 출력할

1387
00:55:15,640 --> 00:55:16,720
수 있도록요?

1388
00:55:16,720 --> 00:55:17,545
그건 불가능합니다.

1389
00:55:17,545 --> 00:55:18,920
함수를 작성하는 것이 너무 어렵습니다.

1390
00:55:18,920 --> 00:55:19,810
닫힌 형태가 없습니다.

1391
00:55:19,810 --> 00:55:20,970
그래서 저는 깊은 네트워크가 필요합니다.

1392
00:55:20,970 --> 00:55:22,010
입력 공간이 큽니다.

1393
00:55:22,010 --> 00:55:23,630
출력 공간이 작습니다.

1394
00:55:23,630 --> 00:55:26,190
그래서 깊은 네트워크를 그렇게 생각하고

1395
00:55:26,190 --> 00:55:29,070
그들이 무엇을 하고 있는지 생각해보면,

1396
00:55:29,070 --> 00:55:31,770
우리가 3D 형태에 대해 깊은 네트워크로

1397
00:55:31,770 --> 00:55:36,670
해왔던 많은 것들이 그 매핑에 잘 맞지 않는 것 같다는 것을

1398
00:55:36,670 --> 00:55:37,570
깨닫게 됩니다.

1399
00:55:37,570 --> 00:55:38,997
그래서 그 매핑이 잘 맞지 않습니다.

1400
00:55:38,997 --> 00:55:40,830
그리고 그것들을 정말 잘

1401
00:55:40,830 --> 00:55:42,530
매핑하는 표현은 무엇인가요?

1402
00:55:42,530 --> 00:55:44,270
패러다임에 정말 잘

1403
00:55:44,270 --> 00:55:47,390
맞는 최적의 표현은 무엇인가요?

1404
00:55:47,390 --> 00:55:50,650
좀 더 신중하게 생각해보면, 2019년경에 사람들은

1405
00:55:50,650 --> 00:55:52,788
깊은 네트워크가 암묵적 함수라는

1406
00:55:52,788 --> 00:55:54,330
것을 깨닫게 됩니다.

1407
00:55:54,330 --> 00:55:57,510
그럼 왜 객체 3D 기하학을 위한 암묵적 함수를

1408
00:55:57,510 --> 00:55:59,470
표현하는 데 사용하지 않을까요?

1409
00:55:59,470 --> 00:56:02,110
복셀을 표현하는 대신,

1410
00:56:02,110 --> 00:56:04,030
이제는 픽셀로

1411
00:56:04,030 --> 00:56:07,870
변환하고, 3D로 확장하는 것입니다.

1412
00:56:07,870 --> 00:56:09,410
그리고 3D 컨볼루션을 적용합니다.

1413
00:56:09,410 --> 00:56:12,310
근본적으로 복셀은 물체의 내부와

1414
00:56:12,310 --> 00:56:14,570
외부에 대한 것입니다.

1415
00:56:14,570 --> 00:56:18,240
그래서 공간을 직접 쿼리하고 복셀을 얻고 그 위에

1416
00:56:18,240 --> 00:56:20,383
컨볼루션을 적용하는 대신, 깊은

1417
00:56:20,383 --> 00:56:22,800
네트워크를 사용하여 그 쿼리를 수행하면

1418
00:56:22,800 --> 00:56:25,840
3D 컨볼루션이나 다른 것을 실행할 필요가

1419
00:56:25,840 --> 00:56:26,400
없습니다.

1420
00:56:26,400 --> 00:56:29,840
저는 3D 공간에서 쿼리하고

1421
00:56:29,840 --> 00:56:34,280
깊은 네트워크가 그 점이 3D 형태의

1422
00:56:34,280 --> 00:56:38,960
내부인지 외부인지 알려줘야 합니다.

1423
00:56:38,960 --> 00:56:41,240
결국, 사람들은 점 구름이나

1424
00:56:41,240 --> 00:56:44,640
스플라인의 특정 표현에서 암묵적 표현으로

1425
00:56:44,640 --> 00:56:47,660
도약하게 됩니다. 그러나 복셀에서 직접

1426
00:56:47,660 --> 00:56:49,300
작업하지는 않습니다.

1427
00:56:49,300 --> 00:56:51,840
대신, 그것을 레벨 세트나 깊은

1428
00:56:51,840 --> 00:56:55,520
네트워크를 사용하여 표현하는 암묵적 함수로 생각합니다.

1429
00:56:55,520 --> 00:56:56,680
그것이 마지막 단계입니다.

1430
00:56:56,680 --> 00:56:59,380
이 AtlasNet 또는 무엇이든

1431
00:56:59,380 --> 00:57:02,760
간에, 2D 공간에서 3D 공간으로의 변환을

1432
00:57:02,760 --> 00:57:03,860
배우고 있습니다.

1433
00:57:03,860 --> 00:57:06,240
하지만 이제 깊은 네트워크를 사용하여 암묵적 쿼리를

1434
00:57:06,240 --> 00:57:07,600
직접 수행할 수 있습니다.

1435
00:57:07,600 --> 00:57:10,840
그래서 깊은 암묵적 함수로 이어지며, 흥미로운

1436
00:57:10,840 --> 00:57:13,460
점은 2019년경에 거의 동일한

1437
00:57:13,460 --> 00:57:16,290
작업을 수행하는 네 개의 논문이

1438
00:57:16,290 --> 00:57:17,330
있다는 것입니다.

1439
00:57:17,330 --> 00:57:19,913
그들은 모두 우리가 복셀, 점 구름, 메시

1440
00:57:19,913 --> 00:57:22,455
등을 사용해왔고, 각각의 장단점이 있다고

1441
00:57:22,455 --> 00:57:23,030
주장합니다.

1442
00:57:23,030 --> 00:57:24,490
하지만 정말로 올바른

1443
00:57:24,490 --> 00:57:28,710
방법은 쿼리를 깊은 네트워크로 보내는 것입니다.

1444
00:57:28,710 --> 00:57:31,990
그래서 깊은 네트워크가 해야 할 일은 입력, 즉

1445
00:57:31,990 --> 00:57:34,110
x, y, z 좌표를 받아

1446
00:57:34,110 --> 00:57:37,770
그 점이 물체의 내부인지 외부인지 출력하는 것입니다.

1447
00:57:37,770 --> 00:57:41,090
그리고 그것이 어떤 의미에서는 최종적인 것, 즉 최종 중 하나가

1448
00:57:41,090 --> 00:57:41,830
될 것입니다.

1449
00:57:41,830 --> 00:57:44,810
그리고 그것이 2019년에 제안된 아이디어입니다.

1450
00:57:44,810 --> 00:57:47,010
그리고 지금 2025년에도 많은 사람들이

1451
00:57:47,010 --> 00:57:49,170
여전히 이 같은 아이디어를 사용하고 있습니다.

1452
00:57:49,170 --> 00:57:51,530
즉, 나는 깊은 네트워크를 사용하여 점이

1453
00:57:51,530 --> 00:57:54,210
객체 내부에 있는지 외부에 있는지를 알려줄 것입니다.

1454
00:57:54,210 --> 00:57:56,850
그리고 내부와 외부의 이진 분류를

1455
00:57:56,850 --> 00:57:59,220
넘어서서, 내가 좀 더 신경

1456
00:57:59,220 --> 00:58:01,470
쓰는 부분도 있을 수 있습니다.

1457
00:58:01,470 --> 00:58:03,553
나는 서명 거리 함수가 무엇일지 말합니다.

1458
00:58:03,553 --> 00:58:06,970
점이 객체 표면에서 얼마나 떨어져 있는지를 말합니다.

1459
00:58:06,970 --> 00:58:09,570
또는 점의 밀도 값이 무엇일지 말합니다.

1460
00:58:09,570 --> 00:58:11,470
또는 나중에 색상이 무엇이 될지 말합니다.

1461
00:58:11,470 --> 00:58:14,030
점의 방사 값은 무엇일까요?

1462
00:58:14,030 --> 00:58:16,550
하지만 여기서 2019년부터 사람들은

1463
00:58:16,550 --> 00:58:19,550
깊은 네트워크를 분류와 유사한 방식으로 적용하기

1464
00:58:19,550 --> 00:58:20,650
시작했습니다.

1465
00:58:20,650 --> 00:58:24,630
즉, 나는 3D 공간의 점을 가져와서 3D

1466
00:58:24,630 --> 00:58:27,550
공간의 점 속성을 쿼리하는 암시적

1467
00:58:27,550 --> 00:58:29,270
함수로 사용합니다.

1468
00:58:29,270 --> 00:58:33,190
사람들은 단순히 PC가 3D 공간으로 변형되어

1469
00:58:33,190 --> 00:58:36,305
3D에서 다양한 종이를 얻는 것이

1470
00:58:36,305 --> 00:58:38,430
아니라, 작은 신경망을

1471
00:58:38,430 --> 00:58:42,070
사용하여 객체의 암시적 부분을 표현하려고

1472
00:58:42,070 --> 00:58:43,250
시도했습니다.

1473
00:58:43,250 --> 00:58:45,950
그들은 복잡한 형태를 형성할 수 있습니다.

1474
00:58:45,950 --> 00:58:52,350
그리고 암시적 함수를 사용하여 3D에서 객체를 표현할 수 있다면, 기하학뿐만
아니라

1475
00:58:52,350 --> 00:58:54,170
그렇게 할 수 있습니다.

1476
00:58:54,170 --> 00:58:56,030
내부 또는 점이 객체 내부에

1477
00:58:56,030 --> 00:58:58,290
있는지 외부에 있는지, 점이 객체 표면에서

1478
00:58:58,290 --> 00:59:01,170
얼마나 떨어져 있는지를 쿼리할 수 있습니다.

1479
00:59:01,170 --> 00:59:03,308
또한 방사선이 무엇일지 쿼리할 수 있습니다.

1480
00:59:03,308 --> 00:59:04,850
객체의 색상은 무엇일까요?

1481
00:59:04,850 --> 00:59:06,490
그리고 나는 1년 후로 바로 갑니다.

1482
00:59:06,490 --> 00:59:08,170
이것은 아마도 1년 또는 2년 후일 것입니다.

1483
00:59:08,170 --> 00:59:10,390
이제 사람들은 NeRF라는

1484
00:59:10,390 --> 00:59:13,240
것을 생각해냈습니다. 여기서의

1485
00:59:13,240 --> 00:59:14,960
차이점은 이제 서명

1486
00:59:14,960 --> 00:59:17,600
거리 함수나 객체의 밀도를 쿼리하기

1487
00:59:17,600 --> 00:59:21,640
위해 우리의 지식을 심화해야 한다는 것입니다.

1488
00:59:21,640 --> 00:59:26,380
그래서 여기서 NeRF에 대해 3D 공간의 x, y, z 좌표를 쿼리하는
것이

1489
00:59:26,380 --> 00:59:28,090
일어나는 것을 볼 수 있습니다.

1490
00:59:28,090 --> 00:59:29,840
또한 우리는 외관을

1491
00:59:29,840 --> 00:59:31,640
모델링하려고 하기

1492
00:59:31,640 --> 00:59:35,400
때문에 카메라의 시점 방향도 쿼리합니다.

1493
00:59:35,400 --> 00:59:39,200
신경망의 출력은 단순히 1 또는 0, 내부 또는

1494
00:59:39,200 --> 00:59:40,440
외부가 아닙니다.

1495
00:59:40,440 --> 00:59:44,080
밀도 값과 색상 값 또는 방사선

1496
00:59:44,080 --> 00:59:45,720
값이 포함됩니다.

1497
00:59:45,720 --> 00:59:50,600
3D 형태에 대해 암시적 함수를 직접 훈련시키면

1498
00:59:50,600 --> 00:59:52,600
3D 감독이 필요합니다.

1499
00:59:52,600 --> 00:59:54,783
3D 객체 모음이 있다면 이를 감독으로

1500
00:59:54,783 --> 00:59:56,200
사용할 수 있습니다.

1501
00:59:56,200 --> 00:59:59,200
그것은 당신에게 3D 객체의 내부 또는 외부에

1502
00:59:59,200 --> 01:00:01,760
점이 있는지에 대한 실제 정보를 제공합니다.

1503
01:00:01,760 --> 01:00:04,525
하지만 여기서는 2D 이미지에서 훈련하고 싶습니다.

1504
01:00:04,525 --> 01:00:05,900
이것이 NeRF에서 일어나는 일입니다.

1505
01:00:05,900 --> 01:00:08,840
그래서 그들은 신경 렌더링과 볼륨 렌더링 함수를

1506
01:00:08,840 --> 01:00:09,940
함께 결합했습니다.

1507
01:00:09,940 --> 01:00:11,773
그리고 그들은 이 볼륨 렌더링

1508
01:00:11,773 --> 01:00:15,010
함수를 미분 가능하게 만들어, 렌더링 모델을 가질 수 있고

1509
01:00:15,010 --> 01:00:17,730
3D 공간의 다양한 점을 쿼리할 수 있습니다.

1510
01:00:17,730 --> 01:00:20,210
그들의 색상과 외관에서의

1511
01:00:20,210 --> 01:00:23,090
밀도를 얻을 수 있습니다.

1512
01:00:23,090 --> 01:00:25,210
그리고 그 후에 경로를 따라 얼마나 많은

1513
01:00:25,210 --> 01:00:27,010
빛이 차단되는지를 계산할 수 있습니다.

1514
01:00:27,010 --> 01:00:29,010
이것은 기본적으로 컴퓨터

1515
01:00:29,010 --> 01:00:30,570
그래픽에서의 볼륨 렌더링입니다.

1516
01:00:30,570 --> 01:00:35,850
변화는 매우 최소화되었습니다. 볼륨 렌더링 방정식에서 직접

1517
01:00:35,850 --> 01:00:38,090
볼 수 있듯이, 여기의

1518
01:00:38,090 --> 01:00:39,890
모든 것은-- 이것은

1519
01:00:39,890 --> 01:00:41,030
근사치입니다.

1520
01:00:41,030 --> 01:00:42,655
하지만 근사치로 인해 여기의 모든

1521
01:00:42,655 --> 01:00:43,890
것은 미분 가능합니다.

1522
01:00:43,890 --> 01:00:46,438
따라서 신경망이 밀도를 제공하면,

1523
01:00:46,438 --> 01:00:48,730
이는 기본적으로 3D

1524
01:00:48,730 --> 01:00:51,610
공간의 점의 불투명도로 생각할 수

1525
01:00:51,610 --> 01:00:53,283
있으며, 색상도 제공하므로,

1526
01:00:53,283 --> 01:00:55,450
그 점 앞에서 샘플링된

1527
01:00:55,450 --> 01:01:00,050
점들에 의해 차단된 빛의 양을 계산할 수 있습니다.

1528
01:01:00,050 --> 01:01:02,450
그리고 그 과정에서,

1529
01:01:02,450 --> 01:01:05,090
특정 점에서 이 광선이 보이는

1530
01:01:05,090 --> 01:01:09,820
데 기여하는 빛의 양도 계산할 수 있습니다.

1531
01:01:09,820 --> 01:01:11,360
그래서 이제 몇 가지가 있습니다.

1532
01:01:11,360 --> 01:01:13,693
신경망을 사용하여 색상 또는 방사선과 밀도를

1533
01:01:13,693 --> 01:01:16,122
나타내는 암시적 함수를 가지고 있습니다.

1534
01:01:16,122 --> 01:01:18,080
그리고 2D 이미지에서 직접

1535
01:01:18,080 --> 01:01:21,260
학습할 수 있도록 미분 가능하게 만든 이 볼륨

1536
01:01:21,260 --> 01:01:23,083
렌더 방정식이 있습니다.

1537
01:01:23,083 --> 01:01:25,000
그래서 이것이 변경된 두 가지입니다.

1538
01:01:25,000 --> 01:01:27,760
하나는 더 이상 3D 형태에 대해 훈련할 필요가 없다는 것입니다.

1539
01:01:27,760 --> 01:01:30,640
이 볼륨 렌더링 방정식으로 2D 이미지에서 훈련할 수 있습니다.

1540
01:01:30,640 --> 01:01:33,940
두 번째는, 3D에서 객체의 기하학이나

1541
01:01:33,940 --> 01:01:38,540
밀도만 보는 대신, 3D에서 그들의 방사선이나 외관도

1542
01:01:38,540 --> 01:01:40,120
살펴본다는 것입니다.

1543
01:01:40,120 --> 01:01:43,060
이 두 가지 변화는

1544
01:01:43,060 --> 01:01:46,100
NeRF, 암시적

1545
01:01:46,100 --> 01:01:49,540
함수 또는 깊은 [? SDF ?] 및 이 모든 다른 방법에서 NeRF로의 큰
도약을 이끌어냅니다.

1546
01:01:49,540 --> 01:01:52,472
많은 사람들이 NeRF가 훌륭하다고 느끼고 있습니다.

1547
01:01:52,472 --> 01:01:53,680
갑자기 나타난 것처럼 보입니다.

1548
01:01:53,680 --> 01:01:55,740
사실은 그렇지 않습니다. 그들은

1549
01:01:55,740 --> 01:01:58,380
매우 많은 영감을 받았습니다-- 그들이 나중에

1550
01:01:58,380 --> 01:02:01,700
스스로 쓴 기사들을 보면, 그들은 깊은 내재적

1551
01:02:01,700 --> 01:02:04,640
함수의 모든 발전에 매우 많은 영감을 받았습니다.

1552
01:02:04,640 --> 01:02:06,600
비록 그들은 기하학에만 집중했지만.

1553
01:02:06,600 --> 01:02:09,900
하지만 이제 나는 기하학과 외관 모두를 다룹니다.

1554
01:02:09,900 --> 01:02:13,920
그리고 3D 형태 대신 2D 이미지에서 학습합니다.

1555
01:02:13,920 --> 01:02:16,200
그래서 네, 여기 NeRF의 몇 가지 결과가 있습니다.

1556
01:02:16,200 --> 01:02:17,950
이것은 여러분이 여러 번 보았을 수도 있습니다.

1557
01:02:24,800 --> 01:02:27,620
좋아요, 그러니까 기억하신다면, 우리는

1558
01:02:27,620 --> 01:02:29,920
과거에 3D 형태를 생성하는

1559
01:02:29,920 --> 01:02:33,908
것과 그들의 2D 외관을 생성하는 작업을 해왔습니다.

1560
01:02:33,908 --> 01:02:36,200
여기에서 처음에는 복셀이라는

1561
01:02:36,200 --> 01:02:38,640
표현을 사용했습니다.

1562
01:02:38,640 --> 01:02:41,253
하지만 이제, 우리가 말했듯이, 네, NeRF는 훌륭합니다.

1563
01:02:41,253 --> 01:02:42,920
그리고 암시적 표현이 있다면,

1564
01:02:42,920 --> 01:02:45,900
정말로 복셀로 표현할 필요는 없습니다.

1565
01:02:45,900 --> 01:02:49,480
그것을 방사선 필드로 대체하면 어떨까요?

1566
01:02:49,480 --> 01:02:50,973
그래서 우리는 그것도 했습니다.

1567
01:02:50,973 --> 01:02:52,640
그래서 우리는 암시적 방사선 필드와

1568
01:02:52,640 --> 01:02:54,980
밀도를 포착하는 신경망을 가지고 있습니다.

1569
01:02:54,980 --> 01:02:57,067
하지만 이것은 생성적 신경망입니다.

1570
01:02:57,067 --> 01:02:59,400
그리고 동일한 GAN 렌더링

1571
01:02:59,400 --> 01:03:01,880
프레임워크를 적용하여 3D 객체와 그들의

1572
01:03:01,880 --> 01:03:04,100
2D 사진을 렌더링할 수 있습니다.

1573
01:03:04,100 --> 01:03:06,730
그리고 제어 가능성 측면에서도 동일한 작업을 수행할 수 있습니다.

1574
01:03:06,730 --> 01:03:10,750
그리고 카메라 시점을 변경할 수 있습니다.

1575
01:03:10,750 --> 01:03:13,768
객체의 정체성을 변경할 수 있지만, 시점은 유지할 수 있습니다.

1576
01:03:13,768 --> 01:03:15,810
이전에 할 수 있었던 모든 것을 할 수 있습니다.

1577
01:03:15,810 --> 01:03:18,237
하지만 이제 NeRF를 사용하면 이미지에서 직접 학습할 수 있습니다.

1578
01:03:18,237 --> 01:03:20,570
그래서 많은 3D 데이터가 있는

1579
01:03:20,570 --> 01:03:23,810
자동차나 의자와 같은 범주에 제한할 필요가 없습니다.

1580
01:03:23,810 --> 01:03:26,930
이미지를 통해 직접 학습할 수 있기 때문입니다.

1581
01:03:26,930 --> 01:03:29,850
네, 그래서 이제 출력이 훨씬 더 현실적으로 변하는 것을 볼

1582
01:03:29,850 --> 01:03:30,510
수 있습니다.

1583
01:03:30,510 --> 01:03:32,850
그래서 이것은 우리가 [라고 부른 것입니다. 비둘기 ?]

1584
01:03:32,850 --> 01:03:35,910
에릭 첸을 제1저자로 하여, 주로

1585
01:03:35,910 --> 01:03:39,110
고든 그룹의 사람들과 함께 작업했습니다.

1586
01:03:42,410 --> 01:03:48,010
좋습니다, 그리고 마지막으로 NeRF는 훌륭하지만, NeRF에는 3D에서
많은

1587
01:03:48,010 --> 01:03:50,890
점을 샘플링해야 하는 문제가 있습니다.

1588
01:03:50,890 --> 01:03:53,890
이제 더 이상 미리 샘플링한 후 볼륨 합성을

1589
01:03:53,890 --> 01:03:55,230
적용하지 않습니다.

1590
01:03:55,230 --> 01:03:56,650
하지만 여전히 레벨 세트처럼

1591
01:03:56,650 --> 01:03:58,025
모든 점을 샘플링하고

1592
01:03:58,025 --> 01:03:59,730
항상 신경망을 생성해야 합니다.

1593
01:03:59,730 --> 01:04:02,583
이제 2D에서 학습하여 이를 수행할 수 있습니다.

1594
01:04:02,583 --> 01:04:04,000
이 모든 훌륭한 일을 할 수 있습니다.

1595
01:04:04,000 --> 01:04:06,083
하지만 여전히 모든 샘플링을 해야

1596
01:04:06,083 --> 01:04:07,380
하므로 매우 느립니다.

1597
01:04:07,380 --> 01:04:09,238
그래서 사람들은 조금 더 생각했습니다.

1598
01:04:09,238 --> 01:04:10,780
다시 그래픽스 사람들로부터, 그들은

1599
01:04:10,780 --> 01:04:13,547
'좋은 점과 메쉬에 대한 아이디어가 있다'고 말했습니다.

1600
01:04:13,547 --> 01:04:15,880
그들의 좋은 점은 공간에서 자유롭다는 것입니다.

1601
01:04:15,880 --> 01:04:17,200
그들은 매우 효율적입니다.

1602
01:04:17,200 --> 01:04:19,200
그렇다면 우리가 두 가지를 통합할 수 있을까요?

1603
01:04:19,200 --> 01:04:20,880
암시적 표현을 가질 수 있을까요?

1604
01:04:20,880 --> 01:04:23,798
하지만 고정 샘플링 그리드를 가질 필요는 없을지도 모릅니다.

1605
01:04:23,798 --> 01:04:25,340
모든 시간을 샘플링할 필요는 없습니다.

1606
01:04:25,340 --> 01:04:26,960
시간이 너무 많이 걸리기 때문입니다.

1607
01:04:26,960 --> 01:04:30,020
그래서 아마도 정말로 그들을 함께 두어야 할 것입니다.

1608
01:04:30,020 --> 01:04:34,117
그래서 NeRF가 밀도를 매개변수화하려고 했다고 주장할 수 있습니다.

1609
01:04:34,117 --> 01:04:36,200
죄송합니다, 장면을 매우 밀집하게

1610
01:04:36,200 --> 01:04:39,660
매개변수화하려고 했습니다. 3D에서 모든 점 밀도를 샘플링해야 합니다.

1611
01:04:39,660 --> 01:04:41,980
많은 점이 낭비됩니다. 마치 복셀처럼.

1612
01:04:41,980 --> 01:04:44,600
빈 공간을 나타내는 모든 점이 있습니다.

1613
01:04:44,600 --> 01:04:45,660
그것을 원하지 않습니다.

1614
01:04:45,660 --> 01:04:48,300
NeRF에서는 많은 샘플링과 많은 쿼리가

1615
01:04:48,300 --> 01:04:50,180
빈 공간을 쿼리하고 있습니다.

1616
01:04:50,180 --> 01:04:52,100
네트워크는 0의 밀도를

1617
01:04:52,100 --> 01:04:55,220
제공할 수도 있지만, 많은 시간이 걸립니다.

1618
01:04:55,220 --> 01:04:57,500
그렇다면 우리는 어떻게 해결할 수 있을까요?

1619
01:04:57,500 --> 01:05:00,440
만약 내가 더 희소하게 샘플링하려고 한다면 어떻게 될까요?

1620
01:05:00,440 --> 01:05:02,790
나는 여전히 이러한 암묵적 표현을 가지고 있다.

1621
01:05:02,790 --> 01:05:06,890
하지만 항상 빈 공간을 샘플링하는 대신, 나는

1622
01:05:06,890 --> 01:05:09,830
물체가 있는 곳에서만 샘플링한다.

1623
01:05:09,830 --> 01:05:11,070
그걸 어떻게 알 수 있을까?

1624
01:05:11,070 --> 01:05:13,590
만약 내가 점 표현을 가지고 있다면?

1625
01:05:13,590 --> 01:05:16,890
그래서 이것이 여러분이 들어봤을 수도 있는 가우시안 스플랫이라는

1626
01:05:16,890 --> 01:05:18,190
개념의 아이디어다.

1627
01:05:18,190 --> 01:05:20,730
그래서 여전히 같은 암묵적 함수가 있다.

1628
01:05:20,730 --> 01:05:23,470
당신은 밀도와 외관 등을 위해 신경망에

1629
01:05:23,470 --> 01:05:24,870
질의하고 있다.

1630
01:05:24,870 --> 01:05:28,170
하지만 항상 신경망을 생성하는 대신, 나는 3D 공간에

1631
01:05:28,170 --> 01:05:30,938
있는 3D 가우시안 블롭의 점 표현을 가지고

1632
01:05:30,938 --> 01:05:33,230
있다. 때때로 이것들을 점 구름으로

1633
01:05:33,230 --> 01:05:34,350
생각할 수 있다.

1634
01:05:34,350 --> 01:05:36,170
하지만 점들은 단일 점과 같지 않다.

1635
01:05:36,170 --> 01:05:37,370
그들은 블롭과 같다.

1636
01:05:37,370 --> 01:05:39,750
그들은 어떤 지역과 같다.

1637
01:05:39,750 --> 01:05:43,050
그리고 이러한 블롭이 어디에 있는지 알기 때문에,

1638
01:05:43,050 --> 01:05:46,115
카메라에서 3D 공간으로 광선을 쏘고 점들을

1639
01:05:46,115 --> 01:05:48,490
샘플링할 때, 항상 샘플링할 필요는 없다.

1640
01:05:48,490 --> 01:05:50,590
당신은 이러한 블롭이 어디에

1641
01:05:50,590 --> 01:05:53,790
있는지를 보고, 그 다양한 가우시안의

1642
01:05:53,790 --> 01:05:55,390
반경에 따라 물체가

1643
01:05:55,390 --> 01:05:56,870
있는 지역에서만

1644
01:05:56,870 --> 01:05:58,470
샘플링할 수 있다.

1645
01:05:58,470 --> 01:06:01,710
그래서 이것은 렌더링을 훨씬 더 효율적으로 만든다.

1646
01:06:01,710 --> 01:06:05,393
여기 3D 가우시안 스플랫을 사용한 일부 재구성 결과가

1647
01:06:05,393 --> 01:06:06,060
있다.

1648
01:06:14,330 --> 01:06:17,530
품질 면에서 실제로 그렇게 나쁘지 않다는

1649
01:06:17,530 --> 01:06:19,858
것을 볼 수 있다. 비교할

1650
01:06:19,858 --> 01:06:20,650
만하다.

1651
01:06:20,650 --> 01:06:22,890
나는 그것들이 NeRF와 비교할 수 있다고 말할 것이다.

1652
01:06:22,890 --> 01:06:25,010
이것은 다른 메트릭, PSNR, SSIM이다.

1653
01:06:25,010 --> 01:06:26,430
그들은 렌더링 품질과 같다.

1654
01:06:26,430 --> 01:06:29,898
그리고 y축은 0에서 시작하지 않는다.

1655
01:06:29,898 --> 01:06:31,190
그래서 이것은 약간 오해의 소지가 있다.

1656
01:06:31,190 --> 01:06:33,230
하지만 기본적으로 이러한 숫자가 정말 가까운 것을 볼 수 있다.

1657
01:06:33,230 --> 01:06:34,610
품질 면에서, 렌더링 품질,

1658
01:06:34,610 --> 01:06:36,850
가우시안 스플랫과 NeRF는 유사하다.

1659
01:06:36,850 --> 01:06:38,370
적어도 처음 제안되었을 때는.

1660
01:06:38,370 --> 01:06:40,890
하지만 가우시안 스플랫은 훨씬 더 효율적이다.

1661
01:06:40,890 --> 01:06:42,610
그래서 이것은 FPS, 초당 프레임이다.

1662
01:06:42,610 --> 01:06:45,110
초당 150장의 사진을 렌더링할 수 있다.

1663
01:06:45,110 --> 01:06:49,370
NeRF의 경우, 단일 사진을 렌더링하는 데 약

1664
01:06:49,370 --> 01:06:51,050
20초가 걸린다.

1665
01:06:51,050 --> 01:06:54,670
그래서 이제 이 기술은 1,000배 더 빨라졌다.

1666
01:06:54,670 --> 01:06:56,170
적어도 그들이 주장하는 바다.

1667
01:06:56,170 --> 01:06:59,340
그래서 더 이상 빈 공간을 샘플링하고

1668
01:06:59,340 --> 01:07:02,500
빈 공간에 있는 점들에 대해 신경망에

1669
01:07:02,500 --> 01:07:06,370
질의하는 데 모든 컴퓨팅 파워를 낭비하지 않는다.

1670
01:07:11,260 --> 01:07:13,940
좋아, 그래서 이것이 기본적으로 딥러닝이

1671
01:07:13,940 --> 01:07:17,167
3D 데이터에 통합된 방식이다. 다양한 표현에서

1672
01:07:17,167 --> 01:07:19,000
어떻게 시작되었고, 어떻게

1673
01:07:19,000 --> 01:07:21,180
발전했으며, 다양한 형태 표현과의

1674
01:07:21,180 --> 01:07:22,060
연결이다.

1675
01:07:22,060 --> 01:07:23,560
그리고 우리가 이야기하지

1676
01:07:23,560 --> 01:07:25,620
않은 한 가지는-- 우리는 단

1677
01:07:25,620 --> 01:07:28,660
2분을 사용하여 빠르게 다룰 것이다-- 물체

1678
01:07:28,660 --> 01:07:30,620
기하학에 대한 흥미로운 것들이

1679
01:07:30,620 --> 01:07:32,720
있다. 그것은 요소 기하학, 특정

1680
01:07:32,720 --> 01:07:36,360
부품에 대한 세부 사항뿐만 아니라 구조에 관한 것이다.

1681
01:07:36,360 --> 01:07:39,605
의자들은 대칭적일 수 있기 때문에 종종 그럴 수 있습니다.

1682
01:07:39,605 --> 01:07:40,980
그래서 우리는 매개변수 표면이

1683
01:07:40,980 --> 01:07:42,980
있는 곳에 대해 조금 이야기합니다.

1684
01:07:42,980 --> 01:07:46,580
그리고 구나 그런 것들을 사용하여 이 폐쇄형 방정식을 사용하여

1685
01:07:46,580 --> 01:07:49,107
표면의 일부를 매개변수화할 수 있습니다.

1686
01:07:49,107 --> 01:07:50,940
그것은 약간의 대칭성을 제공합니다.

1687
01:07:50,940 --> 01:07:53,100
하지만 물체 기하학 내의 규칙성이나

1688
01:07:53,100 --> 01:07:56,110
구조에 대한 보다 체계적인 연구도

1689
01:07:56,110 --> 01:07:58,430
있었습니다. 여기에는 반복성과 대칭성이

1690
01:07:58,430 --> 01:07:59,290
포함됩니다.

1691
01:07:59,290 --> 01:08:01,832
사람들은 또한 그것을 위한

1692
01:08:01,832 --> 01:08:04,350
다양한 표현을 생각해냈습니다.

1693
01:08:04,350 --> 01:08:06,730
그래서 우리는 실제로 어떻게 표현할 수 있을까요?

1694
01:08:06,730 --> 01:08:09,290
어떤 의미에서는 포인트 클라우드, 메시, 암묵적

1695
01:08:09,290 --> 01:08:11,582
함수가 개별 부품의 기하학적 세부 사항을

1696
01:08:11,582 --> 01:08:13,450
나타내고 있다고 주장할 수 있습니다.

1697
01:08:13,450 --> 01:08:15,310
그들 중 어느 것도 규칙성, 대칭

1698
01:08:15,310 --> 01:08:18,290
및 반복과 같은 것을 직접적으로 포착하지 않습니다.

1699
01:08:18,290 --> 01:08:20,189
그렇다면 우리는 어떻게 그것을 포착할 수 있을까요?

1700
01:08:20,189 --> 01:08:23,510
사람들이 탐색해온 몇 가지 다른 시도는

1701
01:08:23,510 --> 01:08:27,270
주로 그래픽 커뮤니티에서, 객체를

1702
01:08:27,270 --> 01:08:31,229
기본적으로 이러한 간단한 기하학적 부분의

1703
01:08:31,229 --> 01:08:33,590
집합으로 표현할 수 있습니다.

1704
01:08:33,590 --> 01:08:36,310
그리고 깊은 네트워크를 사용하여 객체의

1705
01:08:36,310 --> 01:08:38,790
다양한 부분을 나타내는 방법이

1706
01:08:38,790 --> 01:08:40,189
있으며, 간단한

1707
01:08:40,189 --> 01:08:42,750
기하학적 원시를 사용하여 그것들을

1708
01:08:42,750 --> 01:08:45,649
구성하거나 암묵적 함수를 사용하여

1709
01:08:45,649 --> 01:08:47,470
구성하는 방법이 있습니다.

1710
01:08:47,470 --> 01:08:51,547
하지만 단순히 객체를 부분의 집합으로 표현하는

1711
01:08:51,547 --> 01:08:53,630
것뿐만 아니라 이러한

1712
01:08:53,630 --> 01:08:55,297
부분 간의

1713
01:08:55,297 --> 01:08:57,040
관계를 모델링하는

1714
01:08:57,040 --> 01:08:58,560
시도도 있었습니다.

1715
01:08:58,560 --> 01:09:03,319
장면의 경우, 예를 들어 침대와 같은 경우에는 더욱 그렇습니다.

1716
01:09:03,319 --> 01:09:04,883
우리의 침대는 보통 벽 옆에 있습니다.

1717
01:09:04,883 --> 01:09:07,300
의자는 보통 테이블 옆에 있습니다.

1718
01:09:07,300 --> 01:09:09,000
그래서 당신은 그들을 관련

1719
01:09:09,000 --> 01:09:12,580
없는 부분이나 객체의 집합으로 표현하고 싶지 않습니다.

1720
01:09:12,580 --> 01:09:15,000
그들의 관계도 포착하고 싶습니다.

1721
01:09:15,000 --> 01:09:18,008
계층 구조에서, 당신이 건축을

1722
01:09:18,008 --> 01:09:20,300
할 때, 당신이 무언가를

1723
01:09:20,300 --> 01:09:21,640
구축할 때.

1724
01:09:21,640 --> 01:09:22,580
당신은 건축가입니다.

1725
01:09:22,580 --> 01:09:26,000
당신이 건물을 설계할 때, 물론 당신은 단순히

1726
01:09:26,000 --> 01:09:29,180
객체나 그들의 관계를 표현하는 것이 아닙니다.

1727
01:09:29,180 --> 01:09:30,580
당신은 무엇을 먼저

1728
01:09:30,580 --> 01:09:31,960
구축할지를 고려해야 합니다.

1729
01:09:31,960 --> 01:09:33,520
교실이 있고, 교실에는

1730
01:09:33,520 --> 01:09:35,580
테이블과 의자가 있으며, 의자에는

1731
01:09:35,580 --> 01:09:36,740
부품이 있습니다.

1732
01:09:36,740 --> 01:09:38,840
기본적으로 계층 구조의 수준이

1733
01:09:38,840 --> 01:09:41,752
있으며, 이것이 신경망과 어떻게 사용되고 통합될

1734
01:09:41,752 --> 01:09:43,960
수 있는지, 계층뿐만 아니라

1735
01:09:43,960 --> 01:09:46,180
계층과 관계를 구성할 수 있습니다.

1736
01:09:46,180 --> 01:09:48,722
그래서 당신은 계층 그래프를 가지고 있습니다.

1737
01:09:48,722 --> 01:09:50,680
예를 들어 의자의 경우, 기초, 좌석,

1738
01:09:50,680 --> 01:09:53,340
등받이에 대한 서로 다른 수준의 계층이 있습니다.

1739
01:09:53,340 --> 01:09:55,520
그리고 기초는 서로 다른 다리를 가질 수 있습니다.

1740
01:09:55,520 --> 01:09:57,520
하지만 다리 자체도 서로 관련이 있습니다.

1741
01:09:57,520 --> 01:09:59,760
의자의 왼쪽 다리와 오른쪽 다리는

1742
01:09:59,760 --> 01:10:01,180
대칭이어야 합니다.

1743
01:10:01,180 --> 01:10:03,380
그리고 그들은 동일한 형태를 가져야 합니다.

1744
01:10:03,380 --> 01:10:05,780
이 다리들이 있는 위치에 대한 제약이 있습니다.

1745
01:10:05,780 --> 01:10:08,180
그들은 정말로 정렬되어야 하며, 그렇지 않으면

1746
01:10:08,180 --> 01:10:09,400
의자가 넘어질 것입니다.

1747
01:10:09,400 --> 01:10:10,817
그래서 유용한

1748
01:10:10,817 --> 01:10:12,560
제약이 많이 있습니다.

1749
01:10:12,560 --> 01:10:13,960
그렇다면 우리는 그것들을 어떻게 표현할 수 있을까요?

1750
01:10:13,960 --> 01:10:16,520
사람들은 이러한 다양한 표현을 생각해냅니다.

1751
01:10:16,520 --> 01:10:19,060
각각에 대해, 이러한 제약을

1752
01:10:19,060 --> 01:10:21,620
만족하는 객체를 학습하고 포착하며

1753
01:10:21,620 --> 01:10:24,300
생성하도록 설계된 많은 신경망과

1754
01:10:24,300 --> 01:10:26,180
딥러닝 방법이 있습니다.

1755
01:10:26,180 --> 01:10:29,820
예를 들어, 이것은 계층적 그래프이며,

1756
01:10:29,820 --> 01:10:33,580
모든 제약을 만족하면서 계층을 유지하는

1757
01:10:33,580 --> 01:10:37,300
3D 의자를 표현하고 생성하려고 하는

1758
01:10:37,300 --> 01:10:39,392
인코더와 디코더입니다.

1759
01:10:39,392 --> 01:10:43,660
이것은 2019년 레오니다스 그룹의 연구에서 나온 것 같습니다.

1760
01:10:43,660 --> 01:10:45,660
때때로 우리는 반복과 for

1761
01:10:45,660 --> 01:10:47,380
루프와 같은 프로그램의 형태를

1762
01:10:47,380 --> 01:10:49,260
사용하여 형태를 표현할 수

1763
01:10:49,260 --> 01:10:52,070
있으며, 이것이 신경망을 사용하여 객체

1764
01:10:52,070 --> 01:10:54,070
형태를 합성하고 이 객체 부분

1765
01:10:54,070 --> 01:10:57,630
간의 관계를 합성하는 프로그램을 생성하는 데 어떻게 통합될

1766
01:10:57,630 --> 01:10:59,190
수 있는지 보여줍니다.

1767
01:10:59,190 --> 01:11:01,230
이것도 중요한 주제입니다.

1768
01:11:01,230 --> 01:11:05,390
최근 1년 또는 2년 동안 딥 네트워크나

1769
01:11:05,390 --> 01:11:08,270
대형 언어 모델이 매우

1770
01:11:08,270 --> 01:11:11,750
잘 작동하고, 사물을 잘

1771
01:11:11,750 --> 01:11:15,230
이해하고 있다는 새로운 경향이 있다고

1772
01:11:15,230 --> 01:11:16,930
생각합니다.

1773
01:11:16,930 --> 01:11:19,990
우리가 GPT와 같은 대형 언어 모델을 사용하여 이러한

1774
01:11:19,990 --> 01:11:22,470
프로그램을 출력할 수 있을까요? 그들은

1775
01:11:22,470 --> 01:11:23,910
의미론과 의자가 어떻게 되어야

1776
01:11:23,910 --> 01:11:25,070
하는지를 이해합니다.

1777
01:11:25,070 --> 01:11:26,970
의자가 만족해야 할 제약은 무엇인가요?

1778
01:11:26,970 --> 01:11:29,220
그렇다면 대형 언어 모델을 사용하여 프로그램을

1779
01:11:29,220 --> 01:11:30,330
출력할 수 있을까요?

1780
01:11:30,330 --> 01:11:32,950
하지만 아마도 특정 객체 부분의 기하학적 세부

1781
01:11:32,950 --> 01:11:34,430
사항을 포착하기 위해 어떤

1782
01:11:34,430 --> 01:11:37,570
암묵적 함수나 다른 방법을 사용할 수 있을 것입니다.

1783
01:11:37,570 --> 01:11:39,870
현재 이러한 새로운 연구

1784
01:11:39,870 --> 01:11:42,390
경향이 나타나고 있습니다.

1785
01:11:42,390 --> 01:11:43,770
좋습니다, 제가 할 말은 이게 전부입니다.

1786
01:11:43,770 --> 01:11:45,580
감사합니다.
