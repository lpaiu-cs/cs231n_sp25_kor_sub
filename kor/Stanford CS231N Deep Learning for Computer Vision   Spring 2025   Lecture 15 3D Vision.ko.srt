1
00:00:05,440 --> 00:00:08,160
이번 강의의 다음 초청 연사인 Jiajun

2
00:00:08,160 --> 00:00:11,120
Wu 교수님을 소개하게 되어 정말 기쁩니다.

3
00:00:11,120 --> 00:00:14,597
Jiajun 교수님은 스탠포드

4
00:00:14,597 --> 00:00:16,180
컴퓨터과학과의 조교수로,

5
00:00:16,180 --> 00:00:22,720
Stanford Vision and Learning Lab의

6
00:00:22,720 --> 00:00:24,040
교수진이십니다.

7
00:00:24,040 --> 00:00:27,240
교수님의 연구는 멀티모달 인지, 로보틱스

8
00:00:27,240 --> 00:00:31,360
및 구현된 AI, 시각적 생성과 추론, 그리고 3D

9
00:00:31,360 --> 00:00:35,740
이해에 중점을 둔 장면 이해에 집중되어 있으며, 오늘 강의

10
00:00:35,740 --> 00:00:38,120
주제도 바로 3D 이해입니다.

11
00:00:38,120 --> 00:00:41,920
그럼 이제 Jiajun 교수님께 오늘 강의를 시작하도록 넘기겠습니다.

12
00:00:41,920 --> 00:00:43,340
네, 안녕하세요, 저는 Jiajun입니다.

13
00:00:43,340 --> 00:00:44,860
저는 이곳에서 조교수로 일하고 있습니다.

14
00:00:44,860 --> 00:00:46,360
몇 년 전에는 이

15
00:00:46,360 --> 00:00:48,840
수업을 공동 강의하기도 했습니다.

16
00:00:48,840 --> 00:00:51,940
올해가 10주년이라고 들었어요.

17
00:00:51,940 --> 00:00:55,360
그래서 여러 곳에서 초청 연사들이 오셨습니다.

18
00:00:55,360 --> 00:00:58,520
오늘은 3D 비전에 대해 이야기할 예정입니다.

19
00:00:58,520 --> 00:01:01,130
이전 몇 주 동안은 합성곱

20
00:01:01,130 --> 00:01:05,938
신경망, 트랜스포머, 그리고 아마도 비전-언어 모델과

21
00:01:05,938 --> 00:01:07,730
생성 모델에 대해

22
00:01:07,730 --> 00:01:09,970
배웠는데, 오늘 내용은

23
00:01:09,970 --> 00:01:12,100
좀 다를 수 있습니다.

24
00:01:12,100 --> 00:01:13,730
네, 알겠습니다.

25
00:01:13,730 --> 00:01:16,690
3D에 대해 먼저 3D 표현 방식이

26
00:01:16,690 --> 00:01:19,730
무엇인지 조금 소개하겠습니다.

27
00:01:19,730 --> 00:01:22,370
이 부분은 딥러닝과는 꽤 거리가 있을

28
00:01:22,370 --> 00:01:23,430
수 있습니다.

29
00:01:23,430 --> 00:01:25,850
하지만 딥러닝이나 AI가 3D 비전을 어떻게

30
00:01:25,850 --> 00:01:29,010
변화시켰고, 어떻게 다양한 방식으로 통합될 수

31
00:01:29,010 --> 00:01:30,290
있는지 이야기할 겁니다.

32
00:01:30,290 --> 00:01:32,930
그리고 3D 생성, 재구성 등 몇

33
00:01:32,930 --> 00:01:35,570
가지 다양한 응용 분야도 살펴보겠습니다.

34
00:01:35,570 --> 00:01:39,050
좋습니다, 그럼 3D에서 객체를 표현하는 가능한 방법들이

35
00:01:39,050 --> 00:01:41,070
무엇인지부터 살펴보겠습니다.

36
00:01:41,070 --> 00:01:42,755
2D에서는 너무나 간단하니까요.

37
00:01:42,755 --> 00:01:44,130
그냥 픽셀들이 있는 것처럼 보이죠.

38
00:01:44,130 --> 00:01:47,750
PNG 파일이나 JPEG 파일을 불러오는 것과 같습니다.

39
00:01:47,750 --> 00:01:50,130
200x200 픽셀 정도인 거죠.

40
00:01:50,130 --> 00:01:51,950
그런데 3D 객체는 어떻게 표현할 수 있을까요?

41
00:01:51,950 --> 00:01:54,890
이게 우리가 먼저 살펴봐야 할 첫 번째 문제라고 생각합니다.

42
00:01:54,890 --> 00:01:59,260
3D 객체는 매우 다양할 수 있습니다.

43
00:01:59,260 --> 00:02:01,520
다양한 크기일 수 있고요.

44
00:02:01,520 --> 00:02:05,580
거대하고 큰 건물이나 나무, 복잡한 구조물도 있을 수 있습니다.

45
00:02:05,580 --> 00:02:09,380
그리고 확대해 보면 아주 세밀한 디테일도 볼 수 있죠.

46
00:02:09,380 --> 00:02:11,820
그렇다면 이런 다양한 크기와 특징을

47
00:02:11,820 --> 00:02:14,420
가진 여러 종류의 3D 객체를 표현하기 위한

48
00:02:14,420 --> 00:02:16,860
최적의 3D 표현 방법은 무엇일까요?

49
00:02:16,860 --> 00:02:20,220
이미지와 달리, 이미지에서는 모두가 픽셀을 사용해서

50
00:02:20,220 --> 00:02:24,260
200x200, 500x500 같은 식으로 표현하잖아요.

51
00:02:24,260 --> 00:02:27,780
3D 객체를 표현하는 방법은 기하학(geometry),

52
00:02:27,780 --> 00:02:28,650
3D 객체를 표현하는 방법은 기하학(geometry),

53
00:02:28,650 --> 00:02:29,400
텍스처(texture),

54
00:02:29,400 --> 00:02:30,320
재질(material) 같은 요소들이 있습니다.

55
00:02:30,320 --> 00:02:32,640
하지만 우선 기하학부터 살펴보는 것으로 시작해 보겠습니다.

56
00:02:32,640 --> 00:02:34,495
3D 객체 기하학만 해도

57
00:02:34,495 --> 00:02:36,620
표현 방법이 정말 다양합니다.

58
00:02:36,620 --> 00:02:39,680
기본적으로 두 가지 범주로 나눌 수 있습니다.

59
00:02:39,680 --> 00:02:41,860
하나는 명시적 표현(explicit representations)이라고
합니다.

60
00:02:41,860 --> 00:02:45,140
어떤 의미에서는 객체의 일부를 직접,

61
00:02:45,140 --> 00:02:46,700
명확하게 표현하는

62
00:02:46,700 --> 00:02:47,680
방식입니다.

63
00:02:47,680 --> 00:02:50,160
여기에는 3D 점들의 구름인

64
00:02:50,160 --> 00:02:52,460
포인트 클라우드, 폴리곤

65
00:02:52,460 --> 00:02:55,720
메쉬, 서브디비전 등이 포함되며,

66
00:02:55,720 --> 00:02:59,063
이 부분은 나중에 다룰 예정입니다.

67
00:02:59,063 --> 00:03:00,480
다른 범주의 객체 형태 표현도

68
00:03:00,480 --> 00:03:03,550
있는데, 이를 암시적 표현(implicit)이라고 부릅니다.

69
00:03:03,550 --> 00:03:05,300
이 부분도 곧 설명할 것입니다.

70
00:03:05,300 --> 00:03:07,425
나중에 레벨셋(level sets), 대수적 표면(algebraic

71
00:03:07,425 --> 00:03:09,840
surfaces), 거리 함수(distance functions) 등을
포함해

72
00:03:09,840 --> 00:03:10,660
자세히 설명하겠습니다.

73
00:03:10,660 --> 00:03:13,080
기본적으로 3D 객체나

74
00:03:13,080 --> 00:03:14,680
기하학을 함수로 표현하는

75
00:03:14,680 --> 00:03:17,720
방식인데, 단순히 점들의 집합처럼

76
00:03:17,720 --> 00:03:19,985
직관적이지는 않습니다.

77
00:03:19,985 --> 00:03:21,360
하지만 나중에

78
00:03:21,360 --> 00:03:24,280
보시겠지만, 암시적 표현도 나름의

79
00:03:24,280 --> 00:03:26,240
장점과 단점이 있습니다.

80
00:03:26,240 --> 00:03:29,240
각 표현 방식은 적합한 작업과 기하학 유형이

81
00:03:29,240 --> 00:03:30,155
있습니다.

82
00:03:30,155 --> 00:03:32,280
특히 딥러닝 맥락에서는,

83
00:03:32,280 --> 00:03:34,488
딥러닝 기법을 적용할 때

84
00:03:34,488 --> 00:03:37,960
각 방식마다 강점과 약점이 존재합니다.

85
00:03:37,960 --> 00:03:41,480
그렇다면 언제 어떤 표현을 선택해야 할까요?

86
00:03:41,480 --> 00:03:43,480
저장해야 하는데, 픽셀은

87
00:03:43,480 --> 00:03:45,640
행렬 형태라 저장이 쉽습니다.

88
00:03:45,640 --> 00:03:48,620
반면 3D 포인트 클라우드는 더 불규칙적입니다.

89
00:03:48,620 --> 00:03:51,320
그리고 특히 객체를 함수로 표현하는 것

90
00:03:51,320 --> 00:03:53,340
같은 암묵적 표현을 사용할 때,

91
00:03:53,340 --> 00:03:56,090
그것을 컴퓨터에 어떻게 저장할 수 있을까요?

92
00:03:56,090 --> 00:03:59,370
그리고 그것이 새로운 형태를 만드는 것을 어떻게 지원할까요?

93
00:03:59,370 --> 00:04:02,210
특히 지금은 입력이 사진이거나 언어

94
00:04:02,210 --> 00:04:04,770
설명일 수도 있다고 가정해 봅시다.

95
00:04:04,770 --> 00:04:06,390
그리고 다양한 종류의 연산이

96
00:04:06,390 --> 00:04:07,550
있습니다-- 3D 객체가 있죠.

97
00:04:07,550 --> 00:04:10,370
그럼 그것을 어떻게 편집하고, 단순화하고, 부드럽게 하고, 필터링하고,

98
00:04:10,370 --> 00:04:11,310
수리할 수 있을까요?

99
00:04:11,310 --> 00:04:12,850
그래서 훨씬 더 많은 작업을 해야 할 수도 있습니다.

100
00:04:12,850 --> 00:04:14,917
이미지의 경우에도 때때로 그렇게 하고 싶을 때가 있습니다.

101
00:04:14,917 --> 00:04:15,750
편집하고 싶을 때가 있죠.

102
00:04:15,750 --> 00:04:17,208
언어를 사용해서 편집하고 싶을 때가 있습니다.

103
00:04:17,208 --> 00:04:19,010
스트로크를 사용해서 편집하고 싶을 때도 있죠.

104
00:04:19,010 --> 00:04:22,210
그리고 3D 객체와 렌더링에 대해 어떻게 편집하거나 어떤

105
00:04:22,210 --> 00:04:24,070
종류의 연산을 수행할 수 있을까요?

106
00:04:24,070 --> 00:04:28,112
그 3D 객체를 어떻게 2D 픽셀로 바꿀 수 있을까요?

107
00:04:28,112 --> 00:04:29,070
어떤 면에서는 할 수 있습니다.

108
00:04:29,070 --> 00:04:31,210
3D 비전은 그 과정을 역전시키는 것입니다.

109
00:04:31,210 --> 00:04:35,432
어떻게 2D 이미지에서 3D 객체를 재구성할 수 있을까요?

110
00:04:35,432 --> 00:04:37,390
그래서 특히 3D 인간이나

111
00:04:37,390 --> 00:04:40,870
동물을 모델링하고 애니메이션을 만들고 싶을 때,

112
00:04:40,870 --> 00:04:43,790
애니메이션을 포함한 이 모든 다양한 요소들을

113
00:04:43,790 --> 00:04:46,130
어떻게 지원하는지가 중요합니다.

114
00:04:46,130 --> 00:04:49,170
그리고 물론, 이 모든 것을 연결하는 또

115
00:04:49,170 --> 00:04:51,780
다른 점은, 예를 들어 형태 편집,

116
00:04:51,780 --> 00:04:55,180
렌더링, 역렌더링, 그리고 애니메이션 같은 다양한

117
00:04:55,180 --> 00:04:57,260
딥러닝 방법들과의 통합입니다.

118
00:04:57,260 --> 00:04:59,380
그래서 아주 빠르게, 포인트 클라우드

119
00:04:59,380 --> 00:05:01,780
같은 몇 가지 표현들을 살펴볼 수 있습니다.

120
00:05:01,780 --> 00:05:05,820
포인트 클라우드는 아마 가장 간단한 표현일 겁니다.

121
00:05:05,820 --> 00:05:07,120
3D 점들만 가지고 있죠.

122
00:05:07,120 --> 00:05:09,508
연결성이 없어서 이 점들이 어떻게 연결되어

123
00:05:09,508 --> 00:05:10,800
있는지는 포착하지 못합니다.

124
00:05:10,800 --> 00:05:12,383
그래서 기본적으로 n

125
00:05:12,383 --> 00:05:14,260
곱하기 [?] 행렬 대신에, n ? 사진 속 모든 픽셀의

126
00:05:14,260 --> 00:05:16,660
픽셀 값에 대한 행렬 대신에,

127
00:05:16,660 --> 00:05:20,060
이제는 3 곱하기 n 행렬이 있는데,

128
00:05:20,060 --> 00:05:23,960
여기서 3은 각 점의 x, y, z 좌표입니다.

129
00:05:23,960 --> 00:05:26,300
그리고 점의 개수가 있습니다.

130
00:05:26,300 --> 00:05:29,853
때때로, 점의 표면 법선도 표현할 수 있어서,

131
00:05:29,853 --> 00:05:32,020
3D 공간에서 점이 어디에

132
00:05:32,020 --> 00:05:35,960
있는지뿐 아니라 어느 방향을 향하는지도 알 수 있습니다.

133
00:05:35,960 --> 00:05:38,740
그래서 표면 법선이 조금 더 많은

134
00:05:38,740 --> 00:05:40,240
정보를 제공합니다.

135
00:05:40,240 --> 00:05:42,180
때때로 사람들은 이를 방향성을

136
00:05:42,180 --> 00:05:46,020
가진 점이라는 의미로 surfels라고 부르기도 합니다.

137
00:05:46,020 --> 00:05:48,322
네, 그렇다면 왜 표면 법선이 필요할까요?

138
00:05:48,322 --> 00:05:49,780
렌더링을 하려면,

139
00:05:49,780 --> 00:05:52,430
물체가 어떻게 보이는지 말해야

140
00:05:52,430 --> 00:05:55,310
하니까, 조명 원천을 지정해야 합니다.

141
00:05:55,310 --> 00:05:57,350
조명이 어디서 오는지 말이죠.

142
00:05:57,350 --> 00:05:59,430
하지만 렌더링을 현실감 있게

143
00:05:59,430 --> 00:06:01,630
만들려면, 특정 방향에서 오는

144
00:06:01,630 --> 00:06:03,350
조명이 점과 어떻게

145
00:06:03,350 --> 00:06:05,090
상호작용하는지를 고려해야 합니다.

146
00:06:05,090 --> 00:06:07,230
이때 표면 법선이 사용되어

147
00:06:07,230 --> 00:06:10,070
렌더링을 현실감 있게 만드는데 도움을

148
00:06:10,070 --> 00:06:12,550
줍니다. 여기서 보실 수 있죠.

149
00:06:12,550 --> 00:06:14,590
그럼 점들은 어떻게 얻을 수 있을까요?

150
00:06:14,590 --> 00:06:18,790
포인트 클라우드의 장점은, 많은 3D 센서들, 예를

151
00:06:18,790 --> 00:06:21,710
들어 깊이 센서나 3D 스캐너에서

152
00:06:21,710 --> 00:06:25,110
원시(raw) 형식으로 얻는 경우가 많다는 겁니다.

153
00:06:25,110 --> 00:06:27,970
요즘은 아이폰 같은 기기도 사용할 수 있을 겁니다.

154
00:06:27,970 --> 00:06:30,870
AR 키트 같은 소프트웨어가 3D 객체를 스캔할

155
00:06:30,870 --> 00:06:32,230
수 있게 해주죠.

156
00:06:32,230 --> 00:06:34,770
하지만 그 센서들의 원시 출력은 여전히 3D

157
00:06:34,770 --> 00:06:36,050
포인트 클라우드입니다.

158
00:06:36,050 --> 00:06:37,550
물론 그 후에는 처리하고

159
00:06:37,550 --> 00:06:40,103
융합해서 텍스처가 있는 객체처럼

160
00:06:40,103 --> 00:06:41,020
만들어야 합니다.

161
00:06:43,590 --> 00:06:45,570
그래서 네, 보통 스캐너에서 나온 결과물입니다.

162
00:06:45,570 --> 00:06:47,185
잠재적으로 매우 노이즈가 많을 수 있습니다.

163
00:06:47,185 --> 00:06:48,810
이런 것들이 있고,

164
00:06:48,810 --> 00:06:52,130
융합하고 합치고 수리해야 하죠.

165
00:06:52,130 --> 00:06:54,650
이 과정에서는 서로 다른

166
00:06:54,650 --> 00:06:57,770
사진들이 어떻게 정합되어 공유된 포인트

167
00:06:57,770 --> 00:07:00,810
클라우드를 만드는지 고려해야 합니다.

168
00:07:00,810 --> 00:07:04,490
포인트 클라우드는 매우 유연해서, 점들을 여기저기

169
00:07:04,490 --> 00:07:05,870
옮길 수 있습니다.

170
00:07:05,870 --> 00:07:07,850
그래서 기본적으로 어떤 종류의 객체

171
00:07:07,850 --> 00:07:09,110
기하도 표현할 수 있습니다.

172
00:07:09,110 --> 00:07:11,770
토폴로지 같은 제약이 없습니다.

173
00:07:11,770 --> 00:07:14,290
다양한 객체 집합을 고려해야

174
00:07:14,290 --> 00:07:17,330
할 때 큰 데이터셋에 유용합니다.

175
00:07:17,330 --> 00:07:20,370
왜냐하면 점들이 이미 어떤 의미에서는

176
00:07:20,370 --> 00:07:23,390
미리 샘플링된 것으로 간주되기 때문입니다.

177
00:07:23,390 --> 00:07:26,830
그래서 만약 점이 많다면-- 객체를 표현하는데,

178
00:07:26,830 --> 00:07:29,342
예를 들어 토끼의 머리에는

179
00:07:29,342 --> 00:07:31,050
점이 아주 많고 꼬리에는

180
00:07:31,050 --> 00:07:34,090
점이 매우 적게 고르게 샘플링되어 있다면,

181
00:07:34,090 --> 00:07:35,690
이런 부족하게

182
00:07:35,690 --> 00:07:37,650
샘플링된 영역에서 샘플을 뽑는

183
00:07:37,650 --> 00:07:39,470
것이 사실 어렵습니다.

184
00:07:39,470 --> 00:07:41,950
그래서 때때로, 사람들이 점을 샘플링할

185
00:07:41,950 --> 00:07:43,490
때는 객체의 여러

186
00:07:43,490 --> 00:07:45,770
부분에 걸쳐 대략 고르게 샘플링되도록

187
00:07:45,770 --> 00:07:48,020
알고리즘을 설계해야 합니다.

188
00:07:48,020 --> 00:07:50,900
그리고 다른 한계점으로는, 때때로 매우 유용한

189
00:07:50,900 --> 00:07:52,460
연산들, 예를 들어

190
00:07:52,460 --> 00:07:55,340
단순화나 세분화 같은 것을 이런 객체에 직접

191
00:07:55,340 --> 00:07:57,460
수행하는 방법이 명확하지 않습니다.

192
00:07:57,460 --> 00:08:00,500
이것은 부드러운 렌더링을 직접적으로 허용하지 않습니다.

193
00:08:00,500 --> 00:08:02,620
위상학적 정보가 없습니다.

194
00:08:02,620 --> 00:08:06,620
예를 들어 여기 점들의 집합이 있다고 하면, 이것이

195
00:08:06,620 --> 00:08:11,540
토러스인지 아니면 고리 모양인지조차 알 수 없습니다, 왜냐하면 이

196
00:08:11,540 --> 00:08:14,588
점들이 어떻게 연결되어 있는지 알려주지

197
00:08:14,588 --> 00:08:15,880
않기 때문입니다.

198
00:08:15,880 --> 00:08:20,220
그래서 점 구름만 있으면 객체가 무엇인지에 대한 부분적인

199
00:08:20,220 --> 00:08:21,783
정보만 있는 셈입니다.

200
00:08:21,783 --> 00:08:23,200
그래서 자연스럽게 사람들은

201
00:08:23,200 --> 00:08:25,468
이렇게 말하죠, 어떻게 하면 더 많은

202
00:08:25,468 --> 00:08:27,260
정보를 포착해서 이 두 다른

203
00:08:27,260 --> 00:08:28,540
객체를 구분할 수 있을까?

204
00:08:28,540 --> 00:08:32,440
그다음 자연스럽게, 그것은 폴리곤 메쉬로 넘어갑니다.

205
00:08:32,440 --> 00:08:36,080
그래서 객체를 여전히 점들의 집합으로 표현하지만, 이 점들이

206
00:08:36,080 --> 00:08:38,507
어떻게 연결되어 있는지도 나타냅니다.

207
00:08:38,507 --> 00:08:40,840
이제 점뿐만 아니라 면, 즉

208
00:08:40,840 --> 00:08:43,179
표면도 포함하게 되는 거죠.

209
00:08:43,179 --> 00:08:45,930
그리고 이것은 아마도, 제가 말하길, 모든

210
00:08:45,930 --> 00:08:48,310
그래픽 엔진과 컴퓨터 게임 등에서

211
00:08:48,310 --> 00:08:51,350
3D 객체를 표현하는 데 가장 널리 사용되는

212
00:08:51,350 --> 00:08:54,630
방식입니다. 기본적으로 모두 폴리곤 메쉬로 표현됩니다.

213
00:08:54,630 --> 00:08:57,010
하지만 면을 표현하려면 더

214
00:08:57,010 --> 00:09:00,990
복잡해집니다. 특히 원시 메쉬를 보면, 각 면이

215
00:09:00,990 --> 00:09:03,040
서로 다른 수의 점을

216
00:09:03,040 --> 00:09:05,290
가질 수 있기 때문입니다.

217
00:09:05,290 --> 00:09:07,873
어떤 면은 세 점, 어떤 면은 네 점 또는 다섯 점을 가질 수 있습니다.

218
00:09:07,873 --> 00:09:10,310
그리고 특히 초기 단계에서 사람들이 합성곱

219
00:09:10,310 --> 00:09:12,645
신경망을 시작할 때 항상 고정된

220
00:09:12,645 --> 00:09:15,270
해상도를 가정하는데, 이런 불규칙성을 가진 면들을

221
00:09:15,270 --> 00:09:17,070
어떻게 표현하고 신경망과 통합할

222
00:09:17,070 --> 00:09:18,930
수 있을지 고민해야 합니다.

223
00:09:18,930 --> 00:09:20,650
여기서는 원시

224
00:09:20,650 --> 00:09:24,730
정보의 차원이 가변적이라고 할 수 있습니다.

225
00:09:24,730 --> 00:09:26,610
그것이 딥러닝과 어떻게 통합되나요?

226
00:09:26,610 --> 00:09:27,770
그것은 큰 도전 과제였습니다.

227
00:09:27,770 --> 00:09:30,410
그래서 3D 비전과 딥러닝이

228
00:09:30,410 --> 00:09:33,270
다소 늦게 시작된 이유가, 사람들이

229
00:09:33,270 --> 00:09:36,870
이미지처럼 통일되지 않은 복잡한 객체 표현을

230
00:09:36,870 --> 00:09:40,070
다루기 위해 딥러닝 방법을 어떻게

231
00:09:40,070 --> 00:09:42,270
적용할지 고민했기 때문입니다.

232
00:09:42,270 --> 00:09:44,140
하지만 메시는 매우 널리 사용되며,

233
00:09:44,140 --> 00:09:45,880
모든 세부사항을 포착하는

234
00:09:45,880 --> 00:09:47,680
매우 복잡한 메시일 수 있습니다.

235
00:09:47,680 --> 00:09:49,215
예를 들어, 스캐너가 있습니다.

236
00:09:49,215 --> 00:09:50,840
포인트를 얻고, 그것들을 융합합니다.

237
00:09:50,840 --> 00:09:52,260
그리고 어떤 알고리즘을 적용하죠.

238
00:09:52,260 --> 00:09:54,860
매우 큰 메시를 얻을 수 있습니다.

239
00:09:54,860 --> 00:09:58,320
이 메시에는 조각상을 표현하기 위해

240
00:09:58,320 --> 00:10:04,200
5600만 개의 삼각형과 2800만 개의 정점이 있습니다.

241
00:10:04,200 --> 00:10:06,480
더 큰 메시도 있을 수 있는데, 예를 들어 Google

242
00:10:06,480 --> 00:10:07,420
Earth에서요.

243
00:10:07,420 --> 00:10:08,820
그들은 수조 개의 삼각형을 가지고 있습니다.

244
00:10:08,820 --> 00:10:13,138
기본적으로 지구상의 모든 건물을 표현하려는 거죠.

245
00:10:13,138 --> 00:10:15,680
메시의 좋은 점은 세분화 같은 많은 연산을

246
00:10:15,680 --> 00:10:16,657
지원한다는 겁니다.

247
00:10:16,657 --> 00:10:18,240
또는 더 많은 세부사항을

248
00:10:18,240 --> 00:10:22,837
원할 때, 더 많은 메시를 사용해 형태의 세부를 포착할 수 있습니다.

249
00:10:22,837 --> 00:10:24,420
그리고 단순화도 할 수 있습니다.

250
00:10:24,420 --> 00:10:25,962
때로는 매우 빠르게 처리해야 할 때가

251
00:10:25,962 --> 00:10:28,140
있어서, 그럴 땐 그렇게 많은 메시가 필요하지 않습니다.

252
00:10:28,140 --> 00:10:30,640
간단하게 설명하자면, 이미

253
00:10:30,640 --> 00:10:34,520
그런 작업을 할 수 있는 알고리즘들이 존재합니다.

254
00:10:34,520 --> 00:10:37,520
그리고 정규화라는 게 있는데, 불규칙한 메쉬가

255
00:10:37,520 --> 00:10:39,360
있을 때, 모든 면이 삼각형이고

256
00:10:39,360 --> 00:10:42,140
항상 세 개의 꼭짓점이 연결되도록

257
00:10:42,140 --> 00:10:43,840
정규화하고 싶을 때가 있습니다.

258
00:10:43,840 --> 00:10:47,300
이 삼각형들은 대략 같은 크기를 가지게 해서 처리하기가

259
00:10:47,300 --> 00:10:48,360
더 쉬워집니다.

260
00:10:48,360 --> 00:10:51,100
또한, 이런 메쉬들은 앞으로 다양한

261
00:10:51,100 --> 00:10:54,660
그래픽 알고리즘과 메쉬 처리에 유리한 좋은 특성을

262
00:10:54,660 --> 00:10:55,580
갖게 됩니다.

263
00:10:55,580 --> 00:10:58,080
이런 알고리즘을 개발한 사람들도

264
00:10:58,080 --> 00:11:01,600
있어서, 기본적으로 서로 다른 영역의 점들이

265
00:11:01,600 --> 00:11:04,100
대략 고르게 샘플링되도록 보장할 수

266
00:11:04,100 --> 00:11:05,220
있습니다.

267
00:11:05,220 --> 00:11:07,740
예를 들어, 토끼의 머리 부분이

268
00:11:07,740 --> 00:11:09,620
꼬리보다 훨씬 더 촘촘히

269
00:11:09,620 --> 00:11:12,060
샘플링되는 일이 없도록 하는 거죠.

270
00:11:12,060 --> 00:11:14,927
자, 이것이 한 가지 형태의 형태 표현 방식입니다.

271
00:11:14,927 --> 00:11:16,760
그리고 또 다른 형태의 표현 방식도

272
00:11:16,760 --> 00:11:20,740
있는데, 예를 들어 파라메트릭 표현입니다. 왜냐하면 객체가 완전히 불규칙한

273
00:11:20,740 --> 00:11:22,308
것만은 아니기 때문입니다.

274
00:11:22,308 --> 00:11:24,100
점들의 집합만 있는 게 아니죠.

275
00:11:24,100 --> 00:11:26,000
메쉬는 매우 일반적이지만,

276
00:11:26,000 --> 00:11:27,920
때로는 많은 정보를 잃게 됩니다.

277
00:11:27,920 --> 00:11:30,460
예를 들어, 의자나 탁자를 보면

278
00:11:30,460 --> 00:11:31,877
직선들이 많죠.

279
00:11:31,877 --> 00:11:34,127
그런 직선들을 어떻게 표현할 수 있을까요?

280
00:11:34,127 --> 00:11:35,940
사람들이 디자인할 때는

281
00:11:35,940 --> 00:11:38,700
이런 파라메트릭 표현을 자주 사용합니다.

282
00:11:38,700 --> 00:11:41,390
그래서 형태를 함수로 표현할 수 있습니다.

283
00:11:41,390 --> 00:11:42,510
생각해 보세요.

284
00:11:42,510 --> 00:11:45,870
디자인할 때, 표면이나 곡선을

285
00:11:45,870 --> 00:11:48,690
표현하고 싶으면, 실제로

286
00:11:48,690 --> 00:11:51,670
자유도는 더 낮습니다.

287
00:11:51,670 --> 00:11:53,870
곡선이라면 보통

288
00:11:53,870 --> 00:11:55,683
자유도가 하나뿐이죠.

289
00:11:55,683 --> 00:11:57,350
그래서 곡선을

290
00:11:57,350 --> 00:12:01,350
함수 f(x)로 표현할 수 있습니다. x를 변화시키면 y 값을 얻는 거죠.

291
00:12:01,350 --> 00:12:03,750
기본적으로 2D뿐 아니라

292
00:12:03,750 --> 00:12:08,790
3D에서도 이런 다양한 함수들을 사용해서,

293
00:12:08,790 --> 00:12:11,390
객체의 내재된 차원

294
00:12:11,390 --> 00:12:13,890
수(보통 2 또는

295
00:12:13,890 --> 00:12:17,370
1)를 몇 개의 변수로 매핑하고,

296
00:12:17,370 --> 00:12:19,990
그걸 다시 3D

297
00:12:19,990 --> 00:12:22,830
공간으로 변환할 수

298
00:12:22,830 --> 00:12:23,790
있습니다.

299
00:12:23,790 --> 00:12:26,970
이렇게 하면 함수 집합을 이용해 3D 객체를 파라메트릭 표현으로 나타낼 수
있습니다.

300
00:12:26,970 --> 00:12:28,990
곡선, 예를 들어

301
00:12:28,990 --> 00:12:30,950
원을 표현할

302
00:12:30,950 --> 00:12:33,190
때도 마찬가지입니다.

303
00:12:33,190 --> 00:12:35,850
원 하나를 표현하려면 꼭 많은 점을 샘플링하거나,

304
00:12:35,850 --> 00:12:37,230
메쉬처럼 선으로 연결할 필요는 없습니다.

305
00:12:37,230 --> 00:12:40,120
다른 방법은 원의 곡선을 함수로

306
00:12:40,120 --> 00:12:41,782
표현하는 겁니다.

307
00:12:41,782 --> 00:12:43,240
기본적으로 사인

308
00:12:43,240 --> 00:12:48,500
함수와 코사인 함수가 있고, 변수 t만 변화시키면 됩니다.

309
00:12:48,500 --> 00:12:50,700
t는 각도나 도 단위로 생각할 수

310
00:12:50,700 --> 00:12:52,940
있고, 원 위의 모든 점으로 매핑됩니다.

311
00:12:52,940 --> 00:12:56,560
이제 함수 하나로 2D 곡선의 파라메트릭

312
00:12:56,560 --> 00:12:59,100
표현을 할 수 있습니다.

313
00:12:59,100 --> 00:13:01,580
물론 3D에서도 가능합니다.

314
00:13:01,580 --> 00:13:03,440
구를 표현하려면

315
00:13:03,440 --> 00:13:07,382
자유도 두 개, u와 v만 있으면 되고,

316
00:13:07,382 --> 00:13:09,840
이 함수들을 통해 3D

317
00:13:09,840 --> 00:13:14,200
공간의 구 위 모든 점으로 매핑할 수 있습니다.

318
00:13:14,200 --> 00:13:15,480
사람들이 설계한 것들이

319
00:13:15,480 --> 00:13:16,900
있는데요--여기서

320
00:13:16,900 --> 00:13:18,960
자세히 다루진 않겠습니다만--베지에

321
00:13:18,960 --> 00:13:21,280
곡선과 베지에 곡면 같은 더

322
00:13:21,280 --> 00:13:25,760
복잡한 파라메트릭 표현들이 있습니다. 이것들은 기본적으로 몇 개의

323
00:13:25,760 --> 00:13:30,680
제어점만으로 3D에서 꽤 유연하고 부드러운 표면을 표현할 수 있게 해줍니다.

324
00:13:30,680 --> 00:13:33,120
기본적으로 이 베지에 함수를

325
00:13:33,120 --> 00:13:35,520
사용해서 표면의 근본적인

326
00:13:35,520 --> 00:13:37,370
저차원 구조를

327
00:13:37,370 --> 00:13:39,370
포착하고, 그 저차원

328
00:13:39,370 --> 00:13:43,370
구조를 유연한 형태로 매핑할 수 있습니다.

329
00:13:43,370 --> 00:13:46,130
또한 이들은 세분화 같은 것도 가능하게

330
00:13:46,130 --> 00:13:49,570
해서, 표면에 더 많은 디테일을 넣고 더

331
00:13:49,570 --> 00:13:51,823
세밀하게 만들 수 있습니다.

332
00:13:51,823 --> 00:13:53,490
좋습니다, 이것이 두 번째 형태의

333
00:13:53,490 --> 00:13:54,550
형상 표현 방법입니다.

334
00:13:54,550 --> 00:13:57,630
3D 객체를 비파라메트릭 방식으로 표현할 수도 있는데, 예를

335
00:13:57,630 --> 00:14:00,530
들어 순서 없는 점들의 집합이나 메쉬로 연결된 형태로

336
00:14:00,530 --> 00:14:01,230
표현하는 겁니다.

337
00:14:01,230 --> 00:14:04,050
또는 파라메트릭 방식으로 표현할 수도 있는데, 기본적으로

338
00:14:04,050 --> 00:14:05,390
함수가 있는 형태입니다.

339
00:14:05,390 --> 00:14:08,650
그리고 객체 기하학의 진정한 자유도에

340
00:14:08,650 --> 00:14:11,290
해당하는 몇 가지 파라미터를

341
00:14:11,290 --> 00:14:15,970
변화시켜서 더 복잡한 형태로 매핑할 수 있습니다.

342
00:14:15,970 --> 00:14:18,905
기본적으로 여기 있는 모든 것들은, 제가 처음에

343
00:14:18,905 --> 00:14:20,530
말했듯이, 객체 기하학을

344
00:14:20,530 --> 00:14:21,810
표현하는 두 가지 방법

345
00:14:21,810 --> 00:14:23,030
중 하나에 속합니다.

346
00:14:23,030 --> 00:14:24,390
하나는 명시적 표현이고,

347
00:14:24,390 --> 00:14:25,590
다른 하나는 암시적 표현입니다.

348
00:14:25,590 --> 00:14:27,570
그리고 여기 있는 모든 것들은 꽤

349
00:14:27,570 --> 00:14:29,070
명시적인 표현 범주에 속합니다.

350
00:14:29,070 --> 00:14:30,790
즉, 점들이 있고,

351
00:14:30,790 --> 00:14:33,550
점들은 객체 위의 직접적인 점들입니다.

352
00:14:33,550 --> 00:14:36,510
표면이나 파라메트릭 곡선도

353
00:14:36,510 --> 00:14:41,670
마찬가지로, 객체 위의 점들에 직접 매핑됩니다.

354
00:14:41,670 --> 00:14:43,650
그래서 명시적 표현입니다.

355
00:14:43,650 --> 00:14:45,830
이 표현들은 많은 장점이 있습니다.

356
00:14:45,830 --> 00:14:49,950
첫째, 모든 점을 직접 매핑하기 때문에, 모든

357
00:14:49,950 --> 00:14:51,990
점을 얻을 수 있습니다.

358
00:14:51,990 --> 00:14:55,970
일반적으로, 예를 들어 베지에

359
00:14:55,970 --> 00:14:58,810
표면 표현이 있다면,

360
00:14:58,810 --> 00:15:02,230
기본 저차원 공간에서 두 점과 UV 값을 샘플링한

361
00:15:02,230 --> 00:15:04,990
뒤, 그 함수를 통해 3D 공간의

362
00:15:04,990 --> 00:15:06,850
점으로 매핑할 수 있습니다.

363
00:15:06,850 --> 00:15:10,968
그래서 3D 공간의 점을 직접 얻을 수 있습니다.

364
00:15:10,968 --> 00:15:13,510
모든 점이 어떤 의미에서 직접 주어진 셈입니다.

365
00:15:13,510 --> 00:15:15,430
다른 점들도 직접 얻을 수 있습니다.

366
00:15:15,430 --> 00:15:17,810
그래서 점을 샘플링하는 것이 매우 쉽습니다.

367
00:15:17,810 --> 00:15:20,910
예를 들어, 이 토러스가 있고, 이 f 함수로

368
00:15:20,910 --> 00:15:22,450
표현했다고 합시다.

369
00:15:22,450 --> 00:15:24,830
그럼 질문은, 객체 표면 위에서 점을

370
00:15:24,830 --> 00:15:26,850
샘플링할 수 있느냐는 겁니다.

371
00:15:26,850 --> 00:15:29,230
이건 매우 쉽습니다. 그냥 u와 v 값을

372
00:15:29,230 --> 00:15:30,530
무작위로 넣으면 되니까요.

373
00:15:30,530 --> 00:15:33,320
그 u와 v 값을 무작위로

374
00:15:33,320 --> 00:15:37,240
샘플링해서 이 함수에 넣으면, 객체

375
00:15:37,240 --> 00:15:40,840
표면 위에 있는 3D 점들을 계산해서

376
00:15:40,840 --> 00:15:41,960
줍니다.

377
00:15:41,960 --> 00:15:44,640
그래서 샘플링이 훨씬 쉽습니다.

378
00:15:44,640 --> 00:15:48,440
그럼 명시적 표현에서 어려운 점은 무엇일까요?

379
00:15:48,440 --> 00:15:51,880
어려운 점은 어떤 점이 객체 내부에 있는지

380
00:15:51,880 --> 00:15:56,400
외부에 있는지 테스트하는 것이 매우 어렵다는 겁니다.

381
00:15:56,400 --> 00:15:59,560
마찬가지로, 구를 이 함수로 표현했다고

382
00:15:59,560 --> 00:16:03,480
할 때, 구 위의 점을 샘플링하는 것은 쉽지만,

383
00:16:03,480 --> 00:16:05,520
이제 쿼리가

384
00:16:05,520 --> 00:16:07,360
있다고 할 때,

385
00:16:07,360 --> 00:16:10,520
지금 이 시점에서 3분의 4, 2분의 1, 4분의 1이라고 말할 수
있습니다.

386
00:16:10,520 --> 00:16:13,120
3D 공간에서 이 지점이

387
00:16:13,120 --> 00:16:16,720
안쪽 물체인지 바깥쪽 물체인지입니다.

388
00:16:16,720 --> 00:16:18,440
아마도 할 수 있을 것

389
00:16:18,440 --> 00:16:21,360
같은데, 사실은 저도 확신이 없습니다.

390
00:16:21,360 --> 00:16:24,760
그래서 특정 점이 안쪽에 있는지 바깥쪽에 있는지

391
00:16:24,760 --> 00:16:27,000
테스트하는 게 실제로 어렵습니다.

392
00:16:27,000 --> 00:16:31,557
명시적 표현들은 각각 장단점이 있다는

393
00:16:31,557 --> 00:16:33,890
것을 알 수

394
00:16:33,890 --> 00:16:34,655
있습니다.

395
00:16:34,655 --> 00:16:36,030
명시적 표현의 경우,

396
00:16:36,030 --> 00:16:38,290
점을 샘플링하는 것이 꽤 쉽습니다. 이

397
00:16:38,290 --> 00:16:39,450
점들은 때때로 점들의

398
00:16:39,450 --> 00:16:41,590
집합으로 변환할 때 매우 유용합니다.

399
00:16:41,590 --> 00:16:43,310
그리고 나서 그 점들에 대해 어떤 포인트

400
00:16:43,310 --> 00:16:44,490
신경망을 적용할 수 있습니다.

401
00:16:44,490 --> 00:16:47,410
하지만 특정 점이 안쪽에 있는지 바깥쪽에 있는지

402
00:16:47,410 --> 00:16:49,850
테스트하는 것은 어려워서 문제가 될 수 있습니다.

403
00:16:49,850 --> 00:16:52,533
예를 들어, 신경 렌더링 방법을 사용한다고 가정해

404
00:16:52,533 --> 00:16:54,950
봅시다. 현재 많은 신경 렌더링 방법들은

405
00:16:54,950 --> 00:16:56,450
점이 물체 안에 있는지

406
00:16:56,450 --> 00:16:59,070
밖에 있는지에 대한 많은 쿼리를 필요로 합니다.

407
00:16:59,070 --> 00:17:01,330
그 특정 점에서 물체의 기하학적 구조나

408
00:17:01,330 --> 00:17:02,430
밀도는 어떠한가?

409
00:17:02,430 --> 00:17:03,390
재질은 무엇인가?

410
00:17:03,390 --> 00:17:05,609
또는 그 특정 점에서 물체의 방사선이나

411
00:17:05,609 --> 00:17:06,930
색상은 어떠한가?

412
00:17:06,930 --> 00:17:11,170
본질적으로, 명시적 표현들은 이런

413
00:17:11,170 --> 00:17:12,849
연산들을 수행하기에

414
00:17:12,849 --> 00:17:15,740
그리 적합하지 않습니다.

415
00:17:15,740 --> 00:17:17,490
그래서 자연스럽게 사람들은

416
00:17:17,490 --> 00:17:19,157
기하학을 표현하는 다른 방식을

417
00:17:19,157 --> 00:17:20,329
생각하게 되었습니다.

418
00:17:20,329 --> 00:17:23,030
여기서 저는 기하학에 대해 '암시적(implicit)' 표현이라고 말합니다.

419
00:17:23,030 --> 00:17:25,694
하지만 나중에 보시겠지만, 많은 신경 렌더링

420
00:17:25,694 --> 00:17:27,069
방법이나 딥러닝

421
00:17:27,069 --> 00:17:29,569
방법에서는 이런 암시적 표현을 기하학뿐

422
00:17:29,569 --> 00:17:33,100
아니라 3D 물체의 색상과 외관에도 확장해서 사용합니다.

423
00:17:33,100 --> 00:17:36,180
이제 이러한 암시적 표현의 아이디어는,

424
00:17:36,180 --> 00:17:39,160
이 점들을 분류하고 싶다는 것입니다.

425
00:17:39,160 --> 00:17:42,540
즉, 점들이 객체 위에 있다면, 즉 객체 표면 위에

426
00:17:42,540 --> 00:17:44,080
있다면, 그 점들은

427
00:17:44,080 --> 00:17:46,740
어떤 특정한 관계를 만족한다고 가정합니다.

428
00:17:46,740 --> 00:17:48,820
예를 들어, 구에 대해 생각해보면,

429
00:17:48,820 --> 00:17:51,980
단위 구 위의 점들은 어떤 점들일까요?

430
00:17:51,980 --> 00:17:54,580
그들이 만족하는 제약 조건은 x의 제곱,

431
00:17:54,580 --> 00:17:57,340
y의 제곱, 그리고 z의 제곱입니다.

432
00:17:57,340 --> 00:17:59,280
이것들을 모두 더하면 1이 됩니다.

433
00:17:59,280 --> 00:18:03,540
이것이 구 위의 모든 점들이 만족하는

434
00:18:03,540 --> 00:18:05,285
제약 조건입니다.

435
00:18:05,285 --> 00:18:06,660
좀 더 일반적으로,

436
00:18:06,660 --> 00:18:09,740
이 제약 조건은 x, y, z의 함수가

437
00:18:09,740 --> 00:18:12,310
0이 되는 형태로 쓸 수 있습니다.

438
00:18:12,310 --> 00:18:14,060
이 경우 함수 f(x, y,

439
00:18:14,060 --> 00:18:17,680
z)는 x 제곱 더하기 y 제곱 더하기 z 제곱 빼기 1이 됩니다.

440
00:18:17,680 --> 00:18:19,160
이것이 바로 여기서의 함수입니다.

441
00:18:19,160 --> 00:18:20,910
하지만 더 일반적으로, 복잡한

442
00:18:20,910 --> 00:18:23,652
형태에 대해서도 생각할 수 있는데, 때로는 이런

443
00:18:23,652 --> 00:18:25,860
함수들이 너무 복잡해서 닫힌 형태로 표현할

444
00:18:25,860 --> 00:18:27,320
수 없을 수도 있습니다.

445
00:18:27,320 --> 00:18:28,700
그럼 f를 어떻게 표현할 수 있을까요?

446
00:18:28,700 --> 00:18:30,860
그냥 신경망으로 표현하면 됩니다.

447
00:18:30,860 --> 00:18:33,680
신경망이 그것을 표현할 수 있기를 기대하는 거죠.

448
00:18:33,680 --> 00:18:35,600
일반적으로는, 특정

449
00:18:35,600 --> 00:18:38,480
객체 위의 점들이 만족하는

450
00:18:38,480 --> 00:18:41,360
어떤 함수나 제약 조건이 있고,

451
00:18:41,360 --> 00:18:43,460
이것이 객체를 표현하는 방법입니다.

452
00:18:43,460 --> 00:18:45,380
이것을 암시적 표현이라고 부르며,

453
00:18:45,380 --> 00:18:47,100
기하학에서 시작된 개념입니다.

454
00:18:47,100 --> 00:18:49,480
하지만 말씀드렸듯이, 이제는 텍스처,

455
00:18:49,480 --> 00:18:51,920
재질, 외관 등 다양한 방식을 모두

456
00:18:51,920 --> 00:18:52,817
사용하고 있습니다.

457
00:18:52,817 --> 00:18:55,400
암묵적 표현의 좋은 점에 대해 말하기 전에, 먼저 나쁜

458
00:18:55,400 --> 00:18:56,380
점부터 시작하겠습니다.

459
00:18:56,380 --> 00:18:58,172
암묵적 표현의 나쁜 점은 이제 점을

460
00:18:58,172 --> 00:19:00,380
샘플링하는 것이 훨씬 더 어렵다는 겁니다.

461
00:19:00,380 --> 00:19:02,540
예를 들어, 이 토러스가 만족하는

462
00:19:02,540 --> 00:19:04,160
제약 조건이 있다고 합시다.

463
00:19:04,160 --> 00:19:09,160
네, 모든 x, y, z 값에 이 함수를 적용했을 때 출력이 0이라면,

464
00:19:09,160 --> 00:19:11,440
그 점들은 반드시 이 객체의

465
00:19:11,440 --> 00:19:13,460
표면 위에 있어야 합니다.

466
00:19:13,460 --> 00:19:17,398
그런데 이 x, y, z 튜플 몇 개를 어떻게 구할 수 있을까요?

467
00:19:17,398 --> 00:19:19,440
이 함수의 해를 구해야 하므로

468
00:19:19,440 --> 00:19:20,540
매우 어렵습니다.

469
00:19:20,540 --> 00:19:22,720
이 함수가 그렇게 어렵지 않을 수도 있습니다.

470
00:19:22,720 --> 00:19:25,330
아마 고등학교 수학으로도 풀 수 있을 겁니다.

471
00:19:25,330 --> 00:19:29,650
하지만 함수가 임의의 복잡한 형태에 대해 매우 복잡해지면, 이

472
00:19:29,650 --> 00:19:32,310
함수들을 푸는 것이 훨씬 어려워집니다.

473
00:19:32,310 --> 00:19:34,850
그래서 객체를 암묵적으로 표현할 때,

474
00:19:34,850 --> 00:19:38,010
실제로 객체 표면 위의 점을 샘플링하는

475
00:19:38,010 --> 00:19:39,330
것은 쉽지 않습니다.

476
00:19:39,330 --> 00:19:40,715
하지만 장점은, 이제

477
00:19:40,715 --> 00:19:42,090
점이 객체 내부에 있는지

478
00:19:42,090 --> 00:19:44,170
외부에 있는지 테스트하는 것은

479
00:19:44,170 --> 00:19:45,290
꽤 쉽다는 겁니다.

480
00:19:45,290 --> 00:19:48,610
테스트를 하고 싶다면, 쿼리를 하나 보내면 되니까 매우 간단합니다.

481
00:19:48,610 --> 00:19:50,910
내부인지 외부인지 판단할 수 있습니다.

482
00:19:50,910 --> 00:19:52,550
그냥 그 점을 함수에 넣으면 됩니다.

483
00:19:52,550 --> 00:19:55,510
값을 얻을 텐데, 예를 들어 값이 -1/8이라면,

484
00:19:55,510 --> 00:19:56,810
그 값이 0보다 작으니 내부에 있다는 뜻입니다.

485
00:19:56,810 --> 00:20:02,170
그래서 저는 객체가 이 함수로 표현된다고 가정합니다.

486
00:20:02,170 --> 00:20:03,930
그리고 객체의 모든 표면 점들은 그

487
00:20:03,930 --> 00:20:05,870
함수가 0과 같다는 조건을 만족합니다.

488
00:20:05,870 --> 00:20:07,870
무엇이든, [? 모르겠네요, ?] 0보다 낮으면 음수라고

489
00:20:07,870 --> 00:20:08,950
하겠습니다.

490
00:20:08,950 --> 00:20:11,490
출력 값이 음수라면 그 점은 반드시 객체

491
00:20:11,490 --> 00:20:12,910
내부에 있어야 합니다.

492
00:20:12,910 --> 00:20:14,710
출력 값이 양수라면 그

493
00:20:14,710 --> 00:20:17,490
점은 반드시 객체 외부에 있어야 합니다.

494
00:20:17,490 --> 00:20:20,730
이제 특정 점이 객체 내부인지 외부인지 테스트하는

495
00:20:20,730 --> 00:20:22,850
것이 훨씬 쉬워졌지만, 객체

496
00:20:22,850 --> 00:20:24,740
표면 위의 여러 점을 샘플링하는

497
00:20:24,740 --> 00:20:26,460
것은 훨씬 어려워졌습니다.

498
00:20:26,460 --> 00:20:28,700
지금 보시면, 암묵적 표현과 명시적 표현

499
00:20:28,700 --> 00:20:31,500
사이에 명확한 트레이드오프가 있다는 것을 알 수 있습니다.

500
00:20:31,500 --> 00:20:33,500
여기서 다시 기하학에 대해 이야기합니다.

501
00:20:33,500 --> 00:20:36,020
하지만 명시적 표현과 암묵적 표현 사이의

502
00:20:36,020 --> 00:20:38,620
이 구분과 대비는 매우 중요하고

503
00:20:38,620 --> 00:20:40,120
근본적이라고 생각합니다.

504
00:20:40,120 --> 00:20:44,060
이것이 나중에 보게 될 3D 데이터에 딥

505
00:20:44,060 --> 00:20:48,060
뉴럴 네트워크를 적용할 때의 발전 배경입니다.

506
00:20:48,060 --> 00:20:50,800
그래서 우리가-- 잠깐 [? 보세요, 지금 ?] 25분 지났습니다.

507
00:20:50,800 --> 00:20:52,758
5분 이상 쓰지 않겠다고 약속했고,

508
00:20:52,758 --> 00:20:54,592
이제 딥러닝에 대해 이야기하겠습니다.

509
00:20:54,592 --> 00:20:57,380
그래서 딥러닝이 3D 표현에 어떻게 적용될

510
00:20:57,380 --> 00:21:00,420
수 있는지 이야기하기 전에, 암시적 표현에

511
00:21:00,420 --> 00:21:02,140
대해 조금 더

512
00:21:02,140 --> 00:21:04,480
말씀드리겠습니다. 암시적 표현의 다른

513
00:21:04,480 --> 00:21:08,183
특징 중 하나는, 그것들을 합성하기가 쉽다는 점입니다.

514
00:21:08,183 --> 00:21:10,100
때때로 모든 것을 함수로 표현하면,

515
00:21:10,100 --> 00:21:14,060
닫힌 형태가 있으면 좋겠지만, 동시에 매우 제한적일 것 같다는

516
00:21:14,060 --> 00:21:15,980
생각이 듭니다. 왜냐하면 모든

517
00:21:15,980 --> 00:21:18,800
닫힌 형태는 제가 직접 쓸 수 있기 때문입니다.

518
00:21:18,800 --> 00:21:21,400
기하학적 형태들이 매우, 매우 규칙적으로 보입니다.

519
00:21:21,400 --> 00:21:24,285
그래서 만약 소의 형태를 표현하고 싶다면, 어떻게

520
00:21:24,285 --> 00:21:25,410
표현할 수 있을까요?

521
00:21:25,410 --> 00:21:27,370
소의 형태를 위해 어떤 함수를 쓸 수 있을까요?

522
00:21:27,370 --> 00:21:28,430
그건 명확하지 않습니다.

523
00:21:28,430 --> 00:21:30,430
하지만 암시적 표현의 좋은 점은 모든 것을 한

524
00:21:30,430 --> 00:21:32,513
번에 쓸 필요가 없다는 겁니다. 왜냐하면

525
00:21:32,513 --> 00:21:34,190
그것들을 합성하기가 매우 쉽기 때문입니다.

526
00:21:34,190 --> 00:21:36,310
실제로 이런 암시적 함수들에 논리 연산을

527
00:21:36,310 --> 00:21:37,490
수행할 수 있습니다.

528
00:21:37,490 --> 00:21:39,190
두 개의 객체가 있다고 가정해

529
00:21:39,190 --> 00:21:42,070
봅시다. 그리고 합집합, 교집합, 차집합을 찾는 거죠.

530
00:21:42,070 --> 00:21:43,670
다시 말하지만, 이들은 단지 값일 뿐입니다.

531
00:21:43,670 --> 00:21:45,583
그래서 x, y, z를 이 함수에 넣습니다.

532
00:21:45,583 --> 00:21:46,250
값을 얻습니다.

533
00:21:46,250 --> 00:21:47,570
x, y, z를 저 함수에 넣습니다.

534
00:21:47,570 --> 00:21:48,290
값을 얻습니다.

535
00:21:48,290 --> 00:21:50,645
이 값들 위에 산술 연산을 할 수

536
00:21:50,645 --> 00:21:52,270
있고, 이를 통해 객체들

537
00:21:52,270 --> 00:21:54,645
간의 합집합, 교집합, 차집합을

538
00:21:54,645 --> 00:21:56,110
계산할 수 있습니다.

539
00:21:56,110 --> 00:21:59,110
결국에는 이들을 조합해서 꽤 복잡한 형태를

540
00:21:59,110 --> 00:22:00,670
나눌 수 있습니다.

541
00:22:00,670 --> 00:22:04,055
이것은 실제로 많은 산업 디자인의 기반이

542
00:22:04,055 --> 00:22:05,430
됩니다. 사람들이

543
00:22:05,430 --> 00:22:10,788
복잡한 부품을 설계할 때 사용하는 거죠, 제가 말하길, 잘

544
00:22:10,788 --> 00:22:11,330
모르겠지만요.

545
00:22:11,330 --> 00:22:14,550
즉, 제조를 할 때는 복잡한

546
00:22:14,550 --> 00:22:17,077
형태를 제작해야 합니다.

547
00:22:17,077 --> 00:22:18,910
이러한 디자인의 많은 부분은 CAD 모델, 즉

548
00:22:18,910 --> 00:22:20,210
컴퓨터 지원 설계로 이루어집니다.

549
00:22:20,210 --> 00:22:22,970
그리고 이들은 단순한 논리 연산을

550
00:22:22,970 --> 00:22:25,650
사용해 암시적 함수를 구성합니다.

551
00:22:25,650 --> 00:22:29,827
논리 연산을 넘어서서도 할 수 있습니다.

552
00:22:29,827 --> 00:22:31,410
특히 거리 함수가 있다면,

553
00:22:31,410 --> 00:22:34,290
각 점이 양수인지 음수인지가 의미를

554
00:22:34,290 --> 00:22:36,995
가지기 때문에 값을 더할 수도 있습니다.

555
00:22:36,995 --> 00:22:38,370
이 값들은 객체

556
00:22:38,370 --> 00:22:40,010
표면에서 얼마나 떨어져

557
00:22:40,010 --> 00:22:41,590
있는지를 나타냅니다.

558
00:22:41,590 --> 00:22:43,650
그래서 값을 더해서

559
00:22:43,650 --> 00:22:46,756
형태를 부드럽게 혼합할 수 있습니다.

560
00:22:46,756 --> 00:22:49,590
여기서 거리 함수가 있다고 가정하면,

561
00:22:49,590 --> 00:22:51,810
수직선을 표현하고 싶을 때

562
00:22:51,810 --> 00:22:52,830
이렇게 됩니다.

563
00:22:52,830 --> 00:22:55,710
그리고 0보다 작은 값은 선의 왼쪽에 위치합니다.

564
00:22:55,710 --> 00:22:58,258
양수 값은 선의 오른쪽에 위치하죠.

565
00:22:58,258 --> 00:23:00,050
그리고 다른 함수를 사용해 또 다른

566
00:23:00,050 --> 00:23:01,490
선을 표현할 수 있습니다.

567
00:23:01,490 --> 00:23:03,130
그럼 이 둘을 더하면 어떻게 될까요?

568
00:23:03,130 --> 00:23:05,610
더하면 자연스럽게 이 두 형태

569
00:23:05,610 --> 00:23:07,750
사이의 보간이 됩니다.

570
00:23:07,750 --> 00:23:10,370
이것은 1차원에서 하는 예시입니다.

571
00:23:10,370 --> 00:23:13,210
하지만 3차원에서도 비슷하게 할 수 있다고 상상할

572
00:23:13,210 --> 00:23:15,610
수 있습니다. 이제 서로 다른 형태를

573
00:23:15,610 --> 00:23:16,770
혼합할 수 있죠.

574
00:23:16,770 --> 00:23:19,620
이 거리 함수들은 임의로 조합할 수 있어서

575
00:23:19,620 --> 00:23:22,060
이렇게 꽤 복잡한 세계를 만들 수

576
00:23:22,060 --> 00:23:22,560
있습니다.

577
00:23:22,560 --> 00:23:25,620
이것은 쉽지 않지만, 여러분도 한번 생각해볼 수 있습니다.

578
00:23:25,620 --> 00:23:28,300
여러분은 정말 복잡한 세상을 모든 세부사항까지

579
00:23:28,300 --> 00:23:31,220
구성할 수 있는데, 단순히—단순하지는 않지만,

580
00:23:31,220 --> 00:23:34,077
어려운 작업이지만—이 다양한 함수들을 조합해서

581
00:23:34,077 --> 00:23:35,160
만들 수 있습니다.

582
00:23:35,160 --> 00:23:37,118
하지만 실제로는, 여러분이 아주

583
00:23:37,118 --> 00:23:39,820
잘 다룰 수 있다면, 매우 표현력이 뛰어납니다.

584
00:23:39,820 --> 00:23:44,087
좋습니다, 그래서 우리는 파라메트릭 표현이 있는데, 명시적일 수 있고,

585
00:23:44,087 --> 00:23:46,420
3D 표면 위의 점들을 직접 줄 수 있다고

586
00:23:46,420 --> 00:23:47,120
했습니다.

587
00:23:47,120 --> 00:23:48,620
또는 이런 함수들 같은 파라메트릭

588
00:23:48,620 --> 00:23:49,540
표현도 있을 수 있습니다.

589
00:23:49,540 --> 00:23:50,660
하지만 그것들은 암시적입니다.

590
00:23:50,660 --> 00:23:52,660
즉, 이제는 어떤 점이 객체 안에

591
00:23:52,660 --> 00:23:55,240
있는지 밖에 있는지만 검증할 수 있다는 겁니다.

592
00:23:55,240 --> 00:23:56,657
하지만 그런 다음 그것들을 조합해서

593
00:23:56,657 --> 00:23:58,260
더 복잡한 형태를 만들 수도 있습니다.

594
00:23:58,260 --> 00:24:00,500
그런데 암시적 표현과 비파라메트릭,

595
00:24:00,500 --> 00:24:02,460
즉 점 스타일 표현을 가지면서도

596
00:24:02,460 --> 00:24:05,207
쿼리 함수도 함께 가질 수 있을까요?

597
00:24:05,207 --> 00:24:07,540
사실 때때로 그런 것들이 존재합니다.

598
00:24:07,540 --> 00:24:10,080
이것은 결국 레벨셋(level set) 방법 같은 기법으로 이어집니다.

599
00:24:10,080 --> 00:24:13,460
암시적 표면은 매우 좋습니다, 왜냐하면 우리가

600
00:24:13,460 --> 00:24:14,800
말했듯이 합치기도 쉽고,

601
00:24:14,800 --> 00:24:16,100
분할하기도 쉽기 때문입니다.

602
00:24:16,100 --> 00:24:18,690
하지만 때로는, 우리가 말했듯이, 복잡한 형태를 닫힌

603
00:24:18,690 --> 00:24:20,050
형태로 표현하기가 어렵습니다.

604
00:24:20,050 --> 00:24:21,245
예를 들어 소가 있다고 합시다.

605
00:24:21,245 --> 00:24:22,370
그걸 어떻게 표현할까요?

606
00:24:22,370 --> 00:24:23,850
여러분은 그것들을 조합할 수 있습니다.

607
00:24:23,850 --> 00:24:27,390
하지만 매번 어떤 점이 소 안에 있는지 쿼리해야 한다면,

608
00:24:27,390 --> 00:24:30,030
수백 개의 함수가 필요할 겁니다.

609
00:24:30,030 --> 00:24:32,550
그리고 모든 덧셈, 그리고/또는, 더하기/빼기

610
00:24:32,550 --> 00:24:33,970
연산을 수행해야 하죠.

611
00:24:33,970 --> 00:24:35,230
그러면 시간이 오래 걸립니다.

612
00:24:35,230 --> 00:24:37,410
그렇다면 미리 쿼리해두면 어떨까요?

613
00:24:37,410 --> 00:24:41,030
3D 공간이 있고, 예를 들어 100x100x100

614
00:24:41,030 --> 00:24:43,110
격자를 샘플링한다고 합시다.

615
00:24:43,110 --> 00:24:45,887
그래서 이제 백만 개의 점을 샘플링한 셈입니다.

616
00:24:45,887 --> 00:24:47,470
이 백만 개 점에 대해,

617
00:24:47,470 --> 00:24:50,190
그 점들이 객체 안에 있는지 밖에

618
00:24:50,190 --> 00:24:52,150
있는지, 그리고 복잡한

619
00:24:52,150 --> 00:24:55,883
형태의 표면까지의 거리가 얼마인지 미리 계산해둡니다.

620
00:24:55,883 --> 00:24:57,550
그래서 미리 계산해두고, 그

621
00:24:57,550 --> 00:25:00,090
모든 값을 행렬에 저장할 수 있습니다.

622
00:25:00,090 --> 00:25:00,890
이것은 2D 예시입니다.

623
00:25:00,890 --> 00:25:04,070
하지만 시각화를 위한 것이고,

624
00:25:04,070 --> 00:25:05,890
실제로는 3D입니다.

625
00:25:05,890 --> 00:25:09,190
그래서 3D 행렬이 있어서 이 거리 함수의 미리

626
00:25:09,190 --> 00:25:10,950
계산된 모든 값을 저장합니다.

627
00:25:10,950 --> 00:25:13,930
그래서 이제 어떤 의미에서는 여전히 암시적 표현을 가지고 있지만,

628
00:25:13,930 --> 00:25:16,260
미리 쿼리했기 때문에

629
00:25:16,260 --> 00:25:20,280
비파라메트릭 표현으로 바뀌었습니다.

630
00:25:20,280 --> 00:25:23,740
그리고 이 2D 행렬만 봐도 경계가

631
00:25:23,740 --> 00:25:26,373
어디인지 찾을 수 있습니다.

632
00:25:26,373 --> 00:25:27,540
그럼 경계는 어디에 있을까요?

633
00:25:27,540 --> 00:25:30,460
경계는 기본적으로 두 개의 인접한 값이 있는 곳입니다.

634
00:25:30,460 --> 00:25:32,480
하나는 양수이고, 다른 하나는 음수입니다.

635
00:25:32,480 --> 00:25:34,840
즉, 그 사이 어딘가에 반드시 경계가 있다는 뜻이죠.

636
00:25:34,840 --> 00:25:37,340
여기서 중요한 점입니다.

637
00:25:37,340 --> 00:25:39,320
그 점들은 함수 f(x) = 0을

638
00:25:39,320 --> 00:25:42,860
만족하는데, 이는 그 점이 표면 위에 있어야 한다는 의미입니다.

639
00:25:42,860 --> 00:25:46,280
즉, 파라메트릭 표현이나 암시적 표현을

640
00:25:46,280 --> 00:25:48,640
함수들을 이용해 많은

641
00:25:48,640 --> 00:25:50,560
점들을 미리

642
00:25:50,560 --> 00:25:54,760
쿼리함으로써 비파라메트릭 표현으로 바꾸는 겁니다.

643
00:25:54,760 --> 00:25:57,480
이렇게 하면 실제로 더 명확한 제어가 가능해집니다.

644
00:25:57,480 --> 00:26:00,447
왜냐하면 이제 그것들을 시각화할 수 있기 때문입니다.

645
00:26:00,447 --> 00:26:01,780
예를 들어, 저는 이 행렬을 가지고 있습니다.

646
00:26:01,780 --> 00:26:03,900
그리고 그 값들에 따라 시각화할 수 있죠.

647
00:26:03,900 --> 00:26:08,240
이 방법은 CT, MRI 같은 의료 데이터에서

648
00:26:08,240 --> 00:26:09,920
많이 사용됩니다.

649
00:26:09,920 --> 00:26:12,052
관련해서, 만약 모든 거리 값에

650
00:26:12,052 --> 00:26:14,260
신경 쓰지 않는다면 어떻게 할까요?

651
00:26:14,260 --> 00:26:17,203
모든 점에서 무슨 일이 일어나는지 미리 쿼리할 수 있지만,

652
00:26:17,203 --> 00:26:18,620
모든 값을 계산하죠.

653
00:26:18,620 --> 00:26:20,560
예를 들어 +5, -5 같은 값들입니다.

654
00:26:20,560 --> 00:26:23,900
하지만 중요한 건 이 점이 객체 내부인지 외부인지

655
00:26:23,900 --> 00:26:24,578
여부뿐이라면,

656
00:26:24,578 --> 00:26:26,620
양수라면 그냥 1로 처리할 수 있습니다.

657
00:26:26,620 --> 00:26:29,120
음수라면, 즉 물체 내부에 있다는 뜻이니까

658
00:26:29,120 --> 00:26:30,420
0으로 처리한다고 합시다.

659
00:26:30,420 --> 00:26:32,700
그래서 이진화하면, 최종

660
00:26:32,700 --> 00:26:34,900
표현이 나오는데, 가장 이해하기

661
00:26:34,900 --> 00:26:39,000
쉬운 표현은 이것을 voxels라고 부릅니다.

662
00:26:39,000 --> 00:26:42,900
그래서 암묵적 함수가 어디에 있는지 미리 쿼리할 수 있고,

663
00:26:42,900 --> 00:26:45,560
이렇게 밀도 샘플링된 그리드를 갖게 됩니다.

664
00:26:45,560 --> 00:26:47,980
하지만 이제는 거리 함수를

665
00:26:47,980 --> 00:26:49,940
저장하는 대신, 함수에 넣어

666
00:26:49,940 --> 00:26:52,660
+5, -5 값을 주는 대신,

667
00:26:52,660 --> 00:26:54,160
그냥 이진화합니다.

668
00:26:54,160 --> 00:26:57,580
특정 점이 물체 내부인지 외부인지만

669
00:26:57,580 --> 00:26:59,060
신경 쓰는 거죠.

670
00:26:59,060 --> 00:27:00,880
그러면 voxel 표현을 갖게

671
00:27:00,880 --> 00:27:04,980
되는데, 이것도 3D 행렬과 같아서 100x100x100일 수 있습니다.

672
00:27:04,980 --> 00:27:07,820
하지만 모든 점에 대해 이 함수를 통과시켜서

673
00:27:07,820 --> 00:27:10,320
내부인지 외부인지 쿼리해야 합니다.

674
00:27:10,320 --> 00:27:12,910
1 아니면 0이 있고, 이진화된 방식으로 물체를

675
00:27:12,910 --> 00:27:14,010
표현할 수 있습니다.

676
00:27:14,010 --> 00:27:16,510
그래서 이것이 3D 물체 표현에

677
00:27:16,510 --> 00:27:19,670
대해 제가 이야기할 최종 표현입니다.

678
00:27:19,670 --> 00:27:23,028
voxel을 좀 복잡한 방식으로 소개했는데,

679
00:27:23,028 --> 00:27:25,070
다른 관점에서는 사람들이 이게 사실 매우

680
00:27:25,070 --> 00:27:27,190
이해하기 쉽다고 말할 수 있습니다.

681
00:27:27,190 --> 00:27:29,530
왜냐하면 voxel은 픽셀과 많은 유사점이 있기

682
00:27:29,530 --> 00:27:31,470
때문입니다. 픽셀은 2D 행렬이죠.

683
00:27:31,470 --> 00:27:34,630
이제 3D 행렬이 있고, voxel은

684
00:27:34,630 --> 00:27:37,002
기본적으로 3D 행렬입니다.

685
00:27:37,002 --> 00:27:39,630
그래서 다른 형태 표현

686
00:27:39,630 --> 00:27:41,630
방식들과

687
00:27:41,630 --> 00:27:43,150
연결점이 있지만,

688
00:27:43,150 --> 00:27:46,880
제가 이렇게 소개하는 이유는, 사실 딥러닝이

689
00:27:46,880 --> 00:27:49,130
등장하면서—먼저, 딥러닝은 언제

690
00:27:49,130 --> 00:27:49,880
시작됐나요?

691
00:27:49,880 --> 00:27:51,215
2010년입니다.

692
00:27:51,215 --> 00:27:53,090
딥러닝은 오래전부터

693
00:27:53,090 --> 00:27:56,690
있었지만, 현대 딥러닝은 2010년부터입니다.

694
00:27:56,690 --> 00:27:59,210
Geoff Hinton은 음성 인식 분야에서 그것을 시작했습니다.

695
00:27:59,210 --> 00:28:02,345
그리고 2012년에 ImageNet을 기반으로 한 AlexNet이
나왔습니다.

696
00:28:02,345 --> 00:28:04,470
그래서 여러분은 이 모든 것들을 배웠고, 모두 2D입니다.

697
00:28:04,470 --> 00:28:07,370
자, 이제 사람들이 묻습니다, 3D로 하고 싶으면 어떻게 할까요?

698
00:28:07,370 --> 00:28:08,750
이것은 매우 자연스러운 생각입니다.

699
00:28:08,750 --> 00:28:11,360
그래서 2D 컨볼루션 신경망에서 시작하고 싶습니다--

700
00:28:11,360 --> 00:28:14,067
2012년에는 transformer가 없었습니다.

701
00:28:14,067 --> 00:28:16,400
그렇다면 2D 컨볼루션 신경망을 3D 데이터에 어떻게

702
00:28:16,400 --> 00:28:17,120
적용할 수 있을까요?

703
00:28:17,120 --> 00:28:19,640
그리고 모두가 알다시피, 우리는 다양한 3D

704
00:28:19,640 --> 00:28:21,280
표현 방식을 가지고 있습니다.

705
00:28:21,280 --> 00:28:23,912
그런데 어느 것부터 시작해야 할까요?

706
00:28:23,912 --> 00:28:26,390
사실 사람들은 이렇게 말합니다. 3D

707
00:28:26,390 --> 00:28:28,922
데이터에 딥러닝을 처음 적용한 사람들은 컴퓨터

708
00:28:28,922 --> 00:28:30,380
비전 분야 사람들이라고요.

709
00:28:30,380 --> 00:28:31,540
그래픽스 분야 사람들이 아니죠.

710
00:28:31,540 --> 00:28:33,540
그들은 '아, 나는 픽셀 작업을 해왔어.'라고 생각합니다.

711
00:28:33,540 --> 00:28:36,600
그리고 가장 쉬운 방법은 그냥 크기를 키우는 거예요.

712
00:28:36,600 --> 00:28:38,260
2D 행렬 작업 대신 3D

713
00:28:38,260 --> 00:28:40,300
행렬 작업을 하도록 만드는 거죠.

714
00:28:40,300 --> 00:28:41,540
이게 가장 간단한 방법입니다.

715
00:28:41,540 --> 00:28:43,248
2D 컨볼루션 네트워크 대신 볼류메트릭

716
00:28:43,248 --> 00:28:45,280
컨볼루션 신경망을 사용하는 겁니다.

717
00:28:45,280 --> 00:28:47,240
그렇다면, 이 표현들 중에서 어떤 것이

718
00:28:47,240 --> 00:28:50,023
여러분이 사용할 수 있거나 볼륨 컨볼루션을 지원할까요?

719
00:28:50,023 --> 00:28:51,940
그것은 바로 이 복셀(voxel) 표현이었습니다.

720
00:28:51,940 --> 00:28:55,603
이것은 기본적으로 상상할 수 있는 가장 쉬운 방법입니다.

721
00:28:55,603 --> 00:28:57,520
하지만 그래픽스 쪽 사람들은 동의하지 않는데요, 그래픽스

722
00:28:57,520 --> 00:28:58,900
사람들은 이렇게 말합니다, 아, 이

723
00:28:58,900 --> 00:29:00,358
복셀은 정말 계산이 너무 느려서 안 좋다고요. 표현 방식이요?

724
00:29:00,358 --> 00:29:02,760
계산하는 데 너무 느리기 때문입니다.

725
00:29:02,760 --> 00:29:04,920
앞서 말했듯이, 우리는 이 [잘 안 들림] 모든

726
00:29:04,920 --> 00:29:05,900
값을 샘플링해야 합니다.

727
00:29:05,900 --> 00:29:08,130
그리고 그곳에서 품질을 볼 수 있죠.

728
00:29:08,130 --> 00:29:10,378
메시나 포인트 클라우드와 비교하면 품질이 너무 안 좋습니다.

729
00:29:10,378 --> 00:29:12,670
그래서 사람들은 왜 굳이 그걸로 시작하려고 하냐고 묻습니다.

730
00:29:12,670 --> 00:29:14,920
하지만 사람들이 복셀로 3D 데이터에

731
00:29:14,920 --> 00:29:17,356
딥러닝을 시작한 이유는, 픽셀과 복셀

732
00:29:17,356 --> 00:29:20,550
사이에 비유를 하기가 너무 쉽기 때문이라고 생각합니다.

733
00:29:20,550 --> 00:29:22,470
코드 한 줄만 바꾸면 되니까요.

734
00:29:22,470 --> 00:29:24,178
즉, 2D 컨볼루션 대신에 이제

735
00:29:24,178 --> 00:29:25,730
3D 컨볼루션을 하면 되는 겁니다.

736
00:29:25,730 --> 00:29:28,570
그래서 어떤 면에서는 그렇게 시작된 거죠.

737
00:29:28,570 --> 00:29:32,090
하지만 3D 데이터에 대한 딥러닝 방법을 이야기하기 전에, 또 하나 매우

738
00:29:32,090 --> 00:29:34,490
중요한 측면이 있습니다. 바로 데이터, 3D 데이터용

739
00:29:34,490 --> 00:29:35,370
데이터셋입니다.

740
00:29:35,370 --> 00:29:38,030
방법론을 넘어서, 데이터셋도 매우 중요합니다.

741
00:29:38,030 --> 00:29:41,270
ImageNet이 AlexNet 같은 모델을 촉진시켰던 것처럼요.

742
00:29:41,270 --> 00:29:44,650
3D의 경우에도 마찬가지로 많은 데이터를 수집해야 합니다.

743
00:29:44,650 --> 00:29:48,708
그래서 3D, 딥러닝 이전에 사람들이 자주 사용하는 대표적인 데이터셋은

744
00:29:48,708 --> 00:29:51,250
Princeton data Shape Benchmark라는

745
00:29:51,250 --> 00:29:55,070
것으로, 1,800개의 모델과 180개의 카테고리를 가지고 있습니다.

746
00:29:55,070 --> 00:29:57,570
보시면 실제로 꽤 많은 카테고리, 180개

747
00:29:57,570 --> 00:29:58,910
카테고리가 있습니다.

748
00:29:58,910 --> 00:30:01,770
하지만 모델은 1,800개뿐이라서, 카테고리당 모델이 대략

749
00:30:01,770 --> 00:30:04,130
10개 정도밖에 없다는 뜻입니다, 매우 적죠.

750
00:30:04,130 --> 00:30:06,522
하지만 그 당시에는 꽤 큰 데이터셋으로 여겨졌습니다.

751
00:30:06,522 --> 00:30:08,230
사람들은 이 정도면 충분하다고

752
00:30:08,230 --> 00:30:10,605
생각했는데, 사실 이 데이터셋으로는 제대로

753
00:30:10,605 --> 00:30:12,350
된 성과를 내기 어려웠습니다.

754
00:30:12,350 --> 00:30:15,230
그리고 그때는 머신러닝도 거의 없었습니다.

755
00:30:15,230 --> 00:30:20,430
2014년 이전까지는 모든 데이터셋이 대체로 작았습니다.

756
00:30:20,430 --> 00:30:23,630
그들은 모델 수가 많을 수 있는데, 심지어 10,000개, 9,000개,

757
00:30:23,630 --> 00:30:25,070
10,000개까지도 있습니다.

758
00:30:25,070 --> 00:30:27,810
하지만 그것들은 또한 매우 다양한 클래스들로 나뉘어져 있습니다.

759
00:30:27,810 --> 00:30:31,250
그래서 각 클래스마다 모델이 10개 정도, 많아야 100개

760
00:30:31,250 --> 00:30:32,790
이하라고 할 수 있습니다.

761
00:30:32,790 --> 00:30:36,130
그 후에 사람들은 이렇게 말하기 시작했습니다. 이미지넷이 있다면,

762
00:30:36,130 --> 00:30:38,870
3D 모양에 대한 데이터셋도 만들 수 있지 않을까?

763
00:30:38,870 --> 00:30:42,010
이것은 몇몇 동시다발적인 작업들의 배경에 있습니다.

764
00:30:42,010 --> 00:30:43,510
하지만 결국에는 이들이

765
00:30:43,510 --> 00:30:44,968
ShapeNet이라는 것으로 통합되었다고

766
00:30:44,968 --> 00:30:46,670
생각합니다. 이 프로젝트는 사실

767
00:30:46,670 --> 00:30:48,030
스탠포드가 많이 주도했습니다.

768
00:30:48,030 --> 00:30:52,070
레오 귀바스와 실비오 사바레세가 있습니다.

769
00:30:52,070 --> 00:30:55,050
이들이 300만 개의 모델을 가진 대규모

770
00:30:55,050 --> 00:30:57,922
데이터셋인 ShapeNet을 이끌었습니다.

771
00:30:57,922 --> 00:31:00,750
하지만 실제로는, ImageNet만 해도 이렇게 큰 이미지가 있습니다.

772
00:31:00,750 --> 00:31:03,010
그리고 사람들이 자주 사용하는 더 작은 데이터 세트가 있습니다.

773
00:31:03,010 --> 00:31:05,427
ShapeNet도 마찬가지로, 사람들이 보통 사용하는

774
00:31:05,427 --> 00:31:09,440
ShapeNet core 데이터 세트가 있는데, 기본적으로 55개 카테고리에

775
00:31:09,440 --> 00:31:10,600
5만 개 모델이 있습니다.

776
00:31:10,600 --> 00:31:12,100
이제 보시면, 각 카테고리마다

777
00:31:12,100 --> 00:31:13,720
평균적으로 1,000개의 모델이 있습니다.

778
00:31:13,720 --> 00:31:15,460
하지만 실제로는 균형이 맞지 않습니다.

779
00:31:15,460 --> 00:31:17,780
예를 들어 의자 카테고리는 실제로 훨씬 더 많습니다.

780
00:31:17,780 --> 00:31:19,240
그래서 사람들이 이제야

781
00:31:19,240 --> 00:31:21,300
의자 모델이 수천 개나 있어서,

782
00:31:21,300 --> 00:31:22,760
그걸로 딥 네트워크를 훈련할 수 있다고 말하는 겁니다.

783
00:31:22,760 --> 00:31:24,385
모델을 10개 정도 가질 수 있습니다.

784
00:31:24,385 --> 00:31:25,600
하지만 아무것도 할 수 없습니다.

785
00:31:25,600 --> 00:31:28,520
이렇게 시작되었고, 몇 년 동안 많은 발전과

786
00:31:28,520 --> 00:31:31,520
결과들이 의자와 자동차에 대해서만 발표되었습니다.

787
00:31:31,520 --> 00:31:33,620
왜냐하면 ShapeNet에서 가장 큰

788
00:31:33,620 --> 00:31:36,115
카테고리들이기 때문입니다. 그리고

789
00:31:36,115 --> 00:31:37,740
사람들은 '좋다'고 느꼈습니다.

790
00:31:37,740 --> 00:31:38,980
하지만 그것만으로는 충분하지 않습니다.

791
00:31:38,980 --> 00:31:41,960
그래서 더 큰 규모로 나아가야 합니다.

792
00:31:41,960 --> 00:31:45,140
최근 몇 년 동안 시애틀의 Allen Institute,

793
00:31:45,140 --> 00:31:47,662
AI2에서 한 연구가 있는데, 그들은 Objaverse와

794
00:31:47,662 --> 00:31:50,120
Objaverse Extra Large라는

795
00:31:50,120 --> 00:31:52,880
훨씬 더 큰 데이터셋을 수집했습니다. 여기에는

796
00:31:52,880 --> 00:31:57,100
대략 100만 개에서 1000만 개의 다양한 3D 모델이 포함되어 있습니다.

797
00:31:57,100 --> 00:32:00,240
더 많은 카테고리가 있다는 것을 알 수 있습니다.

798
00:32:00,240 --> 00:32:03,330
이 모델들은 평균적으로 더 높은 품질과

799
00:32:03,330 --> 00:32:05,730
텍스처도 포함하고 있습니다.

800
00:32:05,730 --> 00:32:07,190
이것들은 합성 데이터 세트입니다.

801
00:32:07,190 --> 00:32:09,648
하지만 3D 스캔에서 나온 것도 포함해서

802
00:32:09,648 --> 00:32:12,130
실제 데이터 세트도 만들어지고 있습니다.

803
00:32:12,130 --> 00:32:15,470
3D 스캐너를 사용하면 됩니다.

804
00:32:15,470 --> 00:32:17,630
2016년쯤부터 사람들이 이 작업을 해왔습니다.

805
00:32:17,630 --> 00:32:19,750
이 데이터 세트는 Redwood 데이터

806
00:32:19,750 --> 00:32:21,270
세트라고 부르는 것 같습니다.

807
00:32:21,270 --> 00:32:24,810
실제 세계 물체의 스캔 10,000개가 있습니다.

808
00:32:24,810 --> 00:32:28,890
최근에는 더 큰 데이터 세트를 만들면서 사람들에게 데이터를

809
00:32:28,890 --> 00:32:30,850
수집하도록 권장하기도 합니다.

810
00:32:30,850 --> 00:32:35,250
이것은 Meta와 Oxford가 공동 주도하는 노력인 것 같습니다.

811
00:32:35,250 --> 00:32:37,598
사람들에게 데이터를 수집하도록 권장합니다.

812
00:32:37,598 --> 00:32:39,390
사람들에게 데이터를 수집하면 돈도 지급합니다.

813
00:32:39,390 --> 00:32:41,630
사람들은 iPhone을 사용해서—물체를 준비합니다.

814
00:32:41,630 --> 00:32:42,310
테이블 위에 놓고요.

815
00:32:42,310 --> 00:32:43,060
iPhone을 사용합니다.

816
00:32:43,060 --> 00:32:44,890
물체 주변을 360도 영상으로

817
00:32:44,890 --> 00:32:47,370
촬영하면 1달러 정도를 받습니다.

818
00:32:47,370 --> 00:32:49,987
사람들에게 데이터를 수집하도록 권장하는 거죠.

819
00:32:49,987 --> 00:32:51,070
이것이 첫 번째 버전입니다.

820
00:32:51,070 --> 00:32:53,050
19,000개의 물체 영상이 있습니다.

821
00:32:53,050 --> 00:32:55,565
이것들은 실제 물체입니다. 실제 물체를 캡처하는 게 훨씬 어렵기

822
00:32:55,565 --> 00:32:56,190
때문입니다.

823
00:32:56,190 --> 00:32:57,250
앞서 말한 객체 버전과

824
00:32:57,250 --> 00:32:59,590
다른 점은, 이전에는 합성 물체였지만,

825
00:32:59,590 --> 00:33:01,260
이것들은 실제 물체입니다.

826
00:33:01,260 --> 00:33:04,780
그리고 3D 비전 알고리즘 개발이 많이 진행되어서,

827
00:33:04,780 --> 00:33:07,220
이 360도 영상을 이용해

828
00:33:07,220 --> 00:33:09,680
3D 물체를 재구성할 수 있습니다.

829
00:33:09,680 --> 00:33:13,400
그래서 영상이나 이미지와 3D 기하학 및 텍스처가

830
00:33:13,400 --> 00:33:15,510
쌍으로 된 데이터가 있습니다.

831
00:33:27,380 --> 00:33:28,480
이것이 첫 번째 버전입니다.

832
00:33:28,480 --> 00:33:31,020
더 최근 버전인 V2나 아마 V3도

833
00:33:31,020 --> 00:33:33,880
있을 텐데, 더 큰 규모라고 합니다.

834
00:33:33,880 --> 00:33:35,535
하지만 여전히 확장하기는 어렵습니다.

835
00:33:35,535 --> 00:33:36,160
생각해 보세요.

836
00:33:36,160 --> 00:33:39,580
지금 90,000개의 영상, 즉 90,000개의 물체가

837
00:33:39,580 --> 00:33:40,360
있습니다.

838
00:33:40,360 --> 00:33:42,200
확장 중이지만 100,

839
00:33:42,200 --> 00:33:44,440
000개를 넘지는 않는 것 같습니다.

840
00:33:44,440 --> 00:33:47,000
즉, 실제 물체 모델은 100,000개

841
00:33:47,000 --> 00:33:48,900
정도 있다고 생각할 수 있습니다.

842
00:33:48,900 --> 00:33:52,660
그런데 이미지 데이터 세트 크기는 어떻게 될까요?

843
00:33:52,660 --> 00:33:54,880
[? in the ?] 5B 정도라고 생각하시면 됩니다.

844
00:33:54,880 --> 00:33:56,280
그게 약 50억 장의 이미지라는 겁니다.

845
00:33:56,280 --> 00:33:59,240
그리고 Google과 OpenAI는 훨씬 더 큰 데이터 세트를 가지고 있을
겁니다.

846
00:33:59,240 --> 00:34:02,160
그래서 2D 이미지나 비디오에 비해 3D

847
00:34:02,160 --> 00:34:05,520
객체에 사용할 수 있는 데이터 포인트 수에는 여전히

848
00:34:05,520 --> 00:34:06,860
큰 차이가 있습니다.

849
00:34:06,860 --> 00:34:08,400
그래서 3D 비전을 어떻게 발전시킬

850
00:34:08,400 --> 00:34:10,500
수 있을지가 큰 도전 과제라고 생각합니다.

851
00:34:10,500 --> 00:34:12,360
사람마다 다양한 아이디어가 있습니다.

852
00:34:12,360 --> 00:34:15,060
하지만 여전히 이전보다 훨씬 큰 규모입니다.

853
00:34:15,060 --> 00:34:15,962
적어도 할 수는 있습니다.

854
00:34:15,962 --> 00:34:17,920
지금 이 데이터 세트로 어느

855
00:34:17,920 --> 00:34:22,108
정도 딥러닝 모델을 훈련하는 것도 가능할 수 있습니다.

856
00:34:22,108 --> 00:34:24,400
그리고 빠르게, 사람들이 부분 단위로 구축하는

857
00:34:24,400 --> 00:34:25,760
다른 데이터 세트들도 있습니다.

858
00:34:25,760 --> 00:34:27,528
이것도 Stanford에서 나온

859
00:34:27,528 --> 00:34:29,320
것으로, 객체의 일부와 그 대응관계,

860
00:34:29,320 --> 00:34:31,760
계층 구조를 조금씩 주석 달려고 시도한 겁니다.

861
00:34:35,320 --> 00:34:38,719
그리고 PartNet이라는 데이터 세트도 있는데,

862
00:34:38,719 --> 00:34:40,518
여기서는 부품과 의미뿐 아니라

863
00:34:40,518 --> 00:34:42,060
어떻게 움직일 수 있는지도

864
00:34:42,060 --> 00:34:43,280
주석 달려고 합니다.

865
00:34:43,280 --> 00:34:46,100
즉, 다양한 부품의 약간의 이동성 정보입니다.

866
00:34:46,100 --> 00:34:48,239
예를 들어 노트북은 열고 닫을 수 있죠.

867
00:34:48,239 --> 00:34:50,241
그리고 3D 장면을 위한 데이터 세트도 있습니다.

868
00:34:50,241 --> 00:34:51,699
단순히 객체와 부품뿐 아니라,

869
00:34:51,699 --> 00:34:53,600
방들도 포함되어 있습니다.

870
00:34:53,600 --> 00:34:57,200
그래서 스캔 데이터 세트 같은 것들이 있었습니다.

871
00:34:57,200 --> 00:34:59,450
이 사람들은 실제로 여러분의 집이나,

872
00:34:59,450 --> 00:35:01,990
사실 우리 연구실에도 들어오죠.

873
00:35:01,990 --> 00:35:04,630
그냥 들어와서 3D 스캐너를 가지고 있습니다.

874
00:35:04,630 --> 00:35:07,130
집을 스캔하고, 거기에 몇 가지 주석을 달죠.

875
00:35:07,130 --> 00:35:11,850
여기서, 그리고 최근에는, 지금 여러분의

876
00:35:11,850 --> 00:35:14,090
아이폰으로도 할 수 있습니다.

877
00:35:14,090 --> 00:35:17,150
하지만 이런 종류의 데이터 세트는 여전히 훨씬 작습니다.

878
00:35:17,150 --> 00:35:20,945
여기 이 첫 번째 버전 스캐너는 1,500개가 있습니다.

879
00:35:20,945 --> 00:35:23,070
두 번째 버전은 아마 2,

880
00:35:23,070 --> 00:35:26,710
000개나 3,000개 정도로 비슷한 크기일 겁니다.

881
00:35:26,710 --> 00:35:29,170
특히 3D 장면에 대한

882
00:35:29,170 --> 00:35:32,250
3D 데이터 양은 3D 객체에

883
00:35:32,250 --> 00:35:34,703
비해 훨씬 적습니다.

884
00:35:34,703 --> 00:35:36,370
그래서 그 한계를 어떻게

885
00:35:36,370 --> 00:35:38,453
넘을 수 있을지는 명확하지

886
00:35:38,453 --> 00:35:40,010
않습니다. 왜냐하면

887
00:35:40,010 --> 00:35:41,410
직접 스캔해야

888
00:35:41,410 --> 00:35:45,250
한다면, 시간과 인원에 항상 제한을 받기 때문입니다.

889
00:35:45,250 --> 00:35:47,850
어쨌든 데이터를 수집하려는

890
00:35:47,850 --> 00:35:52,010
시도들이 계속되고 있습니다.

891
00:35:52,010 --> 00:35:56,220
마지막으로, 3D 비전에 딥러닝을 적용하려면,

892
00:35:56,220 --> 00:35:59,085
우리가 관심 있는 작업은 무엇일까요?

893
00:35:59,085 --> 00:36:00,460
생성 모델링이

894
00:36:00,460 --> 00:36:03,000
있습니다, 저스틴이 말한 것처럼요.

895
00:36:03,000 --> 00:36:05,700
2D 이미지나 비디오를 생성할 수 있습니다.

896
00:36:05,700 --> 00:36:07,080
3D 형태도 생성할 수 있고,

897
00:36:07,080 --> 00:36:08,240
3D 장면도 생성할 수 있습니다.

898
00:36:08,240 --> 00:36:09,980
조건을 걸 수 있습니다.

899
00:36:09,980 --> 00:36:13,560
조건은 언어에 조건을 걸 수도 있고, 이미지에 조건을 걸 수도 있습니다.

900
00:36:13,560 --> 00:36:14,600
입력 이미지가 있습니다.

901
00:36:14,600 --> 00:36:16,940
그럼 3D 객체를 어떻게 재구성할 수 있을까요?

902
00:36:16,940 --> 00:36:19,000
그리고 형태의 사전 지식을 배워야 합니다.

903
00:36:19,000 --> 00:36:21,320
형태 생성과 완성을 해야 합니다.

904
00:36:21,320 --> 00:36:23,220
때로는 부분적인 객체가 있고,

905
00:36:23,220 --> 00:36:25,280
그것을 복원하고 싶을 때가 있습니다.

906
00:36:25,280 --> 00:36:26,080
수정하고 싶으시죠.

907
00:36:26,080 --> 00:36:28,580
그래서 기하학적 데이터 처리도 있습니다.

908
00:36:28,580 --> 00:36:31,425
다른 작업들로는 판별 모델도 포함됩니다.

909
00:36:31,425 --> 00:36:32,800
예를 들어, 3D 형태가 있습니다.

910
00:36:32,800 --> 00:36:35,700
그 객체가 어떤 카테고리에 속하는지 분류하려면 어떻게

911
00:36:35,700 --> 00:36:36,480
해야 할까요?

912
00:36:36,480 --> 00:36:38,380
의자인가요, 아니면 탁자인가요?

913
00:36:38,380 --> 00:36:39,940
지금은 많은 경우에 그것을

914
00:36:39,940 --> 00:36:41,820
픽셀로 렌더링해서 처리합니다.

915
00:36:41,820 --> 00:36:44,500
왜냐하면 GPT 같은 아주 좋은 이미지 인식

916
00:36:44,500 --> 00:36:46,000
모델이 있기 때문입니다.

917
00:36:46,000 --> 00:36:47,502
그래서 3D 객체를 그냥 가져와서

918
00:36:47,502 --> 00:36:48,960
그것을 그림으로 렌더링할 수 있습니다.

919
00:36:48,960 --> 00:36:51,160
그림을 GPT에 업로드하면, GPT가 분류해 줄 수 있습니다.

920
00:36:51,160 --> 00:36:52,820
이것이 어떤 면에서는

921
00:36:52,820 --> 00:36:55,670
판별 문제를 푸는 한 가지 방법입니다.

922
00:36:55,670 --> 00:36:57,550
하지만 해결하기 쉽지 않은 더

923
00:36:57,550 --> 00:36:59,430
구체적인 문제들도 있습니다.

924
00:36:59,430 --> 00:37:02,070
예를 들어, 다른 종류의 세포가 있고,

925
00:37:02,070 --> 00:37:03,570
3D 스캔 데이터가 있습니다.

926
00:37:03,570 --> 00:37:05,750
그 세포를 어떻게 분류할 수 있을까요? 그리고

927
00:37:05,750 --> 00:37:08,083
데이터가 많지 않은 더 전문화된 영역들에서는요?

928
00:37:08,083 --> 00:37:11,950
그럼 이런 판별 문제를 어떻게 해결할 수 있을까요?

929
00:37:11,950 --> 00:37:13,965
2D와 3D 데이터를 함께 모델링하는 것도

930
00:37:13,965 --> 00:37:16,590
점점 중요해지고 있습니다. 왜냐하면 두 데이터가 훨씬

931
00:37:16,590 --> 00:37:17,650
더 많기 때문입니다.

932
00:37:17,650 --> 00:37:19,188
우리는 수많은 이미지와 비디오를 가지고 있습니다.

933
00:37:19,188 --> 00:37:21,730
그 위에 아주 잘 훈련된 파운데이션 모델도 있습니다.

934
00:37:21,730 --> 00:37:24,670
그래서 2D 파운데이션 모델의 사전 지식을 어떻게 활용할 수

935
00:37:24,670 --> 00:37:25,190
있을까요?

936
00:37:25,190 --> 00:37:26,607
예를 들어, 이미지가 어떻게 생겼는지,

937
00:37:26,607 --> 00:37:28,950
이미지를 어떻게 현실감 있게 만드는지, 비디오를 어떻게 현실감

938
00:37:28,950 --> 00:37:29,730
있게 만드는지 말이죠.

939
00:37:29,730 --> 00:37:32,590
그 정보를 3D 재구성에 활용해서 더 현실감 있게

940
00:37:32,590 --> 00:37:34,270
만들려면 어떻게 해야 할까요?

941
00:37:34,270 --> 00:37:36,490
그래서 2D와 3D 데이터를 함께 모델링하는 것이

942
00:37:36,490 --> 00:37:38,950
중요합니다. 왜냐하면 대규모 2D 데이터셋과 아주 좋은

943
00:37:38,950 --> 00:37:40,450
사전학습 모델이 있기 때문입니다.

944
00:37:40,450 --> 00:37:43,377
또한, 신경 렌더링이나 미분 가능 렌더링 방법에서도 많은

945
00:37:43,377 --> 00:37:45,710
발전이 있었습니다. 이것들은 기본적으로 3D 세계와

946
00:37:45,710 --> 00:37:46,927
2D 세계를 연결합니다.

947
00:37:46,927 --> 00:37:48,010
왜냐하면 3D 세계가 있으니까요.

948
00:37:48,010 --> 00:37:48,760
3D 모델이 있습니다.

949
00:37:48,760 --> 00:37:49,970
이것을 2D로 렌더링할 수 있습니다.

950
00:37:49,970 --> 00:37:52,500
렌더링 과정은 미분 가능하게 만들거나

951
00:37:52,500 --> 00:37:54,460
신경망으로 근사할 수 있습니다.

952
00:37:54,460 --> 00:37:56,680
그럼 이제 미분 가능한 신경망을

953
00:37:56,680 --> 00:37:58,763
통해 서로 다른 모달리티의

954
00:37:58,763 --> 00:38:02,920
데이터를 연결할 수 있어서, 2D 데이터나 2D 기반 모델에서

955
00:38:02,920 --> 00:38:06,360
가진 사전 지식을 3D 세계로 연결할 수 있습니다.

956
00:38:06,360 --> 00:38:09,113
네, 그리고 때로는 시각 데이터뿐 아니라 텍스트 데이터 같은 여러

957
00:38:09,113 --> 00:38:10,780
모달을 함께 다루고 싶을 때도 있습니다.

958
00:38:10,780 --> 00:38:12,238
하지만 때로는 다른 데이터도 있습니다.

959
00:38:12,238 --> 00:38:14,660
예를 들어 로보틱스에서는 촉각 데이터가 자주 있습니다.

960
00:38:14,660 --> 00:38:16,280
그래서 이것들을 어떻게 융합할지도 고민해야 합니다.

961
00:38:16,280 --> 00:38:18,360
그리고 자율주행에서는 LiDAR

962
00:38:18,360 --> 00:38:20,380
데이터나 깊이 데이터가 있을 수 있죠.

963
00:38:20,380 --> 00:38:22,760
이것들도 어떻게 융합할 수 있을까요?

964
00:38:22,760 --> 00:38:25,480
그래서 저는 3D 데이터에 딥러닝을 적용해 이런 다양한

965
00:38:25,480 --> 00:38:26,878
문제를 해결하고 싶습니다.

966
00:38:26,878 --> 00:38:29,170
그래서 우리는 표현 방법에 대해 계속 이야기했습니다.

967
00:38:29,170 --> 00:38:30,640
그럼 어떻게 시작할까요?

968
00:38:30,640 --> 00:38:33,898
제가 말씀드렸듯이, 처음 이 분야를 시작한 사람들은 픽셀을

969
00:38:33,898 --> 00:38:35,940
다루는 컴퓨터 비전 연구자들입니다.

970
00:38:35,940 --> 00:38:36,900
그들은 이미지를 다루죠.

971
00:38:36,900 --> 00:38:39,420
그래서 자연스럽게, 왜 voxel부터 시작하지 않느냐고 생각합니다.

972
00:38:39,420 --> 00:38:42,858
하지만 그 이전에, 그들은 이렇게 말합니다. 이건 오래된 아이디어라고요.

973
00:38:42,858 --> 00:38:45,400
그리고 이것이 사람들이 딥러닝을 3D 비전에 적용할

974
00:38:45,400 --> 00:38:46,900
때 처음 시도한 아이디어입니다.

975
00:38:46,900 --> 00:38:48,643
그리고 지금은 어떤 의미에서 다시 돌아오고 있습니다.

976
00:38:48,643 --> 00:38:50,060
하지만 그들이 처음 시도한 아이디어는,

977
00:38:50,060 --> 00:38:52,080
이제는 voxel에 대해 걱정하지 말자는 겁니다.

978
00:38:52,080 --> 00:38:53,700
그냥 3D 형태가 있다고 합시다.

979
00:38:53,700 --> 00:38:54,320
메시일 수도 있고요.

980
00:38:54,320 --> 00:38:55,700
voxel일 수도 있고요, 뭐든 상관없습니다.

981
00:38:55,700 --> 00:38:59,200
그리고 여러분이 객체가 무엇인지 인식하도록 학습하길 원합니다.

982
00:38:59,200 --> 00:39:00,280
여기 객체가 무엇일까요?

983
00:39:00,280 --> 00:39:01,600
의자입니다.

984
00:39:01,600 --> 00:39:03,120
그런데 입력이 3D 데이터라면요?

985
00:39:03,120 --> 00:39:04,820
그걸 어떻게 처리할 수 있을까요?

986
00:39:04,820 --> 00:39:07,320
3D 딥러닝 방법이 있기 전에는, 이미지 모델이

987
00:39:07,320 --> 00:39:10,140
아주 좋으니까 3D 데이터를 그냥 이미지로 렌더링하면

988
00:39:10,140 --> 00:39:10,790
어떨까요?

989
00:39:13,620 --> 00:39:14,960
3D 객체를 그냥 가져와서요.

990
00:39:14,960 --> 00:39:16,480
카메라를 여러 위치에 놓고,

991
00:39:16,480 --> 00:39:18,230
다양한 시점에서 객체를 모두

992
00:39:18,230 --> 00:39:19,540
렌더링할 수 있습니다.

993
00:39:19,540 --> 00:39:22,120
그리고 이제 이것이 2D 문제로 바뀝니다.

994
00:39:22,120 --> 00:39:24,180
각각의 뷰에 컨볼루션 신경망을

995
00:39:24,180 --> 00:39:27,560
적용하고, 이를 융합하는 방법들이 있습니다.

996
00:39:27,560 --> 00:39:29,580
그래서 풀링 같은 것을 사용하죠.

997
00:39:29,580 --> 00:39:32,500
그리고 나서 이미지 분류를 합니다.

998
00:39:32,500 --> 00:39:34,860
그래서 이것이 이미지 분류 문제로 변합니다.

999
00:39:34,860 --> 00:39:37,722
유일한 차이점은 이제 여러 뷰가 있다는 겁니다.

1000
00:39:37,722 --> 00:39:40,180
이것은 어떤 면에서는 사람들이 3D 비전에 처음

1001
00:39:40,180 --> 00:39:41,700
적용한 아이디어 중 하나입니다.

1002
00:39:41,700 --> 00:39:43,375
그냥 2D 네트워크를 사용한 거죠.

1003
00:39:43,375 --> 00:39:45,000
왜 2D 네트워크를 사용하려고 할까요?

1004
00:39:45,000 --> 00:39:47,042
당시에는 ImageNet에서 성능을 끌어올리고 있었기 때문입니다.

1005
00:39:47,042 --> 00:39:48,150
그리고 ImageNet은 매우 뛰어납니다.

1006
00:39:48,150 --> 00:39:51,535
ImageNet은 3D 데이터셋보다 훨씬 큽니다.

1007
00:39:51,535 --> 00:39:53,410
그래서 ImageNet으로 사전학습된

1008
00:39:53,410 --> 00:39:54,743
모델은 성능이 아주 좋습니다.

1009
00:39:54,743 --> 00:39:57,190
3D 인식 문제를 해결하는 가장 쉬운 방법은

1010
00:39:57,190 --> 00:39:59,670
먼저 3D를 2D로 렌더링하는 것입니다.

1011
00:39:59,670 --> 00:40:02,790
나중에는 사람들이 3D 데이터가 더 많아지면서 이 방법에서

1012
00:40:02,790 --> 00:40:04,010
벗어나기 시작했습니다.

1013
00:40:04,010 --> 00:40:05,550
3D 고유(native) 방식을

1014
00:40:05,550 --> 00:40:07,390
시도해보자는 생각이 생긴 거죠.

1015
00:40:07,390 --> 00:40:10,310
사람들은 또한 neural rendering을 통해 3D와 2D를

1016
00:40:10,310 --> 00:40:11,715
연결하는 아이디어를 내기도 합니다.

1017
00:40:11,715 --> 00:40:13,590
하지만 지금은 이미지와 비디오 모델들이

1018
00:40:13,590 --> 00:40:15,815
너무 좋아져서 이 트렌드가 다시 돌아오는

1019
00:40:15,815 --> 00:40:16,690
것 같습니다.

1020
00:40:16,690 --> 00:40:18,790
어제 VL3 같은 게 나왔다는 걸

1021
00:40:18,790 --> 00:40:21,070
많은 분들이 보셨는지 모르겠네요?

1022
00:40:21,070 --> 00:40:21,570
맞습니다.

1023
00:40:21,570 --> 00:40:24,470
그래서 모델들이 너무 좋다면, 아마도 이미지와 비디오

1024
00:40:24,470 --> 00:40:26,770
기반 모델에 다시 좀 더 의존하는

1025
00:40:26,770 --> 00:40:29,853
게 좋을 수도 있습니다. 왜냐하면 3D 데이터보다 천

1026
00:40:29,853 --> 00:40:31,770
배, 만 배, 심지어 백만 배

1027
00:40:31,770 --> 00:40:34,310
이상 더 많은 데이터로 훈련되었기 때문입니다.

1028
00:40:34,310 --> 00:40:36,090
그걸 어떻게 통합할 수 있을까요?

1029
00:40:36,090 --> 00:40:39,430
다시 돌아와서, 이것이 바로 첫 번째 방법입니다.

1030
00:40:39,430 --> 00:40:43,030
어떤 면에서는 사람들이 3D 데이터를 2D로 변환해서

1031
00:40:43,030 --> 00:40:45,270
딥러닝을 적용하려고 시도합니다.

1032
00:40:45,270 --> 00:40:48,122
그리고 형태 분류에서 아주 좋은 성과를 냅니다.

1033
00:40:48,122 --> 00:40:50,080
형태들이 있고, 그것들을 여러 카테고리로

1034
00:40:50,080 --> 00:40:51,163
분류하려는 거죠.

1035
00:40:51,163 --> 00:40:54,280
그리고 성능이 매우 좋습니다.

1036
00:40:54,280 --> 00:40:58,440
그래서 2D 이미지 사전학습 모델에 관한 많은 문헌을

1037
00:40:58,440 --> 00:41:00,120
활용할 수 있습니다.

1038
00:41:00,120 --> 00:41:02,680
하지만 문제는 투영이 필요하다는 점입니다.

1039
00:41:02,680 --> 00:41:05,140
때로는 입력이 매우 노이즈가 심할 수 있습니다.

1040
00:41:05,140 --> 00:41:07,243
사람들은 입력이 너무 노이즈가 심하면 어떻게 하냐고 묻습니다.

1041
00:41:07,243 --> 00:41:09,660
포인트 클라우드 같은 것들이 별로 좋지 않을 때 말이죠.

1042
00:41:09,660 --> 00:41:11,760
렌더링하면 좀 별로로 보입니다.

1043
00:41:11,760 --> 00:41:15,680
그렇다면 3D 네이티브 방식을 더 개발할 수 있을까요?

1044
00:41:15,680 --> 00:41:20,000
그래서 나중에 사람들은 3D 데이터에 딥러닝을 직접 적용하는 여러

1045
00:41:20,000 --> 00:41:22,040
3D 네이티브 방식을 시도했습니다.

1046
00:41:22,040 --> 00:41:24,280
말씀드렸듯이, 가장 쉬운 방법은

1047
00:41:24,280 --> 00:41:27,640
픽셀 컨볼루션 신경망을 복셀, 즉 부피

1048
00:41:27,640 --> 00:41:30,440
컨볼루션 신경망에 적용하는 겁니다.

1049
00:41:30,440 --> 00:41:33,360
이것은 실제로 생성 네트워크인 Deep Belief

1050
00:41:33,360 --> 00:41:34,880
Network입니다.

1051
00:41:34,880 --> 00:41:38,060
하지만 여전히 3D 컨볼루션 필터가 있습니다.

1052
00:41:38,060 --> 00:41:41,280
이것은 2015년 프린스턴에서 나온 연구입니다.

1053
00:41:41,280 --> 00:41:43,640
그들의 생성 모델은 비교적

1054
00:41:43,640 --> 00:41:48,330
낮은 해상도의 3D 복셀 형태로 3D 형상을 합성할

1055
00:41:48,330 --> 00:41:50,370
수 있음을 보여줍니다.

1056
00:41:50,370 --> 00:41:52,430
하지만 이건 벌써 10년 전 일이죠.

1057
00:41:52,430 --> 00:41:56,090
그때는 꽤 인상적이라고 여겨졌습니다.

1058
00:41:56,090 --> 00:41:58,470
조건부 생성도 할 수 있어서, 박쥐,

1059
00:41:58,470 --> 00:42:02,750
책상, 테이블 같은 조건부 의미 레이블을 적용할 수 있습니다.

1060
00:42:02,750 --> 00:42:04,582
다양한 형태를 합성할 수 있죠.

1061
00:42:04,582 --> 00:42:06,290
그리고 생성 네트워크이기

1062
00:42:06,290 --> 00:42:08,730
때문에 분류에도 사용할 수 있습니다.

1063
00:42:08,730 --> 00:42:12,890
이미지 형태 분류도 가능합니다.

1064
00:42:12,890 --> 00:42:16,890
나중에 저희가 실제로 한 것은 GANs, 즉 Generative

1065
00:42:16,890 --> 00:42:19,330
Adversarial Network를

1066
00:42:19,330 --> 00:42:20,830
적용하는 것이었습니다.

1067
00:42:20,830 --> 00:42:22,510
GANs는 2D 픽셀을 생성하는 데 사용할 수 있습니다.

1068
00:42:22,510 --> 00:42:25,090
GANs를 3D 복셀 생성에 못 쓸 이유가 없습니다.

1069
00:42:25,090 --> 00:42:27,450
그래서 아주 간단하게

1070
00:42:27,450 --> 00:42:30,690
GAN을 3D 복셀에 적용했고, 꽤

1071
00:42:30,690 --> 00:42:33,830
좋은 3D 객체 생성을 보여줬습니다.

1072
00:42:33,830 --> 00:42:36,450
이건 8, 9년 전 일이죠.

1073
00:42:36,450 --> 00:42:39,410
네, 알겠습니다.

1074
00:42:39,410 --> 00:42:44,490
그리고 나중에 CMU에서 훈련하면서 확장도 했습니다.

1075
00:42:44,490 --> 00:42:48,130
GANs를 사용해 3D 형상뿐 아니라 2D로

1076
00:42:48,130 --> 00:42:50,330
렌더링할 수도 있습니다.

1077
00:42:50,330 --> 00:42:53,470
3D 객체를 2D 표면에

1078
00:42:53,470 --> 00:42:57,130
투영해서 깊이 맵을 얻을 수 있죠.

1079
00:42:57,130 --> 00:42:59,950
그리고 이 깊이 맵을 CycleGAN으로

1080
00:42:59,950 --> 00:43:02,273
컬러 이미지로 변환할 수 있습니다.

1081
00:43:02,273 --> 00:43:04,690
이제 3D 형상뿐 아니라 2D 이미지에도 적대적 손실을

1082
00:43:04,690 --> 00:43:05,830
적용할 수 있습니다.

1083
00:43:05,830 --> 00:43:08,270
3D 형상이 실제 3D 객체

1084
00:43:08,270 --> 00:43:12,270
데이터와 구별되지 않도록 현실적으로 보이게 하고 싶고,

1085
00:43:12,270 --> 00:43:14,710
2D 이미지도 실제 자동차 이미지와

1086
00:43:14,710 --> 00:43:18,470
구별되지 않도록 현실적으로 보이게 하고 싶습니다.

1087
00:43:18,470 --> 00:43:20,270
그래서 3D 생성과 2D

1088
00:43:20,270 --> 00:43:22,630
생성을 동시에 할 수 있습니다.

1089
00:43:22,630 --> 00:43:27,210
형상, 시점, 텍스처에 대해 각각 다른 잠재

1090
00:43:27,210 --> 00:43:29,330
벡터가 있어서 어느 정도

1091
00:43:29,330 --> 00:43:31,352
조절도 가능합니다.

1092
00:43:31,352 --> 00:43:32,810
예를 들어 시점을 바꿀 수 있고,

1093
00:43:32,810 --> 00:43:34,310
텍스처를 바꿀 수 있으며,

1094
00:43:34,310 --> 00:43:36,270
보간도 할 수 있습니다.

1095
00:43:36,270 --> 00:43:39,750
그리고 한 자동차의 텍스처를 다른 자동차의

1096
00:43:39,750 --> 00:43:42,260
형태에 옮길 수 있습니다.

1097
00:43:42,260 --> 00:43:45,200
이건 2018년 이야기입니다.

1098
00:43:45,200 --> 00:43:47,480
그래서 사람들은 2D 픽셀 대신 3D

1099
00:43:47,480 --> 00:43:48,980
복셀에 합성곱 신경망,

1100
00:43:48,980 --> 00:43:51,920
생성적 적대 신경망 같은 딥 네트워크를 적용하려고

1101
00:43:51,920 --> 00:43:52,863
시도했습니다.

1102
00:43:52,863 --> 00:43:54,780
복셀로 조금 더 나아질 수 있을까요?

1103
00:43:54,780 --> 00:43:57,200
복셀에 대해 사람들이 불평하는 점 중

1104
00:43:57,200 --> 00:43:59,240
하나는 너무 느리다는 겁니다.

1105
00:43:59,240 --> 00:44:00,420
복셀을 미리 샘플링해야 하거든요.

1106
00:44:00,420 --> 00:44:01,920
그리고 많은 샘플

1107
00:44:01,920 --> 00:44:04,880
포인트가 그냥 빈 공간이라서 낭비가 많습니다.

1108
00:44:04,880 --> 00:44:08,125
또는 물체 내부에 있어서 정보를 주지 않는 경우도 있죠.

1109
00:44:08,125 --> 00:44:09,500
그래서 자연스럽게 사람들은, 좋아, 이걸 실제로

1110
00:44:09,500 --> 00:44:10,792
더 나아지게 할 수 있을까 생각했습니다.

1111
00:44:10,792 --> 00:44:14,120
그래서 옥타브 트리 같은 복셀 개선 방법들이 나왔습니다.

1112
00:44:14,120 --> 00:44:16,160
옥타브 트리의 아이디어는 여전히

1113
00:44:16,160 --> 00:44:18,093
명시적 표현을 가진다는 겁니다.

1114
00:44:18,093 --> 00:44:19,760
죄송하지만, 어떤 면에서는 암묵적

1115
00:44:19,760 --> 00:44:20,885
표현이라고도 할 수 있습니다.

1116
00:44:20,885 --> 00:44:24,400
하지만 비모수적 암묵적 표현 같은 거죠.

1117
00:44:24,400 --> 00:44:26,520
그런데 공간의 모든

1118
00:44:26,520 --> 00:44:31,848
점을 균일한 스케일로 표현하는 대신에,

1119
00:44:31,848 --> 00:44:34,780
복셀 크기가 다를 수 있다고

1120
00:44:34,780 --> 00:44:37,840
가정하고 공간을 여러

1121
00:44:37,840 --> 00:44:40,230
영역으로 나눕니다.

1122
00:44:40,230 --> 00:44:41,490
그리고 훨씬 더 많은 자원을 씁니다.

1123
00:44:41,490 --> 00:44:43,810
그리고 물체 표면에 정말 가까워졌다고

1124
00:44:43,810 --> 00:44:47,110
느낄 때는 훨씬 더 세밀한 스케일로 물체를 표현합니다.

1125
00:44:47,110 --> 00:44:49,890
그리고 제가 이 빈 공간이나 물체 내부에 있을 때, 그 안에서

1126
00:44:49,890 --> 00:44:52,690
무슨 일이 일어나는지 크게 신경 쓰지 않아도 된다면,

1127
00:44:52,690 --> 00:44:54,990
어떤 의미에서는 아주 큰 복셀을 가질 수 있습니다.

1128
00:44:54,990 --> 00:44:57,690
그래서 공간을 재귀적으로 분할할 수 있고,

1129
00:44:57,690 --> 00:45:02,070
공간의 다른 부분에 서로 다른 크기의 복셀을 가질 수 있습니다.

1130
00:45:02,070 --> 00:45:04,730
이것이 정말로 확장할 수 있게 해줍니다.

1131
00:45:04,730 --> 00:45:07,870
그래서 단순히 복셀을 직접 사용하는 것과 비교해

1132
00:45:07,870 --> 00:45:10,130
보면, 이건 2019년쯤의 이야기입니다.

1133
00:45:10,130 --> 00:45:12,890
사람들은 옥타브 트리가 훌륭하다고 말하는데, 왜냐하면

1134
00:45:12,890 --> 00:45:14,950
저해상도에서부터 시작할 수 있게 해주기 때문입니다.

1135
00:45:14,950 --> 00:45:17,770
GPU 메모리에 얼마나 많이 넣을 수 있는지에 관한 이야기입니다.

1136
00:45:17,770 --> 00:45:20,150
복셀로는 64x64를 할 수 있습니다.

1137
00:45:20,150 --> 00:45:23,956
하지만 옥타브 트리를 사용하면 256까지 할 수 있습니다.

1138
00:45:23,956 --> 00:45:26,230
그리고 그것을 생성에도 사용할 수 있습니다.

1139
00:45:26,230 --> 00:45:28,530
물체도 생성할 수 있습니다.

1140
00:45:28,530 --> 00:45:31,330
그것들은 복셀처럼 보이지만, 공간을 더

1141
00:45:31,330 --> 00:45:34,490
효율적으로 표현하기 때문에 해상도가 더 높습니다.

1142
00:45:34,490 --> 00:45:37,260
이것들이 3D 공간에 딥러닝을 적용한 아주

1143
00:45:37,260 --> 00:45:38,620
초기 시도들입니다.

1144
00:45:38,620 --> 00:45:41,406
그리고 여러분은 '왜 그냥 복셀을 시도하지 않지?'라고 생각할 수 있습니다.

1145
00:45:41,406 --> 00:45:44,300
그때 사람들이 좀 더 관심을 갖기 시작하는

1146
00:45:44,300 --> 00:45:46,640
순간이 옵니다. '아니,

1147
00:45:46,640 --> 00:45:50,740
그래픽스 쪽 사람들은 이걸 다 잘못하고 있는 거 아닌가?'

1148
00:45:50,740 --> 00:45:51,700
하는 생각이죠.

1149
00:45:51,700 --> 00:45:54,460
왜 이런 비효율적이고 보기에도 별로인 표현

1150
00:45:54,460 --> 00:45:56,540
방식인 복셀이나 옥타브 트리를

1151
00:45:56,540 --> 00:45:58,067
사용하려고 하느냐는 겁니다.

1152
00:45:58,067 --> 00:45:59,900
지금은 포인트 클라우드, 메시, 스플라인

1153
00:45:59,900 --> 00:46:01,820
같은 훨씬 좋은 표현 방식들이 있기 때문입니다.

1154
00:46:01,820 --> 00:46:03,880
왜 이런 표현들을 사용하지 않는 걸까요?

1155
00:46:03,880 --> 00:46:06,652
하지만 말씀드렸듯이, 문제는 점들이 여기저기에 흩어져 있다는 겁니다.

1156
00:46:06,652 --> 00:46:08,860
그런데 어떻게 컨볼루션 같은 걸 점들에 적용할 수

1157
00:46:08,860 --> 00:46:09,360
있겠습니까?

1158
00:46:09,360 --> 00:46:10,540
그게 그렇게 명확하지 않습니다.

1159
00:46:10,540 --> 00:46:12,420
하지만 사람들이 이 문제에 관심을 갖기 시작했습니다.

1160
00:46:12,420 --> 00:46:15,860
그래서 자연스럽게 사람들은 3D 데이터뿐만 아니라

1161
00:46:15,860 --> 00:46:19,302
포인트 클라우드 같은 다양한 3D 표현에 직접 작동하는

1162
00:46:19,302 --> 00:46:21,260
새로운 딥러닝 방법을 적용하거나

1163
00:46:21,260 --> 00:46:23,060
개발하기 시작했습니다.

1164
00:46:23,060 --> 00:46:26,380
PointNet에서는, 이건 스탠포드의 Leo

1165
00:46:26,380 --> 00:46:29,620
팀에서 나온 중요한 연구라고 생각합니다.

1166
00:46:29,620 --> 00:46:32,300
여기서 일어나는 일은 3D 포인트 클라우드에 직접 작동하는

1167
00:46:32,300 --> 00:46:34,660
새로운 유형의 딥 네트워크를 개발했다는 겁니다.

1168
00:46:34,660 --> 00:46:37,520
그래서 이것을 PointNet이라고 합니다.

1169
00:46:37,520 --> 00:46:42,440
즉, 점들에 대해서는 순열 불변성을 가져야 합니다. 왜냐하면 점 1과

1170
00:46:42,440 --> 00:46:45,840
점 2가 있을 때, 점 1이 여기 있고 점

1171
00:46:45,840 --> 00:46:47,170
2가 저기에 있으면,

1172
00:46:47,170 --> 00:46:49,300
이제 입력이 달라진 겁니다.

1173
00:46:49,300 --> 00:46:52,000
제가 점 1을 여기, 점 2를 저기로 말할 수도 있죠.

1174
00:46:52,000 --> 00:46:55,080
그래서 어떤 경우든, 네트워크는 이런 두

1175
00:46:55,080 --> 00:46:58,880
가지 입력에 대해 불변해야 합니다. 즉, 이 점을

1176
00:46:58,880 --> 00:47:02,060
점 1이라고 하든, 저 점을 점 2라고

1177
00:47:02,060 --> 00:47:03,920
하든, 출력은 같아야

1178
00:47:03,920 --> 00:47:05,900
합니다. 왜냐하면 점들은

1179
00:47:05,900 --> 00:47:08,488
순서가 정해져 있지 않기 때문입니다.

1180
00:47:08,488 --> 00:47:10,280
왼쪽 위가 1,

1181
00:47:10,280 --> 00:47:11,680
1이고

1182
00:47:11,680 --> 00:47:14,660
오른쪽 아래가 100, 100이라는 보장이 없다는 뜻입니다.

1183
00:47:14,660 --> 00:47:17,500
만약 점들이 순서가 없다면,

1184
00:47:17,500 --> 00:47:19,880
순열 불변성을 가져야 합니다.

1185
00:47:19,880 --> 00:47:22,560
그럼 어떻게 할 수 있을까요?

1186
00:47:22,560 --> 00:47:25,400
두 번째는 샘플링 불변성도 가져야 한다는 겁니다.

1187
00:47:25,400 --> 00:47:28,200
예를 들어, 토끼 머리에서 10개

1188
00:47:28,200 --> 00:47:31,320
점을 샘플링하고 꼬리에서 5개

1189
00:47:31,320 --> 00:47:33,380
점을 샘플링할 때가 있죠.

1190
00:47:33,380 --> 00:47:34,970
또 어떤 때는 토끼 꼬리에서

1191
00:47:34,970 --> 00:47:36,690
10개 점을, 머리에서 5개 점만

1192
00:47:36,690 --> 00:47:38,082
샘플링할 수도 있습니다.

1193
00:47:38,082 --> 00:47:39,790
그럼 어떻게 그런 샘플링에도 불변성을 가질 수 있을까요?

1194
00:47:39,790 --> 00:47:42,710
왜냐하면 샘플 점들이 어떻게 뽑힐지는 보장할 수 없기 때문입니다.

1195
00:47:42,710 --> 00:47:45,730
여기저기 약간 문제가 있지만,

1196
00:47:45,730 --> 00:47:50,250
그들이 사용한 한 가지 아이디어가 있는데, 아마도

1197
00:47:50,250 --> 00:47:52,970
가장 중요한 포인트일

1198
00:47:52,970 --> 00:47:53,830
겁니다.

1199
00:47:53,830 --> 00:47:55,910
아주 간단한 방법입니다.

1200
00:47:55,910 --> 00:47:57,450
점들의 임베딩에 대해

1201
00:47:57,450 --> 00:47:59,190
대칭 함수를 적용하는 겁니다.

1202
00:47:59,190 --> 00:48:01,930
기본적으로 모든 점에 대해 먼저

1203
00:48:01,930 --> 00:48:04,270
임베딩을 계산합니다. 이미지의

1204
00:48:04,270 --> 00:48:07,010
다른 영역이나 윈도우에 대해 임베딩을

1205
00:48:07,010 --> 00:48:08,810
계산하는 것과 비슷하죠.

1206
00:48:08,810 --> 00:48:11,370
각 점에 대한 특징을 계산합니다.

1207
00:48:11,370 --> 00:48:13,310
그리고 나서 그것들을 합쳐야 합니다.

1208
00:48:13,310 --> 00:48:16,150
하지만 순열 불변성을 원하기 때문에,

1209
00:48:16,150 --> 00:48:18,890
예를 들어 최대값 함수 같은

1210
00:48:18,890 --> 00:48:21,070
대칭 함수를 사용합니다.

1211
00:48:21,070 --> 00:48:23,410
최대값, 소프트맥스 같은 걸 취할 수 있습니다.

1212
00:48:23,410 --> 00:48:24,670
합 함수도 가능합니다.

1213
00:48:24,670 --> 00:48:26,850
그냥 다 더하는 거죠.

1214
00:48:26,850 --> 00:48:27,990
이게 바로 일어나는 일입니다.

1215
00:48:27,990 --> 00:48:28,790
이것은 매우 간단합니다.

1216
00:48:28,790 --> 00:48:31,583
여러 개의 점들이 있습니다, 1, 2, 3 혹은 1개든지요.

1217
00:48:31,583 --> 00:48:33,500
그리고 나서 그 점들에 대해 임베딩을 계산하고,

1218
00:48:33,500 --> 00:48:34,640
그것들을 단순히 집계합니다.

1219
00:48:34,640 --> 00:48:36,440
각 차원별로 최대값을 계산할 수 있습니다.

1220
00:48:36,440 --> 00:48:38,340
합산하거나 그런 식으로 할 수도 있죠.

1221
00:48:38,340 --> 00:48:39,560
네, 그렇습니다.

1222
00:48:39,560 --> 00:48:42,870
그리고 모든 점들에 대해 이렇게 집계된 임베딩을 갖게 됩니다.

1223
00:48:42,870 --> 00:48:44,620
그 다음에는 몇 개의 완전

1224
00:48:44,620 --> 00:48:46,760
연결층을 거치거나 그런 과정을 거칩니다.

1225
00:48:46,760 --> 00:48:50,380
그리고 그것을 사용해서 이 점들이 의자를

1226
00:48:50,380 --> 00:48:55,380
나타내는지, 아니면 테이블을 나타내는지 분류합니다.

1227
00:48:55,380 --> 00:48:57,440
기본적으로 이런 과정이 진행되며,

1228
00:48:57,440 --> 00:49:00,200
꽤 강력한 결과를 보여주었습니다.

1229
00:49:00,200 --> 00:49:03,735
물론, 그 위에 많은 개선들이 있었습니다.

1230
00:49:03,735 --> 00:49:04,360
물론, 그 위에 많은 개선들이 있었습니다.

1231
00:49:04,360 --> 00:49:06,360
사람들은 PointNet을 개선하는 새로운

1232
00:49:06,360 --> 00:49:07,756
방법들을 계속 제안해 왔습니다.

1233
00:49:07,756 --> 00:49:09,335
PointNet++도 있죠.

1234
00:49:09,335 --> 00:49:11,460
사람들이 시도하는 것 중 하나는

1235
00:49:11,460 --> 00:49:14,940
그래프 신경망입니다. 점들을 그래프의 노드로

1236
00:49:14,940 --> 00:49:19,440
쉽게 변환할 수 있고, 이웃 관계나 점들이 서로 가까운지 여부를

1237
00:49:19,440 --> 00:49:22,100
이 점들을 연결하는 엣지로 표현할 수

1238
00:49:22,100 --> 00:49:23,320
있기 때문입니다.

1239
00:49:23,320 --> 00:49:24,820
그래서 그래프

1240
00:49:24,820 --> 00:49:26,362
신경망과 이런 점군

1241
00:49:26,362 --> 00:49:30,150
처리에 개발된 여러 다른 방법들이 있었습니다.

1242
00:49:30,150 --> 00:49:34,410
하지만 PointNet 논문의 원래 아이디어는 매우 간단했고,

1243
00:49:34,410 --> 00:49:36,990
동시에 매우 강력하다는 것이 밝혀졌습니다.

1244
00:49:36,990 --> 00:49:38,510
고려해야 할 또 다른 점은

1245
00:49:38,510 --> 00:49:40,350
측정도 해야 한다는 것입니다.

1246
00:49:40,350 --> 00:49:41,410
픽셀의 경우는 쉽습니다.

1247
00:49:41,410 --> 00:49:42,650
출력 이미지가 있습니다.

1248
00:49:42,650 --> 00:49:44,170
정답 이미지가 있습니다.

1249
00:49:44,170 --> 00:49:46,128
두 이미지 간의 차이를 계산하면 됩니다.

1250
00:49:46,128 --> 00:49:48,070
손실 함수 두 개가 있거나 뭐 그런 겁니다.

1251
00:49:48,070 --> 00:49:50,950
포인트의 경우, 출력 포인트 클라우드와 입력 포인트

1252
00:49:50,950 --> 00:49:52,910
클라우드를 어떻게 비교할까요, 특히

1253
00:49:52,910 --> 00:49:54,035
생성 작업을 할 때는요?

1254
00:49:54,035 --> 00:49:55,702
분류 작업이라면 괜찮습니다.

1255
00:49:55,702 --> 00:49:57,350
입력 포인트 클라우드가 있고

1256
00:49:57,350 --> 00:49:59,350
출력은 의자, 테이블 등입니다.

1257
00:49:59,350 --> 00:50:00,850
크로스 엔트로피 손실이 있습니다.

1258
00:50:00,850 --> 00:50:02,110
그게 전부입니다.

1259
00:50:02,110 --> 00:50:04,670
하지만 생성 작업을 하고 있고 출력이

1260
00:50:04,670 --> 00:50:06,270
복셀이라면, 이것도 쉽습니다.

1261
00:50:06,270 --> 00:50:08,510
100x100x100 복셀 그리드에 대해

1262
00:50:08,510 --> 00:50:10,630
크로스 엔트로피 손실을 계산하면 됩니다.

1263
00:50:10,630 --> 00:50:13,230
하지만 출력이 100개의 포인트라면, 출력

1264
00:50:13,230 --> 00:50:16,150
포인트 클라우드와 정답 포인트 클라우드를 어떻게

1265
00:50:16,150 --> 00:50:16,810
비교할까요?

1266
00:50:16,810 --> 00:50:19,270
거리 측정 지표도 설계해야 합니다.

1267
00:50:19,270 --> 00:50:22,992
사람들이 흔히 사용하는 두 가지 거리 측정 지표가 있는데, 하나는
Chamfer

1268
00:50:22,992 --> 00:50:24,450
distance라고 합니다.

1269
00:50:24,450 --> 00:50:26,210
Chamfer distance는 이해하기 쉽습니다.

1270
00:50:26,210 --> 00:50:27,790
두 개의 점 집합이 있다고 생각하시면 됩니다.

1271
00:50:27,790 --> 00:50:31,370
각 집합의 각 점마다 가장 가까운

1272
00:50:31,370 --> 00:50:33,485
이웃을 찾는 거죠.

1273
00:50:33,485 --> 00:50:35,110
빨간 점들이 모여 있는 집합이 있습니다.

1274
00:50:35,110 --> 00:50:36,630
파란 점들이 모여 있는 집합도 있구요.

1275
00:50:36,630 --> 00:50:38,150
빨간 점 각각에 대해 파란

1276
00:50:38,150 --> 00:50:40,590
집합에서 가장 가까운 이웃을 찾습니다.

1277
00:50:40,590 --> 00:50:41,930
파란 점 각각에 대해서도 빨간 집합에서

1278
00:50:41,930 --> 00:50:43,130
가장 가까운 이웃을 찾는 거죠.

1279
00:50:43,130 --> 00:50:44,850
그리고 각 점과 다른

1280
00:50:44,850 --> 00:50:46,850
집합에서 가장 가까운 이웃

1281
00:50:46,850 --> 00:50:49,170
간의 거리를 최소화하려고 합니다.

1282
00:50:49,170 --> 00:50:51,770
두 번째 아이디어로 사람들이 사용하는 손실 함수는 Earth

1283
00:50:51,770 --> 00:50:53,270
Mover distance라고 합니다.

1284
00:50:53,270 --> 00:50:55,770
여기서는 두 점 집합 사이에 이분

1285
00:50:55,770 --> 00:50:58,107
매칭을 수행하고, 각 점들이

1286
00:50:58,107 --> 00:50:59,690
일대일로 짝지어지며,

1287
00:50:59,690 --> 00:51:02,672
모든 쌍의 거리 합을 최소화하려고 합니다.

1288
00:51:02,672 --> 00:51:04,130
이 두 가지가 점 구름

1289
00:51:04,130 --> 00:51:05,930
간 거리를 비교할 때 흔히

1290
00:51:05,930 --> 00:51:07,170
사용하는 지표입니다.

1291
00:51:07,170 --> 00:51:08,470
이 함수들은 미분

1292
00:51:08,470 --> 00:51:10,345
가능하게 만들 수 있어서, 이제

1293
00:51:10,345 --> 00:51:12,530
기울기를 계산해 신경망을 최적화하는

1294
00:51:12,530 --> 00:51:14,530
데 사용할 수 있습니다. 그래서

1295
00:51:14,530 --> 00:51:19,330
점 구름 생성 문제에 관심이 있다면 더 나은 점 구름 출력을 기대할 수
있죠.

1296
00:51:19,330 --> 00:51:23,050
우리는 이제 복셀에서 점 구름으로 넘어왔습니다.

1297
00:51:23,050 --> 00:51:24,950
그리고 사람들은 '좋아, 이거 괜찮네'라고 생각했습니다.

1298
00:51:24,950 --> 00:51:28,080
이제 점들을 처리하고 점들을 출력할 수 있게 되었죠.

1299
00:51:28,080 --> 00:51:31,900
하지만 우리는 스플라인 같은 다른 멋진 분할 방법도 가지고 있습니다.

1300
00:51:31,900 --> 00:51:34,320
물체의 표면을 아주 잘 포착합니다.

1301
00:51:34,320 --> 00:51:36,340
어떤 신경망을 사용해서 복셀이나

1302
00:51:36,340 --> 00:51:38,200
포인트 클라우드를 생성하면,

1303
00:51:38,200 --> 00:51:39,880
항상 매우 보기 흉합니다.

1304
00:51:39,880 --> 00:51:42,400
그래서 매끄러운 표면 같은 게 없죠.

1305
00:51:42,400 --> 00:51:43,858
그렇다면 신경망이 물체를

1306
00:51:43,858 --> 00:51:46,900
출력하거나 이해할 수 있으면서도 아름다운 표면을 표현할

1307
00:51:46,900 --> 00:51:48,940
수 있으려면 어떻게 해야 할까요?

1308
00:51:48,940 --> 00:51:51,772
그래서 사람들은 신경망을 스플라인 같은

1309
00:51:51,772 --> 00:51:53,980
함수와 통합하는 방법에 대해

1310
00:51:53,980 --> 00:51:56,340
조금 더 생각하기 시작했습니다.

1311
00:51:56,340 --> 00:51:58,220
주목할 만한 예가 있는데,

1312
00:51:58,220 --> 00:52:00,400
바로 AtlasNet이라는 것입니다.

1313
00:52:00,400 --> 00:52:04,060
여기서 하는 일은 딥러닝을 사용해보려는 시도입니다.

1314
00:52:04,060 --> 00:52:06,940
하지만 3D 포인트 클라우드 집합을

1315
00:52:06,940 --> 00:52:10,940
직접 출력하는 대신, 변환 함수를 학습합니다.

1316
00:52:10,940 --> 00:52:13,420
잠재적인 형태 표현을 가지고 있죠.

1317
00:52:13,420 --> 00:52:16,940
그리고 기억하시면, 물체 형태의 매개변수

1318
00:52:16,940 --> 00:52:19,680
표현이란, 예를 들어 2D 공간의

1319
00:52:19,680 --> 00:52:25,030
u와 v를 3D 공간, 예를 들어 구로 변환하는 것입니다.

1320
00:52:25,030 --> 00:52:27,353
구 같은 단순한 것은 쉽습니다.

1321
00:52:27,353 --> 00:52:28,270
직접 쓸 수 있죠.

1322
00:52:28,270 --> 00:52:32,088
사인과 코사인 같은 함수가 무엇인지 말입니다.

1323
00:52:32,088 --> 00:52:34,630
하지만 복잡한 물체는 함수를 쓰기가 매우 어렵습니다.

1324
00:52:34,630 --> 00:52:36,470
그리고 종종 닫힌 형태가 존재하지 않습니다.

1325
00:52:36,470 --> 00:52:39,158
그래서 여기서 아이디어는, 닫힌 형태가 없다면

1326
00:52:39,158 --> 00:52:40,950
왜 신경망을 사용해서 그것을

1327
00:52:40,950 --> 00:52:42,210
표현하지 않느냐는 겁니다.

1328
00:52:42,210 --> 00:52:44,390
여기 보시면, MLP로 구현된

1329
00:52:44,390 --> 00:52:49,210
이 신경망이 함수 f를 학습하는 것을 볼 수 있습니다.

1330
00:52:49,210 --> 00:52:51,750
함수 f의 입력으로 두 값 u와 v를

1331
00:52:51,750 --> 00:52:53,110
사용할 수 있습니다.

1332
00:52:53,110 --> 00:52:55,510
신경망은 함수 f와 u, v의

1333
00:52:55,510 --> 00:52:59,470
계산을 수행하여 3D 공간의 한 점을 출력합니다.

1334
00:52:59,470 --> 00:53:04,070
즉, 2D 공간을 3D 공간으로 변환하는 방법을

1335
00:53:04,070 --> 00:53:09,070
학습하는 거죠. 전체 객체를 단일 변환으로 표현하는

1336
00:53:09,070 --> 00:53:11,920
것은 너무 어려울 수 있습니다.

1337
00:53:11,920 --> 00:53:13,670
그래서 여러 개의 작은 신경망을 사용할

1338
00:53:13,670 --> 00:53:14,885
수 있다고 생각했습니다.

1339
00:53:14,885 --> 00:53:17,010
지금 종이 한 장이 있다고 생각해보세요.

1340
00:53:17,010 --> 00:53:18,450
종이를 여러 가지 방식으로 접을 수 있습니다.

1341
00:53:18,450 --> 00:53:20,010
여러 번 접을 수도 있죠.

1342
00:53:20,010 --> 00:53:21,750
이 모든 접기들이

1343
00:53:21,750 --> 00:53:25,920
모여서 최종적으로 원하는 형태를 만듭니다.

1344
00:53:25,920 --> 00:53:29,007
여기서 두세 가지 다른 표현 방식의 차이를

1345
00:53:29,007 --> 00:53:30,340
볼 수 있습니다.

1346
00:53:30,340 --> 00:53:31,480
입력 이미지가 있습니다.

1347
00:53:31,480 --> 00:53:34,440
이걸 복셀로 재구성하려고 하면, 뭔가

1348
00:53:34,440 --> 00:53:36,680
하고 있는 것을 볼 수 있습니다.

1349
00:53:36,680 --> 00:53:40,400
하지만 복셀 해상도에 제한을 받습니다.

1350
00:53:40,400 --> 00:53:42,440
포인트 클라우드의 경우, 해상도

1351
00:53:42,440 --> 00:53:43,860
제한을 받지 않습니다.

1352
00:53:43,860 --> 00:53:46,260
그래서 좀 더 세부적인 표현이 가능할 수 있습니다.

1353
00:53:46,260 --> 00:53:48,020
하지만 점들은 순서가 없다는 단점이 있습니다.

1354
00:53:48,020 --> 00:53:50,720
포인트 클라우드에서 매끄러운 표면을 얻기는

1355
00:53:50,720 --> 00:53:51,560
어렵습니다.

1356
00:53:51,560 --> 00:53:54,063
AtlasNet이라는 것은 기본적으로 변환

1357
00:53:54,063 --> 00:53:55,480
조각을 학습하는 것인데,

1358
00:53:55,480 --> 00:53:58,160
실제로 더 매끄러운 표면을 얻을 수 있습니다.

1359
00:53:58,160 --> 00:54:00,160
신경망을 사용해 저차원

1360
00:54:00,160 --> 00:54:02,240
공간에서 고차원 공간으로 매개변수

1361
00:54:02,240 --> 00:54:05,320
표현을 매핑하는 방법을 학습하고, 여러

1362
00:54:05,320 --> 00:54:07,340
개의 매핑을 배우는 거죠.

1363
00:54:07,340 --> 00:54:10,080
이 매핑들을 결합하면 2D 이미지에 조건화된 최종 출력

1364
00:54:10,080 --> 00:54:11,610
기하학을 얻을 수 있습니다.

1365
00:54:16,200 --> 00:54:30,020
자, 마지막으로 이렇게 말할 수 있습니다.

1366
00:54:30,020 --> 00:54:32,660
그렇다면 딥 네트워크가 ImageNet 분류를

1367
00:54:32,660 --> 00:54:34,380
할 때 무엇을 하는 걸까요?

1368
00:54:34,380 --> 00:54:36,980
기본적으로 픽셀 형태의 입력 이미지를

1369
00:54:36,980 --> 00:54:40,220
최종 카테고리 레이블로 매핑하는 매우 복잡한

1370
00:54:40,220 --> 00:54:42,040
함수를 학습하는 겁니다.

1371
00:54:42,040 --> 00:54:45,060
고양이인지, 개인지, 사람인지, 아니면 다른 것인지 말이죠.

1372
00:54:45,060 --> 00:54:47,500
그 함수는 정말 복잡하고, 출력 공간은

1373
00:54:47,500 --> 00:54:48,240
매우 작습니다.

1374
00:54:48,240 --> 00:54:50,620
출력 공간은 1,000차원입니다.

1375
00:54:50,620 --> 00:54:52,200
그래서 '이게 고양이인가 개인가?' 하는 거죠.

1376
00:54:52,200 --> 00:54:53,617
1,000가지 분류 방법이 있습니다.

1377
00:54:53,617 --> 00:54:54,680
출력 공간이 너무 작습니다.

1378
00:54:54,680 --> 00:54:57,260
입력 공간은 훨씬 큽니다, 왜냐하면 500x500

1379
00:54:57,260 --> 00:54:58,480
픽셀이 있으니까요.

1380
00:54:58,480 --> 00:55:00,935
그래서 대략 250,000 정도 됩니다.

1381
00:55:00,935 --> 00:55:02,060
입력 공간이 훨씬 더 큽니다.

1382
00:55:02,060 --> 00:55:03,268
출력 공간은 정말 작습니다.

1383
00:55:03,268 --> 00:55:07,340
함수를 작성하는 것이 정말 어렵습니다.

1384
00:55:07,340 --> 00:55:09,500
입력 이미지를 분류하기 위해

1385
00:55:09,500 --> 00:55:13,540
어떤 특정 값을 계산해서 이것이 고양이인지 개인지

1386
00:55:13,540 --> 00:55:15,640
출력하는 공식을 적을

1387
00:55:15,640 --> 00:55:16,720
수 있을까요?

1388
00:55:16,720 --> 00:55:17,545
그건 할 수 없습니다.

1389
00:55:17,545 --> 00:55:18,920
함수를 작성하는 것이 너무 어렵습니다.

1390
00:55:18,920 --> 00:55:19,810
닫힌 형태가 없습니다.

1391
00:55:19,810 --> 00:55:20,970
그래서 딥 네트워크가 필요한 겁니다.

1392
00:55:20,970 --> 00:55:22,010
입력 공간은 큽니다.

1393
00:55:22,010 --> 00:55:23,630
출력 공간은 작습니다.

1394
00:55:23,630 --> 00:55:26,190
딥 네트워크를 그렇게 생각하고

1395
00:55:26,190 --> 00:55:29,070
그들이 무엇을 하는지 생각해 보면,

1396
00:55:29,070 --> 00:55:31,770
우리가 3D 형태에 딥 네트워크를

1397
00:55:31,770 --> 00:55:36,670
적용해온 많은 것들이 그 방정식에 잘 맞지 않는다는 것을

1398
00:55:36,670 --> 00:55:37,570
알게 됩니다.

1399
00:55:37,570 --> 00:55:38,997
그래서 잘 맞지 않습니다.

1400
00:55:38,997 --> 00:55:40,830
그리고 무엇이 그들을 가장

1401
00:55:40,830 --> 00:55:42,530
잘 매핑하는 표현일까요?

1402
00:55:42,530 --> 00:55:44,270
무엇이 그 패러다임에

1403
00:55:44,270 --> 00:55:47,390
가장 적합한 최적의 표현일까요?

1404
00:55:47,390 --> 00:55:50,650
좀 더 신중히 생각해 보면, 2019년쯤에 사람들은 딥

1405
00:55:50,650 --> 00:55:52,788
네트워크가 어떤 의미에서는 암시적

1406
00:55:52,788 --> 00:55:54,330
함수라는 것을 깨달았습니다.

1407
00:55:54,330 --> 00:55:57,510
그렇다면 왜 그것을 3D 객체 기하학의 암시적 함수를

1408
00:55:57,510 --> 00:55:59,470
표현하는 데 사용하지 않겠습니까?

1409
00:55:59,470 --> 00:56:02,110
픽셀로 변환하는 대신,

1410
00:56:02,110 --> 00:56:04,030
이제 3D로 확장하는

1411
00:56:04,030 --> 00:56:07,870
대신 복셀을 표현하는 대신 말이죠.

1412
00:56:07,870 --> 00:56:09,410
그리고 3D 컨볼루션을 적용합니다.

1413
00:56:09,410 --> 00:56:12,310
하지만 근본적으로 voxel은 물체 안과

1414
00:56:12,310 --> 00:56:14,570
밖에 있는지 여부에 관한 것입니다.

1415
00:56:14,570 --> 00:56:18,240
그래서 공간을 직접 쿼리해서 voxel을 얻고 그

1416
00:56:18,240 --> 00:56:20,383
위에 컨볼루션을 적용하는 대신,

1417
00:56:20,383 --> 00:56:22,800
딥 네트워크를 사용해 직접 그

1418
00:56:22,800 --> 00:56:25,840
쿼리를 수행하면 3D 컨볼루션을 돌릴 필요가

1419
00:56:25,840 --> 00:56:26,400
없겠죠?

1420
00:56:26,400 --> 00:56:29,840
3D 공간에서 쿼리만 하면 딥 네트워크가

1421
00:56:29,840 --> 00:56:34,280
그 점이 3D 형태 안에 있는지 밖에 있는지,

1422
00:56:34,280 --> 00:56:38,960
즉 1차원적으로 안과 밖을 알려줄 수 있습니다.

1423
00:56:38,960 --> 00:56:41,240
결국 사람들은 포인트 클라우드나

1424
00:56:41,240 --> 00:56:44,640
스플라인 같은 특정 표현에서 암시적 표현으로,

1425
00:56:44,640 --> 00:56:47,660
voxel을 직접 다루지 않고

1426
00:56:47,660 --> 00:56:49,300
넘어가는 도약을 했습니다.

1427
00:56:49,300 --> 00:56:51,840
대신 레벨셋이나 딥 네트워크를

1428
00:56:51,840 --> 00:56:55,520
이용한 암시적 함수로 생각하는 거죠.

1429
00:56:55,520 --> 00:56:56,680
그게 최종 단계입니다.

1430
00:56:56,680 --> 00:56:59,380
AtlasNet 같은 것을 통해

1431
00:56:59,380 --> 00:57:02,760
2D 공간에서 3D 공간으로 변환을

1432
00:57:02,760 --> 00:57:03,860
배우는 거죠.

1433
00:57:03,860 --> 00:57:06,240
하지만 이제는 딥 네트워크를 사용해 직접 암시적

1434
00:57:06,240 --> 00:57:07,600
쿼리를 할 수 있습니다.

1435
00:57:07,600 --> 00:57:10,840
이것이 딥 임플리시트 함수로 이어지는데,

1436
00:57:10,840 --> 00:57:13,460
2019년 즈음에 거의

1437
00:57:13,460 --> 00:57:16,290
같은 내용을 다룬 논문이 네 편이나

1438
00:57:16,290 --> 00:57:17,330
나왔습니다.

1439
00:57:17,330 --> 00:57:19,913
그들은 voxel, 포인트

1440
00:57:19,913 --> 00:57:22,455
클라우드, 메시 등 각각 장단점이

1441
00:57:22,455 --> 00:57:23,030
있지만,

1442
00:57:23,030 --> 00:57:24,490
정말 올바른 방법은

1443
00:57:24,490 --> 00:57:28,710
쿼리를 딥 네트워크에 넣는 것이라고 주장했습니다.

1444
00:57:28,710 --> 00:57:31,990
딥 네트워크는 입력으로 x, y, z

1445
00:57:31,990 --> 00:57:34,110
좌표를 받아 그 점이 물체

1446
00:57:34,110 --> 00:57:37,770
안에 있는지 밖에 있는지를 출력해야 합니다.

1447
00:57:37,770 --> 00:57:41,090
이것이 어떤 의미에서는 최종, 아니 최종 중 하나라고 할

1448
00:57:41,090 --> 00:57:41,830
수 있습니다.

1449
00:57:41,830 --> 00:57:44,810
이런 아이디어가 2019년에 제안되었습니다.

1450
00:57:44,810 --> 00:57:47,010
그리고 지금 2025년에도 많은 사람들이

1451
00:57:47,010 --> 00:57:49,170
여전히 이 같은 아이디어를 사용하고 있습니다.

1452
00:57:49,170 --> 00:57:51,530
즉, 저는 딥 네트워크를 사용해서 한 점이

1453
00:57:51,530 --> 00:57:54,210
객체 안에 있는지 밖에 있는지 알려주도록 할 겁니다.

1454
00:57:54,210 --> 00:57:56,850
그리고 단순히 안팎을 이진 분류하는 것보다 조금

1455
00:57:56,850 --> 00:57:59,220
더 나아갈 수도 있습니다. 왜냐하면 조금

1456
00:57:59,220 --> 00:58:01,470
더 세밀하게 신경 쓸 수도 있기 때문이죠.

1457
00:58:01,470 --> 00:58:03,553
예를 들어, 서명 거리 함수(signed distance function)는
무엇일까요?

1458
00:58:03,553 --> 00:58:06,970
한 점이 객체 표면에서 얼마나 떨어져 있는지입니다.

1459
00:58:06,970 --> 00:58:09,570
또는 그 점의 밀도 값은 무엇일까요?

1460
00:58:09,570 --> 00:58:11,470
나중에는 색깔은 어떻게 될까요?

1461
00:58:11,470 --> 00:58:14,030
그 점의 방사선 값(radiance)은 어떻게 될까요?

1462
00:58:14,030 --> 00:58:16,550
하지만 여기서 2019년부터 사람들은

1463
00:58:16,550 --> 00:58:19,550
딥 네트워크를 분류와 유사한 방식으로 적용하기

1464
00:58:19,550 --> 00:58:20,650
시작했습니다.

1465
00:58:20,650 --> 00:58:24,630
즉, 3D 공간의 점들을 가져와서 암묵적 함수(implicit

1466
00:58:24,630 --> 00:58:27,550
function)로 사용해 3D 공간 점들의

1467
00:58:27,550 --> 00:58:29,270
속성을 쿼리하는 겁니다.

1468
00:58:29,270 --> 00:58:33,190
사람들은 이를 단순히 포인트 클라우드가

1469
00:58:33,190 --> 00:58:36,305
3D 공간에서 변형되는 것뿐 아니라,

1470
00:58:36,305 --> 00:58:38,430
작은 신경망을 사용해

1471
00:58:38,430 --> 00:58:42,070
객체의 암묵적 부분들을 표현하는 데도

1472
00:58:42,070 --> 00:58:43,250
시도했습니다.

1473
00:58:43,250 --> 00:58:45,950
그리고 이들은 복잡한 형태를 만들 수 있습니다.

1474
00:58:45,950 --> 00:58:52,350
만약 암묵적 함수를 사용해 3D 객체를 표현할 수 있다면, 기하학뿐 아니라
다른

1475
00:58:52,350 --> 00:58:54,170
것도 할 수 있습니다.

1476
00:58:54,170 --> 00:58:56,030
점이 객체 안에 있는지,

1477
00:58:56,030 --> 00:58:58,290
밖에 있는지, 또는 표면에서

1478
00:58:58,290 --> 00:59:01,170
얼마나 떨어져 있는지뿐 아니라,

1479
00:59:01,170 --> 00:59:03,308
방사선 값은 무엇인지,

1480
00:59:03,308 --> 00:59:04,850
객체의 색깔은 무엇인지도 쿼리할 수 있습니다.

1481
00:59:04,850 --> 00:59:06,490
그리고 1년 후에 바로 이런 연구가 나왔습니다.

1482
00:59:06,490 --> 00:59:08,170
아마 1~2년 후쯤입니다.

1483
00:59:08,170 --> 00:59:10,390
사람들은 NeRF라는

1484
00:59:10,390 --> 00:59:13,240
것을 고안했는데, 여기서

1485
00:59:13,240 --> 00:59:14,960
차이점은 이제

1486
00:59:14,960 --> 00:59:17,600
서명 거리 함수나 밀도뿐

1487
00:59:17,600 --> 00:59:21,640
아니라 방사선도 쿼리한다는 겁니다.

1488
00:59:21,640 --> 00:59:26,380
여기서 보시면, 3D 공간의 x, y, z 좌표를

1489
00:59:26,380 --> 00:59:28,090
NeRF에 쿼리합니다.

1490
00:59:28,090 --> 00:59:29,840
게다가 우리는 외관도

1491
00:59:29,840 --> 00:59:31,640
모델링하려고 하기

1492
00:59:31,640 --> 00:59:35,400
때문에, 카메라 시점 방향도 쿼리합니다.

1493
00:59:35,400 --> 00:59:39,200
신경망의 출력은 단순히 1이나 0,

1494
00:59:39,200 --> 00:59:40,440
안팎이 아니라,

1495
00:59:40,440 --> 00:59:44,080
밀도 값과 색깔 값, 즉 방사선 값을

1496
00:59:44,080 --> 00:59:45,720
함께 출력합니다.

1497
00:59:45,720 --> 00:59:50,600
만약 3D 형태에 암묵적 함수를 직접 학습시키면

1498
00:59:50,600 --> 00:59:52,600
3D 감독이 필요합니다.

1499
00:59:52,600 --> 00:59:54,783
즉, 3D 객체 모음이 있다면 그것을

1500
00:59:54,783 --> 00:59:56,200
감독으로 사용할 수 있죠.

1501
00:59:56,200 --> 00:59:59,200
그러면 점이 3D 객체 안에 있는지 밖에

1502
00:59:59,200 --> 01:00:01,760
있는지에 대한 정답을 갖게 됩니다.

1503
01:00:01,760 --> 01:00:04,525
하지만 여기서는 2D 이미지로 학습하려고 합니다.

1504
01:00:04,525 --> 01:00:05,900
그게 바로 NeRF의 핵심입니다.

1505
01:00:05,900 --> 01:00:08,840
그래서 이들은 신경 렌더링, 즉 볼륨 렌더링 함수와 함께

1506
01:00:08,840 --> 01:00:09,940
이를 결합했습니다.

1507
01:00:09,940 --> 01:00:11,773
그리고 이 볼륨 렌더링 함수를

1508
01:00:11,773 --> 01:00:15,010
미분 가능하게 만들어서, 렌더링 모델이 3D

1509
01:00:15,010 --> 01:00:17,730
공간의 여러 점을 쿼리할 수 있게 했습니다.

1510
01:00:17,730 --> 01:00:20,210
각 점의 색깔과 밀도,

1511
01:00:20,210 --> 01:00:23,090
외관을 얻을 수 있죠.

1512
01:00:23,090 --> 01:00:25,210
그리고 빛이 경로를 따라 얼마나

1513
01:00:25,210 --> 01:00:27,010
차단되는지도 계산할 수 있습니다.

1514
01:00:27,010 --> 01:00:29,010
이것이 기본적으로 컴퓨터 그래픽스에서의

1515
01:00:29,010 --> 01:00:30,570
볼륨 렌더링입니다.

1516
01:00:30,570 --> 01:00:35,850
변경된 부분은 매우 적습니다. 볼륨 렌더링 방정식만 봐도

1517
01:00:35,850 --> 01:00:38,090
여기 있는 모든 것이

1518
01:00:38,090 --> 01:00:39,890
근사치라는 걸 알

1519
01:00:39,890 --> 01:00:41,030
수 있습니다.

1520
01:00:41,030 --> 01:00:42,655
하지만 근사치이기 때문에 여기 있는 모든

1521
01:00:42,655 --> 01:00:43,890
것이 미분 가능하다는 겁니다.

1522
01:00:43,890 --> 01:00:46,438
그래서 신경망이 밀도, 즉

1523
01:00:46,438 --> 01:00:48,730
3D 공간의 점의

1524
01:00:48,730 --> 01:00:51,610
불투명도라고 생각할 수 있고 색상도

1525
01:00:51,610 --> 01:00:53,283
준다면, 그 점

1526
01:00:53,283 --> 01:00:55,450
앞에서 샘플링된 점들이

1527
01:00:55,450 --> 01:01:00,050
얼마나 빛을 차단했는지 계산할 수 있습니다.

1528
01:01:00,050 --> 01:01:02,450
그리고 그 과정에서 특정 점에서

1529
01:01:02,450 --> 01:01:05,090
이 광선에서 내가 보게 될

1530
01:01:05,090 --> 01:01:09,820
것에 기여하는 빛이 얼마나 되는지도 계산할 수 있습니다.

1531
01:01:09,820 --> 01:01:11,360
이제 몇 가지가 생겼습니다.

1532
01:01:11,360 --> 01:01:13,693
색상이나 복사도와 밀도를 나타내는

1533
01:01:13,693 --> 01:01:16,122
암시적 함수를 표현하는 신경망이 있고,

1534
01:01:16,122 --> 01:01:18,080
그리고 2D 이미지로부터

1535
01:01:18,080 --> 01:01:21,260
직접 학습할 수 있도록 미분 가능하게 만든 볼륨

1536
01:01:21,260 --> 01:01:23,083
렌더 방정식이 있습니다.

1537
01:01:23,083 --> 01:01:25,000
이 두 가지가 바뀐 부분입니다.

1538
01:01:25,000 --> 01:01:27,760
그리고 첫 번째는, 더 이상 3D 형태에 대해 학습할 필요가 없다는 겁니다.

1539
01:01:27,760 --> 01:01:30,640
이 부피 렌더링 방정식을 이용해 2D 이미지로 학습할 수 있습니다.

1540
01:01:30,640 --> 01:01:33,940
두 번째는, 3D에서 단순히 기하학이나

1541
01:01:33,940 --> 01:01:38,540
밀도만 보는 것이 아니라, 3D에서 방사광이나 외형도

1542
01:01:38,540 --> 01:01:40,120
본다는 점입니다.

1543
01:01:40,120 --> 01:01:43,060
이 두 가지 변화가

1544
01:01:43,060 --> 01:01:46,100
NeRF, 암시적

1545
01:01:46,100 --> 01:01:49,540
함수 또는 딥 [? SDF ?] 그리고 이 모든 다른 방법들에서 NeRF로의
큰 도약을 이끌었습니다.

1546
01:01:49,540 --> 01:01:52,472
그래서 많은 사람들이 NeRF가 정말 대단하다고 느낍니다.

1547
01:01:52,472 --> 01:01:53,680
마치 갑자기 나타난 것처럼 보이죠.

1548
01:01:53,680 --> 01:01:55,740
그렇지 않습니다. 왜냐하면

1549
01:01:55,740 --> 01:01:58,380
그들이 나중에 직접 쓴

1550
01:01:58,380 --> 01:02:01,700
논문들을 보면, 모두 딥 내재 함수의 발전에

1551
01:02:01,700 --> 01:02:04,640
크게 영감을 받았기 때문입니다.

1552
01:02:04,640 --> 01:02:06,600
하지만 그들은 오직 기하학에만 집중했습니다.

1553
01:02:06,600 --> 01:02:09,900
하지만 저는 이제 기하학과 외관 모두를 다룹니다.

1554
01:02:09,900 --> 01:02:13,920
그리고 3D 형태 대신 2D 이미지로부터 학습합니다.

1555
01:02:13,920 --> 01:02:16,200
네, 여기 NeRF의 몇 가지 결과가 있습니다.

1556
01:02:16,200 --> 01:02:17,950
이것은 아마 여러 번 보셨을 겁니다.

1557
01:02:24,800 --> 01:02:27,620
자, 기억하시면, 과거에는 3D

1558
01:02:27,620 --> 01:02:29,920
형태를 생성하고 그

1559
01:02:29,920 --> 01:02:33,908
2D 외관도 생성하는 작업을 했다고 했습니다.

1560
01:02:33,908 --> 01:02:36,200
처음에는 복셀(voxels)이라는

1561
01:02:36,200 --> 01:02:38,640
표현 방식을 사용했습니다.

1562
01:02:38,640 --> 01:02:41,253
하지만 지금은, 말씀드렸듯이, NeRF가 훌륭합니다.

1563
01:02:41,253 --> 01:02:42,920
암묵적 표현이 있다면

1564
01:02:42,920 --> 01:02:45,900
굳이 복셀로 표현할 필요가 없습니다.

1565
01:02:45,900 --> 01:02:49,480
그 대신 방사선장(radiance fields)으로 대체하면 어떨까요?

1566
01:02:49,480 --> 01:02:50,973
그래서 저희도 그렇게 했습니다.

1567
01:02:50,973 --> 01:02:52,640
즉, 암묵적 방사선장과

1568
01:02:52,640 --> 01:02:54,980
밀도를 포착하는 신경망을 만들었습니다.

1569
01:02:54,980 --> 01:02:57,067
하지만 이것은 생성 신경망입니다.

1570
01:02:57,067 --> 01:02:59,400
그리고 같은 GAN 렌더링 프레임워크를

1571
01:02:59,400 --> 01:03:01,880
적용해서 3D 객체와 그 2D

1572
01:03:01,880 --> 01:03:04,100
이미지를 렌더링할 수 있습니다.

1573
01:03:04,100 --> 01:03:06,730
또한 제어 가능성도 똑같이 구현할 수 있습니다.

1574
01:03:06,730 --> 01:03:10,750
그리고 카메라 시점을 바꿀 수 있습니다.

1575
01:03:10,750 --> 01:03:13,768
객체의 정체성을 바꿀 수 있지만, 시점은 유지할 수 있습니다.

1576
01:03:13,768 --> 01:03:15,810
이전에 할 수 있었던 모든 것을 할 수 있습니다.

1577
01:03:15,810 --> 01:03:18,237
하지만 이제 NeRF를 사용하면 이미지에서 직접 학습할 수 있습니다.

1578
01:03:18,237 --> 01:03:20,570
그래서 자동차나 의자 같은 3D

1579
01:03:20,570 --> 01:03:23,810
데이터가 많은 카테고리에만 제한될 필요가

1580
01:03:23,810 --> 01:03:26,930
없고, 이미지에서 바로 학습할 수 있습니다.

1581
01:03:26,930 --> 01:03:29,850
네, 이제 출력이 훨씬 더 현실적으로 변하는 것을 볼

1582
01:03:29,850 --> 01:03:30,510
수 있습니다.

1583
01:03:30,510 --> 01:03:32,850
이것은 우리가 한 작업인데, 이름이 [? pigeon ?]입니다.

1584
01:03:32,850 --> 01:03:35,910
Eric Chen이 제1저자이고, 주로

1585
01:03:35,910 --> 01:03:39,110
Gordon 그룹 사람들과 함께 했습니다.

1586
01:03:42,410 --> 01:03:48,010
좋습니다, 마지막으로 NeRF는 훌륭하지만, NeRF에는 3D에서 많은

1587
01:03:48,010 --> 01:03:50,890
점을 샘플링해야 하는 문제가 있습니다.

1588
01:03:50,890 --> 01:03:53,890
더 이상 미리 샘플링한 후 볼류메트릭 컨볼루션을

1589
01:03:53,890 --> 01:03:55,230
적용하는 방식이 아닙니다.

1590
01:03:55,230 --> 01:03:56,650
하지만 여전히 레벨셋처럼

1591
01:03:56,650 --> 01:03:58,025
모든 점을 샘플링하고

1592
01:03:58,025 --> 01:03:59,730
신경망을 계속 만들어야 합니다.

1593
01:03:59,730 --> 01:04:02,583
그리고 이제 2D에서 학습할 수 있습니다.

1594
01:04:02,583 --> 01:04:04,000
이 모든 훌륭한 일들을 할 수 있습니다.

1595
01:04:04,000 --> 01:04:06,083
하지만 여전히 모든 샘플링을 해야

1596
01:04:06,083 --> 01:04:07,380
해서 매우 느립니다.

1597
01:04:07,380 --> 01:04:09,238
그래서 사람들이 좀 더 고민했습니다.

1598
01:04:09,238 --> 01:04:10,780
그래픽스 쪽 사람들로부터 다시 얘기하자면,

1599
01:04:10,780 --> 01:04:13,547
그들은 '좋아, 점과 메시에 대해 좋은 아이디어가 있어요'라고 했습니다.

1600
01:04:13,547 --> 01:04:15,880
그리고 그들의 좋은 점은 공간에서 자유롭다는 겁니다.

1601
01:04:15,880 --> 01:04:17,200
아주 효율적이죠.

1602
01:04:17,200 --> 01:04:19,200
그럼 이 둘을 통합할 수 있을까요?

1603
01:04:19,200 --> 01:04:20,880
암시적 표현을 가질 수 있을까요?

1604
01:04:20,880 --> 01:04:23,798
하지만 고정된 샘플링 그리드를 가질 필요는 없을지도 모릅니다.

1605
01:04:23,798 --> 01:04:25,340
항상 샘플링할 필요도 없죠,

1606
01:04:25,340 --> 01:04:26,960
왜냐하면 시간이 너무 많이 걸리니까요.

1607
01:04:26,960 --> 01:04:30,020
그래서 아마도 이 둘을 정말로 합쳐야 할 겁니다.

1608
01:04:30,020 --> 01:04:34,117
NeRF가 밀도, 아니 씬을 아주 아주 밀도 높게 파라미터화하려고

1609
01:04:34,117 --> 01:04:36,200
시도했다고 주장할 수 있습니다.

1610
01:04:36,200 --> 01:04:39,660
3D에서 모든 점의 밀도를 샘플링해야 하니까요.

1611
01:04:39,660 --> 01:04:41,980
많은 점들이 낭비됩니다, 마치 복셀에서처럼요.

1612
01:04:41,980 --> 01:04:44,600
빈 공간을 나타내는 점들이 다 있죠.

1613
01:04:44,600 --> 01:04:45,660
그건 원하지 않습니다.

1614
01:04:45,660 --> 01:04:48,300
NeRF에서는 많은 샘플링과 쿼리가 빈

1615
01:04:48,300 --> 01:04:50,180
공간을 대상으로 하기도 합니다.

1616
01:04:50,180 --> 01:04:52,100
네트워크가 밀도 0 같은

1617
01:04:52,100 --> 01:04:55,220
값을 줄 수 있지만, 시간이 많이 걸립니다.

1618
01:04:55,220 --> 01:04:57,500
그럼 어떻게 해결할 수 있을까요?

1619
01:04:57,500 --> 01:05:00,440
좀 더 희소하게 샘플링해보면 어떨까요?

1620
01:05:00,440 --> 01:05:02,790
저는 여전히 이 암시적 표현들을 가지고 있습니다.

1621
01:05:02,790 --> 01:05:06,890
하지만 항상 빈 공간을 샘플링하는 대신,

1622
01:05:06,890 --> 01:05:09,830
물체가 있는 곳에서만 샘플링합니다.

1623
01:05:09,830 --> 01:05:11,070
그런데 그걸 어떻게 알 수 있을까요?

1624
01:05:11,070 --> 01:05:13,590
만약 점 표현이 있다면 어떨까요?

1625
01:05:13,590 --> 01:05:16,890
이것이 바로 Gaussian splats라는 개념의 아이디어입니다,

1626
01:05:16,890 --> 01:05:18,190
아마 들어보셨을 겁니다.

1627
01:05:18,190 --> 01:05:20,730
그래서 여전히 같은 암시적 함수들을 가지고 있습니다.

1628
01:05:20,730 --> 01:05:23,470
밀도와 외관 같은 것을 위해 신경망에

1629
01:05:23,470 --> 01:05:24,870
질의를 하는 거죠.

1630
01:05:24,870 --> 01:05:28,170
하지만 매번 신경망을 생성하는 대신, 3D 공간에 있는 3D

1631
01:05:28,170 --> 01:05:30,938
Gaussian 블롭의 점 표현을 가지고 있습니다.

1632
01:05:30,938 --> 01:05:33,230
때때로 이것을 포인트 클라우드라고

1633
01:05:33,230 --> 01:05:34,350
생각할 수도 있습니다.

1634
01:05:34,350 --> 01:05:36,170
하지만 이 점들은 단일 점 같은 게 아닙니다.

1635
01:05:36,170 --> 01:05:37,370
이들은 블롭 같은 거죠.

1636
01:05:37,370 --> 01:05:39,750
어떤 영역 같은 겁니다.

1637
01:05:39,750 --> 01:05:43,050
그리고 이 블롭들이 어디에 있는지 알기 때문에,

1638
01:05:43,050 --> 01:05:46,115
카메라에서 3D 공간으로 광선을 쏘고 점들을 샘플링할

1639
01:05:46,115 --> 01:05:48,490
때 항상 샘플링할 필요가 없습니다.

1640
01:05:48,490 --> 01:05:50,590
그저 이 블롭들이 어디에

1641
01:05:50,590 --> 01:05:53,790
있는지 보고, 각 Gaussian의 반경을

1642
01:05:53,790 --> 01:05:55,390
기준으로 물체가

1643
01:05:55,390 --> 01:05:56,870
있는 영역에서만

1644
01:05:56,870 --> 01:05:58,470
샘플링할 수 있습니다.

1645
01:05:58,470 --> 01:06:01,710
이렇게 하면 렌더링이 훨씬 효율적이 됩니다.

1646
01:06:01,710 --> 01:06:05,393
여기 3D Gaussian splats를 사용한 재구성 결과들이

1647
01:06:05,393 --> 01:06:06,060
있습니다.

1648
01:06:14,330 --> 01:06:17,530
품질 면에서 보면, 사실 그렇게

1649
01:06:17,530 --> 01:06:19,858
나쁘지 않고, 비교할

1650
01:06:19,858 --> 01:06:20,650
만합니다.

1651
01:06:20,650 --> 01:06:22,890
저는 이들이 NeRF와 비교할 만하다고 말하고 싶습니다.

1652
01:06:22,890 --> 01:06:25,010
이것은 다른 지표들, PSNR, SSIM입니다.

1653
01:06:25,010 --> 01:06:26,430
이들은 렌더링 품질과 같습니다.

1654
01:06:26,430 --> 01:06:29,898
그리고 y축이 0부터 시작하지 않는 것 같습니다.

1655
01:06:29,898 --> 01:06:31,190
그래서 약간 오해의 소지가 있습니다.

1656
01:06:31,190 --> 01:06:33,230
하지만 기본적으로 이 숫자들이 매우 가깝다는 것을 볼 수 있습니다.

1657
01:06:33,230 --> 01:06:34,610
그래서 품질, 렌더링 품질

1658
01:06:34,610 --> 01:06:36,850
측면에서 Gaussian splats와 NeRF는 적어도

1659
01:06:36,850 --> 01:06:38,370
처음 제안되었을 때 비슷합니다.

1660
01:06:38,370 --> 01:06:40,890
하지만 Gaussian splats는 훨씬 더 효율적입니다.

1661
01:06:40,890 --> 01:06:42,610
이것은 FPS, 초당 프레임 수입니다.

1662
01:06:42,610 --> 01:06:45,110
초당 150장의 이미지를 렌더링할 수 있습니다.

1663
01:06:45,110 --> 01:06:49,370
반면 NeRF는 단 한 장의 이미지를 렌더링하는 데

1664
01:06:49,370 --> 01:06:51,050
20초 정도 걸립니다.

1665
01:06:51,050 --> 01:06:54,670
그래서 이제 이 기술은 1,000배 더 빨라졌습니다.

1666
01:06:54,670 --> 01:06:56,170
적어도 그들이 주장한 바입니다.

1667
01:06:56,170 --> 01:06:59,340
빈 공간을 샘플링하고 빈 공간에 있는

1668
01:06:59,340 --> 01:07:02,500
점들에 대해 신경망에 계속 질의하는 데

1669
01:07:02,500 --> 01:07:06,370
모든 계산 자원을 낭비하지 않기 때문입니다.

1670
01:07:11,260 --> 01:07:13,940
네, 그래서 이것이 기본적으로 딥러닝이 3D

1671
01:07:13,940 --> 01:07:17,167
데이터에 다양한 표현 방식으로 어떻게 통합되었는지,

1672
01:07:17,167 --> 01:07:19,000
어떻게 시작되었고 발전했는지,

1673
01:07:19,000 --> 01:07:21,180
그리고 다양한 형태 표현과의

1674
01:07:21,180 --> 01:07:22,060
연결고리입니다.

1675
01:07:22,060 --> 01:07:23,560
그리고 우리가 다루지

1676
01:07:23,560 --> 01:07:25,620
않은 한 가지는—잠깐 2분 정도만

1677
01:07:25,620 --> 01:07:28,660
빠르게 다루자면—객체 기하학에 관한

1678
01:07:28,660 --> 01:07:30,620
흥미로운 점들이 있는데, 이는

1679
01:07:30,620 --> 01:07:32,720
단순히 요소 기하학, 즉 부분의

1680
01:07:32,720 --> 01:07:36,360
구체적인 세부사항뿐만 아니라 구조에 관한 내용입니다.

1681
01:07:36,360 --> 01:07:39,605
왜냐하면 종종 의자들이 대칭적일 수 있기 때문입니다.

1682
01:07:39,605 --> 01:07:40,980
그래서 매개변수화된 곡면에

1683
01:07:40,980 --> 01:07:42,980
대해 조금 이야기해 보겠습니다.

1684
01:07:42,980 --> 01:07:46,580
그리고 구 같은 것을 이용해 곡면의 일부를 이런 닫힌 형태의

1685
01:07:46,580 --> 01:07:49,107
방정식으로 매개변수화할 수 있습니다.

1686
01:07:49,107 --> 01:07:50,940
그렇게 하면 약간의 대칭성을 얻을 수 있습니다.

1687
01:07:50,940 --> 01:07:53,100
하지만 객체 기하학 내의

1688
01:07:53,100 --> 01:07:56,110
규칙성이나 구조, 반복성, 대칭성을

1689
01:07:56,110 --> 01:07:58,430
포함한 더 체계적인 연구들도

1690
01:07:58,430 --> 01:07:59,290
있었습니다.

1691
01:07:59,290 --> 01:08:01,832
사람들은 그것을 표현하기 위한

1692
01:08:01,832 --> 01:08:04,350
다양한 표현 방법도 고안했습니다.

1693
01:08:04,350 --> 01:08:06,730
그래서 어떻게 표현할 수 있을까요—어떤

1694
01:08:06,730 --> 01:08:09,290
의미에서는 포인트 클라우드, 메시, 암시적

1695
01:08:09,290 --> 01:08:11,582
함수들이 개별 부품의 기하학적 세부사항을

1696
01:08:11,582 --> 01:08:13,450
표현한다고 볼 수 있습니다.

1697
01:08:13,450 --> 01:08:15,310
하지만 이들 중 어느 것도 대칭성이나

1698
01:08:15,310 --> 01:08:18,290
반복성과 같은 규칙성을 직접적으로 포착하지는 못합니다.

1699
01:08:18,290 --> 01:08:20,189
그럼 어떻게 그걸 포착할 수 있을까요?

1700
01:08:20,189 --> 01:08:23,510
사람들이 주로 그래픽스 커뮤니티에서

1701
01:08:23,510 --> 01:08:27,270
탐구해온 몇 가지 시도는, 객체를 기본적으로

1702
01:08:27,270 --> 01:08:31,229
이런 단순한 기하학적 부품들의 집합, 즉

1703
01:08:31,229 --> 01:08:33,590
파트 세트로 표현하는 겁니다.

1704
01:08:33,590 --> 01:08:36,310
그리고 딥러닝을 적용해 객체의 다양한 부품을

1705
01:08:36,310 --> 01:08:38,790
표현하는 방법도 있었는데, 단순한 기하학적

1706
01:08:38,790 --> 01:08:40,189
원시 도형을 사용해

1707
01:08:40,189 --> 01:08:42,750
표현하고 이를 조합하거나, 앞서 말한 것처럼

1708
01:08:42,750 --> 01:08:45,649
암시적 함수(implicit functions)를

1709
01:08:45,649 --> 01:08:47,470
사용해 조합하는 방식입니다.

1710
01:08:47,470 --> 01:08:51,547
하지만 단순히 부품들의 집합으로 객체를

1711
01:08:51,547 --> 01:08:53,630
표현하는 데 그치지 않고,

1712
01:08:53,630 --> 01:08:55,297
부품들 간의 관계도

1713
01:08:55,297 --> 01:08:57,040
모델링하려는

1714
01:08:57,040 --> 01:08:58,560
시도도 있었습니다.

1715
01:08:58,560 --> 01:09:03,319
이것은 장면(scene)에서는 더더욱 그렇습니다, 예를 들어 침대를
생각해보죠.

1716
01:09:03,319 --> 01:09:04,883
침대는 보통 벽 옆에 위치합니다.

1717
01:09:04,883 --> 01:09:07,300
의자는 보통 탁자 옆에 있죠, 이런 식입니다.

1718
01:09:07,300 --> 01:09:09,000
그래서 단순히 부품이나 객체를

1719
01:09:09,000 --> 01:09:12,580
서로 관련 없는 집합으로 표현하는 것만으로는 부족합니다.

1720
01:09:12,580 --> 01:09:15,000
관계도 함께 포착하고 싶으실 겁니다.

1721
01:09:15,000 --> 01:09:18,008
계층 구조를 만들 때, 즉 건축을

1722
01:09:18,008 --> 01:09:20,300
할 때-- 건축 작업을

1723
01:09:20,300 --> 01:09:21,640
할 때 말이죠.

1724
01:09:21,640 --> 01:09:22,580
여러분은 건축가입니다.

1725
01:09:22,580 --> 01:09:26,000
건물을 설계할 때, 물론 단순히 객체나

1726
01:09:26,000 --> 01:09:29,180
그 관계만 표현하는 게 아닙니다.

1727
01:09:29,180 --> 01:09:30,580
무엇을 먼저 만들지, 계층

1728
01:09:30,580 --> 01:09:31,960
구조를 고려해야 합니다.

1729
01:09:31,960 --> 01:09:33,520
교실이 있고, 교실 안에는

1730
01:09:33,520 --> 01:09:35,580
책상과 의자가 있으며, 의자는 부품으로

1731
01:09:35,580 --> 01:09:36,740
구성되어 있습니다.

1732
01:09:36,740 --> 01:09:38,840
기본적으로 계층적 레벨이 있고,

1733
01:09:38,840 --> 01:09:41,752
이것을 신경망과 어떻게 통합할 수 있는지,

1734
01:09:41,752 --> 01:09:43,960
그리고 계층뿐 아니라 계층과

1735
01:09:43,960 --> 01:09:46,180
관계를 조합할 수도 있습니다.

1736
01:09:46,180 --> 01:09:48,722
그래서 계층적 그래프가 있는데, 예를 들어

1737
01:09:48,722 --> 01:09:50,680
의자의 경우, 받침대, 좌석,

1738
01:09:50,680 --> 01:09:53,340
등받이에 대해 서로 다른 계층 레벨이 있습니다.

1739
01:09:53,340 --> 01:09:55,520
받침대에는 여러 개의 다리가 있을 수 있습니다.

1740
01:09:55,520 --> 01:09:57,520
하지만 다리들 자체도 서로 관련이 있습니다.

1741
01:09:57,520 --> 01:09:59,760
의자의 왼쪽 다리와 오른쪽 다리는

1742
01:09:59,760 --> 01:10:01,180
대칭이어야 합니다.

1743
01:10:01,180 --> 01:10:03,380
그리고 동일한 모양이어야 하죠.

1744
01:10:03,380 --> 01:10:05,780
이 다리들이 위치하는 데에는 제약이 있습니다.

1745
01:10:05,780 --> 01:10:08,180
정확히 정렬되어야 합니다, 그렇지 않으면

1746
01:10:08,180 --> 01:10:09,400
의자가 넘어질 테니까요.

1747
01:10:09,400 --> 01:10:10,817
이처럼 꽤 유용한

1748
01:10:10,817 --> 01:10:12,560
제약들이 존재합니다.

1749
01:10:12,560 --> 01:10:13,960
그런데 이것들을 어떻게 표현할 수 있을까요?

1750
01:10:13,960 --> 01:10:16,520
사람들은 이런 다양한 표현 방법들을 생각해 냅니다.

1751
01:10:16,520 --> 01:10:19,060
그리고 각각에 대해, 이러한 제약

1752
01:10:19,060 --> 01:10:21,620
조건을 만족하는 객체를 학습하고 포착하며

1753
01:10:21,620 --> 01:10:24,300
생성하기 위해 설계된 많은 신경망과

1754
01:10:24,300 --> 01:10:26,180
딥러닝 방법들이 있습니다.

1755
01:10:26,180 --> 01:10:29,820
예를 들어, 이것은 계층적 그래프,

1756
01:10:29,820 --> 01:10:33,580
인코더와 디코더로 3D 의자를 표현하고 생성하려고

1757
01:10:33,580 --> 01:10:37,300
하며, 모든 제약 조건을 만족하면서

1758
01:10:37,300 --> 01:10:39,392
계층 구조를 유지합니다.

1759
01:10:39,392 --> 01:10:43,660
이것도 2019년 Leonidas 연구실에서 나온 것 같습니다.

1760
01:10:43,660 --> 01:10:45,660
때로는 반복문과 for

1761
01:10:45,660 --> 01:10:47,380
루프가 있기 때문에

1762
01:10:47,380 --> 01:10:49,260
프로그램 형태로도 도형을

1763
01:10:49,260 --> 01:10:52,070
표현할 수 있고, 이것을 신경망에

1764
01:10:52,070 --> 01:10:54,070
통합해 객체 형태와

1765
01:10:54,070 --> 01:10:57,630
객체 부품 간 관계를 합성하는 프로그램을

1766
01:10:57,630 --> 01:10:59,190
생성할 수 있습니다.

1767
01:10:59,190 --> 01:11:01,230
이것도 중요한 주제입니다.

1768
01:11:01,230 --> 01:11:05,390
가장 최근에는, 지난 1~2년 사이에 딥

1769
01:11:05,390 --> 01:11:08,270
네트워크나 대형 언어 모델이 매우

1770
01:11:08,270 --> 01:11:11,750
잘 작동하고 사물을 잘 이해해서,

1771
01:11:11,750 --> 01:11:15,230
사람들이 탐구하는 새로운 경향이 있다고

1772
01:11:15,230 --> 01:11:16,930
말씀드리고 싶습니다.

1773
01:11:16,930 --> 01:11:19,990
GPT 같은 대형 언어 모델을 사용해, 의자가

1774
01:11:19,990 --> 01:11:22,470
어떻게 생겨야 하는지 의미를

1775
01:11:22,470 --> 01:11:23,910
이해하고, 프로그램을 출력할

1776
01:11:23,910 --> 01:11:25,070
수 있을까요?

1777
01:11:25,070 --> 01:11:26,970
의자가 만족해야 하는 제약 조건은 무엇일까요?

1778
01:11:26,970 --> 01:11:29,220
그래서 대형 언어 모델을 사용해 프로그램을

1779
01:11:29,220 --> 01:11:30,330
출력하는 것이 가능할까요?

1780
01:11:30,330 --> 01:11:32,950
그런 다음 암묵적 함수 같은 것을 사용해

1781
01:11:32,950 --> 01:11:34,430
의자 같은 객체 부품의

1782
01:11:34,430 --> 01:11:37,570
구체적인 기하학적 세부 사항을 포착할 수도 있겠죠.

1783
01:11:37,570 --> 01:11:39,870
이런 새로운 연구 경향이

1784
01:11:39,870 --> 01:11:42,390
요즘 나타나고 있습니다.

1785
01:11:42,390 --> 01:11:43,770
네, 이게 제가 준비한 내용 전부입니다.

1786
01:11:43,770 --> 01:11:45,580
감사합니다.
