1
00:00:05,210 --> 00:00:10,410
CS231N 분기의 마지막 강의에 오신 것을 환영합니다.

2
00:00:10,410 --> 00:00:14,150
처음과 지금 끝에서 여러분을 만나게

3
00:00:14,150 --> 00:00:15,630
되어 기쁩니다.

4
00:00:15,630 --> 00:00:18,360
이번 강의는 약간의 변화가 있습니다.

5
00:00:18,360 --> 00:00:21,230
알고리즘 측면에서 새로운 자료를

6
00:00:21,230 --> 00:00:23,100
가르치지 않을 것입니다.

7
00:00:23,100 --> 00:00:27,590
더 긴 연구 진화에 대한 관점을

8
00:00:27,590 --> 00:00:33,830
제시하는 학생들에게 하고 싶은 이야기이며, 오늘날

9
00:00:33,830 --> 00:00:39,140
AI에 중요한 또 다른 차원인 인간의

10
00:00:39,140 --> 00:00:42,140
관점에 대해서도 이야기하고자

11
00:00:42,140 --> 00:00:43,560
합니다.

12
00:00:43,560 --> 00:00:47,400
자료의 완전성을 위해 이 과정의

13
00:00:47,400 --> 00:00:49,520
다른 부분과 약간의

14
00:00:49,520 --> 00:00:53,040
중복이 있을 수 있지만,

15
00:00:53,040 --> 00:00:58,980
hopefully, 더 완전한 방식으로 이해되기를 바랍니다.

16
00:00:58,980 --> 00:01:05,200
이 슬라이드 또는 강의의 제목은 우리가 보고 가치 있게 여기는

17
00:01:05,200 --> 00:01:08,960
것, 인간의 관점을 가진 AI입니다.

18
00:01:08,960 --> 00:01:12,040
여러분 중 일부는 이미 이 이야기를 들었을 것입니다.

19
00:01:12,040 --> 00:01:15,380
이는 진화와 기술 모두에서

20
00:01:15,380 --> 00:01:18,430
비전의 시작, 즉

21
00:01:18,430 --> 00:01:20,270
기원입니다.

22
00:01:20,270 --> 00:01:23,830
540백만 년 전 동물 세계에

23
00:01:23,830 --> 00:01:30,260
등장한 첫 번째 슬라이드에 대해 이야기했습니다.

24
00:01:30,260 --> 00:01:35,360
그때 동물, 특히 삼엽충이 외부

25
00:01:35,360 --> 00:01:41,410
세계를 이해하기 위해 광감지 세포를

26
00:01:41,410 --> 00:01:43,670
발전시켰습니다.

27
00:01:43,670 --> 00:01:49,510
앤드류 파커와 같은 동물학자에 따르면,

28
00:01:49,510 --> 00:01:56,960
비전의 시작으로 인해 진화의 무기 경쟁이

29
00:01:56,960 --> 00:02:02,370
촉발되었고, 동물들은 진화하거나

30
00:02:02,370 --> 00:02:04,600
멸종했습니다.

31
00:02:04,600 --> 00:02:09,210
이 무기 경쟁은 동물의 종 분화 또는 폭발적

32
00:02:09,210 --> 00:02:12,280
종 분화를 초래했으며, 이를

33
00:02:12,280 --> 00:02:16,470
동물학자들은 캄브리아기 폭발 또는 진화의

34
00:02:16,470 --> 00:02:18,580
빅뱅이라고 부릅니다.

35
00:02:18,580 --> 00:02:22,470
물론, 오늘날에도 비전이 많은

36
00:02:22,470 --> 00:02:25,120
동물에서 주요 감각

37
00:02:25,120 --> 00:02:31,420
지능 시스템이라는 사실에 놀라지 않을 것입니다.

38
00:02:31,420 --> 00:02:35,980
모든 동물이 비전을 사용하는 것은 아니지만, 많은 동물이 사용합니다.

39
00:02:35,980 --> 00:02:39,300
인간에게도 주요 감각 시스템

40
00:02:39,300 --> 00:02:41,170
중 하나입니다.

41
00:02:41,170 --> 00:02:48,060
우리는 생존, 일, 오락, 사회화, 학습,

42
00:02:48,060 --> 00:02:51,180
발전 등 모든 것을

43
00:02:51,180 --> 00:02:54,730
위해 비전을 사용합니다.

44
00:02:54,730 --> 00:03:01,390
그래서 이것이 진화의 요약입니다.

45
00:03:01,390 --> 00:03:07,060
또한 1960년대 여름 비전 프로젝트로서 컴퓨터 비전에

46
00:03:07,060 --> 00:03:13,260
대해 간단히 이야기했습니다. 이는 몇몇 학부생을

47
00:03:13,260 --> 00:03:18,240
사용하여 시각 시스템의 중요한 부분을 구성하려는

48
00:03:18,240 --> 00:03:19,570
시도였습니다.

49
00:03:19,570 --> 00:03:23,770
이는 AI의 역사와 매우 일치하며, 우리는

50
00:03:23,770 --> 00:03:28,660
북극성의 명확성을 가지고 있지만, 얼마나

51
00:03:28,660 --> 00:03:32,230
오랜 시간이 걸릴지를 과소평가합니다.

52
00:03:32,230 --> 00:03:34,990
우리는 아마도 오늘날에도 그런 경험을

53
00:03:34,990 --> 00:03:37,874
하고 있지만, 많은 일이 일어났습니다.

54
00:03:37,874 --> 00:03:42,270
자율주행차의 발전부터 이미지

55
00:03:42,270 --> 00:03:45,600
이해, 생성 AI 혁명까지,

56
00:03:45,600 --> 00:03:49,110
비전이 큰 역할을

57
00:03:49,110 --> 00:03:54,770
하고 있으며, 많은 부분에서 물결을 이끌고

58
00:03:54,770 --> 00:03:56,630
있습니다.

59
00:03:56,630 --> 00:04:02,580
그래서 이제 역사적으로 그리고 미래를 향해 이 문제를 다른

60
00:04:02,580 --> 00:04:05,240
시각으로 바라볼 때입니다.

61
00:04:05,240 --> 00:04:09,090
우리는 어디에서 왔고, 어디로 가고 있습니까?

62
00:04:09,090 --> 00:04:13,650
이는 중요한 주제이며, 많은 일이 일어난

63
00:04:13,650 --> 00:04:16,310
만큼 앞으로 일어날 일에

64
00:04:16,310 --> 00:04:18,950
대한 정보를 제공합니다.

65
00:04:18,950 --> 00:04:23,390
이 강의를 세 부분으로 나누어 진행하겠습니다.

66
00:04:23,390 --> 00:04:28,980
첫 번째는 인간이 보는 것을 보기 위해 AI를 구축하는 것입니다.

67
00:04:28,980 --> 00:04:30,660
그것이 우리가 출발한 곳입니다.

68
00:04:30,660 --> 00:04:33,980
우리는 인간의 능력에 깊은 영감을 받아

69
00:04:33,980 --> 00:04:37,560
같은 일을 하는 기계를 만들고 싶었습니다.

70
00:04:37,560 --> 00:04:39,380
그 다음에는 인간이 보지 못하는 것을 보기

71
00:04:39,380 --> 00:04:41,640
위해 AI를 구축하는 것에 대해 이야기하겠습니다.

72
00:04:41,640 --> 00:04:44,390
마지막으로 인간이 보고 싶어하는 것을 보기

73
00:04:44,390 --> 00:04:46,970
위해 AI를 구축하는 것으로 마무리하겠습니다.

74
00:04:46,970 --> 00:04:48,840
첫 번째부터 시작하겠습니다.

75
00:04:48,840 --> 00:04:50,820
인간이 보는 것을 보기 위해 AI를 구축하는 것입니다.

76
00:04:50,820 --> 00:04:53,440
다시, 간단한 복습입니다.

77
00:04:53,440 --> 00:04:55,930
인간은 보는 데 매우 능숙합니다.

78
00:04:55,930 --> 00:04:57,050
우리는 이를 알고 있습니다.

79
00:04:57,050 --> 00:05:02,830
이 실험은 반세기 전의 것으로, 한 번도 보지 않은

80
00:05:02,830 --> 00:05:07,810
비디오를 10헤르츠로 재생할 때, 즉 각 프레임이

81
00:05:07,810 --> 00:05:11,890
화면에 100밀리초만 나타나는

82
00:05:11,890 --> 00:05:14,750
상황에서도 인간의 눈이 대상을

83
00:05:14,750 --> 00:05:18,220
감지하는 데 문제가 없음을

84
00:05:18,220 --> 00:05:22,900
보여줍니다. 여기서는 사람을 대상으로 합니다.

85
00:05:22,900 --> 00:05:26,950
이 복잡한 장면에서 이 사람이 무엇인지에

86
00:05:26,950 --> 00:05:29,290
대한 사전 지식이

87
00:05:29,290 --> 00:05:36,530
전혀 없더라도, 이는 인간의 시각적 이해, 특히 객체 중심 이해의

88
00:05:36,530 --> 00:05:39,560
뛰어난 능력을 강조합니다.

89
00:05:39,560 --> 00:05:43,900
우리는 또한 세기 전환기

90
00:05:43,900 --> 00:05:47,920
즈음에 신경생리학자들이 EEG

91
00:05:47,920 --> 00:05:53,820
캡에서 측정된 뇌 신호 형태로 복잡한

92
00:05:53,820 --> 00:06:01,290
객체를 보는 인간의 시각 속도를 측정하고 있다는

93
00:06:01,290 --> 00:06:05,740
점을 간략히 언급했습니다.

94
00:06:05,740 --> 00:06:10,020
우리는 동물과 동물을 구별하거나 분류하는

95
00:06:10,020 --> 00:06:13,480
것이 매우 복잡한 작업임을 알지만,

96
00:06:13,480 --> 00:06:18,930
인간은 자극 시작 후 150밀리초 만에 이를

97
00:06:18,930 --> 00:06:21,160
수행할 수 있습니다.

98
00:06:21,160 --> 00:06:25,230
이는 우리의 두개골 아래에 있는 생물학적 구조를

99
00:06:25,230 --> 00:06:28,300
고려할 때 놀라운 속도입니다.

100
00:06:28,300 --> 00:06:31,830
또한 신경생리학자들은 객체가

101
00:06:31,830 --> 00:06:38,070
인간의 시각 지능에서 매우 중요한 기능이라는

102
00:06:38,070 --> 00:06:41,050
것을 가르쳐 주었습니다.

103
00:06:41,050 --> 00:06:45,390
너무 중요해서 우리의 뇌에 신경 상관관계가 존재합니다.

104
00:06:45,390 --> 00:06:49,240
객체 이해를 위해 전용된 영역, 즉 위상

105
00:06:49,240 --> 00:06:54,330
영역, 장소 영역 또는 신체 부위 영역이 있습니다.

106
00:06:54,330 --> 00:06:57,680
이는 진화가 객체 인식에 관한 우리의

107
00:06:57,680 --> 00:07:01,250
시각 지능 기술을 연마하는 데 많은

108
00:07:01,250 --> 00:07:03,720
시간을 투자했음을 보여줍니다.

109
00:07:03,720 --> 00:07:10,040
이 모든 것이 컴퓨터 비전 분야의 역사를 쌓아왔고,

110
00:07:10,040 --> 00:07:13,850
몇십 년 전 객체 인식이 시각

111
00:07:13,850 --> 00:07:17,820
지능의 기본 구성 요소가 되었습니다.

112
00:07:17,820 --> 00:07:20,640
우리는 기계에 이를 부여하고자 합니다.

113
00:07:20,640 --> 00:07:25,280
이를 위해 우리는 문제를 정의합니다.

114
00:07:25,280 --> 00:07:29,490
즉, 이미지를 주었을 때, 컴퓨터가

115
00:07:29,490 --> 00:07:35,870
이미지에서 객체를 식별하거나 객체가 무엇인지 알

116
00:07:35,870 --> 00:07:40,370
수 있도록 어떻게 할 것인가입니다.

117
00:07:40,370 --> 00:07:43,410
이는 인간에게는 매우 수월한 작업입니다.

118
00:07:43,410 --> 00:07:45,230
하지만 이제 충분한

119
00:07:45,230 --> 00:07:48,950
컴퓨터 비전을 배웠으니, 수학적으로는

120
00:07:48,950 --> 00:07:54,200
조명, 질감, 배경, 가림, 시점, 크기

121
00:07:54,200 --> 00:07:59,000
조정 등 다양한 요인으로 인해 실제로 어떤 객체를

122
00:07:59,000 --> 00:08:04,610
인식하는 데 무한한 가능성이 있다는 것을 생각해

123
00:08:04,610 --> 00:08:05,460
보십시오.

124
00:08:05,460 --> 00:08:12,500
따라서 이는 근본적으로 어려운 작업입니다.

125
00:08:12,500 --> 00:08:16,920
딥러닝 이전의 역사도 매우 흥미롭습니다.

126
00:08:16,920 --> 00:08:20,120
일반화 가능한 객체 인식 문제를

127
00:08:20,120 --> 00:08:25,040
해결하기 위한 몇 가지 영웅적인 시도가

128
00:08:25,040 --> 00:08:26,010
있었습니다.

129
00:08:26,010 --> 00:08:30,920
첫 번째 시도는 실제로 심리학 자체에서

130
00:08:30,920 --> 00:08:32,730
영감을 받았습니다.

131
00:08:32,730 --> 00:08:36,470
우리는 때때로 과도한 자기 성찰의 해악에도

132
00:08:36,470 --> 00:08:39,140
불구하고 자기 성찰을 합니다.

133
00:08:39,140 --> 00:08:43,415
우리는 인간이 부분을 구성한다고 생각합니다.

134
00:08:43,415 --> 00:08:47,060
우리는 객체를 보고 기하학적 부분을 볼 수 있으며,

135
00:08:47,060 --> 00:08:50,360
이를 다양한 객체로 구성할 수 있습니다.

136
00:08:50,360 --> 00:08:57,850
사전 지정된 부분이나 형태를 사용하여 특정

137
00:08:57,850 --> 00:09:03,340
방식으로 구성하는 아이디어가 객체 인식의

138
00:09:03,340 --> 00:09:07,340
첫 번째 물결이었습니다.

139
00:09:07,340 --> 00:09:11,260
따라서 이는 70년대, 80년대, 심지어

140
00:09:11,260 --> 00:09:15,430
90년대까지 다양한 부분과 구성을 사용하여 객체를

141
00:09:15,430 --> 00:09:18,220
인식하는 다양한 작업이나

142
00:09:18,220 --> 00:09:19,040
모델입니다.

143
00:09:19,040 --> 00:09:21,260
물론, 이는 실제로 잘 작동하지 않았습니다.

144
00:09:21,260 --> 00:09:24,590
수학적으로 아름답고 간단하지만, 작동하지 않았습니다.

145
00:09:24,590 --> 00:09:30,070
따라서 딥러닝 이전의 두 번째 객체 인식

146
00:09:30,070 --> 00:09:36,970
물결은 AI 분야에서 정말 중요한 시대였습니다.

147
00:09:36,970 --> 00:09:39,380
이는 기계 학습의 시작입니다.

148
00:09:39,380 --> 00:09:41,330
통계적 기계 학습.

149
00:09:41,330 --> 00:09:44,140
이는 컴퓨터 프로그래밍과 통계

150
00:09:44,140 --> 00:09:46,480
모델링의 결합이었습니다.

151
00:09:46,480 --> 00:09:49,320
그 결혼을 통해 우리는 세상이

152
00:09:49,320 --> 00:09:53,550
매우 복잡하다는 것을 깨닫기 시작합니다.

153
00:09:53,550 --> 00:09:57,000
이러한 문제들, 즉 시각 지능,

154
00:09:57,000 --> 00:10:00,150
언어 지능 또는 다른 종류의

155
00:10:00,150 --> 00:10:05,710
지능 문제를 일반화하기 위해서는 매개변수를 배워야 합니다.

156
00:10:05,710 --> 00:10:15,190
손으로 조정한 모델을 사용하여 좋은 학습을 얻는 것은 매우 어렵습니다.

157
00:10:15,190 --> 00:10:19,140
우리는 이제 데이터가 필요하다는 것을 알고 있습니다. 비록 그 당시에는
얼마나 많은

158
00:10:19,140 --> 00:10:20,350
데이터가 필요한지 몰랐지만.

159
00:10:20,350 --> 00:10:25,200
하지만 우리는 또한 통계 모델을 설계하거나 구조화해야 한다는

160
00:10:25,200 --> 00:10:28,320
것을 알고 있습니다. 그래야 다양한 학습

161
00:10:28,320 --> 00:10:31,950
규칙을 통해 학습할 수 있는 능력을 가질 수

162
00:10:31,950 --> 00:10:32,710
있습니다.

163
00:10:32,710 --> 00:10:37,650
그로 인해 우리는 무작위 필드, 베이즈 네트워크,

164
00:10:37,650 --> 00:10:41,250
서포트 벡터 머신 등을 배우는

165
00:10:41,250 --> 00:10:45,110
모델이 꽃피는 시대를 보았습니다.

166
00:10:45,110 --> 00:10:50,720
실제로 21세기 첫 번째 10년이 되었을 때 객체

167
00:10:50,720 --> 00:10:55,230
인식에서 많은 진전이 이루어졌고, 우리는

168
00:10:55,230 --> 00:10:59,390
알고리즘을 비교하도록 모든 사람을 격려하기

169
00:10:59,390 --> 00:11:04,970
위해 소수의 객체 클래스에 대한 국제 기준을 갖게

170
00:11:04,970 --> 00:11:06,210
되었습니다.

171
00:11:06,210 --> 00:11:08,160
우리는 함께 조금씩 나아가고 있습니다.

172
00:11:08,160 --> 00:11:12,920
객체 인식의 마지막 열쇠는 우리가 배운 대로

173
00:11:12,920 --> 00:11:15,900
다시 인지 과학으로 돌아갑니다.

174
00:11:15,900 --> 00:11:19,170
이 심리학자, 어브 비더만은

175
00:11:19,170 --> 00:11:23,600
인간이 엄청난 수의 객체를 인식할 수 있다고

176
00:11:23,600 --> 00:11:26,190
오랫동안 추측해왔습니다.

177
00:11:26,190 --> 00:11:28,980
이는 우리의 일반적인 지식으로 직관적입니다.

178
00:11:28,980 --> 00:11:32,000
하지만 그는 실제로 그 수치를 제시했습니다.

179
00:11:32,000 --> 00:11:34,620
저는 개인적으로 이를 비더만

180
00:11:34,620 --> 00:11:40,530
수라고 부르는데, 그는 6세 또는 7세가 되면 아이들이 약 30,

181
00:11:40,530 --> 00:11:46,070
000에서 100,000개의 서로 다른 시각 범주를 인식할 수 있다고

182
00:11:46,070 --> 00:11:47,580
추측했습니다.

183
00:11:47,580 --> 00:11:50,040
그는 이것을 어떻게 생각해냈을까요?

184
00:11:50,040 --> 00:11:54,000
이 숫자는 사전에서 명사의 수와 아이들이

185
00:11:54,000 --> 00:11:58,610
서로 다른 객체를 인식하는 방법에 대한

186
00:11:58,610 --> 00:12:01,590
시각적 연구를 결합한 것입니다.

187
00:12:01,590 --> 00:12:06,020
하지만 이는 컴퓨터 비전 분야에 있어 꽤

188
00:12:06,020 --> 00:12:10,320
위협적이고 냉정한 숫자입니다. 왜냐하면 지금까지,

189
00:12:10,320 --> 00:12:13,440
21세기 첫 번째 10년

190
00:12:13,440 --> 00:12:18,770
중반까지 우리는 인간이 경험하는 것에 비해 극소수의 객체

191
00:12:18,770 --> 00:12:23,150
범주와 극소수의 이미지로 작업하고 있었기

192
00:12:23,150 --> 00:12:24,120
때문입니다.

193
00:12:24,120 --> 00:12:29,120
그리고 이는 여러분이 아시는 바와 같이

194
00:12:29,120 --> 00:12:36,380
ImageNet 프로젝트의 동기가 되었으며, 이 숫자를 정말로 진지하게

195
00:12:36,380 --> 00:12:38,630
받아들여 비더만이 추측한

196
00:12:38,630 --> 00:12:42,590
것과 동등한 데이터 세트를 구성했습니다.

197
00:12:42,590 --> 00:12:45,300
이는 약 22,

198
00:12:45,300 --> 00:12:51,480
000개의 객체 클래스와 1,500만 개 이상의 이미지입니다.

199
00:12:51,480 --> 00:12:53,720
물론, 이는 여러분이 이

200
00:12:53,720 --> 00:12:57,330
수업에 들어오기 시작하는 시작점입니다.

201
00:12:57,330 --> 00:13:01,890
ImageNet이 제공한 대량의 데이터 덕분에

202
00:13:01,890 --> 00:13:07,250
우리는 신경망과 같은 강력한 알고리즘이 처음에는 합성곱 신경망으로,

203
00:13:07,250 --> 00:13:09,630
현재는 변환기 등을

204
00:13:09,630 --> 00:13:12,500
사용하여 대량의 데이터를 통해

205
00:13:12,500 --> 00:13:17,750
그 힘을 정말로 보여주기 시작하는 것을 볼 수 있습니다.

206
00:13:17,750 --> 00:13:23,360
이것은 이 내용을 배우지 않은 사람들을 위한 일반적인

207
00:13:23,360 --> 00:13:24,630
슬라이드입니다.

208
00:13:24,630 --> 00:13:26,790
여러분 모두 이 내용을 알고 있기 때문에 저는 이 부분을 건너뛰겠습니다.

209
00:13:26,790 --> 00:13:31,740
간단한 역사는 ImageNet이 생기고 합성곱

210
00:13:31,740 --> 00:13:35,360
신경망을 사용하기 시작한 직후,

211
00:13:35,360 --> 00:13:38,270
ImageNet의 시작 몇 년 후에

212
00:13:38,270 --> 00:13:41,460
객체 인식 문제를 해결하는 데

213
00:13:41,460 --> 00:13:45,610
있어 문이 폭발적으로 열렸다는 것입니다.

214
00:13:45,610 --> 00:13:48,120
이제 우리는 세상의

215
00:13:48,120 --> 00:13:51,420
어떤 사진을 보고도 크고 작고

216
00:13:51,420 --> 00:13:55,440
어떤 방향에서도 객체를 인식할 수

217
00:13:55,440 --> 00:13:59,250
있는 알고리즘을 갖게 되었습니다.

218
00:13:59,250 --> 00:14:01,030
100% 정확한가요?

219
00:14:01,030 --> 00:14:01,530
아니요.

220
00:14:01,530 --> 00:14:04,840
우리가 해결할 수 있는 긴 꼬리 문제는 항상 존재합니다.

221
00:14:04,840 --> 00:14:07,720
하지만 산업 응용 프로그램 측면에서

222
00:14:07,720 --> 00:14:10,590
이는 많은 발전을 이루었고,

223
00:14:10,590 --> 00:14:13,630
정말로 성숙한 문제로 자리 잡았습니다.

224
00:14:13,630 --> 00:14:16,860
그리고 물론 여러분 모두 아시겠지만, 이

225
00:14:16,860 --> 00:14:21,660
모든 것은 2012년이라는 수렴점에서 이루어졌습니다. 그 해

226
00:14:21,660 --> 00:14:24,240
ImageNet 챌린지가 합성곱

227
00:14:24,240 --> 00:14:26,770
신경망을 위한 데이터를 제공했고,

228
00:14:26,770 --> 00:14:30,340
그 당시 두 개의 GPU를 사용했습니다.

229
00:14:30,340 --> 00:14:34,590
세 가지 요소가 결합하여 딥러닝의

230
00:14:34,590 --> 00:14:37,580
순간, 즉 딥러닝의 탄생을

231
00:14:37,580 --> 00:14:39,300
가져왔습니다.

232
00:14:39,300 --> 00:14:42,980
이 수업에서는 지난 10년 동안

233
00:14:42,980 --> 00:14:46,220
ImageNet 챌린지가

234
00:14:46,220 --> 00:14:49,880
유도한 다양한 합성곱 신경망

235
00:14:49,880 --> 00:14:53,510
또는 ResNet 등의 다양한

236
00:14:53,510 --> 00:14:57,990
아키텍처에 대해서도 조금 이야기했습니다.

237
00:14:57,990 --> 00:15:05,610
그래서 이것이 정말로 딥러닝 혁명의 시작입니다.

238
00:15:05,610 --> 00:15:09,510
그리고 물론 시각 지능을 추구하는 과정에서 우리는 단순히

239
00:15:09,510 --> 00:15:13,220
장면의 객체에 레이블을 붙이는 것에 그치지 않을

240
00:15:13,220 --> 00:15:14,070
것입니다.

241
00:15:14,070 --> 00:15:18,420
예를 들어, 이 두 장면에서 객체에 레이블을 붙인다면, 여러분은

242
00:15:18,420 --> 00:15:21,150
단순히 라마와 사람이라고 생각할 것입니다.

243
00:15:21,150 --> 00:15:23,450
하지만 내가 라마와 사람의 두

244
00:15:23,450 --> 00:15:25,670
번째 장면을 보여주면

245
00:15:25,670 --> 00:15:27,420
이야기는 완전히 다릅니다.

246
00:15:27,420 --> 00:15:29,730
같은 객체가 있어도

247
00:15:29,730 --> 00:15:31,920
관계는 매우 다릅니다.

248
00:15:31,920 --> 00:15:35,290
그래서 인지 과학자들은 다시 한 번

249
00:15:35,290 --> 00:15:37,780
컴퓨터 과학자들의 선두주자가

250
00:15:37,780 --> 00:15:43,270
되어 우리가 단순히 객체를 이름 짓거나 분류하는 것을 넘어 시각적

251
00:15:43,270 --> 00:15:47,330
지능에 대해 생각하도록 영감을 주었습니다.

252
00:15:47,330 --> 00:15:49,790
이 특정 논문에서 저명한

253
00:15:49,790 --> 00:15:53,530
심리학자인 제레미 울프는 객체

254
00:15:53,530 --> 00:15:56,830
간의 관계가 복잡한 자연 장면을

255
00:15:56,830 --> 00:15:59,590
이해하는 데 반드시

256
00:15:59,590 --> 00:16:02,890
코드화되어야 한다고 강조하는

257
00:16:02,890 --> 00:16:05,420
아름다운 논문을 썼습니다.

258
00:16:05,420 --> 00:16:09,160
그 작업에 영감을 받아 컴퓨터 비전 분야는

259
00:16:09,160 --> 00:16:13,220
관계를 이해하는 방법을 살펴보기 시작했습니다.

260
00:16:13,220 --> 00:16:15,140
이것은 초기 작업입니다.

261
00:16:15,140 --> 00:16:20,730
여러분은 지난주에 Ranjay의 강의를 들었습니다.

262
00:16:20,730 --> 00:16:21,230
여러분은 지난주에 Ranjay의 강의를 들었습니다.

263
00:16:21,230 --> 00:16:21,910
지난주였습니다.

264
00:16:21,910 --> 00:16:27,850
이것은 장면 그래프를 표현으로 사용하여 객체 관계

265
00:16:27,850 --> 00:16:31,820
학습을 다룬 그의 박사 논문이었습니다.

266
00:16:31,820 --> 00:16:34,390
이 경우 장면 그래프는

267
00:16:34,390 --> 00:16:37,880
객체인 이러한 엔티티 노드로 정의되며,

268
00:16:37,880 --> 00:16:40,510
그들의 관계는 노드

269
00:16:40,510 --> 00:16:42,710
간의 연결성으로 정의되거나

270
00:16:42,710 --> 00:16:45,760
때로는 특정 객체를 정의하는

271
00:16:45,760 --> 00:16:48,380
속성 관계를 가집니다.

272
00:16:48,380 --> 00:16:51,250
그리고 대부분 두 사람만 있는 간단한

273
00:16:51,250 --> 00:16:56,590
상황에서도, 한 사람이 다른 사람에게 케이크를 주는 것처럼

274
00:16:56,590 --> 00:17:01,510
시각적 장면의 풍부함 덕분에 매우 밀집된 장면 그래프를 형성할

275
00:17:01,510 --> 00:17:02,900
수 있습니다.

276
00:17:02,900 --> 00:17:10,630
이것은 객체 인식 오류 이후 Ranjay의 논문으로, 우리는

277
00:17:10,630 --> 00:17:16,480
객체 관계와 이야기 설명을 함께 구성하려고

278
00:17:16,480 --> 00:17:22,810
시도한 '비주얼 제노믹'이라는 데이터 세트를

279
00:17:22,810 --> 00:17:24,380
만들었습니다.

280
00:17:24,380 --> 00:17:27,440
Ranjay가 한 작업 중 정말

281
00:17:27,440 --> 00:17:30,820
재미있었던 것은 비정상적인 객체

282
00:17:30,820 --> 00:17:33,790
관계의 제로 샷 학습이었습니다.

283
00:17:33,790 --> 00:17:38,560
예를 들어, 사람이 말을 타고 있는 것은 드문 일이 아닙니다.

284
00:17:38,560 --> 00:17:42,070
모자가 있는 사람을 보는 것도 드문 일이 아니지만,

285
00:17:42,070 --> 00:17:45,910
말이 모자를 쓰고 있는 것은 일반적으로 드문 일입니다.

286
00:17:45,910 --> 00:17:49,390
빅 데이터 훈련 시대에는 이러한

287
00:17:49,390 --> 00:17:51,540
종류의 데이터를

288
00:17:51,540 --> 00:17:54,580
반복적으로 얻기가 어렵습니다.

289
00:17:54,580 --> 00:17:58,750
하지만 이 조합적 장면 그래프 표현을

290
00:17:58,750 --> 00:18:02,280
사용하여 더 일반적인 관계를 학습하고,

291
00:18:02,280 --> 00:18:06,880
그 표현에서 드문 관계를 도출할 수 있었습니다.

292
00:18:06,880 --> 00:18:09,630
그리고 다시, 이것은 제로 샷

293
00:18:09,630 --> 00:18:13,920
학습의 또 다른 예로, 의자에 앉아 있는 사람과

294
00:18:13,920 --> 00:18:16,080
잔디밭이나 필드에 있는

295
00:18:16,080 --> 00:18:18,840
소화전은 모두 일반적인 관계이지만,

296
00:18:18,840 --> 00:18:22,880
소화전 위에 앉아 있는 사람은 데이터를 얻기

297
00:18:22,880 --> 00:18:24,370
어려운 관계입니다.

298
00:18:24,370 --> 00:18:27,790
우리는 그것을 가능하게 만들 수 있었습니다.

299
00:18:27,790 --> 00:18:31,190
이것은 Ranjay의 작업이 그

300
00:18:31,190 --> 00:18:35,060
당시 다른 많은 방법들과 비교하여 최첨단

301
00:18:35,060 --> 00:18:39,530
인식률을 달성했음을 보여주는 논문의 그림입니다.

302
00:18:39,530 --> 00:18:42,530
하지만 관계만으로는 충분하지 않습니다.

303
00:18:42,530 --> 00:18:46,220
더 풍부한 이야기를 실제로

304
00:18:46,220 --> 00:18:50,630
전달하는 능력, 또는 자연어를

305
00:18:50,630 --> 00:18:55,560
사용하는 것이 실제로 다음 큰 목표입니다.

306
00:18:55,560 --> 00:19:00,920
2014년경에 우리는 그 문제에 대해 작업을

307
00:19:00,920 --> 00:19:04,710
시작하고 생각하기 시작했습니다.

308
00:19:04,710 --> 00:19:09,360
그것은 Alex의 이미지가 나온 지 단 2년 후입니다.

309
00:19:09,360 --> 00:19:12,660
하지만 이 분야는 매우 빠르게 발전하기 시작했습니다.

310
00:19:12,660 --> 00:19:16,850
우리는 합성곱 신경망과 LSTM이라는

311
00:19:16,850 --> 00:19:21,950
언어 모델의 조합을 사용하여 할

312
00:19:21,950 --> 00:19:26,880
수 있는 것에 매우 영감을 받았습니다.

313
00:19:26,880 --> 00:19:29,960
그리고 이것은 이미지 캡셔닝 또는

314
00:19:29,960 --> 00:19:34,480
스토리텔링, 그리고 저스틴 존슨이 한 작업의 일부인

315
00:19:34,480 --> 00:19:38,800
밀집 캡셔닝을 수행하는 방법을 보여준 최초의

316
00:19:38,800 --> 00:19:42,340
팀 중 하나인 Andrej Karpathy의

317
00:19:42,340 --> 00:19:43,820
논문입니다.

318
00:19:43,820 --> 00:19:48,380
그는 이 과정의 공동 강사 중 한 명입니다.

319
00:19:48,380 --> 00:19:53,840
그것은 2015년에서 2018년 사이의 시기였습니다.

320
00:19:53,840 --> 00:19:58,130
문제를 해결하기 위해 많은 작업이 이루어졌습니다.

321
00:19:58,130 --> 00:20:01,940
물론 오늘날 다중 모달 LLM을 사용하여

322
00:20:01,940 --> 00:20:04,420
우리는 이 문제의

323
00:20:04,420 --> 00:20:07,790
해결책을 한 단계 더 발전시켰습니다.

324
00:20:07,790 --> 00:20:10,940
하지만 이것은 그 작업의 시작입니다.

325
00:20:10,940 --> 00:20:15,730
솔직히 말하자면, 21세기 초에 이 분야에 들어온

326
00:20:15,730 --> 00:20:18,860
컴퓨터 비전 과학자로서,

327
00:20:18,860 --> 00:20:24,130
데이터와 신경망 알고리즘이 확보되자마자 우리 분야가 이

328
00:20:24,130 --> 00:20:27,130
문제를 얼마나 빠르게 해결할

329
00:20:27,130 --> 00:20:29,970
수 있었는지 매우 놀랐습니다.

330
00:20:29,970 --> 00:20:34,660
하지만 훨씬 더 어려운 문제는 실제로 동적 장면에 있습니다.

331
00:20:34,660 --> 00:20:38,400
동적 장면에서는 훨씬 더 복잡한 관계가

332
00:20:38,400 --> 00:20:40,030
존재합니다.

333
00:20:40,030 --> 00:20:42,760
훨씬 더 복잡한 움직임이 있습니다.

334
00:20:42,760 --> 00:20:50,350
또한 카메라 움직임이나 장면 내의 주체, 배우들이

335
00:20:50,350 --> 00:20:55,000
다양한 행동을 할 수 있습니다.

336
00:20:55,000 --> 00:20:57,720
그래서 이 작업은 Esan과 우리

337
00:20:57,720 --> 00:21:01,390
연구실의 여러 학생들과의 협업으로, 우리는

338
00:21:01,390 --> 00:21:05,040
이를 다중 객체 다중 행위자 활동 이해라고

339
00:21:05,040 --> 00:21:05,970
부릅니다.

340
00:21:05,970 --> 00:21:07,960
이것은 훨씬 더 새로운 작업입니다.

341
00:21:07,960 --> 00:21:11,040
우리는 이 작업을 몇 년 전에만 발표했습니다.

342
00:21:11,040 --> 00:21:15,570
동적 장면에서 이러한 행위자와 그들의 활동 간의

343
00:21:15,570 --> 00:21:19,630
관계를 포착하는 것은 여전히 해결되지 않은

344
00:21:19,630 --> 00:21:22,180
문제라고 할 수 있습니다.

345
00:21:22,180 --> 00:21:24,970
그리고 이것은 깊은 의미를 가질 것입니다.

346
00:21:24,970 --> 00:21:27,370
여러분은 실리콘 밸리에 있다는 것을 알고 있습니다.

347
00:21:27,370 --> 00:21:34,510
그래서 예를 들어 로봇에 대한 많은 흥분을 듣고

348
00:21:34,510 --> 00:21:35,410
있습니다.

349
00:21:35,410 --> 00:21:38,580
우리가 만약 우리와 함께 일하는 일상적인

350
00:21:38,580 --> 00:21:42,370
로봇을 꿈꾼다면, 로봇은 이 문제를 해결해야 합니다.

351
00:21:42,370 --> 00:21:46,180
장면이 얼마나 복잡한지, 사람들이 무엇을 하고 있는지, 누가 무엇을 하고
있는지,

352
00:21:46,180 --> 00:21:48,370
다음에 무엇이 일어날지를 이해해야 합니다.

353
00:21:48,370 --> 00:21:49,985
그리고 이것은 해결되지 않은 문제입니다.

354
00:21:53,730 --> 00:21:57,680
제가 보여준 것 외에도, 여러분은 이

355
00:21:57,680 --> 00:22:02,340
수업에서 조금 배웠고 관련된 컴퓨터 비전 문제에 대해

356
00:22:02,340 --> 00:22:06,670
배웠지만, 자세히 설명할 시간이 없었습니다.

357
00:22:06,670 --> 00:22:11,010
예를 들어, 3D 컴퓨터 비전이나 인간 자세 이해입니다.

358
00:22:11,010 --> 00:22:15,580
물론 생성 AI와 생성 모델도 있습니다.

359
00:22:15,580 --> 00:22:18,390
그래서 이것은 현대 AI의

360
00:22:18,390 --> 00:22:22,800
재탄생 이후 컴퓨터 비전 분야가 얼마나 빠르게

361
00:22:22,800 --> 00:22:27,410
발전하고 있는지를 보여주기 위한 것입니다.

362
00:22:27,410 --> 00:22:31,220
하지만 이 섹션에서 제가 전하고 싶은

363
00:22:31,220 --> 00:22:34,110
핵심 메시지는 두 가지입니다.

364
00:22:34,110 --> 00:22:38,240
하나는 데이터, 컴퓨팅, 신경망 알고리즘이 실제로 약

365
00:22:38,240 --> 00:22:42,030
10년 또는 13년 전에 수렴했다는 것입니다.

366
00:22:42,030 --> 00:22:45,770
그것이 현대 AI 또는 딥러닝 혁명이 일어난

367
00:22:45,770 --> 00:22:47,340
순간이었습니다.

368
00:22:47,340 --> 00:22:50,060
하지만 그 역사와 우리가

369
00:22:50,060 --> 00:22:52,320
작업해온 많은 문제는

370
00:22:52,320 --> 00:22:57,110
실제로 인지 과학, 심리학, 신경 과학에서 영감을

371
00:22:57,110 --> 00:22:58,580
받았습니다.

372
00:22:58,580 --> 00:23:05,930
그리고 그것은 앞으로도 계속될 것입니다.

373
00:23:05,930 --> 00:23:10,640
우리는 뇌가 할 수 있는 것, 뇌가 일을 처리하는

374
00:23:10,640 --> 00:23:14,300
방식에서 계속 영감을 받을 것이며, 또한 AI를

375
00:23:14,300 --> 00:23:18,270
사용하여 우리의 뇌 연구를 도울 것입니다.

376
00:23:18,270 --> 00:23:22,450
그래서 오늘날의 AI와 인지 과학, 신경 과학,

377
00:23:22,450 --> 00:23:25,510
뇌 과학 사이에는 매우 밀접한

378
00:23:25,510 --> 00:23:26,810
관계가 있습니다.

379
00:23:26,810 --> 00:23:29,540
그래서 이것이 첫 번째 섹션입니다.

380
00:23:29,540 --> 00:23:33,640
물론 많은 사람들, 학생들, 협력자들이

381
00:23:33,640 --> 00:23:37,840
제가 방금 발표한 내용에 기여했습니다.

382
00:23:37,840 --> 00:23:42,580
이제 AI를 구축하는 것을 넘어 인간이 보지 못하는 것을

383
00:23:42,580 --> 00:23:45,320
보는 것에 대해 이야기해 보겠습니다.

384
00:23:45,320 --> 00:23:49,600
여기서 AI를 인간의 능력을 넘어, 또는 초인이라고 부를 수 있는

385
00:23:49,600 --> 00:23:51,320
방향으로 밀어붙이는 것입니다.

386
00:23:51,320 --> 00:23:57,380
예를 들어, 대부분의 사람들은 많은 공룡을 인식하지 못합니다.

387
00:23:57,380 --> 00:23:59,450
여러분은 아마 몇 가지 이름을 지을 수 있을 것입니다.

388
00:23:59,450 --> 00:24:01,910
어떤 아이들은 정말 많은 것을 이름 지을 수 있습니다.

389
00:24:01,910 --> 00:24:05,920
수천, 수만 종의 새나

390
00:24:05,920 --> 00:24:11,440
수만 가지 자동차 카테고리는

391
00:24:11,440 --> 00:24:14,480
말할 것도 없죠.

392
00:24:14,480 --> 00:24:19,600
그래서 제가 부르는 이 작업은 세밀한 객체

393
00:24:19,600 --> 00:24:20,870
분류입니다.

394
00:24:20,870 --> 00:24:24,010
인간은 그걸 잘하지 못합니다.

395
00:24:24,010 --> 00:24:27,780
솔직히 말해서, 이 문제는 아직 완전히

396
00:24:27,780 --> 00:24:31,170
해결되지 않았다고 생각합니다.

397
00:24:31,170 --> 00:24:34,170
이 생성적 AI 시대에는 특히 다중 모달

398
00:24:34,170 --> 00:24:37,600
LLM에 대해 많은 이야기를 하고 있습니다.

399
00:24:37,600 --> 00:24:42,160
이 문제는 다소 간과되었거나

400
00:24:42,160 --> 00:24:44,950
주류 문제가 아닙니다.

401
00:24:44,950 --> 00:24:46,650
하지만 정말로

402
00:24:46,650 --> 00:24:50,650
중요한 역할을 할 것입니다.

403
00:24:50,650 --> 00:24:53,910
그래서 세밀한 새 종 인식의

404
00:24:53,910 --> 00:24:58,320
초기 작업에서, 우리는 4,000종의

405
00:24:58,320 --> 00:25:02,230
새 데이터 세트를 만들었습니다.

406
00:25:02,230 --> 00:25:04,770
보시다시피, 종의

407
00:25:04,770 --> 00:25:13,570
나무를 내려갈수록, 오류는 실제로 더 일반적인 이름을

408
00:25:13,570 --> 00:25:20,490
가질 때 감소합니다. 즉, 세밀한 수준을

409
00:25:20,490 --> 00:25:24,620
읽을 때 여전히 많은 오류를

410
00:25:24,620 --> 00:25:30,120
범하고 있다는 복잡한 방식으로

411
00:25:30,120 --> 00:25:32,490
말하는 것입니다.

412
00:25:32,490 --> 00:25:39,710
알고리즘은 아직 완전히 준비되지 않았습니다.

413
00:25:39,710 --> 00:25:42,980
제가 흥미롭게 생각하는 또

414
00:25:42,980 --> 00:25:50,660
다른 작업은 몇 년 전, 제 연구실의 학생들이 제조사,

415
00:25:50,660 --> 00:25:54,110
모델 및 연도에 따라 세밀한

416
00:25:54,110 --> 00:25:58,680
자동차 분류기를 훈련시킨 것입니다.

417
00:25:58,680 --> 00:26:07,010
1970년대 이후로는 서로 다른 제조사, 모델 및 연도로 정의된

418
00:26:07,010 --> 00:26:11,460
수천 개의 자동차 모델이 있습니다.

419
00:26:11,460 --> 00:26:13,410
그리고 우리는

420
00:26:13,410 --> 00:26:20,910
전국의 200개 또는 100개 주요 도시에서 구글 스트리트 뷰

421
00:26:20,910 --> 00:26:23,970
이미지를 가져왔습니다.

422
00:26:23,970 --> 00:26:28,250
그런 다음 세밀한 자동차 탐지기를 사용하여 이

423
00:26:28,250 --> 00:26:32,610
도시의 거리에서 어떤 자동차가 있는지 감지했습니다.

424
00:26:32,610 --> 00:26:36,930
그리고 우리는 그것을 사회적 패턴을 연구하는 렌즈로 사용했습니다.

425
00:26:36,930 --> 00:26:40,620
예를 들어, 여기서 보여준 교육

426
00:26:40,620 --> 00:26:43,465
패턴은 어떤 패턴인지.

427
00:26:43,465 --> 00:26:46,220
자동차 모델과 교육 패턴은

428
00:26:46,220 --> 00:26:53,850
높은 상관관계를 가지고 있으며, 소득 패턴과도 높은 상관관계를 가지고
있습니다.

429
00:26:53,850 --> 00:26:59,060
그 논문에서는 투표 패턴도 높은 상관관계를 보여줍니다.

430
00:26:59,060 --> 00:27:03,270
심지어 환경 패턴도 높은 상관관계를 가지고 있습니다.

431
00:27:03,270 --> 00:27:07,010
그래서 컴퓨터 비전을 사회를 연구하는 렌즈로

432
00:27:07,010 --> 00:27:09,720
사용하는 것은 정말 흥미로운 방법입니다.

433
00:27:09,720 --> 00:27:12,000
어떤 인간도, 개인도,

434
00:27:12,000 --> 00:27:17,380
심지어 인간의 집합도 이것을 쉽게 할 수 없습니다.

435
00:27:17,380 --> 00:27:24,070
그래서 AI는 인간이 볼 수 있는 한계를 정말로 확장하고 있습니다.

436
00:27:24,070 --> 00:27:27,980
이 아이디어를 강조하기 위해 몇 가지 테스트를 해봅시다.

437
00:27:27,980 --> 00:27:31,840
인간은 실제로 한계가 있습니다.

438
00:27:31,840 --> 00:27:35,120
저는 인간의 시각 능력을 축하하는 것에 대해 이야기했습니다.

439
00:27:35,120 --> 00:27:36,680
하지만 우리에게도 한계가 있습니다.

440
00:27:36,680 --> 00:27:39,490
이것은 스트룹 테스트라는 매우 유명한

441
00:27:39,490 --> 00:27:41,240
시각적 환상 테스트입니다.

442
00:27:41,240 --> 00:27:44,390
아이디어는 여러분이 단어를 읽을 수 있다는 것입니다.

443
00:27:44,390 --> 00:27:49,810
하지만 단어의 색상을 가능한 한 빨리 왼쪽에서 오른쪽,

444
00:27:49,810 --> 00:27:54,080
위에서 아래로 읽으라고 하면, 그렇게 쉽지

445
00:27:54,080 --> 00:27:56,660
않다는 것을 알게 됩니다.

446
00:27:56,660 --> 00:28:04,910
빨강, 노랑, 초록, 보라, 파랑, 검정, 주황을

447
00:28:04,910 --> 00:28:07,095
읽어보세요.

448
00:28:07,095 --> 00:28:09,680
당신과 싸우고 있습니다.

449
00:28:09,680 --> 00:28:13,520
이것은 시각적 주의와 그 모든 것 사이의 싸움입니다.

450
00:28:13,520 --> 00:28:15,810
여기 또 다른 예가 있습니다.

451
00:28:15,810 --> 00:28:20,440
그림의 두 개의 교차하는 이미지가 있습니다.

452
00:28:20,440 --> 00:28:22,960
그리고 하나의 변화가 있습니다.

453
00:28:22,960 --> 00:28:26,250
두 개의 교차하는 그림 사이에서 일어나는

454
00:28:26,250 --> 00:28:27,640
꽤 큰 변화입니다.

455
00:28:27,640 --> 00:28:29,950
변화를 발견했는지 모르겠습니다.

456
00:28:29,950 --> 00:28:31,616
발견하셨나요?

457
00:28:31,616 --> 00:28:32,490
엔진--

458
00:28:32,490 --> 00:28:34,320
네, 엔진입니다.

459
00:28:34,320 --> 00:28:37,240
그래서 발견하는 데 시간이 좀 걸립니다.

460
00:28:37,240 --> 00:28:41,640
이것은 변화 맹목성이라고 불리는 매우 유명한

461
00:28:41,640 --> 00:28:43,150
심리 실험입니다.

462
00:28:43,150 --> 00:28:44,820
이제, 이 모든 것이 재미있습니다.

463
00:28:44,820 --> 00:28:46,870
스트룹 테스트도 재미있고, 이것도 재미있습니다.

464
00:28:46,870 --> 00:28:48,810
하지만 이것은 재미없습니다.

465
00:28:48,810 --> 00:28:51,850
인간의 주의력은 제한적입니다.

466
00:28:51,850 --> 00:28:56,260
그리고 우리의 업무 생활에서 이러한

467
00:28:56,260 --> 00:29:00,280
주의력의 제한은 심각할 수 있습니다.

468
00:29:00,280 --> 00:29:05,940
예를 들어, 의료 오류는 미국 의료 시스템에서

469
00:29:05,940 --> 00:29:10,210
세 번째로 주요한 사망 원인입니다.

470
00:29:10,210 --> 00:29:13,370
물론, 환자의 몸에 이 가위를

471
00:29:13,370 --> 00:29:16,700
두고 오는 것은 의료 오류의 상징적인

472
00:29:16,700 --> 00:29:18,000
이미지입니다.

473
00:29:18,000 --> 00:29:20,130
하지만 의료 오류는 정말 많습니다.

474
00:29:20,130 --> 00:29:25,350
약물 오류, 절차 오류, 문서 오류,

475
00:29:25,350 --> 00:29:28,590
진단 오류가 있습니다.

476
00:29:28,590 --> 00:29:31,260
그래서 매우 조심해야 합니다.

477
00:29:31,260 --> 00:29:35,630
예를 들어, 수술실에서는 솔직히 가위가

478
00:29:35,630 --> 00:29:40,130
몸에 남겨지지는 않지만, 봉합사, 바늘,

479
00:29:40,130 --> 00:29:45,930
거즈 조각 같은 훨씬 작은 것들이 남겨질 수 있습니다.

480
00:29:45,930 --> 00:29:52,615
그래서 오늘날 대부분은 여전히 손으로 추적됩니다.

481
00:29:52,615 --> 00:30:00,180
우리는 수술실에서 추적하기 위한 체크리스트를 가지고 있습니다.

482
00:30:00,180 --> 00:30:04,170
무언가가 누락되면 수술을 일시 중단해야 합니다.

483
00:30:04,170 --> 00:30:07,920
평균적으로 그 일시 중단은 거의 한 시간에 가깝습니다.

484
00:30:07,920 --> 00:30:11,040
환자에게 얼마나 위험한지 생각해 보세요.

485
00:30:11,040 --> 00:30:14,650
세균 노출과 출혈 등, 그

486
00:30:14,650 --> 00:30:18,470
항목을 찾기 위해서입니다.

487
00:30:18,470 --> 00:30:25,810
그래서 AI를 사용하여 의사와 외과의사가 항목을 추적하는 데 도움이 되는

488
00:30:25,810 --> 00:30:29,510
방법이 있다면, 정말 강력할 것입니다.

489
00:30:29,510 --> 00:30:30,860
그리고 이것은 단지 데모입니다.

490
00:30:30,860 --> 00:30:33,200
이것은 배포 시스템이 아닙니다.

491
00:30:33,200 --> 00:30:35,690
우리는 충실도 측면에서 아직 그곳에 도달하지 못했습니다.

492
00:30:35,690 --> 00:30:37,570
하지만 이것은 AI를 사용하여,

493
00:30:37,570 --> 00:30:42,560
이 경우 거즈와 같은 것을 세는 데 사용할 수 있음을 보여주는 데모입니다.

494
00:30:42,560 --> 00:30:49,090
그리고 이것은 AI를 활용하여 인간이 보지 못하는

495
00:30:49,090 --> 00:30:51,740
것을 보는 예시입니다.

496
00:30:51,740 --> 00:30:56,030
여기 또 다른 정말 재미있는 예가 있습니다.

497
00:30:56,030 --> 00:30:57,800
이걸 전에 보여줬는지 모르겠네요.

498
00:30:57,800 --> 00:31:01,060
하지만 이것은 제가 가장 좋아하는 시각적 착시 중

499
00:31:01,060 --> 00:31:03,620
하나로, 제가 답을 드리고 있습니다.

500
00:31:03,620 --> 00:31:07,030
체커보드 위의 두 정사각형 A와

501
00:31:07,030 --> 00:31:11,170
B를 보면, 같은 그레이스케일이나 밝기를

502
00:31:11,170 --> 00:31:14,838
가지고 있다고 믿기 정말 어렵습니다.

503
00:31:14,838 --> 00:31:16,880
그리고 아래를 보면, 아, 그렇군요.

504
00:31:16,880 --> 00:31:18,310
물론 그렇습니다.

505
00:31:18,310 --> 00:31:19,400
하지만 왜일까요?

506
00:31:19,400 --> 00:31:24,500
아래 그림이 눈앞에 있음에도 불구하고,

507
00:31:24,500 --> 00:31:28,820
위를 보면 여전히 착시가 발생합니다.

508
00:31:28,820 --> 00:31:29,680
왜일까요?

509
00:31:29,680 --> 00:31:33,676
진화가 우리를 일반적인 방식으로 세상을

510
00:31:33,676 --> 00:31:39,800
추론하거나 이해하도록 미리 연결해 놓았기 때문에,

511
00:31:39,800 --> 00:31:42,430
물체의 형태, 조명 원,

512
00:31:42,430 --> 00:31:48,380
그림자가 만들어지는 방식 등과 같은 일반적인 물리학으로,

513
00:31:48,380 --> 00:31:54,460
이것은 우리의 시각 발달에 깊이 뿌리내려 있습니다.

514
00:31:54,460 --> 00:31:59,480
그래서 우리는 다른 방식으로 보는 것이 어렵습니다.

515
00:31:59,480 --> 00:32:04,280
제가 말하고자 하는 것은 우리의 인간 시각 시스템에

516
00:32:04,280 --> 00:32:06,410
편향이 있다는 것입니다.

517
00:32:06,410 --> 00:32:10,360
편향은 진화적 구조에서 올 수 있고,

518
00:32:10,360 --> 00:32:14,860
사회적 경험에서 올 수 있으며,

519
00:32:14,860 --> 00:32:19,420
우리가 노출된 데이터에서 올 수 있습니다.

520
00:32:19,420 --> 00:32:22,980
하지만 이러한 편향 중 일부는 해로울 수 있습니다.

521
00:32:22,980 --> 00:32:26,280
편향이 발생하면, 특정 집단에

522
00:32:26,280 --> 00:32:29,350
불공정해질 수 있습니다.

523
00:32:29,350 --> 00:32:30,580
커뮤니티입니다.

524
00:32:30,580 --> 00:32:32,530
우리는 이것을 인식해야 합니다.

525
00:32:32,530 --> 00:32:35,520
몇 년 전, 얼굴 인식 알고리즘은

526
00:32:35,520 --> 00:32:39,540
좋지 않았고, 특정 피부색과 성별을 다른

527
00:32:39,540 --> 00:32:43,750
것보다 더 잘 인식하는 경향이 있었습니다.

528
00:32:43,750 --> 00:32:45,400
그리고 그것은 결과를 초래합니다.

529
00:32:45,400 --> 00:32:47,230
자율주행차에 대해 생각해 보세요.

530
00:32:47,230 --> 00:32:53,070
다른 많은 의료 사례에 대해서도 생각해 보세요.

531
00:32:53,070 --> 00:32:56,100
우리는 이에 대해 경계를 해야 합니다.

532
00:32:56,100 --> 00:33:03,210
AI 편향이 현재 사람들이 안고 있는 문제라고

533
00:33:03,210 --> 00:33:04,460
믿습니다.

534
00:33:04,460 --> 00:33:07,490
몇 년 전, 이 문제는 너무 새로워서

535
00:33:07,490 --> 00:33:10,440
많은 사람들이 주목조차 하지 않았습니다.

536
00:33:10,440 --> 00:33:13,070
하지만 2025년으로 넘어가면, 이

537
00:33:13,070 --> 00:33:14,880
문제를 해결했다고 말하는

538
00:33:14,880 --> 00:33:18,230
것은 아니지만, 많은 사람들이 이 문제에

539
00:33:18,230 --> 00:33:21,450
주목하고 있는 것을 보니 개인적으로 매우

540
00:33:21,450 --> 00:33:25,730
기쁩니다. 이는 학계뿐만 아니라 산업에서도 마찬가지입니다.

541
00:33:25,730 --> 00:33:28,860
그리고 또 다른 종류의 보이지 않는 것이 있습니다.

542
00:33:28,860 --> 00:33:30,810
이것은 흥미롭습니다.

543
00:33:30,810 --> 00:33:34,280
때때로 보이지 않는 것이 우리가 원하는 것일 수

544
00:33:34,280 --> 00:33:38,700
있습니다. 왜냐하면 개인 정보를 존중하고 싶기 때문입니다.

545
00:33:38,700 --> 00:33:45,350
그렇다면 사람들에게 보이는 것을 도와주면서도 여전히 원하지 않는 것을 보지
않도록 AI를 어떻게

546
00:33:45,350 --> 00:33:46,680
만들 수 있을까요?

547
00:33:46,680 --> 00:33:49,200
사람들이 원하지 않는 것을 보지 않도록 하는 것입니다.

548
00:33:49,200 --> 00:33:50,960
이것은 매우 깊은 문제입니다.

549
00:33:50,960 --> 00:33:54,180
기술적인 문제이자 인간적인 문제이기도 합니다.

550
00:33:54,180 --> 00:33:57,120
기술적인 관점에서 ML, 머신러닝

551
00:33:57,120 --> 00:34:01,560
프라이버시를 고려할 수 있는 방법은 많습니다.

552
00:34:01,560 --> 00:34:05,990
몇 년 전, 우리 연구실은 환자 방이나

553
00:34:05,990 --> 00:34:08,949
환자 집에서 의사가 더

554
00:34:08,949 --> 00:34:14,679
잘 볼 수 있도록 스마트 카메라를 사용하는 것에

555
00:34:14,679 --> 00:34:17,409
대한 논문을 작성했습니다.

556
00:34:17,409 --> 00:34:20,920
하지만 그곳에서도 얼굴이나

557
00:34:20,920 --> 00:34:27,050
전신 정보, 심지어 집과 같은 문제를 인식해야 합니다.

558
00:34:27,050 --> 00:34:30,230
그리고 이것은 잠재적 해결책 목록입니다.

559
00:34:30,230 --> 00:34:34,460
예를 들어, 블러링을 하거나 마스킹을

560
00:34:34,460 --> 00:34:37,130
하거나 차원 축소를 할

561
00:34:37,130 --> 00:34:41,750
수 있지만, 모든 데이터를 서버로 전송하지

562
00:34:41,750 --> 00:34:44,080
않도록 연합 학습과

563
00:34:44,080 --> 00:34:49,550
같은 다양한 접근 방식을 시도할 수도 있습니다.

564
00:34:49,550 --> 00:34:51,620
이 부분에 대해 길게 설명하지는 않겠지만,

565
00:34:51,620 --> 00:34:53,420
보여주고 싶은 작업이 하나 있습니다.

566
00:34:53,420 --> 00:34:56,330
이것은 제 작업도 아니지만, 이 작업이 정말 마음에 듭니다.

567
00:34:56,330 --> 00:35:02,560
이 작업은 사람들의 비디오를 촬영하고 사람들의 행동을

568
00:35:02,560 --> 00:35:06,460
인식하려고 하지만, 사람들의

569
00:35:06,460 --> 00:35:09,740
프라이버시를 존중하는 것입니다.

570
00:35:09,740 --> 00:35:10,760
어떻게 할 수 있을까요?

571
00:35:10,760 --> 00:35:15,310
예를 들어, 이 경우에는 이 아이가

572
00:35:15,310 --> 00:35:20,200
장면에서 움직이는 비디오를 촬영하고 싶습니다.

573
00:35:20,200 --> 00:35:22,610
이렇게 할 수 있는 방법이 있습니다.

574
00:35:22,610 --> 00:35:30,615
이것을 블러 처리하거나 초점을 흐리게 하거나 일부 작업을 수행하면, 네,
제공할

575
00:35:30,615 --> 00:35:31,810
수 있습니다.

576
00:35:31,810 --> 00:35:35,020
프라이버시를 보호할 수 있지만, 이 사람이 무엇을 하고 있는지

577
00:35:35,020 --> 00:35:37,700
알 수 없을 만큼 충분한 정보를 잃게 됩니다.

578
00:35:37,700 --> 00:35:40,030
많은 응용 프로그램에서 전체 목표는 이

579
00:35:40,030 --> 00:35:42,410
사람이 무엇을 하고 있는지를 아는 것입니다.

580
00:35:42,410 --> 00:35:48,680
그래서 이 특정 작업은 칼의 학생들이

581
00:35:48,680 --> 00:35:52,690
주도했으며, 하드웨어와

582
00:35:52,690 --> 00:35:58,360
소프트웨어 접근 방식을 결합하여 특정

583
00:35:58,360 --> 00:36:06,940
방식으로 시각 데이터를 필터링하는 렌즈를 제작했습니다.

584
00:36:06,940 --> 00:36:12,100
특히 상단 행을 보면, 렌즈가 카메라에

585
00:36:12,100 --> 00:36:14,910
캡처하는 것은 프라이버시를

586
00:36:14,910 --> 00:36:17,080
많이 보호합니다.

587
00:36:17,080 --> 00:36:18,960
사람의 얼굴이나

588
00:36:18,960 --> 00:36:21,460
몸을 볼 수 없습니다.

589
00:36:21,460 --> 00:36:24,750
하지만 소프트웨어와 연결된

590
00:36:24,750 --> 00:36:28,360
특별히 설계된 렌즈이기

591
00:36:28,360 --> 00:36:32,460
때문에, 움직임 정보나 인간

592
00:36:32,460 --> 00:36:35,880
활동 정보를 차단하는

593
00:36:35,880 --> 00:36:39,730
데 도움이 될 수 있습니다.

594
00:36:39,730 --> 00:36:42,100
그래서 이것은 정말 흥미로운 접근 방식입니다.

595
00:36:42,100 --> 00:36:45,400
하드웨어와 소프트웨어의 하이브리드입니다.

596
00:36:45,400 --> 00:36:48,570
사람들을 보호하기 위해 보고 싶지만

597
00:36:48,570 --> 00:36:51,790
너무 많이 보지 않기를 원하는

598
00:36:51,790 --> 00:36:54,180
중요한 응용 프로그램을

599
00:36:54,180 --> 00:36:55,570
목표로 합니다.

600
00:36:55,570 --> 00:36:57,910
그래서 제가 정말 좋아하는 작업입니다.

601
00:36:57,910 --> 00:37:00,847
그 작업의 정신이 정말 마음에 듭니다.

602
00:37:00,847 --> 00:37:02,040
좋습니다.

603
00:37:02,040 --> 00:37:06,110
강의의 이 부분에서, 저는 인간이 보지 못하는

604
00:37:06,110 --> 00:37:10,460
것을 보기 위해 AI를 구축하는 것에 대한 여러 가지

605
00:37:10,460 --> 00:37:12,510
고려 사항을 공유했습니다.

606
00:37:12,510 --> 00:37:16,580
때때로 우리는 AI를 통해 인간의 능력을 넘어서는

607
00:37:16,580 --> 00:37:19,350
세밀한 새 인식을 추진하고 있습니다.

608
00:37:19,350 --> 00:37:21,030
그것은 초인간적인 능력입니다.

609
00:37:21,030 --> 00:37:23,580
때때로 우리는 인간이 좋지 않다는 것을 압니다.

610
00:37:23,580 --> 00:37:26,820
편향이 있거나 주의 문제를 가지고 있습니다.

611
00:37:26,820 --> 00:37:29,250
그리고 우리는 AI를 사용하여 도움을 받고자 합니다.

612
00:37:29,250 --> 00:37:33,140
그리고 때때로 우리는 아무도 보지 않기를

613
00:37:33,140 --> 00:37:35,070
원하는 상황이 있습니다.

614
00:37:35,070 --> 00:37:37,790
그렇다면 프라이버시 문제를 위반하지

615
00:37:37,790 --> 00:37:41,580
않으면서 AI를 어떻게 계속 사용할 수 있을까요?

616
00:37:41,580 --> 00:37:45,840
AI는 매우 흥미롭고 강력한 도구라는 것을 알 수 있습니다.

617
00:37:45,840 --> 00:37:49,890
AI는 우리를 도울 뿐만 아니라 증폭시킬 수 있습니다.

618
00:37:49,890 --> 00:37:54,870
그리고 우리가 편향이 있거나 문제가 있다면, AI도 우리를 증폭시킬 수
있습니다.

619
00:37:54,870 --> 00:37:58,570
따라서 AI를 구축할 때 기술적 관점뿐만

620
00:37:58,570 --> 00:38:02,380
아니라 인간적 관점을 고려하고, 예측을

621
00:38:02,380 --> 00:38:05,200
연구하며 AI가 인간에게

622
00:38:05,200 --> 00:38:09,430
미치는 영향을 이해하고 인간의 가치를 존중하도록

623
00:38:09,430 --> 00:38:12,980
안내하는 것이 매우 중요합니다.

624
00:38:12,980 --> 00:38:17,600
그래서 이것이 두 번째 핵심 메시지입니다.

625
00:38:17,600 --> 00:38:21,100
그리고 다시 말하지만, 여러 협력자와

626
00:38:21,100 --> 00:38:23,800
학생들이 이 작업에 참여했습니다.

627
00:38:23,800 --> 00:38:24,670
좋습니다.

628
00:38:24,670 --> 00:38:27,400
이제 AI를 구축하여 인간이 보고

629
00:38:27,400 --> 00:38:29,480
싶어하는 것을 보도록 해봅시다.

630
00:38:29,480 --> 00:38:32,660
사실, 우리는 보는 것을 넘어설 것입니다.

631
00:38:32,660 --> 00:38:35,630
우리는 보는 것과 하는 것을 연결할 것입니다.

632
00:38:35,630 --> 00:38:42,260
오늘날 AI에 대한 사회적 불안에 대해 생각해보면,

633
00:38:42,260 --> 00:38:46,450
가장 큰 불안 중 하나는 노동입니다.

634
00:38:46,450 --> 00:38:51,170
많은 헤드라인 뉴스는 노동이 위협받고 있다고 말할 것입니다.

635
00:38:51,170 --> 00:38:54,370
로봇이 일자리를 차지하고 있습니다.

636
00:38:54,370 --> 00:38:58,080
진실은 상황이 복잡하다는 것입니다.

637
00:38:58,080 --> 00:39:01,690
일자리 변화 부정을 하는 것은 잘못입니다.

638
00:39:01,690 --> 00:39:05,040
인류 역사에서 모든 기술적 변화는 노동

639
00:39:05,040 --> 00:39:08,700
시장의 변화를 초래했으며, 그 중 일부는 매우

640
00:39:08,700 --> 00:39:10,030
고통스러웠습니다.

641
00:39:10,030 --> 00:39:15,780
그 중 일부는 심지어 내전과 전쟁으로 이어질 수 있습니다.

642
00:39:15,780 --> 00:39:20,290
하지만 그 변화는 때때로 불가피합니다.

643
00:39:20,290 --> 00:39:24,610
그리고 작은 탈선입니다.

644
00:39:24,610 --> 00:39:27,690
우리가 듣고 있는 많은 노동

645
00:39:27,690 --> 00:39:31,680
위협 담론은 육체 노동자에 대한 것입니다.

646
00:39:31,680 --> 00:39:34,360
하지만 오늘날, 지난

647
00:39:34,360 --> 00:39:39,330
2년 동안, GenAI의 영향은 사무직에서

648
00:39:39,330 --> 00:39:42,730
특히 소프트웨어

649
00:39:42,730 --> 00:39:49,240
엔지니어링과 분석 작업에 크게 영향을 미치고 있습니다.

650
00:39:49,240 --> 00:39:53,020
그래서 분명히 노동 변화가 있습니다.

651
00:39:53,020 --> 00:39:55,020
하지만 그와 동시에

652
00:39:55,020 --> 00:39:59,320
AI가 도움이 될 수 있다는 것도 인식해야 합니다.

653
00:39:59,320 --> 00:40:03,360
실제로 많은 상황에서 인간 노동력이

654
00:40:03,360 --> 00:40:08,100
부족합니다, 특히 노인 돌봄과 건강

655
00:40:08,100 --> 00:40:08,920
분야에서.

656
00:40:08,920 --> 00:40:12,690
우선, 현대 의학이 발전함에 따라

657
00:40:12,690 --> 00:40:15,670
인간의 기대 수명이 증가합니다.

658
00:40:15,670 --> 00:40:21,790
그리고 이는 불가피하게 사회를 더 오래 사는 방향으로 밀어냅니다.

659
00:40:21,790 --> 00:40:23,230
그것은 좋은 일입니다.

660
00:40:23,230 --> 00:40:28,090
하지만 그와 동시에 노동자가 부족합니다.

661
00:40:28,090 --> 00:40:29,760
젊은이들이 일해야 합니다.

662
00:40:29,760 --> 00:40:33,490
그것이 이 사회를 활기차게 만드는 방법입니다.

663
00:40:33,490 --> 00:40:34,750
경제를 활기차게 합니다.

664
00:40:34,750 --> 00:40:37,170
하지만 누가 우리의 노인들을 돌보고 있습니까?

665
00:40:37,170 --> 00:40:40,230
우리의 만성 질환자를 돌보는 사람은 누구인가요?

666
00:40:40,230 --> 00:40:45,090
미국의 병원에서도 간호사를 포함한

667
00:40:45,090 --> 00:40:49,110
의료 종사자의 이탈이 심각해

668
00:40:49,110 --> 00:40:55,080
환자를 도와줄 손, 귀, 눈이 부족합니다.

669
00:40:55,080 --> 00:40:59,280
따라서 이 단어 '대체'에 대해 생각하는 대신,

670
00:40:59,280 --> 00:41:03,420
AI가 보완하는 방식으로 생각할 수 있습니다.

671
00:41:03,420 --> 00:41:07,140
수술실 예시에서 그 점을 엿볼 수 있었습니다.

672
00:41:07,140 --> 00:41:12,560
실제로 건강 분야에는 눈이 부족한

673
00:41:12,560 --> 00:41:15,390
공간이 많습니다.

674
00:41:15,390 --> 00:41:19,410
이것이 제가 건강의 어두운 공간이라고 부르는 것입니다.

675
00:41:19,410 --> 00:41:24,920
수술실에서 환자실, 제약, 가정 등으로

676
00:41:24,920 --> 00:41:26,250
이어집니다.

677
00:41:26,250 --> 00:41:29,010
그렇다면 AI가 어떻게 도움을 줄 수 있을까요?

678
00:41:29,010 --> 00:41:31,520
이 일의 많은 부분을

679
00:41:31,520 --> 00:41:33,750
이산이 이끌고 있습니다.

680
00:41:33,750 --> 00:41:37,070
또한, 우리는 스마트

681
00:41:37,070 --> 00:41:40,830
센서를 머신러닝 알고리즘과

682
00:41:40,830 --> 00:41:45,620
결합하여 건강 상황에서 중요한

683
00:41:45,620 --> 00:41:52,780
통찰을 얻고, 이를 통해 환자나 가족, 의사에게

684
00:41:52,780 --> 00:41:57,790
제때 경고할 수 있는 환경 지능

685
00:41:57,790 --> 00:42:01,970
문제를 살펴보고 있습니다.

686
00:42:01,970 --> 00:42:05,620
그리고 이와 관련된 더 자세한 논문은 몇 년 전에

687
00:42:05,620 --> 00:42:07,550
발표한 논문에 있습니다.

688
00:42:07,550 --> 00:42:10,340
몇 가지 예를 들어보겠습니다.

689
00:42:10,340 --> 00:42:13,360
첫 번째 예는 COVID 이전에

690
00:42:13,360 --> 00:42:16,360
시작된 손 위생 프로젝트입니다.

691
00:42:16,360 --> 00:42:21,730
손 위생은 병원 감염을 낮추는

692
00:42:21,730 --> 00:42:25,030
데 정말 중요합니다.

693
00:42:25,030 --> 00:42:28,810
병원에서 발생하는 감염은

694
00:42:28,810 --> 00:42:32,110
미국 환자의 사망 원인

695
00:42:32,110 --> 00:42:34,490
중 하나입니다.

696
00:42:34,490 --> 00:42:39,520
전국적으로 자동차 사고보다 연간 세 배 더 많은

697
00:42:39,520 --> 00:42:43,850
사람을 죽이고, 통제가 매우 어렵습니다.

698
00:42:43,850 --> 00:42:46,510
이 세균의 대부분은 환자실에서 환자실로

699
00:42:46,510 --> 00:42:47,560
전파됩니다.

700
00:42:47,560 --> 00:42:50,630
그리고 그들은 함께 양조됩니다.

701
00:42:50,630 --> 00:42:52,690
그럼 우리는 무엇을 해야 할까요?

702
00:42:52,690 --> 00:42:55,390
병원은 인간 감사인을 사용하려고

703
00:42:55,390 --> 00:42:58,420
하지만, 우리는 간호사조차

704
00:42:58,420 --> 00:43:00,610
부족하다고 이야기했습니다.

705
00:43:00,610 --> 00:43:04,030
그리고 그들을 충분히 고용할 수 없습니다.

706
00:43:04,030 --> 00:43:05,620
인간의 피로가 있습니다.

707
00:43:05,620 --> 00:43:07,930
우리는 인간의 주의 문제에 대해 이야기합니다.

708
00:43:07,930 --> 00:43:12,160
그래서 이것은 그리 바람직한 해결책이 아닙니다.

709
00:43:12,160 --> 00:43:16,150
RFID와 같은 기술적 해결책이 있었고, 배지를

710
00:43:16,150 --> 00:43:17,170
부착했습니다.

711
00:43:17,170 --> 00:43:19,470
배지나 배지를 착용한

712
00:43:19,470 --> 00:43:25,170
사람이 싱크대나 손 위생 손 세정제 분배기에 가까이 있으면,

713
00:43:25,170 --> 00:43:28,210
그 사람이 손을 씻고 있을

714
00:43:28,210 --> 00:43:31,600
가능성이 높다는 힌트를 줍니다.

715
00:43:31,600 --> 00:43:33,340
하지만 그것은 매우 비특정적입니다.

716
00:43:33,340 --> 00:43:34,440
보장할 수 없습니다.

717
00:43:34,440 --> 00:43:36,790
병실은 꽤 작고, 복도도 작으며,

718
00:43:36,790 --> 00:43:40,650
단순히 무언가 옆에 서 있다고 해서 그것을 하고 있다는

719
00:43:40,650 --> 00:43:42,130
의미는 아닙니다.

720
00:43:42,130 --> 00:43:45,150
몇 년 전, 우리는

721
00:43:45,150 --> 00:43:50,150
깊이 정보만 수집하여 개인 정보를 보호하는

722
00:43:50,150 --> 00:43:54,590
스마트 센서를 설치하는 프로젝트를

723
00:43:54,590 --> 00:43:56,880
진행했습니다.

724
00:43:56,880 --> 00:44:01,890
그리고 우리는 행동을 분류하기 위해 컴퓨터 비전 알고리즘을 사용했습니다.

725
00:44:01,890 --> 00:44:04,770
그 사람이 손을 씻고 있는지 아닌지?

726
00:44:04,770 --> 00:44:08,510
결과적으로, 알고리즘 출력과

727
00:44:08,510 --> 00:44:17,240
인간 출력 또는 인간 탐지 결과를 비교하면 알고리즘이 인간보다

728
00:44:17,240 --> 00:44:21,110
훨씬 더 우수하고 일관성이 있음을

729
00:44:21,110 --> 00:44:23,780
알 수 있습니다.

730
00:44:23,780 --> 00:44:29,720
AI만큼 좋으려면 거의 같은 비디오를 네 명의 인간에게

731
00:44:29,720 --> 00:44:35,520
보여줘야 하며, 이는 그리 현실적이지 않습니다.

732
00:44:35,520 --> 00:44:40,050
한 사람일 경우 탐지가 얼마나 드문지를 알 수 있으며, 이는

733
00:44:40,050 --> 00:44:41,070
좋지 않습니다.

734
00:44:41,070 --> 00:44:43,110
그래서 이것은 하나의 응용 프로그램입니다.

735
00:44:43,110 --> 00:44:48,620
우리가 작업한 또 다른 응용 프로그램은 ICU입니다.

736
00:44:48,620 --> 00:44:52,110
ICU는 환자들이 생사를 다투는 곳입니다.

737
00:44:52,110 --> 00:44:59,070
ICU는 또한 미국 GDP의 1%가 소비되는 곳입니다.

738
00:44:59,070 --> 00:45:04,700
따라서 ICU를 가능한 한 안전하고 효과적으로 만드는 것이

739
00:45:04,700 --> 00:45:06,300
최우선 과제입니다.

740
00:45:06,300 --> 00:45:10,250
ICU의 목표 중 하나는 환자들이

741
00:45:10,250 --> 00:45:14,390
안전하게 ICU를 나가고 단계적 치료실로

742
00:45:14,390 --> 00:45:17,490
가거나 집으로 돌아가는 것입니다.

743
00:45:17,490 --> 00:45:23,360
ICU에서 사람들이 배운 가장 중요한 것 중 하나는 환자들이

744
00:45:23,360 --> 00:45:26,900
움직일 수 있도록 돕는 것입니다.

745
00:45:26,900 --> 00:45:30,180
우리가 이동이라고 부르는 적절한 움직임은

746
00:45:30,180 --> 00:45:32,400
회복에 실제로 중요합니다.

747
00:45:32,400 --> 00:45:34,770
하지만 이는 매우 위험한 상황입니다.

748
00:45:34,770 --> 00:45:36,690
간호사들이 도와야 합니다.

749
00:45:36,690 --> 00:45:40,980
의사들이 지시를 내려야 하고, 적절하게

750
00:45:40,980 --> 00:45:45,390
움직여야 하며, 정해진 시간에 이루어져야 합니다.

751
00:45:45,390 --> 00:45:47,560
그리고 움직임을 평가해야 하며,

752
00:45:47,560 --> 00:45:49,790
이 모든 것이 쉽지 않죠?

753
00:45:49,790 --> 00:45:54,220
그래서 우리는 스탠포드와 유타의 인터마운틴 병원과 협력하여 ICU

754
00:45:54,220 --> 00:45:57,730
유닛에 스마트 센서를 설치하고 의사들이 환자

755
00:45:57,730 --> 00:46:02,710
움직임을 모니터링하도록 도왔습니다. 이 경우에는 침대에서 일어나는 것,

756
00:46:02,710 --> 00:46:05,925
침대에 들어가는 것, 의자에서 일어나는 것,

757
00:46:05,925 --> 00:46:08,300
의자에 앉는 것 등 네 가지 종류의

758
00:46:08,300 --> 00:46:09,320
움직임입니다.

759
00:46:09,320 --> 00:46:12,350
이것들은 ICU 환자에게 매우 중요합니다.

760
00:46:12,350 --> 00:46:15,080
우리에게는 당연한 일이지만,

761
00:46:15,080 --> 00:46:18,440
이는 정말로 중요합니다.

762
00:46:18,440 --> 00:46:23,560
그리고 저는 의사들에게 특히 인력 부족 상황에서

763
00:46:23,560 --> 00:46:28,510
매우 유용한 탐지 및 예측을 도울 수 있다는

764
00:46:28,510 --> 00:46:30,610
것을 알 수 있습니다.

765
00:46:30,610 --> 00:46:34,250
마지막으로, 노인 돌봄의 예가 있습니다.

766
00:46:34,250 --> 00:46:38,510
이는 여러 가지 이유로 매우 중요합니다.

767
00:46:38,510 --> 00:46:42,220
노인들은 독립적이고 건강하게 집에서

768
00:46:42,220 --> 00:46:43,600
살기를 원합니다.

769
00:46:43,600 --> 00:46:47,820
COVID 초기에 노인들

770
00:46:47,820 --> 00:46:54,250
사이에서 많은 사망자가 발생했던 것을 기억합니다.

771
00:46:54,250 --> 00:46:59,700
이는 병원이 과부하되고 과도하게 부담을 받는 것과 관련이

772
00:46:59,700 --> 00:47:04,500
많습니다. 따라서 노인들을 안전하고 건강하게 집에 두는

773
00:47:04,500 --> 00:47:06,730
것이 정말로 중요합니다.

774
00:47:06,730 --> 00:47:10,410
스마트 센서를 사용하여 감염의 조기 탐지를

775
00:47:10,410 --> 00:47:12,900
도울 수 있으며, 특히 열화상

776
00:47:12,900 --> 00:47:16,390
카메라나 ICU에서 이야기한 이동성을

777
00:47:16,390 --> 00:47:19,080
사용하여, 여기서도 비슷하게

778
00:47:19,080 --> 00:47:22,050
수면 패턴이나 식이 패턴을 이해할

779
00:47:22,050 --> 00:47:23,320
수 있습니다.

780
00:47:23,320 --> 00:47:26,370
이 모든 것은 AI와 스마트

781
00:47:26,370 --> 00:47:29,700
센서에 의해 가능한 영역입니다.

782
00:47:29,700 --> 00:47:33,990
그리고 마지막으로, 스마트 센서 이후에도 여전히

783
00:47:33,990 --> 00:47:36,700
인력 부족이 있다면 어떻게 될까요?

784
00:47:36,700 --> 00:47:40,740
스마트 센서의 특징은 정보

785
00:47:40,740 --> 00:47:46,010
수집 시스템이지만, 환자를 돌리거나 노인에게

786
00:47:46,010 --> 00:47:51,450
물과 약을 가져다 줄 수는 없습니다.

787
00:47:51,450 --> 00:47:55,730
그래서 이것은 우리를 마지막

788
00:47:55,730 --> 00:47:59,540
기술 주제인 구현된 AI, 즉

789
00:47:59,540 --> 00:48:03,960
로봇 공학으로 이끌어 줍니다.

790
00:48:03,960 --> 00:48:07,790
여기서 저는 매우 흥미롭게 생각하는데, 이는

791
00:48:07,790 --> 00:48:11,850
인식과 행동 사이의 고리를 닫기 때문입니다.

792
00:48:11,850 --> 00:48:18,350
진화의 캄브리아 폭발을 생각해보면, 눈이 생기면서

793
00:48:18,350 --> 00:48:22,680
동물들이 움직이기 시작합니다.

794
00:48:22,680 --> 00:48:26,420
따라서 로봇 공학 분야는 보는 것과 행동하는 것

795
00:48:26,420 --> 00:48:29,310
사이의 고리를 닫을 수 있는 곳입니다.

796
00:48:29,310 --> 00:48:31,140
하지만 쉽지 않죠?

797
00:48:31,140 --> 00:48:34,730
로봇은 우리가 매우 흥미롭게 생각하지만

798
00:48:34,730 --> 00:48:36,360
여전히 매우 느립니다.

799
00:48:36,360 --> 00:48:38,850
그들은 매우 서투릅니다.

800
00:48:38,850 --> 00:48:45,730
일반화 가능한 상황에 적응하기가 매우 어렵습니다.

801
00:48:45,730 --> 00:48:50,170
오늘날 로봇 연구에서 우리는 많은

802
00:48:50,170 --> 00:48:55,840
진전을 이루었고, 스탠포드는 확실히 로봇 학습의

803
00:48:55,840 --> 00:48:58,520
중심지 중 하나입니다.

804
00:48:58,520 --> 00:49:03,860
하지만 여전히 대부분의 작업은 설정에

805
00:49:03,860 --> 00:49:07,240
제약이 있으며, 우리의 짧은

806
00:49:07,240 --> 00:49:15,070
수평 작업인 집기와 놓기 작업은 일화적인 설정과 표준

807
00:49:15,070 --> 00:49:18,260
벤치마크의 부족이 있습니다.

808
00:49:18,260 --> 00:49:22,870
그래서 우리 연구실의 몇 가지 작업을 공유하겠습니다.

809
00:49:22,870 --> 00:49:25,540
몇 년 전, 우리는 로봇을

810
00:49:25,540 --> 00:49:29,120
야생으로 데려가는 방법을 연구했습니다.

811
00:49:29,120 --> 00:49:35,270
우리가 작업 세트를 미리 지정해야 한다면, 그것은 불만족스럽습니다.

812
00:49:35,270 --> 00:49:37,970
반면에, 오늘날의 LLM을 보면, 완전히

813
00:49:37,970 --> 00:49:39,560
자유롭게 작동하고 있습니다.

814
00:49:39,560 --> 00:49:41,090
무엇이든 이야기할 수 있습니다.

815
00:49:41,090 --> 00:49:44,320
그래서 제 학생은 배우고 싶어하고 몇몇 학생은 이

816
00:49:44,320 --> 00:49:45,950
격차를 줄이고 싶어합니다.

817
00:49:45,950 --> 00:49:50,410
이 아이디어는 로봇에게 미리

818
00:49:50,410 --> 00:49:55,120
훈련된 닫힌 세계에서 모든 것을

819
00:49:55,120 --> 00:50:02,200
훈련하지 않고도 열린 지시를 어떻게 줄 수

820
00:50:02,200 --> 00:50:03,680
있는가입니다.

821
00:50:03,680 --> 00:50:08,650
예를 들어, 당신의 훈련 세트가 문을 여는 것이라고 합시다.

822
00:50:08,650 --> 00:50:11,720
자연 상태에서는 그런 문들이 있습니다.

823
00:50:11,720 --> 00:50:17,830
그 문제에서 어떻게 진전을 이룰 수 있을까요?

824
00:50:17,830 --> 00:50:22,760
목표는 자연 환경에서 일반화하는 것입니다.

825
00:50:22,760 --> 00:50:31,130
여기 결과 또는 전체 알고리즘이 있습니다.

826
00:50:31,130 --> 00:50:34,330
이게 그렇게 버그가 많은지 모르겠지만, 어쨌든 상관없습니다.

827
00:50:34,330 --> 00:50:38,970
당신이 말하는 것은 이 로봇 팔에게 꽃을

828
00:50:38,970 --> 00:50:45,240
쓰러뜨리지 않도록 경로를 계획하여 서랍을 열라고

829
00:50:45,240 --> 00:50:46,990
지시하는 것입니다.

830
00:50:46,990 --> 00:50:51,520
이 모든 지시는 사전 훈련되지 않았습니다.

831
00:50:51,520 --> 00:50:57,840
우리가 하는 것은 최신 LLM과 시각 언어

832
00:50:57,840 --> 00:51:02,320
모델의 발전을 차용하는 것입니다.

833
00:51:02,320 --> 00:51:10,020
아이디어는 LLM과 VLM을 사용하여 지시 세트를

834
00:51:10,020 --> 00:51:11,980
제공하는 것입니다.

835
00:51:11,980 --> 00:51:14,250
그런 다음 시각 언어 모델을

836
00:51:14,250 --> 00:51:17,680
사용하여 환경을 인식하거나 이해하는 데 도움을 줍니다.

837
00:51:17,680 --> 00:51:21,480
그 후 이를 모션 계획 맵으로 변환하여

838
00:51:21,480 --> 00:51:24,790
로봇 팔이 실행할 수 있도록 합니다.

839
00:51:24,790 --> 00:51:29,290
LLM과 VLM을 사용하기 때문에

840
00:51:29,290 --> 00:51:36,110
로봇을 폐쇄된 세계에서 훈련하는 문제를 없애고 더

841
00:51:36,110 --> 00:51:39,890
일반화된 자연 환경으로 가져옵니다.

842
00:51:39,890 --> 00:51:44,510
세부 사항은 열린 서랍에 대한 지시가 들어오는

843
00:51:44,510 --> 00:51:45,690
것입니다.

844
00:51:45,690 --> 00:51:51,240
LLM은 이를 문자 그대로 코드로 변환합니다.

845
00:51:51,240 --> 00:51:55,220
그런 다음 '서랍'이나 '손잡이'와

846
00:51:55,220 --> 00:52:02,700
같은 이러한 지시 때문에 이 정보를 VLM 모델에 보냅니다.

847
00:52:02,700 --> 00:52:07,260
그 모델은 장면에서 서랍과 손잡이를 감지합니다.

848
00:52:07,260 --> 00:52:13,700
그로 인해 정보를 업데이트하고 모션

849
00:52:13,700 --> 00:52:16,740
맵을 업데이트합니다.

850
00:52:16,740 --> 00:52:19,730
이는 로봇 팔이 집중해야 할 곳과

851
00:52:19,730 --> 00:52:22,020
집중하지 말아야 할 곳을

852
00:52:22,020 --> 00:52:25,970
보여주기 위해 히트 맵으로 제시됩니다. 그런

853
00:52:25,970 --> 00:52:30,030
다음 또 다른 지시를 주지만 꽃병에 주의하세요.

854
00:52:30,030 --> 00:52:34,000
다시 말해, LLM과 같은 과정을 거쳐 코드를

855
00:52:34,000 --> 00:52:39,650
작성하거나 생성하고, 이를 VLM 모델을 통해 전송합니다.

856
00:52:39,650 --> 00:52:45,130
VLM 모델은 객체를 감지한 후, 모션 계획 맵을

857
00:52:45,130 --> 00:52:45,920
업데이트합니다.

858
00:52:45,920 --> 00:52:49,040
이 경우, 피해야 할 것이므로

859
00:52:49,040 --> 00:52:51,050
긍정이 아닌 부정입니다.

860
00:52:51,050 --> 00:52:53,840
그리고 이전 맵과 결합하여 피해야

861
00:52:53,840 --> 00:52:57,950
할 곳과 가야 할 곳의 열지도를 얻습니다.

862
00:52:57,950 --> 00:53:04,140
결국 우리가 하는 것은 모션 계획 맵을 위해 이 작업을 수행하는

863
00:53:04,140 --> 00:53:04,640
것입니다.

864
00:53:04,640 --> 00:53:08,230
우리는 그리퍼의 회전, 속도에 대해 이

865
00:53:08,230 --> 00:53:11,650
작업을 수행하며, 이것이 결과입니다. 사실, 이 결과를

866
00:53:11,650 --> 00:53:13,360
보여드리겠습니다.

867
00:53:13,360 --> 00:53:18,560
이것은 로봇의 실제 결과입니다.

868
00:53:18,560 --> 00:53:21,675
그리고 우리는 여러 가지 다른 작업에 대해 이 작업을 수행합니다, 맞죠?

869
00:53:21,675 --> 00:53:26,120
우리는 관절이 있는 물체 조작을 할 수 있습니다.

870
00:53:26,120 --> 00:53:27,345
여기에는

871
00:53:30,670 --> 00:53:33,640
다양한 예가 있습니다.

872
00:53:33,640 --> 00:53:37,470
냅킨이나 바닥 청소.

873
00:53:37,470 --> 00:53:38,530
이게 뭐죠?

874
00:53:38,530 --> 00:53:44,670
토스트를 가져오고, 테이블을 차리고, 온라인 방해

875
00:53:44,670 --> 00:53:48,190
요소를 처리하는 것입니다.

876
00:53:48,190 --> 00:53:50,710
그래서 이것은 하나의 작업입니다.

877
00:53:50,710 --> 00:53:54,810
제가 빠르게 보여드리고 싶은 또 다른

878
00:53:54,810 --> 00:54:03,420
작업은 전반적인 로봇 연구가 여전히 좋은 벤치마크가 부족하다는 것입니다.

879
00:54:03,420 --> 00:54:10,240
실험실에서 여전히 실험 중이지만, 실제 세계는 훨씬 더

880
00:54:10,240 --> 00:54:14,400
복잡하고 불확실하며, 큰 변동성을 가지고

881
00:54:14,400 --> 00:54:17,140
있고, 매우 상호작용적이며

882
00:54:17,140 --> 00:54:20,400
사회적이며, 많은

883
00:54:20,400 --> 00:54:23,020
멀티태스킹 작업이 있습니다.

884
00:54:23,020 --> 00:54:26,850
그리고 우리는 자연어와 컴퓨터 비전 모두가

885
00:54:26,850 --> 00:54:33,060
훈련 및 벤치마크를 위한 중요한 대규모 데이터 세트를 설정함으로써 많은

886
00:54:33,060 --> 00:54:36,460
혜택을 받았다는 것을 알고 있습니다.

887
00:54:36,460 --> 00:54:40,680
그래서 우리 연구실에서는 생태

888
00:54:40,680 --> 00:54:47,250
로봇 학습 환경을 구축하고 다양한 활동 세트에

889
00:54:47,250 --> 00:54:52,590
대해 벤치마크하도록 연구자들을 장려하는

890
00:54:52,590 --> 00:54:57,190
프로젝트에 대해 작업해왔습니다.

891
00:54:57,190 --> 00:55:00,280
그리고 이것이 일상

892
00:55:00,280 --> 00:55:03,330
가정 활동을 위한

893
00:55:03,330 --> 00:55:06,330
벤치마크인 행동

894
00:55:06,330 --> 00:55:08,130
벤치마크입니다.

895
00:55:08,130 --> 00:55:11,160
이제, 이 강의가 인간의 가치와 관련이

896
00:55:11,160 --> 00:55:15,240
많기 때문에 질문이 있습니다. 로봇이 어떤 작업을

897
00:55:15,240 --> 00:55:17,830
해야 하는지 누가 결정할까요?

898
00:55:17,830 --> 00:55:19,830
로봇 공학을 연구하는 모든

899
00:55:19,830 --> 00:55:22,600
대학원생들은 두 가지 작업을 원합니다.

900
00:55:22,600 --> 00:55:25,440
하나는 세탁, 다른 하나는 식기 세척기입니다.

901
00:55:25,440 --> 00:55:31,790
좋습니다, 하지만 대학원 이후에는 로봇이 우리를 위해 어떤

902
00:55:31,790 --> 00:55:34,200
작업을 해야 할까요?

903
00:55:34,200 --> 00:55:38,760
그래서 우리가 이 작업 목록을 만드는 대신, 우리는

904
00:55:38,760 --> 00:55:44,390
실제로 로봇에게-- 아니, 인간에게-- [웃음] 로봇이 당신을 도와주길

905
00:55:44,390 --> 00:55:46,000
원하는 것이

906
00:55:46,000 --> 00:55:47,660
무엇인지 묻는 인간 중심의

907
00:55:47,660 --> 00:55:49,920
설문조사를 실시했습니다.

908
00:55:49,920 --> 00:55:52,100
이것을 테스트해 보겠습니다.

909
00:55:52,100 --> 00:55:57,320
로봇이 주방 바닥 청소를 도와주길 원하십니까?

910
00:55:57,320 --> 00:55:58,700
예 또는 아니오로 대답해 주세요.

911
00:55:58,700 --> 00:56:00,320
좋습니다, 좋습니다.

912
00:56:00,320 --> 00:56:03,440
일반 사람들은 예라고 말할 것입니다.

913
00:56:03,440 --> 00:56:05,600
눈 치우기요?

914
00:56:05,600 --> 00:56:06,440
좋습니다.

915
00:56:06,440 --> 00:56:07,555
세탁물 개기요?

916
00:56:07,555 --> 00:56:08,360
네.

917
00:56:08,360 --> 00:56:09,950
좋아요.

918
00:56:09,950 --> 00:56:11,460
아침 식사 준비 중인가요?

919
00:56:11,460 --> 00:56:11,960
아니요.

920
00:56:11,960 --> 00:56:12,710
네.

921
00:56:12,710 --> 00:56:16,490
보세요, 우리는 혼합된 대답을 받고 있죠?

922
00:56:16,490 --> 00:56:18,790
크리스마스 선물 열기에는 어때요?

923
00:56:18,790 --> 00:56:19,490
아니요.

924
00:56:19,490 --> 00:56:21,150
정확히 그렇습니다.

925
00:56:21,150 --> 00:56:22,600
사람들은 다릅니다.

926
00:56:22,600 --> 00:56:25,320
사실 로봇이 이걸 꽤 잘할 수

927
00:56:25,320 --> 00:56:28,970
있다고 생각하지만, 우리는 원하지 않습니다.

928
00:56:28,970 --> 00:56:31,400
우리가 요청하는 작업 중 하나는 결혼 반지 구매입니다.

929
00:56:31,400 --> 00:56:33,220
상상할 수 있나요?

930
00:56:33,220 --> 00:56:37,330
그래서 우리가 한 것은 실제로 인간의 선호를

931
00:56:37,330 --> 00:56:39,380
존중하고 싶었습니다.

932
00:56:39,380 --> 00:56:42,970
그래서 우리는 미국과 유럽의

933
00:56:42,970 --> 00:56:48,410
노동 사무소에서 여러 정부 설문조사를

934
00:56:48,410 --> 00:56:55,190
모아 일상 활동 작업 수천 개를 정리했습니다.

935
00:56:55,190 --> 00:56:59,270
그리고 나서 우리는 온라인에서 사람들을 찾으러 갔습니다.

936
00:56:59,270 --> 00:57:02,030
우리는 가능한 한 다양해지기를

937
00:57:02,030 --> 00:57:05,690
원하지만, 개선할 여지가 있다고 생각합니다.

938
00:57:05,690 --> 00:57:08,450
하지만 우리는 1,400명을 찾았습니다.

939
00:57:08,450 --> 00:57:12,700
그리고 이 작업에 답하고 로봇이 어떤 작업을 도와주기를

940
00:57:12,700 --> 00:57:16,790
원하는지 말해주면, 우리는 그것을 순위 매깁니다.

941
00:57:16,790 --> 00:57:20,830
그리고 대학원생들처럼 사람들은 로봇이

942
00:57:20,830 --> 00:57:25,610
청소, 많은 청소, 화장실 청소, 바닥 청소를

943
00:57:25,610 --> 00:57:30,150
도와주기를 원하지만, 로봇이 스쿼시를 대신 치거나

944
00:57:30,150 --> 00:57:34,390
결혼 반지를 사거나 아기 시리얼을 섞는

945
00:57:34,390 --> 00:57:36,550
것을 원하지는 않습니다.

946
00:57:36,550 --> 00:57:38,430
우리 인간에게 감정적으로나

947
00:57:38,430 --> 00:57:42,370
사회적으로나 중요한 많은 작업이 있습니다.

948
00:57:42,370 --> 00:57:51,810
그래서 우리의 목표는 먼저 로봇을 훈련시키고 싶은 1,000개의 작업을
결정할 수 있는

949
00:57:51,810 --> 00:57:57,030
원칙적인 방법을 갖는 것이며, 이는 인간이 도움을

950
00:57:57,030 --> 00:57:59,950
받고 싶어하는 작업입니다.

951
00:57:59,950 --> 00:58:05,010
그 점을 염두에 두고, 우리는 실제로 가상 환경을

952
00:58:05,010 --> 00:58:07,060
구축해야 합니다.

953
00:58:07,060 --> 00:58:15,900
그래서 우리는 레스토랑, 아파트, 식료품점, 사무실 등 50개의

954
00:58:15,900 --> 00:58:19,410
다양한 실제 환경에서

955
00:58:19,410 --> 00:58:24,820
3D 장면을 스캔하거나 획득했습니다.

956
00:58:24,820 --> 00:58:29,980
그리고 이 숫자는 실제로 구식이지만, 우리는 10,

957
00:58:29,980 --> 00:58:34,000
000개 이상의 객체 자산, 많은 속성을

958
00:58:34,000 --> 00:58:37,930
가진 3D 자산을 획득했습니다. 이는

959
00:58:37,930 --> 00:58:41,160
관절, 변형 가능성 등 모든

960
00:58:41,160 --> 00:58:43,030
속성을 포함합니다.

961
00:58:43,030 --> 00:58:47,620
그리고 우리는 시뮬레이션 환경을 구축해야 합니다.

962
00:58:47,620 --> 00:58:50,350
많은 사람들이 시뮬레이션 환경을 구축했습니다.

963
00:58:50,350 --> 00:58:51,730
제가 그냥 빨리 진행하겠습니다.

964
00:58:51,730 --> 00:58:54,810
하지만 우리의 특정 시뮬레이션 환경은 NVIDIA의

965
00:58:54,810 --> 00:58:58,090
Omniverse 그룹과의 협업이었습니다.

966
00:58:58,090 --> 00:59:03,010
우리는 물리적으로, 지각적으로, 그리고

967
00:59:03,010 --> 00:59:06,390
상호작용적으로 고품질의 시뮬레이션

968
00:59:06,390 --> 00:59:11,700
환경을 구축하는 것을 목표로 했으며, 이는 특히

969
00:59:11,700 --> 00:59:14,340
열 투명성, 변형

970
00:59:14,340 --> 00:59:18,550
가능성과 같은 물리적 효과를 고려합니다.

971
00:59:18,550 --> 00:59:22,830
우리는 또한 인간 사용자 연구를 통해 지각적

972
00:59:22,830 --> 00:59:27,740
현실성 측면에서 우리의 행동 환경을 다른

973
00:59:27,740 --> 00:59:29,730
환경과 비교했습니다.

974
00:59:29,730 --> 00:59:32,840
여기 천이나 액체와

975
00:59:32,840 --> 00:59:39,270
같은 물리적 상호작용의 몇 가지 예가 있습니다.

976
00:59:39,270 --> 00:59:43,350
이 작업에는 많은 미묘한 요소가 포함되어 있습니다.

977
00:59:43,350 --> 00:59:48,530
그리고 제가 빠르게 넘어가겠습니다. 이것은 우리가 다른 작업과 비교하여

978
00:59:48,530 --> 00:59:51,030
수행한 몇 가지 벤치마크입니다.

979
00:59:51,030 --> 00:59:51,530
좋습니다.

980
00:59:51,530 --> 00:59:54,410
제가 빠르게 넘어가겠습니다.

981
00:59:54,410 --> 00:59:58,320
이것은 실제로 우리 연구실에서

982
00:59:58,320 --> 01:00:04,790
진행 중인 작업이며, 이로 인해 우리는 행동을 사용하여

983
01:00:04,790 --> 01:00:08,360
로봇 공학을 배우고, 더 흥미로운

984
01:00:08,360 --> 01:00:11,960
데이터를 수집하도록 우리를

985
01:00:11,960 --> 01:00:17,700
밀어주고, 이를 인지 연구에도 활용하고 있습니다.

986
01:00:17,700 --> 01:00:19,253
제가 빠르게 넘어가겠습니다.

987
01:00:23,410 --> 01:00:28,150
여러분과 공유하고 싶은 한 가지는

988
01:00:28,150 --> 01:00:33,670
오늘날의 알고리즘이 여전히 행동 과제를 수행할 수

989
01:00:33,670 --> 01:00:35,990
없다는 숫자입니다.

990
01:00:35,990 --> 01:00:41,320
이 모든 역할 중에서 가장 중요한 역할은 우리가

991
01:00:41,320 --> 01:00:45,110
로봇이 할 수 있기를 바라는 것입니다.

992
01:00:45,110 --> 01:00:47,210
특별한 정보를 주지 마십시오.

993
01:00:47,210 --> 01:00:50,750
그들은 환경에 투입되어 이러한 작업을 수행해야 합니다.

994
01:00:50,750 --> 01:00:53,710
우리는 오늘날의 로봇 알고리즘을

995
01:00:53,710 --> 01:00:57,620
사용하여 세 가지 행동 과제를 벤치마킹했습니다.

996
01:00:57,620 --> 01:01:00,260
성과는 제로입니다.

997
01:01:00,260 --> 01:01:06,280
더 많은 특권 정보를 제공하거나 작업을 단순하게

998
01:01:06,280 --> 01:01:08,530
만드는 가정을

999
01:01:08,530 --> 01:01:15,290
하면, 마법 같은 동작이나 완벽한 기억 등으로 상황이

1000
01:01:15,290 --> 01:01:18,130
나아지기 시작합니다.

1001
01:01:18,130 --> 01:01:23,110
위의 행만 보면 오늘날의 로봇에 대해 꽤

1002
01:01:23,110 --> 01:01:25,780
우울해질 수 있습니다.

1003
01:01:25,780 --> 01:01:27,720
하지만 대학원생으로서

1004
01:01:27,720 --> 01:01:33,750
여러분이 영감을 받기를 바랍니다. 이는 우리가 성장할 여지가 많다는 것을
의미합니다.

1005
01:01:33,750 --> 01:01:35,070
좋습니다.

1006
01:01:35,070 --> 01:01:37,360
이것은 우리 연구실의 다양한 논문들입니다.

1007
01:01:37,360 --> 01:01:39,780
이 주제에 대해 충분히 이야기했다고

1008
01:01:39,780 --> 01:01:42,035
생각하므로 실제로 빠르게 넘어가겠습니다.

1009
01:01:44,910 --> 01:01:50,040
그런데 우리는 디지털 환경과 실제 환경에서 행동의

1010
01:01:50,040 --> 01:01:52,830
디지털 트윈도 하고

1011
01:01:52,830 --> 01:01:56,340
있으며, 이는 실제에서 시뮬레이션으로의

1012
01:01:56,340 --> 01:02:00,880
전이를 테스트하는 훌륭한 방법입니다.

1013
01:02:00,880 --> 01:02:03,730
다시 말하지만, 이것은 해결되지 않은 문제입니다.

1014
01:02:03,730 --> 01:02:07,720
아직 갈 길이 멉니다.

1015
01:02:07,720 --> 01:02:09,930
특히 이 경우,

1016
01:02:09,930 --> 01:02:13,590
이 로봇이 얼마나 느린지 보실

1017
01:02:13,590 --> 01:02:15,580
수 있습니다.

1018
01:02:15,580 --> 01:02:17,515
이 방을 청소하려고 하고 있습니다.

1019
01:02:21,200 --> 01:02:21,710
좋습니다.

1020
01:02:21,710 --> 01:02:23,420
축하합니다.

1021
01:02:23,420 --> 01:02:27,590
이 로봇이 저지르는 몇 가지

1022
01:02:27,590 --> 01:02:30,890
실수입니다. 예를 들어,

1023
01:02:30,890 --> 01:02:35,120
병을 집을 수 없거나,

1024
01:02:35,120 --> 01:02:41,720
이전에 잘못된 방향으로 가서 잘못된 곳에

1025
01:02:41,720 --> 01:02:42,690
놓았습니다.

1026
01:02:42,690 --> 01:02:45,420
아직 많은 실수가 있습니다.

1027
01:02:45,420 --> 01:02:50,150
좋습니다, 제가 빠르게 넘어가겠습니다.

1028
01:02:50,150 --> 01:02:53,330
우리는 실제로 이 환경을 사용하여

1029
01:02:53,330 --> 01:02:56,040
시각 장애인 환자를

1030
01:02:56,040 --> 01:02:59,630
연구하고 있으며, 이는 환자를 안전한

1031
01:02:59,630 --> 01:03:03,950
환경에 두고 연구하는 훌륭한 방법입니다.

1032
01:03:03,950 --> 01:03:07,950
마지막으로 보여드리고 싶은 것은 정말

1033
01:03:07,950 --> 01:03:12,740
멋진 것이며, 제가 보여드리고 싶은 마지막

1034
01:03:12,740 --> 01:03:20,060
기술 작업은 우리가 이제 심리학자 및 의사와 협력하여 뇌파를

1035
01:03:20,060 --> 01:03:25,100
사용하여 로봇을 제어하는 방법을 연구하고 있다는

1036
01:03:25,100 --> 01:03:26,040
것입니다.

1037
01:03:26,040 --> 01:03:28,790
여기 보시는 것은 대학원생이

1038
01:03:28,790 --> 01:03:34,380
EEG 캡을 착용하고 있는 데모입니다. 이

1039
01:03:34,380 --> 01:03:38,130
캡이 지시를 보내고, 로봇

1040
01:03:38,130 --> 01:03:42,440
팔이 순전히 생각으로 일본 요리를 하고

1041
01:03:42,440 --> 01:03:43,740
있습니다.

1042
01:03:43,740 --> 01:03:47,250
침습적인 뇌 제어는 없습니다.

1043
01:03:47,250 --> 01:03:49,530
이것은 전기 신호에서 나옵니다.

1044
01:03:49,530 --> 01:03:53,580
우리가 해야 할 일은 이러한 생각을 사전 훈련하는 것입니다.

1045
01:03:53,580 --> 01:03:59,030
로봇 팔을 들어올리기, 놓기, 떨어뜨리기 등으로

1046
01:03:59,030 --> 01:04:01,680
사전 훈련해야 합니다.

1047
01:04:01,680 --> 01:04:04,640
그리고 그렇게 하면, 이것은 파도를

1048
01:04:04,640 --> 01:04:06,750
기반으로 요리된 전체 식사입니다.

1049
01:04:06,750 --> 01:04:08,820
정말 공상 과학 영화 같습니다.

1050
01:04:08,820 --> 01:04:11,640
그리고 이것은 작년에 일어났습니다.

1051
01:04:11,640 --> 01:04:16,840
그래서 저는 비전, 인식, 로봇 공학을 결합하고 임상

1052
01:04:16,840 --> 01:04:19,630
환경에서 사람들을 돕는 방향으로

1053
01:04:19,630 --> 01:04:23,180
가고 있는 것에 매우 흥분하고 있습니다.

1054
01:04:23,180 --> 01:04:25,450
이것이 심각하게

1055
01:04:25,450 --> 01:04:29,530
마비된 환자들을 돕는 미래입니다.

1056
01:04:29,530 --> 01:04:34,000
좋아요, 행동 프로젝트는 사람들을 보강하는 데

1057
01:04:34,000 --> 01:04:37,150
정말로 초점을 맞추고 있습니다.

1058
01:04:37,150 --> 01:04:41,690
대규모의 다양한 벤치마크입니다.

1059
01:04:41,690 --> 01:04:45,670
현실적이고 생태적인 물리학과 인식을 가지고

1060
01:04:45,670 --> 01:04:46,880
있습니다.

1061
01:04:46,880 --> 01:04:52,510
마지막으로 전할 메시지는 우리는 단순히 일을 하거나 사물을

1062
01:04:52,510 --> 01:04:57,280
보는 AI를 만들고 싶지 않고, 사람들을 돕기 위해

1063
01:04:57,280 --> 01:05:00,400
AI를 만들고 싶다는 것입니다.

1064
01:05:00,400 --> 01:05:05,920
AI가 인류를 위한 보강 도구 또는 향상 도구가 되는 것이

1065
01:05:05,920 --> 01:05:10,050
대체하는 도구가 되는 것보다 매우 중요합니다.
