1
00:00:05,510 --> 00:00:07,230
이것은 CS231n입니다.

2
00:00:07,230 --> 00:00:11,000
저는 컴퓨터 과학과의 페이페이 리

3
00:00:11,000 --> 00:00:11,820
교수입니다.

4
00:00:11,820 --> 00:00:14,960
이번 학기에는 에산 아델리 교수님과

5
00:00:14,960 --> 00:00:19,320
제 대학원생 제인과 함께 수업을 진행할 것입니다.

6
00:00:19,320 --> 00:00:23,300
그래서 여러분은 그들과 나중에 만날 훌륭한 TA

7
00:00:23,300 --> 00:00:24,900
팀을 만날 것입니다.

8
00:00:24,900 --> 00:00:28,250
그럼 시작하겠습니다.

9
00:00:28,250 --> 00:00:32,030
제가 흥미롭게 생각하는 것은 AI가 매우

10
00:00:32,030 --> 00:00:35,520
학제간 분야가 되었다는 것입니다. 이

11
00:00:35,520 --> 00:00:38,520
수업에서 배우게 될 내용은

12
00:00:38,520 --> 00:00:40,530
물론 매우 기술적입니다.

13
00:00:40,530 --> 00:00:42,750
이것은 컴퓨터 비전과 딥러닝에 관한 것입니다.

14
00:00:42,750 --> 00:00:44,600
하지만 여러분이 일하는

15
00:00:44,600 --> 00:00:48,590
분야와 열정을 가지고 있는 분야에

16
00:00:48,590 --> 00:00:49,920
적용하길 바랍니다.

17
00:00:49,920 --> 00:00:52,800
AI 분야에 대해 많은 이야기를 듣습니다.

18
00:00:52,800 --> 00:00:56,030
그렇다면 컴퓨터 비전과 이 수업의 범위를

19
00:00:56,030 --> 00:00:57,920
어떻게 설정할까요?

20
00:00:57,920 --> 00:01:02,250
AI를 큰 거품으로 생각한다면,

21
00:01:02,250 --> 00:01:07,350
컴퓨터 비전은 AI의 중요한 부분입니다.

22
00:01:07,350 --> 00:01:10,830
여러분 중 일부는 비전이 지능의 일부일 뿐만 아니라

23
00:01:10,830 --> 00:01:13,960
지능의 초석이라고 말하는 저를 들었을 것입니다.

24
00:01:13,960 --> 00:01:16,530
시각적 지능의 신비를 푸는

25
00:01:16,530 --> 00:01:20,080
것은 지능의 신비를 푸는 것입니다.

26
00:01:20,080 --> 00:01:25,250
하지만 AI를 해결하는 데 가장 중요한 도구 중 하나는

27
00:01:25,250 --> 00:01:29,130
기계 학습 또는 통계적 기계 학습이라고

28
00:01:29,130 --> 00:01:31,060
부르는 것입니다.

29
00:01:31,060 --> 00:01:36,300
그리고 이것이 바로 우리가 이야기할 내용입니다.

30
00:01:36,300 --> 00:01:38,670
기계 학습 분야에서 지난

31
00:01:38,670 --> 00:01:42,390
10년 이상 동안 우리는 딥러닝이라는 큰 혁명을

32
00:01:42,390 --> 00:01:43,570
보았습니다.

33
00:01:43,570 --> 00:01:46,930
딥러닝이 무엇인지 조금 설명하겠습니다.

34
00:01:46,930 --> 00:01:50,640
딥러닝은 신경망이라고 불리는 알고리즘

35
00:01:50,640 --> 00:01:54,120
가족을 중심으로 구축된 알고리즘

36
00:01:54,120 --> 00:01:55,540
기술 집합입니다.

37
00:01:55,540 --> 00:02:02,040
이 수업의 범위를 정확히 정리해달라고 하신다면, 우리는 컴퓨터

38
00:02:02,040 --> 00:02:05,250
비전의 전부를 다룰 수는 없습니다.

39
00:02:05,250 --> 00:02:07,850
우리는 기계 학습이나 딥러닝의 전부를

40
00:02:07,850 --> 00:02:09,030
다룰 수는 없습니다.

41
00:02:09,030 --> 00:02:12,410
하지만 이 두 분야의 핵심 교차점을 다룰

42
00:02:12,410 --> 00:02:13,290
것입니다.

43
00:02:13,290 --> 00:02:18,300
물론 AI의 전반과 마찬가지로 컴퓨터 비전도

44
00:02:18,300 --> 00:02:20,900
점점 더 학제간

45
00:02:20,900 --> 00:02:23,340
분야가 되고 있습니다.

46
00:02:23,340 --> 00:02:26,060
우리가 사용하는 많은 기술과

47
00:02:26,060 --> 00:02:28,310
우리가 다루는 문제는

48
00:02:28,310 --> 00:02:31,280
자연어 처리, 음성 인식,

49
00:02:31,280 --> 00:02:37,850
로봇 공학 등 여러 다른 분야와 교차합니다. AI는 수학, 신경

50
00:02:37,850 --> 00:02:41,340
과학, 컴퓨터 과학, 심리학, 물리학,

51
00:02:41,340 --> 00:02:44,160
생물학, 의학, 법률,

52
00:02:44,160 --> 00:02:46,430
교육, 비즈니스 등 많은

53
00:02:46,430 --> 00:02:49,950
응용 분야와 교차하는 분야입니다.

54
00:02:49,950 --> 00:02:55,170
그래서 이번 강의, 첫 번째 강의에서 여러분이 받을

55
00:02:55,170 --> 00:02:58,260
내용은 컴퓨터 비전과 딥러닝의

56
00:02:58,260 --> 00:02:59,890
간단한 역사입니다.

57
00:02:59,890 --> 00:03:05,310
그 후 아델리 교수님이 이 과정의 개요를 설명하고 이 과정이

58
00:03:05,310 --> 00:03:08,130
어떻게 구성되어 있는지, 우리의 기대가

59
00:03:08,130 --> 00:03:11,670
무엇인지에 대한 기초를 다질 것입니다.

60
00:03:11,670 --> 00:03:19,140
비전의 역사는 여러분이 태어났을 때나 인류가 태어났을 때 시작되지

61
00:03:19,140 --> 00:03:20,980
않았습니다.

62
00:03:20,980 --> 00:03:25,720
비전의 역사는 5억 4천만 년 전부터 시작되었습니다.

63
00:03:25,720 --> 00:03:29,920
여러분은 5억 4천만 년 전에는 무슨 일이 있었는지 물어볼 수 있습니다.

64
00:03:29,920 --> 00:03:34,230
왜 진화에서 상대적으로 구체적인 날짜나 연도를

65
00:03:34,230 --> 00:03:35,500
정하고 있나요?

66
00:03:35,500 --> 00:03:37,830
그것은 많은 화석 연구가

67
00:03:37,830 --> 00:03:43,380
캄브리아기 폭발이라는 신비한 시기가 있었음을

68
00:03:43,380 --> 00:03:45,550
보여주었기 때문입니다.

69
00:03:45,550 --> 00:03:49,200
화석 연구는 그 시기에 약 1천만 년의 진화가

70
00:03:49,200 --> 00:03:52,440
있었음을 보여주었으며, 이는 진화에 있어 매우

71
00:03:52,440 --> 00:03:53,810
짧은 기간입니다.

72
00:03:53,810 --> 00:03:58,340
화석 연구에서 동물 종의 폭발을 볼 수 있으며,

73
00:03:58,340 --> 00:04:02,820
이는 캄브리아기 폭발 이전에 지구의 생명체가 꽤

74
00:04:02,820 --> 00:04:05,220
평화로웠음을 의미합니다.

75
00:04:05,220 --> 00:04:06,930
사실 물속에 있었습니다.

76
00:04:06,930 --> 00:04:10,320
육지에는 아직 동물이 없습니다.

77
00:04:10,320 --> 00:04:13,770
동물들은 그냥 떠다닙니다.

78
00:04:13,770 --> 00:04:18,240
그렇다면 동물 종의 폭발적인 증가를 초래한 원인은 무엇일까요?

79
00:04:18,240 --> 00:04:21,620
기후에서부터 해양 수의 화학 성분까지 많은

80
00:04:21,620 --> 00:04:23,190
이론이 있었습니다.

81
00:04:23,190 --> 00:04:29,360
하지만 가장 설득력 있는 이론 중 하나는 얼음의 시작이었습니다.

82
00:04:29,360 --> 00:04:32,570
첫 번째 동물인 삼엽충은 광감수성

83
00:04:32,570 --> 00:04:34,950
세포를 얻었습니다.

84
00:04:34,950 --> 00:04:37,310
우리가 이야기했던 눈은 정교한

85
00:04:37,310 --> 00:04:41,010
렌즈와 망막, 신경 세포가 아니었습니다.

86
00:04:41,010 --> 00:04:44,520
정말로 아주 간단한 핀홀입니다.

87
00:04:44,520 --> 00:04:47,340
그 핀홀이 빛을 모았습니다.

88
00:04:47,340 --> 00:04:53,550
빛을 모으면, 생명은 완전히 달라집니다.

89
00:04:53,550 --> 00:04:57,660
센서가 없으면, 생명은 대사입니다.

90
00:04:57,660 --> 00:04:59,410
매우 수동적입니다.

91
00:04:59,410 --> 00:05:01,180
그냥 대사입니다.

92
00:05:01,180 --> 00:05:02,530
그리고 당신은 오고 갑니다.

93
00:05:02,530 --> 00:05:06,690
센서가 있으면, 당신은 변화하고 싶을 수 있는 환경의

94
00:05:06,690 --> 00:05:08,980
필수적인 부분이 됩니다.

95
00:05:08,980 --> 00:05:11,920
실제로 그 환경에서 생존하고 싶을 수 있습니다.

96
00:05:11,920 --> 00:05:16,170
어떤 동물이나 식물이 당신의 저녁이 될 수 있습니다.

97
00:05:16,170 --> 00:05:18,070
그리고 당신은 다른 누군가의 저녁이 됩니다.

98
00:05:18,070 --> 00:05:24,120
진화의 힘은 센서의 출현, 시각의

99
00:05:24,120 --> 00:05:27,580
출현, 촉각 감각과

100
00:05:27,580 --> 00:05:31,530
함께 지능이 진화하도록

101
00:05:31,530 --> 00:05:33,220
이끕니다.

102
00:05:33,220 --> 00:05:38,080
그것들은 동물의 가장 오래된 센서입니다.

103
00:05:38,080 --> 00:05:41,880
비전의 5억 4천만 년 진화

104
00:05:41,880 --> 00:05:46,510
과정 전체는 지능의 진화입니다.

105
00:05:46,510 --> 00:05:49,850
동물의 주요 감각 중 하나로서의

106
00:05:49,850 --> 00:05:54,260
시각은 신경계의 발전, 지능의 발전을

107
00:05:54,260 --> 00:05:55,320
이끌었습니다.

108
00:05:55,320 --> 00:05:59,450
오늘날 우리가 아는 거의 모든 지구상의 동물들은 시각을

109
00:05:59,450 --> 00:06:03,420
가지고 있거나 주요 감각 중 하나로 시각을 사용합니다.

110
00:06:03,420 --> 00:06:06,450
인간은 특히 시각적인 동물입니다.

111
00:06:06,450 --> 00:06:08,810
우리의 피질 세포의 절반

112
00:06:08,810 --> 00:06:11,820
이상이 시각 처리에 관여합니다.

113
00:06:11,820 --> 00:06:15,930
그리고 우리는 매우 복잡하고 얽힌 시각 시스템을 가지고 있습니다.

114
00:06:15,930 --> 00:06:19,800
그래서 이것이 제가 시각 분야에 들어가고 싶어하는 이유입니다.

115
00:06:19,800 --> 00:06:21,870
그리고 여러분도 흥미를 느끼길 바랍니다.

116
00:06:21,870 --> 00:06:30,620
이제 캄브리아 폭발에서 실제 인간 문명으로 빠르게

117
00:06:30,620 --> 00:06:33,470
넘어가 보겠습니다.

118
00:06:33,470 --> 00:06:35,850
인간은 혁신을 합니다.

119
00:06:35,850 --> 00:06:37,610
그리고 우리는 단지 보는 것만이 아닙니다.

120
00:06:37,610 --> 00:06:40,050
우리는 볼 수 있는 기계를 만들고 싶습니다.

121
00:06:40,050 --> 00:06:44,850
그래서 여기 레오나르도 다 빈치의 몇 가지 그림이 있습니다.

122
00:06:44,850 --> 00:06:48,540
그는 모든 것에 대해 끝없이 호기심이

123
00:06:48,540 --> 00:06:49,540
많았습니다.

124
00:06:49,540 --> 00:06:56,740
그는 증기 기계를 만드는 방법으로 카메라 옵스쿠라를 연구했습니다.

125
00:06:56,740 --> 00:07:01,830
사실, 그보다 훨씬 이전에 고대

126
00:07:01,830 --> 00:07:05,160
그리스와 고대 중국에서도 핀홀을

127
00:07:05,160 --> 00:07:09,990
통해 물체를 투사하고 물체의

128
00:07:09,990 --> 00:07:15,600
이미지를 만드는 방법에 대해 생각한 사상가들에

129
00:07:15,600 --> 00:07:19,330
대한 문서가 있습니다.

130
00:07:19,330 --> 00:07:22,750
그리고 물론, 현대 생활에서 카메라는

131
00:07:22,750 --> 00:07:25,990
정말 폭발적으로 증가했습니다.

132
00:07:25,990 --> 00:07:30,780
하지만 카메라는 보는 데 충분하지 않습니다. 눈도 보는 데 충분하지

133
00:07:30,780 --> 00:07:31,720
않습니다.

134
00:07:31,720 --> 00:07:33,010
이것들은 장치입니다.

135
00:07:33,010 --> 00:07:35,950
우리는 시각적 지능이 어떻게 발생하는지 이해해야 합니다.

136
00:07:35,950 --> 00:07:38,590
그리고 그것이 바로 이 과정의 핵심입니다.

137
00:07:38,590 --> 00:07:45,670
그래서 딥러닝과 컴퓨터 비전의 교차점에 이르게 한 역사에

138
00:07:45,670 --> 00:07:49,790
대해 조금 이야기해 보겠습니다.

139
00:07:49,790 --> 00:07:57,160
1950년대로 돌아가 보겠습니다.

140
00:07:57,160 --> 00:08:03,370
1950년대에는 신경과학에서 매우 중요한 실험들이

141
00:08:03,370 --> 00:08:05,090
일어났습니다.

142
00:08:05,090 --> 00:08:08,020
그것은 포유류의 시각 경로에 대한 연구였으며,

143
00:08:08,020 --> 00:08:10,630
특히 허벨과 와이젤의 기념비적인

144
00:08:10,630 --> 00:08:11,990
작업이었습니다.

145
00:08:11,990 --> 00:08:18,410
그들은 마취된 살아있는 고양이에 전극을 삽입했습니다.

146
00:08:18,410 --> 00:08:21,220
그리고 나서 그들은 일차 시각

147
00:08:21,220 --> 00:08:25,760
피질에 있는 뉴런의 수용 필드를 연구했습니다.

148
00:08:25,760 --> 00:08:28,910
그들이 놀랍게도 배운 두 가지

149
00:08:28,910 --> 00:08:31,070
중요한 사실이 있습니다.

150
00:08:31,070 --> 00:08:38,740
하나는 일차 시각 피질에서 보는 역할을 하는 뉴런이 각자의

151
00:08:38,740 --> 00:08:41,860
개별 수용 필드를

152
00:08:41,860 --> 00:08:44,820
가지고 있다는 것입니다.

153
00:08:44,820 --> 00:08:48,320
수용 필드는 각 뉴런이 실제로

154
00:08:48,320 --> 00:08:52,590
보는 공간의 일부를 의미합니다.

155
00:08:52,590 --> 00:08:54,870
모든 공간이 아닙니다.

156
00:08:54,870 --> 00:08:55,800
그리 크지 않습니다.

157
00:08:55,800 --> 00:09:00,780
대개는 매우 제한된 공간의 패치입니다.

158
00:09:00,780 --> 00:09:06,630
그리고 그 공간 내에서 초기 시각

159
00:09:06,630 --> 00:09:12,320
경로에서 측정할 때 전문화된 패턴,

160
00:09:12,320 --> 00:09:15,470
간단한 패턴을 봅니다.

161
00:09:15,470 --> 00:09:18,840
그리고 대체로 일차 시각 피질에서는 머리

162
00:09:18,840 --> 00:09:23,120
뒤쪽, 눈 근처가 아닌 곳에 위치하며, 방향이 있는 가장자리

163
00:09:23,120 --> 00:09:27,210
또는 움직이는 방향이 있는 가장자리를 인식합니다.

164
00:09:27,210 --> 00:09:28,970
그래서 모든 뉴런은 어떤 뉴런은 이렇게

165
00:09:28,970 --> 00:09:30,330
생긴 가장자리를 보고 있습니다.

166
00:09:30,330 --> 00:09:32,970
어떤 뉴런은 이렇게 생긴 가장자리를 보거나 이렇게 생긴 가장자리를 보고
있습니다.

167
00:09:32,970 --> 00:09:39,030
그리고 그것이 뇌에서 계산이 시작되는 방식입니다.

168
00:09:39,030 --> 00:09:42,370
그들이 배운 두 번째 사실은 시각 경로가

169
00:09:42,370 --> 00:09:43,520
계층적이라는 것입니다.

170
00:09:43,520 --> 00:09:47,150
시각 경로를 넘어가면 뉴런이

171
00:09:47,150 --> 00:09:50,630
다른 뉴런으로 연결됩니다.

172
00:09:50,630 --> 00:09:54,730
그리고 시각 계층의 더 높은 층 또는 더

173
00:09:54,730 --> 00:09:57,460
깊은 층의 뉴런은 더 복잡한

174
00:09:57,460 --> 00:09:59,990
수용 필드를 가지고 있습니다.

175
00:09:59,990 --> 00:10:04,010
그래서 방향이 있는 가장자리로 시작하면 코너

176
00:10:04,010 --> 00:10:06,890
수용체로 연결될 수 있습니다.

177
00:10:06,890 --> 00:10:10,400
물체 수용체로 연결될 수 있습니다.

178
00:10:10,400 --> 00:10:12,200
제가 지나치게 단순화하고 있습니다.

179
00:10:12,200 --> 00:10:16,360
하지만 그 개념은 뉴런들이 서로 연결된다는 것입니다.

180
00:10:16,360 --> 00:10:23,360
그리고 그들은 이 큰 계산 네트워크를 만듭니다.

181
00:10:23,360 --> 00:10:25,720
물론, 여기 앉아 있는

182
00:10:25,720 --> 00:10:27,850
대부분은 제가 설명한 방식이

183
00:10:27,850 --> 00:10:30,670
시각 알고리즘의 신경망

184
00:10:30,670 --> 00:10:36,020
모델링에 깊은 영향을 미칠 것이라고 이미 생각하고 있습니다.

185
00:10:36,020 --> 00:10:37,070
계속 진행합시다.

186
00:10:37,070 --> 00:10:40,260
그것은 1959년입니다.

187
00:10:40,260 --> 00:10:43,500
아주 초기의 시각 연구입니다.

188
00:10:43,500 --> 00:10:48,290
그런데 약 30년 후-- 아마도 그보다

189
00:10:48,290 --> 00:10:50,970
조금 덜-- 20년

190
00:10:50,970 --> 00:10:54,770
정도 후에, 후벨과 위젤은 시각

191
00:10:54,770 --> 00:10:59,840
처리 원리를 밝혀내어 의학 분야에서 노벨상을

192
00:10:59,840 --> 00:11:01,790
수상했습니다.

193
00:11:01,790 --> 00:11:05,780
컴퓨터 비전 초기 역사에서 또 다른 이정표는

194
00:11:05,780 --> 00:11:09,180
컴퓨터 비전의 첫 번째 박사 논문이었습니다.

195
00:11:09,180 --> 00:11:13,040
대부분의 사람들은 1963년에 모양을 연구한

196
00:11:13,040 --> 00:11:17,880
첫 번째 박사 논문을 쓴 래리 로버츠를 언급합니다.

197
00:11:17,880 --> 00:11:21,350
그리고 이것은 세상의 매우, 매우 특성적인

198
00:11:21,350 --> 00:11:22,260
표현입니다.

199
00:11:22,260 --> 00:11:26,090
아이디어는 우리가 이런 모양을 가지고

200
00:11:26,090 --> 00:11:30,560
이 모양의 표면과 모서리 및 특징을 이해할

201
00:11:30,560 --> 00:11:32,210
수 있을까요?

202
00:11:32,210 --> 00:11:34,230
인간이 그렇게 한다는 것은 직관적입니다.

203
00:11:34,230 --> 00:11:39,350
그래서 전체 박사 논문이 이에 전념하고 있습니다.

204
00:11:39,350 --> 00:11:44,980
그리고 그것이 컴퓨터 비전의 시작입니다.

205
00:11:44,980 --> 00:11:52,870
그 무렵인 1966년, MIT의 한 교수는 MIT에서 여름

206
00:11:52,870 --> 00:11:56,710
프로젝트를 만들고 몇 명의 매우

207
00:11:56,710 --> 00:12:03,830
똑똑한 학부생을 고용하여 시각을 연구하도록 요청했습니다.

208
00:12:03,830 --> 00:12:07,120
목표는 거의 컴퓨터 비전을 해결하거나 한 여름

209
00:12:07,120 --> 00:12:09,400
동안 시각을 해결하는 것이었습니다.

210
00:12:09,400 --> 00:12:13,280
물론, AI의 나머지 역사처럼, 우리는 짧은

211
00:12:13,280 --> 00:12:18,310
시간 안에 우리가 할 수 있는 것에 대해 지나치게 낙관적이

212
00:12:18,310 --> 00:12:20,330
되는 경향이 있습니다.

213
00:12:20,330 --> 00:12:24,530
그래서 그 여름에 시각이 해결되지 않았습니다.

214
00:12:24,530 --> 00:12:29,800
사실, 그것은 놀라운 컴퓨터 과학 분야로

215
00:12:29,800 --> 00:12:30,710
발전했습니다.

216
00:12:30,710 --> 00:12:33,830
지금 매년 열리는 우리의 연례 회의에 가면,

217
00:12:33,830 --> 00:12:36,420
10,000명 이상의 사람들이 참석합니다.

218
00:12:36,420 --> 00:12:43,880
하지만 1960년대는 래리 로버츠의 박사 논문과 이러한 종류의

219
00:12:43,880 --> 00:12:48,500
프로젝트 사이에서 우리가 컴퓨터 비전 분야의

220
00:12:48,500 --> 00:12:51,830
시작으로 간주하는 시기입니다.

221
00:12:51,830 --> 00:12:55,620
1970년대에 데이비드 마르가 쓴 기념비적인 책이 있습니다.

222
00:12:55,620 --> 00:12:58,470
그는 불행히도 너무 일찍 세상을 떠났습니다.

223
00:12:58,470 --> 00:13:01,940
그는 시각을 체계적으로 연구하고 시각 처리가

224
00:13:01,940 --> 00:13:05,790
어떻게 이루어지는지를 고려하기 시작하고 싶었습니다.

225
00:13:05,790 --> 00:13:07,640
비록 이것이 명시적으로

226
00:13:07,640 --> 00:13:10,310
언급되지는 않지만, 신경 과학과 인지

227
00:13:10,310 --> 00:13:12,930
과학에서 많은 영감을 받았습니다.

228
00:13:12,930 --> 00:13:20,070
그는 입력 이미지를 가져오면 이미지를 어떻게 시각적으로 처리하고

229
00:13:20,070 --> 00:13:23,580
이해하는지를 생각하고 있었습니다.

230
00:13:23,580 --> 00:13:28,730
아마도 첫 번째 층은 우리가 본 것처럼 가장자리에 더 가깝습니다.

231
00:13:28,730 --> 00:13:30,630
그는 이를 원시 스케치라고 부릅니다.

232
00:13:30,630 --> 00:13:37,890
그리고 이미지의 객체의 서로 다른 깊이를

233
00:13:37,890 --> 00:13:42,910
구분하는 2.5D 스케치가 있습니다.

234
00:13:42,910 --> 00:13:45,060
그래서 공은 전경 객체입니다.

235
00:13:45,060 --> 00:13:47,860
그리고 여기의 풀-- 아, 아니요,

236
00:13:47,860 --> 00:13:48,820
풀은 아닙니다.

237
00:13:48,820 --> 00:13:51,520
여기의 바닥은 배경입니다.

238
00:13:51,520 --> 00:13:53,920
그래서 그는 이러한 2.5D 스케치를 합니다.

239
00:13:53,920 --> 00:14:01,440
마지막으로, 데이비드 마르는 비전 문제를 해결하는 궁극적인

240
00:14:01,440 --> 00:14:06,660
성과는 전체 3D 표현을 아는 것이라고

241
00:14:06,660 --> 00:14:07,960
믿습니다.

242
00:14:07,960 --> 00:14:12,880
그것이 실제로 비전의 가장 어려운 점입니다.

243
00:14:12,880 --> 00:14:15,130
20초 정도 다른 이야기를 하겠습니다.

244
00:14:15,130 --> 00:14:20,950
모든 동물의 비전을 생각해보면, 이는 잘 정의되지

245
00:14:20,950 --> 00:14:23,350
않은 문제입니다.

246
00:14:23,350 --> 00:14:27,390
수중에서 빛을 수집한 초기

247
00:14:27,390 --> 00:14:30,660
삼엽충부터 시작하여,

248
00:14:30,660 --> 00:14:35,810
빛은 대체로 2D 표면에 어떤

249
00:14:35,810 --> 00:14:38,070
것에 투사됩니다.

250
00:14:38,070 --> 00:14:40,880
그 당시에는 동물의 어떤 패치였던

251
00:14:40,880 --> 00:14:42,060
것 같습니다.

252
00:14:42,060 --> 00:14:45,470
하지만 지금 우리에게는 망막이 있습니다.

253
00:14:45,470 --> 00:14:47,910
하지만 실제 세계는 3D입니다.

254
00:14:47,910 --> 00:14:55,610
따라서 2D 이미지에서 3D 정보를, 즉 전체 3D 세계를 복원하는 것은
자연이

255
00:14:55,610 --> 00:15:00,230
해결해야 했던 근본적인 문제이며, 컴퓨터 비전이

256
00:15:00,230 --> 00:15:02,730
해결해야 할 문제입니다.

257
00:15:02,730 --> 00:15:05,840
수학적으로 이는 잘 정의되지 않은 문제입니다.

258
00:15:05,840 --> 00:15:07,940
그럼 우리는 나중에 무엇을 했습니까?

259
00:15:07,940 --> 00:15:09,745
누구든지 wild guess가 있습니까?

260
00:15:14,900 --> 00:15:17,300
[듣기 불가]

261
00:15:17,300 --> 00:15:18,800
네.

262
00:15:18,800 --> 00:15:22,200
자연이 한 트릭은 주로 두 개의 눈을 개발하는

263
00:15:22,200 --> 00:15:22,700
것입니다.

264
00:15:22,700 --> 00:15:25,260
일부 동물은 두 개 이상의 눈을 가지고 있습니다.

265
00:15:25,260 --> 00:15:28,110
그리고 정보를 삼각측량합니다.

266
00:15:28,110 --> 00:15:29,740
하지만 두 개의 눈만으로는 충분하지 않습니다.

267
00:15:29,740 --> 00:15:33,250
실제로는 대응 관계를 이해해야 합니다.

268
00:15:33,250 --> 00:15:35,050
이러한 주제 중 일부를 다룰 것입니다.

269
00:15:35,050 --> 00:15:38,880
하지만 스탠포드에서 제공하는 다른 컴퓨터 비전 수업도

270
00:15:38,880 --> 00:15:42,090
3D 비전에 대해 구체적으로 이야기합니다.

271
00:15:42,090 --> 00:15:45,660
하지만 요점은 이것이 매우 어려운 문제라는 것입니다.

272
00:15:45,660 --> 00:15:47,590
우리는 이를 해결해야 합니다.

273
00:15:47,590 --> 00:15:48,790
자연은 이를 해결했습니다.

274
00:15:48,790 --> 00:15:53,110
인간도 이를 해결했지만 극도의 정밀도로는 아닙니다.

275
00:15:53,110 --> 00:15:55,750
사실, 인간은 그렇게 정밀하지 않습니다.

276
00:15:55,750 --> 00:15:58,510
나는 대략적인 3D 형태를 알고 있습니다.

277
00:15:58,510 --> 00:16:03,430
하지만 모든 형태의 기하학적 정밀도는 없습니다.

278
00:16:03,430 --> 00:16:06,780
그래서 이 문제의 어려움을 고려하고

279
00:16:06,780 --> 00:16:08,620
인식하는 것이 중요합니다.

280
00:16:08,620 --> 00:16:12,420
컴퓨터 비전과 언어의 또 다른

281
00:16:12,420 --> 00:16:15,480
매우 다른 점은 철학적으로

282
00:16:15,480 --> 00:16:17,370
미묘한 것입니다.

283
00:16:17,370 --> 00:16:20,170
언어는 자연에 존재하지 않습니다.

284
00:16:20,170 --> 00:16:24,340
무언가를 가리키며 언어가 있다고 말할 수 없습니다.

285
00:16:24,340 --> 00:16:30,090
언어는 순전히 생성된 것입니다.

286
00:16:30,090 --> 00:16:31,860
어떤 단어를 사용해야 할지 모르겠어요.

287
00:16:31,860 --> 00:16:35,460
이것은 우리의 뇌를 통해 전달됩니다.

288
00:16:35,460 --> 00:16:37,290
생성됩니다.

289
00:16:37,290 --> 00:16:38,580
1D입니다.

290
00:16:38,580 --> 00:16:40,310
순차적입니다.

291
00:16:40,310 --> 00:16:44,450
그래서 이것은 최신 GenAI 알고리즘의

292
00:16:44,450 --> 00:16:47,510
심오한 의미를 가지고 있습니다.

293
00:16:47,510 --> 00:16:50,420
이것이 바로 이 수업의 범위를 벗어난

294
00:16:50,420 --> 00:16:54,890
LLM이 강력한 이유입니다. 우리는 그렇게 언어를

295
00:16:54,890 --> 00:16:56,760
모델링할 수 있습니다.

296
00:16:56,760 --> 00:16:58,650
하지만 비전은 생성되지 않습니다.

297
00:16:58,650 --> 00:17:01,670
물리학과 재료의 법칙을

298
00:17:01,670 --> 00:17:05,839
존중하는 물리적 세계가 실제로 존재합니다.

299
00:17:05,839 --> 00:17:06,510
존중하는 물리적 세계가 실제로 존재합니다.

300
00:17:06,510 --> 00:17:09,420
그래서 비전은 매우 다른 작업을 가지고 있습니다.

301
00:17:09,420 --> 00:17:14,089
그래서 저는 여러분이 언어와 비전의 차이를 인식하고,

302
00:17:14,089 --> 00:17:17,450
솔직히 말해 자연이 이 문제를 어떻게

303
00:17:17,450 --> 00:17:19,880
해결했는지 감상하기를 바랍니다.

304
00:17:19,880 --> 00:17:21,060
계속 진행합시다.

305
00:17:21,060 --> 00:17:28,150
1970년대, 데이터도 없고, 강력한 컴퓨터도 없고, 오늘날

306
00:17:28,150 --> 00:17:32,320
우리가 본 수학적 발전도 없이,

307
00:17:32,320 --> 00:17:36,970
컴퓨터 비전의 초기 개척자들이 이미

308
00:17:36,970 --> 00:17:40,290
물체 인식과 같은 어려운

309
00:17:40,290 --> 00:17:43,780
문제를 해결하기 시작했습니다.

310
00:17:43,780 --> 00:17:48,120
여기 스탠포드에서, 로드니 브룩스와 톰

311
00:17:48,120 --> 00:17:52,140
빈포드의 일반화된 실린더라는 개척 작업이

312
00:17:52,140 --> 00:17:52,900
있습니다.

313
00:17:52,900 --> 00:17:58,650
아이러니하게도, 오늘 로드니 브룩스는 캠퍼스에 있으며, 실제로

314
00:17:58,650 --> 00:18:03,520
저기 로봇 공학 회의에서 강연을 하고 있습니다.

315
00:18:03,520 --> 00:18:05,760
그는 우리 시대의 가장

316
00:18:05,760 --> 00:18:10,080
위대한 로봇 공학자가 되었고, 룸바와 많은 다른

317
00:18:10,080 --> 00:18:11,770
로봇의 창립자였습니다.

318
00:18:11,770 --> 00:18:16,530
그리고 우리와 그리 멀지 않은 팔로알토의

319
00:18:16,530 --> 00:18:24,760
다른 지역에서는 연구자들이 인간의 몸과 물체의 조합

320
00:18:24,760 --> 00:18:27,860
모델에 대해 작업했습니다.

321
00:18:27,860 --> 00:18:34,250
그리고 1980년대에는 디지털 사진이 나타나기 시작했습니다.

322
00:18:34,250 --> 00:18:37,220
최소한 사진이 나타나기 시작했습니다.

323
00:18:37,220 --> 00:18:39,680
사람들은 그것을 조금 디지털화할 수 있습니다.

324
00:18:39,680 --> 00:18:43,940
그리고 에지 감지에 대한 훌륭한 작업이 있었습니다.

325
00:18:43,940 --> 00:18:48,190
이 모든 것을 보고 아마

326
00:18:48,190 --> 00:18:50,900
실망감을 느낄 것입니다.

327
00:18:50,900 --> 00:18:55,540
스케치와 에지를 얻는 것은 다소 사소한 일입니다.

328
00:18:55,540 --> 00:18:58,460
그리고 그다지 나아가지 않고 있습니다.

329
00:18:58,460 --> 00:19:02,060
그 당시 컴퓨터 비전은 그렇게 작동했습니다.

330
00:19:02,060 --> 00:19:03,980
사실, 여러분이 틀린 것은 아닙니다.

331
00:19:03,980 --> 00:19:07,660
여러분 중 많은 사람들이 태어나기 전, 우리는

332
00:19:07,660 --> 00:19:10,280
AI 겨울에 접어들었습니다.

333
00:19:10,280 --> 00:19:15,250
이 분야는 AI 연구에 대한 열정과 자금이 정말로

334
00:19:15,250 --> 00:19:18,530
줄어들면서 AI 겨울에 접어들었습니다.

335
00:19:18,530 --> 00:19:20,510
많은 것들이 성과를 내지 못했습니다.

336
00:19:20,510 --> 00:19:22,270
컴퓨터 비전은 성과를 내지 못했습니다.

337
00:19:22,270 --> 00:19:24,460
전문 시스템은 성과를 내지 못했습니다.

338
00:19:24,460 --> 00:19:26,520
로봇 공학은 성과를 내지 못했습니다.

339
00:19:26,520 --> 00:19:32,310
하지만 이 겨울의 이면에서는 컴퓨터 비전, 자연어 처리, 로봇

340
00:19:32,310 --> 00:19:34,530
공학 등 다양한 분야에서

341
00:19:34,530 --> 00:19:37,510
많은 연구가 시작되고 있습니다.

342
00:19:37,510 --> 00:19:40,380
그래서 컴퓨터 비전에서 깊은 영향을 미친 또

343
00:19:40,380 --> 00:19:43,290
다른 연구 분야를 살펴보겠습니다. 그것은 인지

344
00:19:43,290 --> 00:19:45,270
과학과 신경 과학이 계속해서

345
00:19:45,270 --> 00:19:46,960
발전하고 있다는 것입니다.

346
00:19:46,960 --> 00:19:49,320
특히 컴퓨터 비전 분야에서 중요한

347
00:19:49,320 --> 00:19:52,480
것은 인지 과학과 신경 과학이 우리가

348
00:19:52,480 --> 00:19:55,800
작업해야 할 북극성 문제를 지적하기

349
00:19:55,800 --> 00:19:57,490
시작하고 있다는 것입니다.

350
00:19:57,490 --> 00:20:00,030
예를 들어, 심리학자들은

351
00:20:00,030 --> 00:20:02,620
자연을 보고, 실제 세계를 보는

352
00:20:02,620 --> 00:20:06,360
것에 특별한 무언가가 있다고 말했습니다.

353
00:20:06,360 --> 00:20:09,210
이것은 Irv Biederman의

354
00:20:09,210 --> 00:20:13,980
연구로, 두 이미지에서 자전거를 감지하는 것이

355
00:20:13,980 --> 00:20:18,820
이미지가 섞였는지 여부에 따라 다르다는 것을 보여줍니다.

356
00:20:18,820 --> 00:20:19,570
생각해 보세요.

357
00:20:19,570 --> 00:20:22,090
광자 관점에서 보면, 이

358
00:20:22,090 --> 00:20:26,630
두 자전거는 망막의 같은 위치에 놓입니다.

359
00:20:26,630 --> 00:20:28,720
하지만 이미지의

360
00:20:28,720 --> 00:20:39,080
나머지 부분이 관찰자가 목표 객체를 보는 방식에 영향을 미칩니다.

361
00:20:39,080 --> 00:20:41,440
그래서 전체 숲이나 전체 세계를

362
00:20:41,440 --> 00:20:44,170
보는 것이 우리가 객체를 보는 방식에

363
00:20:44,170 --> 00:20:46,730
영향을 미친다는 것을 알려줍니다.

364
00:20:46,730 --> 00:20:49,820
또한 시각 처리 속도가 매우 빠르다는 것을 알려줍니다.

365
00:20:49,820 --> 00:20:55,340
여기 객체를 감지하는 속도의 또 다른 직접적인 측정이 있습니다.

366
00:20:55,340 --> 00:21:00,670
이것은 1970년대 초 실험으로, 사람들에게

367
00:21:00,670 --> 00:21:03,061
비디오를 보여줍니다.

368
00:21:03,061 --> 00:21:07,630
피험자의 테스트는 프레임 중 하나에서 인간을

369
00:21:07,630 --> 00:21:09,170
감지하는 것입니다.

370
00:21:09,170 --> 00:21:11,920
여러분 모두가 프레임 중 하나에서 그 인간을

371
00:21:11,920 --> 00:21:13,250
보았다고 생각합니다.

372
00:21:13,250 --> 00:21:15,520
하지만 여러분의 눈이나 뇌가 얼마나 놀라운지

373
00:21:15,520 --> 00:21:19,080
생각해 보세요. 왜냐하면 여러분은 이 비디오를 본 적이 없기 때문입니다.

374
00:21:19,080 --> 00:21:22,610
어떤 프레임에서 목표 객체가 나타날지 말씀드리지

375
00:21:22,610 --> 00:21:23,160
않았습니다.

376
00:21:23,160 --> 00:21:24,980
목표 객체가 어떻게 생겼는지,

377
00:21:24,980 --> 00:21:28,860
어디에 있는지, 제스처가 무엇인지 등도 말씀드리지 않았습니다.

378
00:21:28,860 --> 00:21:31,690
그럼에도 불구하고 여러분은 인간을 감지하는 데 아무런 문제가 없습니다.

379
00:21:34,570 --> 00:21:37,670
게다가 이 프레임은 10헤르츠로

380
00:21:37,670 --> 00:21:39,860
재생되므로, 여러분은 각

381
00:21:39,860 --> 00:21:43,800
프레임을 단 100밀리초 동안만 보고 있습니다.

382
00:21:43,800 --> 00:21:47,880
이것이 우리의 시각 시스템이 얼마나 놀라운지입니다.

383
00:21:47,880 --> 00:21:53,700
사실, 또 다른 인지 신경 과학자인 Simon Thorpe는

384
00:21:53,700 --> 00:21:55,410
속도를 측정했습니다.

385
00:21:55,410 --> 00:21:58,430
사람들에게 EEG 캡을

386
00:21:58,430 --> 00:22:01,770
착용시키고 복잡한 자연 장면을

387
00:22:01,770 --> 00:22:05,870
보여주고, 동물이 있는 것과

388
00:22:05,870 --> 00:22:07,970
없는 것에서 사물을

389
00:22:07,970 --> 00:22:10,260
분류하도록

390
00:22:10,260 --> 00:22:11,310
요청했습니다.

391
00:22:11,310 --> 00:22:13,290
그리고 나서 뇌파를 측정했습니다.

392
00:22:13,290 --> 00:22:18,910
사진을 본 후 150밀리초가 지나면, 여러분의 뇌는 이미

393
00:22:18,910 --> 00:22:22,540
분류하는 차별 신호를 가지고 있다는

394
00:22:22,540 --> 00:22:24,020
것이 밝혀졌습니다.

395
00:22:24,020 --> 00:22:25,990
여러분은 그렇게 감명받지 않을 수도 있습니다.

396
00:22:25,990 --> 00:22:29,870
오늘날의 GPU와 현대 칩에 비하면

397
00:22:29,870 --> 00:22:34,550
150밀리초는 정말로 몇 배 느립니다.

398
00:22:34,550 --> 00:22:37,210
하지만 감탄해야 합니다.

399
00:22:37,210 --> 00:22:40,780
우리의 웨트웨어, 즉 뇌와 뉴런은 트랜지스터만큼

400
00:22:40,780 --> 00:22:43,370
빠르게 작동하지 않습니다.

401
00:22:43,370 --> 00:22:46,610
150밀리초는 실제로 매우 빠릅니다.

402
00:22:46,610 --> 00:22:49,310
신경 처리 측면에서 뇌에서 몇

403
00:22:49,310 --> 00:22:51,520
번의 홉에 불과합니다.

404
00:22:51,520 --> 00:22:53,950
그래서 다시 말하지만, 이것은

405
00:22:53,950 --> 00:22:59,990
인간이 객체를 보고 분류하는 데 정말로 능숙하다는 것을 알려줍니다.

406
00:22:59,990 --> 00:23:02,560
사실, 우리는 객체를 보고

407
00:23:02,560 --> 00:23:05,830
분류하는 데 매우 능숙할 뿐만 아니라,

408
00:23:05,830 --> 00:23:10,060
얼굴이나 장소, 신체 부위를 인식하는 전문적인 능력을

409
00:23:10,060 --> 00:23:13,100
가진 특수한 뇌 영역을 발전시켰습니다.

410
00:23:13,100 --> 00:23:19,040
이것들은 1990년대와 21세기 초 MIT 신경생리학자들의

411
00:23:19,040 --> 00:23:21,120
발견입니다.

412
00:23:21,120 --> 00:23:26,090
이 모든 연구들은 우리가 이러한 문자 형태나

413
00:23:26,090 --> 00:23:30,020
이미지 스케치를 연구하는 것만으로는

414
00:23:30,020 --> 00:23:33,660
충분하지 않다는 것을 알려줍니다.

415
00:23:33,660 --> 00:23:38,750
우리는 시각적 지능을 이끄는 중요한 근본적인 문제를

416
00:23:38,750 --> 00:23:40,770
추구해야 합니다.

417
00:23:40,770 --> 00:23:43,340
그 문제 중 하나는 모든

418
00:23:43,340 --> 00:23:46,100
것이 말해주는 객체 인식입니다.

419
00:23:46,100 --> 00:23:49,830
자연 환경에서의 객체 인식입니다.

420
00:23:49,830 --> 00:23:52,950
세상에는 많은 객체가 있습니다.

421
00:23:52,950 --> 00:23:57,740
이것을 연구하는 것은 시각적 지능을 여는 데

422
00:23:57,740 --> 00:24:00,300
중요한 부분이 될 것입니다.

423
00:24:00,300 --> 00:24:01,550
그것이 우리가 한 일입니다.

424
00:24:01,550 --> 00:24:04,670
우리는 전경 객체와 배경 객체를

425
00:24:04,670 --> 00:24:08,210
분리하는 방법을 살펴보는 것부터

426
00:24:08,210 --> 00:24:09,960
시작했습니다.

427
00:24:09,960 --> 00:24:14,570
이것은 1990년대에 그룹화에 의한 인식이라고 불립니다.

428
00:24:14,570 --> 00:24:16,850
우리는 여전히 AI 겨울에 있다는 점을 명심하세요.

429
00:24:16,850 --> 00:24:20,090
하지만 연구는 실제로 진행되고 있습니다.

430
00:24:20,090 --> 00:24:24,560
그리고 특징에 대한 연구가 있었습니다.

431
00:24:24,560 --> 00:24:27,550
여러분 중 일부는 여전히 SIFT 특징과

432
00:24:27,550 --> 00:24:29,780
매칭을 기억할 수 있습니다.

433
00:24:29,780 --> 00:24:33,610
제가 대학원에 들어갔을 때 가장 흥미로운 것은 얼굴

434
00:24:33,610 --> 00:24:34,790
인식이었습니다.

435
00:24:34,790 --> 00:24:37,280
대학원 첫 해에 이 논문이

436
00:24:37,280 --> 00:24:39,380
발표된 것을 기억합니다.

437
00:24:39,380 --> 00:24:42,550
5년 후, 첫 디지털

438
00:24:42,550 --> 00:24:49,030
카메라가 이 논문의 알고리즘을 사용하여 자동 얼굴

439
00:24:49,030 --> 00:24:51,260
초점을 제공했습니다.

440
00:24:51,260 --> 00:24:56,560
그래서 일이 시작되었고 산업에 도입되었습니다.

441
00:24:56,560 --> 00:25:01,190
그리고 21세기 초에 매우 중요한

442
00:25:01,190 --> 00:25:04,810
일이 시작되었습니다. 인터넷이

443
00:25:04,810 --> 00:25:06,820
시작된 것입니다.

444
00:25:06,820 --> 00:25:12,600
인터넷이 시작되면서 데이터가 proliferate하기 시작했습니다.

445
00:25:12,600 --> 00:25:16,970
디지털 카메라와 인터넷의 결합은 컴퓨터

446
00:25:16,970 --> 00:25:19,850
비전 분야에 작업할 데이터를

447
00:25:19,850 --> 00:25:22,050
제공하기 시작했습니다.

448
00:25:22,050 --> 00:25:26,420
그래서 그 초기에는 수천 개 또는 수만 개의

449
00:25:26,420 --> 00:25:30,470
이미지를 가지고 시각 인식 문제 또는 객체

450
00:25:30,470 --> 00:25:32,880
인식 문제를 연구했습니다.

451
00:25:32,880 --> 00:25:36,350
Pascal Visual Object Challenge나

452
00:25:36,350 --> 00:25:40,760
Caltech 101과 같은 데이터 세트가 있었습니다.

453
00:25:40,760 --> 00:25:43,610
여기서 잠시 멈추겠습니다.

454
00:25:43,610 --> 00:25:50,060
여기서 컴퓨터 비전의 첫 번째 실마리가 발전하기

455
00:25:50,060 --> 00:25:51,060
시작합니다.

456
00:25:51,060 --> 00:25:54,420
여러분은 왜 그녀가 멈추는지 궁금할 수 있습니다.

457
00:25:54,420 --> 00:25:57,300
왜냐하면 저는 딥러닝에 대해 다시 이야기할 것이기 때문입니다.

458
00:25:57,300 --> 00:26:03,170
시각 분야가 신경생리학에서 컴퓨터 비전,

459
00:26:03,170 --> 00:26:06,980
인지 신경과학, 다시 컴퓨터

460
00:26:06,980 --> 00:26:11,490
비전으로 발전하는 동안, 별도의

461
00:26:11,490 --> 00:26:14,980
노력이 병행되고 있었습니다.

462
00:26:14,980 --> 00:26:17,380
그것이 결국 딥러닝이 되었습니다.

463
00:26:17,380 --> 00:26:22,870
이것은 초기 신경망 연구, 퍼셉트론과 같은 것에서

464
00:26:22,870 --> 00:26:24,270
시작되었습니다.

465
00:26:24,270 --> 00:26:29,800
Rumelhart와 같은 사람들이 작업을 시작했습니다.

466
00:26:29,800 --> 00:26:32,140
물론, Jeff Hinton은

467
00:26:32,140 --> 00:26:35,400
초기 시절에 소수의 인공 뉴런으로

468
00:26:35,400 --> 00:26:41,010
작업을 시작하고 그것이 정보를 처리하고 학습하는 방법을 살펴보았습니다.

469
00:26:41,010 --> 00:26:48,270
여러분은 Marvin Minsky와 그의 동료들처럼 이 인식의

470
00:26:48,270 --> 00:26:52,620
다양한 측면에서 작업하는 위대한 정신들을

471
00:26:52,620 --> 00:26:54,550
들었을 것입니다.

472
00:26:54,550 --> 00:27:02,850
하지만 마빈 민스키는 퍼셉트론이 XOR 논리 함수를 배울 수

473
00:27:02,850 --> 00:27:05,220
없다고 말했습니다.

474
00:27:05,220 --> 00:27:10,130
그리고 그것은 신경망에 약간의 차질을 초래했습니다.

475
00:27:10,130 --> 00:27:14,670
하지만 차질에도 불구하고 상황은 계속 발전했습니다.

476
00:27:14,670 --> 00:27:21,530
첫 번째 전환점 이전의 가장 중요한 작업 중 하나는 일본

477
00:27:21,530 --> 00:27:25,890
후쿠시마의 이 네오코그니트론 작업입니다.

478
00:27:25,890 --> 00:27:31,980
후쿠시마는 이렇게 생긴 신경망을 손으로 설계했습니다.

479
00:27:31,980 --> 00:27:35,700
약 5개 또는 6개의 층이 있습니다.

480
00:27:35,700 --> 00:27:41,780
그리고 그는 층마다 다양한 기능을 설계했으며,

481
00:27:41,780 --> 00:27:43,700
이는

482
00:27:43,700 --> 00:27:46,910
제가 설명한 시각

483
00:27:46,910 --> 00:27:50,850
경로에서 영감을 받았습니다.

484
00:27:50,850 --> 00:27:54,560
간단한 수용 필드에서 더 복잡한 수용 필드로의

485
00:27:54,560 --> 00:27:56,790
고양이 실험을 기억하세요.

486
00:27:56,790 --> 00:27:59,040
그는 여기서 그런 작업을 하고 있었습니다.

487
00:27:59,040 --> 00:28:01,830
초기 층은 간단한 기능을 가지고 있습니다.

488
00:28:01,830 --> 00:28:03,270
그리고 나중의 더 밝은

489
00:28:03,270 --> 00:28:05,490
층은 더 복잡한 기능을 가지고 있습니다.

490
00:28:05,490 --> 00:28:08,680
간단한 것들은 합성곱이라고 부를 수 있습니다.

491
00:28:08,680 --> 00:28:10,710
그는 합성곱 함수를 사용합니다.

492
00:28:10,710 --> 00:28:13,620
더 복잡한 것에서는 합성곱 층에서

493
00:28:13,620 --> 00:28:15,220
정보를 끌어왔습니다.

494
00:28:15,220 --> 00:28:19,800
그래서 네오코그니트론은 모든 매개변수가

495
00:28:19,800 --> 00:28:24,795
손으로 설계된 공학적 업적이었습니다.

496
00:28:24,795 --> 00:28:26,170
수백 개의 매개변수가 있습니다.

497
00:28:26,170 --> 00:28:29,430
그는 이 작은 신경망이 숫자나

498
00:28:29,430 --> 00:28:32,610
문자를 인식할 수 있도록

499
00:28:32,610 --> 00:28:35,910
세심하게 조합해야 했습니다.

500
00:28:35,910 --> 00:28:41,130
실질적인 돌파구는 1986년경에 학습 규칙이

501
00:28:41,130 --> 00:28:43,180
등장하면서 왔습니다.

502
00:28:43,180 --> 00:28:45,580
그 학습 규칙은 역전파라고 불립니다.

503
00:28:45,580 --> 00:28:47,580
이것은

504
00:28:47,580 --> 00:28:52,455
Rumelhart와 Jeff Hinton이

505
00:28:52,455 --> 00:28:58,020
신경망 아키텍처를 가져와 오류 수정 목표

506
00:28:58,020 --> 00:29:04,260
함수를 도입하여 입력을 넣고 올바른 출력이

507
00:29:04,260 --> 00:29:07,400
무엇인지 알 때, 신경망의

508
00:29:07,400 --> 00:29:10,280
출력과 실제 정답

509
00:29:10,280 --> 00:29:14,780
간의 차이를 어떻게 계산하고 정보를

510
00:29:14,780 --> 00:29:17,900
다시 전파하여 신경망의

511
00:29:17,900 --> 00:29:22,640
매개변수를 개선할 수 있는지를

512
00:29:22,640 --> 00:29:28,590
보여주는 첫 번째 수업 중 하나가 될 것입니다.

513
00:29:28,590 --> 00:29:31,250
출력에서 전체

514
00:29:31,250 --> 00:29:33,800
신경망으로의 전파를

515
00:29:33,800 --> 00:29:35,850
역전파라고 합니다.

516
00:29:35,850 --> 00:29:39,180
이는 기본 미적분 체인 규칙 중 일부를 따릅니다.

517
00:29:39,180 --> 00:29:47,420
그리고 그것은 신경망 알고리즘의 중대한 순간이었습니다.

518
00:29:47,420 --> 00:29:50,970
물론 우리는 여전히 AI 겨울의 한가운데에 있습니다.

519
00:29:50,970 --> 00:29:54,810
이 모든 작업은 대중의 주목 없이 진행되었습니다.

520
00:29:54,810 --> 00:29:57,930
하지만 연구 세계에서는 이것들이 매우

521
00:29:57,930 --> 00:29:59,650
중요한 이정표입니다.

522
00:29:59,650 --> 00:30:03,720
역전파가 적용된 신경망의 가장 초기 응용

523
00:30:03,720 --> 00:30:07,020
중 하나는 1990년대 벨 연구소에서

524
00:30:07,020 --> 00:30:10,410
작업하던 얀 르쿤의 합성곱

525
00:30:10,410 --> 00:30:11,500
신경망입니다.

526
00:30:11,500 --> 00:30:15,970
그가 한 일은 약 7개 층 정도의 조금 더

527
00:30:15,970 --> 00:30:20,610
큰 네트워크를 만들고, 문자를 인식할 수

528
00:30:20,610 --> 00:30:25,120
있도록 훌륭한 공학적 능력을 갖춘 것입니다.

529
00:30:25,120 --> 00:30:28,710
실제로 미국 우체국과 은행의

530
00:30:28,710 --> 00:30:33,580
일부에 배송되어 숫자와 문자를 읽었습니다.

531
00:30:33,580 --> 00:30:37,600
그래서 그것은 초기 신경망의 응용이었습니다.

532
00:30:37,600 --> 00:30:41,250
그리고 제프 힌튼과 얀 르쿤은 신경망에

533
00:30:41,250 --> 00:30:43,390
대한 작업을 계속했습니다.

534
00:30:43,390 --> 00:30:45,720
그것은 그리 멀리 가지 않았습니다.

535
00:30:45,720 --> 00:30:52,050
이 신경망의 개선과 조정에도 불구하고,

536
00:30:52,050 --> 00:30:57,290
상황은 더 이상 진전이 없었습니다.

537
00:30:57,290 --> 00:31:00,280
그들은 숫자와 문자로 구성된 대규모 데이터 세트를 수집했습니다.

538
00:31:00,280 --> 00:31:03,730
숫자와 문자는 인식 측면에서 준 소프트한

539
00:31:03,730 --> 00:31:05,090
특성을 가졌습니다.

540
00:31:05,090 --> 00:31:08,020
하지만 신경과학자들이 고양이, 개,

541
00:31:08,020 --> 00:31:11,500
전자레인지, 의자, 꽃을 인식하기 위해

542
00:31:11,500 --> 00:31:14,470
사용한 디지털 사진을 시스템에 넣으면,

543
00:31:14,470 --> 00:31:17,180
전혀 작동하지 않았습니다.

544
00:31:17,180 --> 00:31:22,550
이 문제의 큰 부분은 데이터 부족입니다.

545
00:31:22,550 --> 00:31:27,500
데이터 부족은 단순한 불편함이 아닙니다.

546
00:31:27,500 --> 00:31:29,990
이는 실제로 수학적

547
00:31:29,990 --> 00:31:36,430
문제입니다. 이러한 알고리즘은 일반화 학습을 위해 많은 데이터에

548
00:31:36,430 --> 00:31:39,850
의해 구동되어야 하는 고용량

549
00:31:39,850 --> 00:31:42,350
알고리즘이기 때문입니다.

550
00:31:42,350 --> 00:31:45,010
일반화 및 모델 과적합의

551
00:31:45,010 --> 00:31:48,380
규칙 뒤에는 깊은 수학적 원리가

552
00:31:48,380 --> 00:31:49,210
있습니다.

553
00:31:49,210 --> 00:31:52,660
데이터는 과소평가되었고, 대부분의

554
00:31:52,660 --> 00:31:54,840
사람들은 이러한 구조에만

555
00:31:54,840 --> 00:31:56,560
주목했습니다.

556
00:31:56,560 --> 00:31:59,190
그들은 데이터가 기계 학습과 딥

557
00:31:59,190 --> 00:32:02,070
러닝의 1급 시민의 일부라는 것을

558
00:32:02,070 --> 00:32:03,490
깨닫지 못했습니다.

559
00:32:03,490 --> 00:32:08,340
그래서 이것은 2000년대 초에 저와 제

560
00:32:08,340 --> 00:32:14,760
학생들이 한 작업의 일부로, 데이터의 중요성을

561
00:32:14,760 --> 00:32:15,640
인식했습니다.

562
00:32:15,640 --> 00:32:21,240
우리는 전체 분야가 실제로 이 점을 간과하고

563
00:32:21,240 --> 00:32:24,520
있다는 가설을 세웠습니다.

564
00:32:24,520 --> 00:32:27,090
그래서 우리는 10억 개의 이미지를 정리한

565
00:32:27,090 --> 00:32:30,120
후 5천만 개의 이미지를 포함하는 대규모 데이터

566
00:32:30,120 --> 00:32:32,260
세트인 ImageNet을 수집했습니다.

567
00:32:32,260 --> 00:32:38,310
이 1500만 개의 이미지는 22,000개의 객체 카테고리로

568
00:32:38,310 --> 00:32:39,310
분류되었습니다.

569
00:32:39,310 --> 00:32:43,110
우리는 22,000개의 카테고리가

570
00:32:43,110 --> 00:32:51,480
인간이 생애 초기 몇 년 동안 인식하는 카테고리 수와 대략

571
00:32:51,480 --> 00:32:54,880
일치한다는 것을 이해하기 위해

572
00:32:54,880 --> 00:32:58,510
많은 인지 및 심리학 문헌을

573
00:32:58,510 --> 00:33:00,470
연구했습니다.

574
00:33:00,470 --> 00:33:02,180
그리고 우리는 이 데이터

575
00:33:02,180 --> 00:33:05,860
세트를 오픈 소스화하고 대규모 시각 인식 챌린지라는 ImageNet

576
00:33:05,860 --> 00:33:07,580
챌린지를 만들었습니다.

577
00:33:07,580 --> 00:33:12,700
우리는 100만 개 이상의 이미지와 1,000개의 객체

578
00:33:12,700 --> 00:33:16,870
클래스로 구성된 ImageNet의 하위 집합을

579
00:33:16,870 --> 00:33:21,430
큐레이션하고, 여러 해 동안 국제 객체 인식 챌린지를

580
00:33:21,430 --> 00:33:22,040
진행했습니다.

581
00:33:22,040 --> 00:33:26,900
목표는 연구자들에게 참여를 요청하는 것입니다.

582
00:33:26,900 --> 00:33:29,420
그들의 목표는 알고리즘을 만드는 것입니다.

583
00:33:29,420 --> 00:33:31,430
어떤 종류의 알고리즘이든 상관없습니다.

584
00:33:31,430 --> 00:33:35,650
그들은 당신의 알고리즘이 사진을 인식하는 능력을 테스트하고,

585
00:33:35,650 --> 00:33:40,900
1,000개의 객체 클래스를 가능한 한 정확하게 호출할 수

586
00:33:40,900 --> 00:33:42,800
있는지를 확인할 것입니다.

587
00:33:42,800 --> 00:33:45,040
여기 오류가 있습니다.

588
00:33:45,040 --> 00:33:53,070
이 대회를 처음 개최했을 때, 가장 성능이 좋은 알고리즘의

589
00:33:53,070 --> 00:33:57,000
오류율은 거의 30%였습니다.

590
00:33:57,000 --> 00:34:00,860
이는 정말 끔찍한 수치입니다. 인간은 약 3%의

591
00:34:00,860 --> 00:34:03,510
오류로 수행할 수 있습니다.

592
00:34:03,510 --> 00:34:07,260
그리고 2011년은 그리 흥미롭지 않았습니다.

593
00:34:07,260 --> 00:34:09,560
하지만 2012년에 무언가가 일어났습니다.

594
00:34:09,560 --> 00:34:12,389
그 해는 가장 흥미로운 해였습니다.

595
00:34:12,389 --> 00:34:16,190
그 해, 제프 힌튼과 그의 학생들이 합성곱

596
00:34:16,190 --> 00:34:18,650
신경망을 사용하여 이

597
00:34:18,650 --> 00:34:20,340
챌린지에 참여했습니다.

598
00:34:20,340 --> 00:34:23,100
그들은 오류를 거의 절반으로 줄였습니다.

599
00:34:23,100 --> 00:34:29,520
이는 딥 러닝 알고리즘의 힘을 진정으로 보여주었습니다.

600
00:34:29,520 --> 00:34:34,760
2012년 ImageNet 챌린지에 참여한 알고리즘은

601
00:34:34,760 --> 00:34:36,960
AlexNet이라고 불렸습니다.

602
00:34:36,960 --> 00:34:42,560
재미있는 점은 AlexNet을 보면, 32년 전

603
00:34:42,560 --> 00:34:47,449
후쿠시마의 네오코그니트론과 그리 다르지

604
00:34:47,449 --> 00:34:49,580
않다는 것입니다.

605
00:34:49,580 --> 00:34:54,830
하지만 이 두 가지 사이에 두 가지 주요한 일이 일어났습니다.

606
00:34:54,830 --> 00:34:57,530
하나는 역전파가 발생했습니다.

607
00:34:57,530 --> 00:35:01,270
이는 원칙적이고 수학적으로 엄밀한 학습

608
00:35:01,270 --> 00:35:04,300
규칙으로, 매개변수를 수동으로 조정할

609
00:35:04,300 --> 00:35:06,140
필요가 없습니다.

610
00:35:06,140 --> 00:35:09,410
이것은 이론적으로 중요한 돌파구였습니다.

611
00:35:09,410 --> 00:35:14,180
또 다른 돌파구는 데이터였습니다.

612
00:35:14,180 --> 00:35:19,630
데이터의 인식과 이러한 고용량 모델을

613
00:35:19,630 --> 00:35:23,200
구동하는 데이터의 이해는

614
00:35:23,200 --> 00:35:26,110
결국 조 단위의

615
00:35:26,110 --> 00:35:34,831
매개변수를 가질 모델을 위한 깊은 학습을 시작하는 데

616
00:35:34,831 --> 00:35:36,410
중요했습니다.

617
00:35:36,410 --> 00:35:42,406
실제로 많은 사람들은 2012년과 ImageNet 챌린지를

618
00:35:42,406 --> 00:35:46,870
우승한 AlexNet 알고리즘을 현대

619
00:35:46,870 --> 00:35:51,020
AI의 탄생 또는 재탄생, 또는 딥러닝

620
00:35:51,020 --> 00:35:54,410
혁명의 탄생의 역사적 순간으로

621
00:35:54,410 --> 00:35:55,760
간주합니다.

622
00:35:55,760 --> 00:35:59,540
물론 여러분 중 많은 분들이 여기 있는 이유는

623
00:35:59,540 --> 00:36:04,320
그 이후로 우리는 딥러닝 폭발의 시대에 있기 때문입니다.

624
00:36:04,320 --> 00:36:10,910
컴퓨터 비전을 살펴보면, CVPR이라는 주요 연례 연구

625
00:36:10,910 --> 00:36:13,190
회의에서 논문 수가

626
00:36:13,190 --> 00:36:15,620
폭발적으로 증가했습니다.

627
00:36:15,620 --> 00:36:18,870
우리의 arXiv 논문도 폭발적으로 증가했습니다.

628
00:36:18,870 --> 00:36:22,730
그 이후로 ImageNet 챌린지에

629
00:36:22,730 --> 00:36:27,350
참여하기 위해 많은 새로운 알고리즘이 발명되었습니다.

630
00:36:27,350 --> 00:36:28,050
참여하기 위해 많은 새로운 알고리즘이 발명되었습니다.

631
00:36:28,050 --> 00:36:29,870
앞으로 몇 년 동안 우리는 이러한

632
00:36:29,870 --> 00:36:31,740
알고리즘 중 일부를 공부할 것입니다.

633
00:36:31,740 --> 00:36:34,640
하지만 요점은

634
00:36:34,640 --> 00:36:39,380
AlexNet을 넘어선 이러한 알고리즘 중

635
00:36:39,380 --> 00:36:43,610
일부가 컴퓨터 비전 분야의 발전과

636
00:36:43,610 --> 00:36:49,090
응용에 깊은 영향을 미쳤다는 것입니다.

637
00:36:49,090 --> 00:36:52,720
많은 일이 일어났습니다.

638
00:36:52,720 --> 00:36:54,530
우리는 이러한 것들 중 일부를 다룰 것입니다.

639
00:36:54,530 --> 00:36:57,340
컴퓨터 비전 분야는 고양이,

640
00:36:57,340 --> 00:37:01,510
개, 의자와 같은 일상적인 물체를

641
00:37:01,510 --> 00:37:06,260
인식하는 알고리즘을 만드는 데 큰 발전을

642
00:37:06,260 --> 00:37:10,400
이루었을 뿐만 아니라, ImageNet

643
00:37:10,400 --> 00:37:14,140
챌린지 직후인 2012년 순간에

644
00:37:14,140 --> 00:37:22,550
훨씬 더 복잡한 이미지를 인식하고, 이미지를 검색하고, 여러 객체 탐지를

645
00:37:22,550 --> 00:37:27,470
수행하고, 이미지 분할을 할 수 있는

646
00:37:27,470 --> 00:37:30,560
알고리즘을 빠르게 개발했습니다.

647
00:37:30,560 --> 00:37:34,360
이들은 시각 인식에서 여러분이 이 과정에서

648
00:37:34,360 --> 00:37:36,220
익숙해질 다양한

649
00:37:36,220 --> 00:37:38,690
작업입니다. 비전은 단순히

650
00:37:38,690 --> 00:37:42,140
고양이와 개를 부르는 것이 아닙니다.

651
00:37:42,140 --> 00:37:48,860
시각 인식의 미묘한 능력에는 많은 것이 있습니다.

652
00:37:48,860 --> 00:37:52,830
물론 비전은 정적인 이미지에 국한되지 않습니다.

653
00:37:52,830 --> 00:37:57,500
비디오 분류, 인간 활동 인식에 대한 연구도

654
00:37:57,500 --> 00:37:58,710
있습니다.

655
00:37:58,710 --> 00:38:00,930
이 개요를 보여드리고 있습니다.

656
00:38:00,930 --> 00:38:04,775
여러분은 이러한 것들 중 일부를 배우게 될 것입니다.

657
00:38:04,775 --> 00:38:08,460
여기서 무슨 일이 일어나고 있는지 정확히 이해할 필요는 없습니다.

658
00:38:08,460 --> 00:38:14,940
하지만 시각 작업의 다양성을 인식해 주셨으면 합니다.

659
00:38:14,940 --> 00:38:20,870
의료 이미징, 의료 분야에서 오신 분들은 방사선학,

660
00:38:20,870 --> 00:38:24,650
병리학 또는 의학의 다른 측면에서

661
00:38:24,650 --> 00:38:28,260
깊은 시각적 요소가 있습니다.

662
00:38:28,260 --> 00:38:31,550
이것은 깊은 영향을 미칩니다.

663
00:38:31,550 --> 00:38:37,550
과학적 발견 - 아마도 여러분이 기억할 첫

664
00:38:37,550 --> 00:38:41,700
번째 블랙홀 사진은 많은 컴퓨터

665
00:38:41,700 --> 00:38:46,830
비전 및 계산 사진 기술을

666
00:38:46,830 --> 00:38:47,980
사용했습니다.

667
00:38:47,980 --> 00:38:52,980
물론 지속 가능성과 환경 분야의

668
00:38:52,980 --> 00:38:58,890
응용에서도 컴퓨터 비전이 많은 기여를 했습니다.

669
00:38:58,890 --> 00:39:02,310
우리는 또한 2012년 그 순간

670
00:39:02,310 --> 00:39:07,450
이후 이미지 캡셔닝에서도 많은 발전을 이루었습니다.

671
00:39:07,450 --> 00:39:09,990
이것은 실제로 Andrej Karpathy의

672
00:39:09,990 --> 00:39:13,800
작업으로, 그는 제 학생이었고 그의 논문 작업입니다.

673
00:39:13,800 --> 00:39:19,030
그런 다음 우리는 관계 이해에 대해서도 작업했습니다.

674
00:39:19,030 --> 00:39:22,710
시각 지능은 픽셀에서 무엇을

675
00:39:22,710 --> 00:39:24,640
보는 것뿐만 아니라,

676
00:39:24,640 --> 00:39:26,860
객체의 관계와

677
00:39:26,860 --> 00:39:33,360
스타일 전송을 포함하여 픽셀 너머의 것을 볼 수 있습니다.

678
00:39:33,360 --> 00:39:35,880
이 작업의 많은 부분은 실제로

679
00:39:35,880 --> 00:39:39,000
이 과정의 게스트 강사로 올 저스틴

680
00:39:39,000 --> 00:39:45,320
존슨이 스타일 전이에서 그의 기념비적인 작업에 대해 모두 이야기할 것입니다.

681
00:39:45,320 --> 00:39:48,510
물론 생성 AI 시대에는 얼굴

682
00:39:48,510 --> 00:39:53,430
생성과 같은 정말 놀라운 결과를 얻습니다.

683
00:39:53,430 --> 00:39:59,240
그리고 이것은 Dall-E의 이미지 생성 초기 단계입니다. 이것이 초기
Dall-E라고

684
00:39:59,240 --> 00:40:03,380
생각합니다. 물론 이제 Midjourney와 모든

685
00:40:03,380 --> 00:40:08,690
것이 이러한 아보카도와 복숭아 의자를 넘어섰습니다.

686
00:40:08,690 --> 00:40:14,780
하지만 정말로 우리는 AI 폭발의 가장 흥미로운 현대

687
00:40:14,780 --> 00:40:16,246
시대에 있습니다.

688
00:40:20,070 --> 00:40:25,370
계산, 알고리즘, 데이터의 세 가지 수렴하는

689
00:40:25,370 --> 00:40:29,720
힘이 이 분야를 완전히 다른 수준으로

690
00:40:29,720 --> 00:40:32,930
끌어올렸고, 우리는 이제 AI

691
00:40:32,930 --> 00:40:36,120
겨울에서 완전히 벗어났습니다.

692
00:40:36,120 --> 00:40:40,260
저는 우리가 AI 지구온난화 기간에 있다고 말하고 싶습니다.

693
00:40:40,260 --> 00:40:46,050
그리고 좋은 이유와 나쁜 이유 모두에서 이것이

694
00:40:46,050 --> 00:40:48,820
느려질 것 같지 않습니다.

695
00:40:48,820 --> 00:40:53,170
그리고 실리콘 밸리에 있기 때문에,

696
00:40:53,170 --> 00:40:58,050
우리는 황 건물과 NVIDIA 강의실에

697
00:40:58,050 --> 00:41:02,040
있으므로 하드웨어의 발전과 그

698
00:41:02,040 --> 00:41:05,050
역할도 무시할 수 없습니다.

699
00:41:05,050 --> 00:41:14,080
여기 NVIDIA의 GPU에 대한 FLOP당 그래프가 있습니다.

700
00:41:14,080 --> 00:41:19,210
2020년 이전에는 발전이 꾸준했습니다.

701
00:41:19,210 --> 00:41:22,800
하지만 딥러닝이 이러한

702
00:41:22,800 --> 00:41:27,420
GPU와 칩을 구동하기 시작하자

703
00:41:27,420 --> 00:41:33,520
GFLOPS가 완전히 급증한 것을 볼 수 있습니다.

704
00:41:33,520 --> 00:41:40,610
어떤 기준으로 보더라도 우리는 많은 계산과 많은

705
00:41:40,610 --> 00:41:45,360
AI의 가속화된 곡선에 있습니다.

706
00:41:45,360 --> 00:41:47,360
이 그래프들은 컴퓨터

707
00:41:47,360 --> 00:41:50,540
비전뿐만 아니라 AI의 컨퍼런스

708
00:41:50,540 --> 00:41:54,500
참석자, 스타트업, 기업 응용 프로그램을

709
00:41:54,500 --> 00:41:55,710
보여줍니다.

710
00:41:55,710 --> 00:42:02,100
하지만 NLP와 다른 분야도 폭발적으로 성장했습니다.

711
00:42:02,100 --> 00:42:06,300
그래서 빠르게, 마지막으로, 흥미로운 일이 많았습니다.

712
00:42:06,300 --> 00:42:08,070
많은 성공이 있었습니다.

713
00:42:08,070 --> 00:42:11,310
하지만 컴퓨터 비전에서 여전히 해야 할 일이 많습니다.

714
00:42:11,310 --> 00:42:14,330
이 문제는 아직 완전히 해결되지 않았습니다.

715
00:42:14,330 --> 00:42:19,970
훌륭한 도구에는 큰 결과가 따릅니다.

716
00:42:19,970 --> 00:42:24,450
그래서 컴퓨터 비전은 많은 선한 일을 할 수 있습니다.

717
00:42:24,450 --> 00:42:26,040
하지만 해를 끼칠 수도 있습니다.

718
00:42:26,040 --> 00:42:28,730
예를 들어, 인간의 편견 - 오늘날의

719
00:42:28,730 --> 00:42:32,360
모든 AI 알고리즘, 대규모 알고리즘은 데이터에

720
00:42:32,360 --> 00:42:33,880
의해 구동됩니다.

721
00:42:33,880 --> 00:42:38,550
데이터는 지구와 역사에서 인간 활동의

722
00:42:38,550 --> 00:42:40,360
산물입니다.

723
00:42:40,360 --> 00:42:43,900
많은 데이터는 우리의 편견을 담고 있습니다.

724
00:42:43,900 --> 00:42:47,200
이것은 AI 시스템에 전달됩니다.

725
00:42:47,200 --> 00:42:50,610
우리는 많은 얼굴 인식 알고리즘이 인간이 가진 것과 같은

726
00:42:50,610 --> 00:42:52,990
편견을 가지고 있는 것을 보았습니다.

727
00:42:52,990 --> 00:42:55,920
우리는 이를 정말로 인식해야 합니다.

728
00:42:55,920 --> 00:43:01,450
우리는 AI를 사용하여 인간의 삶에 영향을 미칠 수 있으며, 일부는 선한
방향으로.

729
00:43:01,450 --> 00:43:02,890
의료 이미징을 생각해 보세요.

730
00:43:02,890 --> 00:43:05,200
하지만 일부는 의문이 듭니다.

731
00:43:05,200 --> 00:43:09,300
AI가 당신의 직업이나 재정 대출 결정을 전적으로

732
00:43:09,300 --> 00:43:11,620
담당한다면 어떻게 될까요?

733
00:43:11,620 --> 00:43:15,790
그렇다면, 정말 나쁜 것인가요?

734
00:43:15,790 --> 00:43:17,050
정말 좋은 것인가요?

735
00:43:17,050 --> 00:43:19,150
이것들은 매우 복잡한 문제입니다.

736
00:43:19,150 --> 00:43:23,490
이것이 바로 제가 HMS, 법대, 교육대, 경영대의

737
00:43:23,490 --> 00:43:26,550
학생들이 제 수업에 참석할 때마다 항상

738
00:43:26,550 --> 00:43:29,670
흥분하는 이유입니다. 모든 AI 문제는

739
00:43:29,670 --> 00:43:31,790
공학적 문제만은 아닙니다.

740
00:43:31,790 --> 00:43:36,560
우리는 해결해야 할 많은 인간적 요인과 사회적 문제가 있습니다.

741
00:43:36,560 --> 00:43:40,600
저는 AI의 의학 및 건강 관리 활용에 특히 흥미를

742
00:43:40,600 --> 00:43:41,140
느낍니다.

743
00:43:41,140 --> 00:43:43,960
이것은 제 마음에 정말 소중한 것입니다.

744
00:43:43,960 --> 00:43:46,120
이 과정의 공동 강사인

745
00:43:46,120 --> 00:43:49,630
아델리 교수와 제인과 함께, 우리는

746
00:43:49,630 --> 00:43:53,500
노인 인구와 환자를 위한 AI 연구를 하고

747
00:43:53,500 --> 00:43:59,050
있으며, 컴퓨터 비전을 사용하여 사람들에게 치료를 제공하려고

748
00:43:59,050 --> 00:44:00,170
합니다.

749
00:44:00,170 --> 00:44:01,820
그래서 이것은 좋은 활용입니다.

750
00:44:01,820 --> 00:44:04,820
그리고 기술 측면에서도 인간의

751
00:44:04,820 --> 00:44:07,190
시각은 놀랍습니다.

752
00:44:07,190 --> 00:44:10,670
저는 여러분이 오늘 수업뿐만 아니라 이

753
00:44:10,670 --> 00:44:14,240
전체 과정에서 컴퓨터 비전이 할 수

754
00:44:14,240 --> 00:44:16,970
있는 것에도 불구하고, 인간의

755
00:44:16,970 --> 00:44:22,250
시각에는 훨씬 더 많은 뉘앙스, 미묘함, 풍부함, 복잡성,

756
00:44:22,250 --> 00:44:26,390
그리고 감정이 있다는 것을 인식하기를 바랍니다.

757
00:44:26,390 --> 00:44:29,370
이 아이들이 호기심에 이끌려

758
00:44:29,370 --> 00:44:33,160
공부하는 모습이나 이 이미지의 유머를 보세요.

759
00:44:33,160 --> 00:44:36,130
컴퓨터 비전이 할 수 없는 것이 여전히 많습니다.

760
00:44:36,130 --> 00:44:38,430
그래서 제가 여러분이 컴퓨터 비전을

761
00:44:38,430 --> 00:44:40,870
공부하도록 계속 유도하기를 바랍니다.

762
00:44:40,870 --> 00:44:45,690
이제 아델리 교수에게 마이크를 넘겨 나머지 수업을

763
00:44:45,690 --> 00:44:48,370
진행하도록 하겠습니다.

764
00:44:48,370 --> 00:44:49,040
감사합니다.

765
00:44:49,040 --> 00:44:50,760
[박수]

766
00:44:50,760 --> 00:44:51,990
멋져요.

767
00:44:51,990 --> 00:44:55,140
감사합니다, Fei-Fei.

768
00:44:55,140 --> 00:44:57,090
학기 시작이 좋습니다.

769
00:44:57,090 --> 00:45:00,640
제 마이크가 잘 작동하길 바랍니다.

770
00:45:00,640 --> 00:45:01,390
좋아요, 잘 됐습니다.

771
00:45:01,390 --> 00:45:05,730
고개를 끄덕이는 분들이 보입니다.

772
00:45:05,730 --> 00:45:13,080
여러분과 함께 할 수 있어 매우 기쁩니다.

773
00:45:13,080 --> 00:45:18,630
여러분이 훌륭한 강사와 멋진 조교들과

774
00:45:18,630 --> 00:45:23,160
함께 재미있고 도전적인 수업을

775
00:45:23,160 --> 00:45:26,380
경험하길 바랍니다.

776
00:45:26,380 --> 00:45:31,000
이번 수업에서는 컴퓨터 비전과 이

777
00:45:31,000 --> 00:45:34,690
분야에서의 딥러닝 사용에

778
00:45:34,690 --> 00:45:37,660
관한 다양한 주제를 네

779
00:45:37,660 --> 00:45:41,570
가지로 나누어 다룰 것입니다.

780
00:45:41,570 --> 00:45:45,230
딥러닝 기초부터 시작하겠습니다.

781
00:45:45,230 --> 00:45:48,430
사실, 컴퓨터 비전이 무엇인지에

782
00:45:48,430 --> 00:45:52,010
대한 간단한 질문으로 시작해 보겠습니다.

783
00:45:52,010 --> 00:45:57,610
본질적으로, 이는 기계가 이미지를 보고 이해할

784
00:45:57,610 --> 00:46:00,620
수 있도록 하는 것입니다.

785
00:46:00,620 --> 00:46:09,340
기본적으로, 이 분야에서 가장 근본적인 작업은

786
00:46:09,340 --> 00:46:13,390
이미지 분류입니다.

787
00:46:13,390 --> 00:46:17,060
모델에 고양이의 이미지를 제공하면,

788
00:46:17,060 --> 00:46:21,550
모델은 '고양이'라는 레이블을 출력해야 합니다.

789
00:46:21,550 --> 00:46:23,740
그게 전부입니다.

790
00:46:23,740 --> 00:46:29,480
하지만 이 겉보기에는 간단한 작업이 자율주행부터

791
00:46:29,480 --> 00:46:32,040
의료 진단 등 더

792
00:46:32,040 --> 00:46:36,410
복잡한 응용 프로그램의 기초입니다.

793
00:46:36,410 --> 00:46:40,430
그렇다면 기계에게 이를 어떻게 가르칠까요?

794
00:46:40,430 --> 00:46:44,640
가장 간단한 접근 방식 중 하나는 이 슬라이드에서 볼

795
00:46:44,640 --> 00:46:48,090
수 있는 선형 분류를 사용하는 것입니다.

796
00:46:48,090 --> 00:46:53,810
우리 데이터 세트의 각 이미지를 그 공간에 점으로

797
00:46:53,810 --> 00:46:57,120
표시한다고 상상해 보세요.

798
00:46:57,120 --> 00:47:02,780
각 축은 이미지 자체에서 유도된 어떤 종류의

799
00:47:02,780 --> 00:47:05,280
특징을 나타냅니다.

800
00:47:05,280 --> 00:47:09,420
여기서는 단순성을 위해 2D 공간을 보여주고 있습니다.

801
00:47:09,420 --> 00:47:12,470
선형 분류기의 작업은

802
00:47:12,470 --> 00:47:17,150
고양이와 개를 구분하는

803
00:47:17,150 --> 00:47:23,470
초평면 또는 선형 함수를 찾는 것입니다.

804
00:47:23,470 --> 00:47:26,260
하지만 우리는 이러한 선형 모델이

805
00:47:26,260 --> 00:47:29,110
종종 한계가 있다는 것을 알고 있습니다.

806
00:47:29,110 --> 00:47:32,350
데이터가 직선으로 깔끔하게 분리되지 않을 때

807
00:47:32,350 --> 00:47:33,800
어려움을 겪습니다.

808
00:47:33,800 --> 00:47:36,320
그래서 질문은, 다음은 무엇인가요?

809
00:47:36,320 --> 00:47:44,090
우리는 더 복잡한 패턴을 모델링하는 주제로 들어갈 것입니다.

810
00:47:44,090 --> 00:47:49,900
그렇게 할 경우, 우리는 종종 과적합과 과소적합의

811
00:47:49,900 --> 00:47:54,220
문제에 직면하게 되며, 이는

812
00:47:54,220 --> 00:47:59,440
수업의 초기 강의에서 다룰 주제입니다.

813
00:47:59,440 --> 00:48:05,110
올바른 균형을 맞추기 위해, 우리는 모델 복잡성을

814
00:48:05,110 --> 00:48:08,320
제어하고 최적화를 통해

815
00:48:08,320 --> 00:48:14,110
최적의 적합 매개변수를 찾기 위해 정규화와 같은

816
00:48:14,110 --> 00:48:16,060
기술을 사용합니다.

817
00:48:16,060 --> 00:48:21,080
이것들이 바로 딥러닝의 핵심 요소이며, 데이터에

818
00:48:21,080 --> 00:48:26,660
적합할 뿐만 아니라 보지 못한 새로운 데이터에도

819
00:48:26,660 --> 00:48:31,320
일반화할 수 있는 모델을 훈련시키는 것입니다.

820
00:48:31,320 --> 00:48:33,540
이제 재미있는 부분인 신경망으로

821
00:48:33,540 --> 00:48:34,380
넘어갑니다.

822
00:48:34,380 --> 00:48:38,060
우리는 그것들에 대해 꽤 많이 이야기해왔습니다.

823
00:48:38,060 --> 00:48:43,550
신경망은 선형 분류기와 달리

824
00:48:43,550 --> 00:48:47,780
비선형 함수를 모델링하기

825
00:48:47,780 --> 00:48:54,770
위해 여러 작업 층을 쌓아 분류하거나

826
00:48:54,770 --> 00:48:59,390
이미지 분류 문제를 해결하는

827
00:48:59,390 --> 00:49:04,490
등의 작업을 수행합니다.

828
00:49:04,490 --> 00:49:09,870
이 모델들은 Google Photos를 포함한 모든 것을 지원합니다.

829
00:49:09,870 --> 00:49:13,430
이제 모든 사람이 ChatGPT, ChatGPT의

830
00:49:13,430 --> 00:49:15,440
비전 모델 등에 익숙합니다.

831
00:49:15,440 --> 00:49:24,100
이 과정에서는 그들이 어떻게 작동하는지, 어떻게 훈련되는지에 대해 깊이

832
00:49:24,100 --> 00:49:26,300
있게 다룰 것입니다.

833
00:49:26,300 --> 00:49:31,090
우리는 그들을 디버깅하고 개선하는 방법도 살펴볼 것입니다.

834
00:49:31,090 --> 00:49:35,030
딥러닝 기초를 살펴본 후,

835
00:49:35,030 --> 00:49:39,280
우리는 시각 세계를 인식하고 이해하는

836
00:49:39,280 --> 00:49:44,620
주제를 다룰 것입니다. 이는 방대한

837
00:49:44,620 --> 00:49:49,880
시각 정보를 해석하는 복잡한 과정입니다.

838
00:49:49,880 --> 00:49:52,330
이를 위해 우리는 종종 특정

839
00:49:52,330 --> 00:49:56,740
도전 과제나 문제를 나타내는 작업을 먼저 정의합니다.

840
00:49:56,740 --> 00:49:59,150
우리가 해결하고자 하는 것-- 몇

841
00:49:59,150 --> 00:50:02,180
가지 예로는 객체 탐지, 장면 이해, 동작

842
00:50:02,180 --> 00:50:03,620
탐지 등이 있습니다.

843
00:50:03,620 --> 00:50:10,540
이러한 작업을 해결하기 위해 우리는 우리의 시각 시스템이 이러한

844
00:50:10,540 --> 00:50:13,930
작업을 수행하는 방식을 모방하거나

845
00:50:13,930 --> 00:50:17,780
설명하기 위해 개발한 계산적 및

846
00:50:17,780 --> 00:50:22,350
이론적 프레임워크인 다양한 모델을 사용합니다.

847
00:50:22,350 --> 00:50:25,610
이러한 유형의 모델 중 하나의

848
00:50:25,610 --> 00:50:27,730
예는 신경망입니다.

849
00:50:30,260 --> 00:50:36,150
따라서 작업과 모델을 정렬함으로써 우리는 주변

850
00:50:36,150 --> 00:50:41,030
세계를 보고 해석할 수 있는 시스템을

851
00:50:41,030 --> 00:50:43,730
만들 수 있습니다.

852
00:50:43,730 --> 00:50:48,740
작업에 대해 이야기하자면, 이미지 분류,

853
00:50:48,740 --> 00:50:53,240
즉 전체 이미지에 대해 단일 레이블을

854
00:50:53,240 --> 00:50:56,990
예측하는 주제로 돌아갑니다.

855
00:50:56,990 --> 00:50:59,360
하지만 우리는 실제 세계의 컴퓨터 비전이

856
00:50:59,360 --> 00:51:02,340
이보다 훨씬 더 풍부하다는 것을 알고 있습니다.

857
00:51:02,340 --> 00:51:05,240
그리고 분류를 넘어서는 몇 가지

858
00:51:05,240 --> 00:51:06,870
작업을 살펴보겠습니다.

859
00:51:06,870 --> 00:51:13,340
첫째, 의미론적 분할로, 우리는 단순히 객체나 전체 이미지를

860
00:51:13,340 --> 00:51:17,520
고양이, 나무 또는 기타로 레이블링하는

861
00:51:17,520 --> 00:51:19,740
것이 아닙니다.

862
00:51:19,740 --> 00:51:25,020
여기서 우리는 이미지의 모든 픽셀에 대한 레이블을 찾고

863
00:51:25,020 --> 00:51:25,810
있습니다.

864
00:51:25,810 --> 00:51:30,670
그래서 모든 픽셀은 풀, 고양이, 나무 또는 하늘입니다.

865
00:51:30,670 --> 00:51:34,960
하지만 우리는 개별 객체를 구분하지 않습니다.

866
00:51:34,960 --> 00:51:38,280
다음으로 객체 탐지가 있으며,

867
00:51:38,280 --> 00:51:45,580
이제 우리는 이미지에 무엇이 있는지 말할 뿐만 아니라 위치도 정확히

868
00:51:45,580 --> 00:51:47,440
지정하고자 합니다.

869
00:51:47,440 --> 00:51:49,860
그래서 우리는 객체 주위에

870
00:51:49,860 --> 00:51:54,670
경계 상자를 만들고 이를 특정 레이블과 연관시킵니다.

871
00:51:54,670 --> 00:51:58,270
마지막으로 인스턴스 분할이 있습니다.

872
00:51:58,270 --> 00:52:01,140
우리는 모든 것 중에서 가장 세밀한

873
00:52:01,140 --> 00:52:04,410
인스턴스 분할에 대해 다룰 것입니다.

874
00:52:04,410 --> 00:52:08,280
이것은 탐지와 분할의 아이디어를

875
00:52:08,280 --> 00:52:09,130
결합합니다.

876
00:52:09,130 --> 00:52:13,040
모든 객체 인스턴스는 고유한 마스크를 갖습니다.

877
00:52:13,040 --> 00:52:20,090
이러한 작업은 훨씬 더 깊은 전문적인 이해와 이미지를

878
00:52:20,090 --> 00:52:21,060
요구합니다.

879
00:52:21,060 --> 00:52:23,810
그리고 그것들은 모델이 단순히

880
00:52:23,810 --> 00:52:27,860
범주를 인식하는 것 이상을 하도록 압박합니다.

881
00:52:27,860 --> 00:52:30,660
복잡성은 정적 이미지에서 그치지 않습니다.

882
00:52:30,660 --> 00:52:33,270
일부 시간적 차원을 살펴보겠습니다.

883
00:52:33,270 --> 00:52:36,270
그래서 비디오 분류 작업이 있으며,

884
00:52:36,270 --> 00:52:40,430
Fei-Fei가 언급한 것처럼 우리는 비디오에서 무슨 일이 일어나고

885
00:52:40,430 --> 00:52:42,350
있는지 이해하고자 합니다.

886
00:52:42,350 --> 00:52:47,210
누군가 달리거나, 점프하거나, 춤추고 있습니까?

887
00:52:47,210 --> 00:52:51,630
비전과 소리 및 기타 양식을 결합하는

888
00:52:51,630 --> 00:52:56,630
다중 모달 비디오 이해라는 주제가 있습니다.

889
00:52:56,630 --> 00:53:00,560
예를 들어, 이 예에서 사람은 비브라폰을 연주하여

890
00:53:00,560 --> 00:53:04,070
여기서 무슨 일이 일어나고 있는지 정말로 이해하고자

891
00:53:04,070 --> 00:53:05,040
합니다.

892
00:53:05,040 --> 00:53:08,210
우리는 무슨 일이 일어나고 있는지를 이해하기 위해

893
00:53:08,210 --> 00:53:11,280
시각적 특징과 오디오 특징의 혼합을 만들어야 합니다.

894
00:53:11,280 --> 00:53:14,680
마지막으로, 우리는 이

895
00:53:14,680 --> 00:53:19,330
수업에서 다룰 시각화 및 이해라는 주제가

896
00:53:19,330 --> 00:53:24,340
있으며, 여기서 우리는 모델이 학습한 내용을

897
00:53:24,340 --> 00:53:31,270
해석하고 모델이 올바른 분류를 수행하기 위해 주목하는

898
00:53:31,270 --> 00:53:35,080
주의 프레임 또는 주의 맵을 볼

899
00:53:35,080 --> 00:53:36,820
수 있습니다.

900
00:53:36,820 --> 00:53:39,650
그리고 우리는 작업을 넘어선 모델이 있습니다.

901
00:53:39,650 --> 00:53:41,740
우리는 모델을 살펴봅니다.

902
00:53:41,740 --> 00:53:46,510
그리고 첫 번째 주제는 우리가 다룰

903
00:53:46,510 --> 00:53:50,170
컨볼루션 신경망 또는

904
00:53:50,170 --> 00:53:51,230
CNN입니다.

905
00:53:51,230 --> 00:53:52,760
여러 가지 작업이 있습니다.

906
00:53:52,760 --> 00:53:55,930
우리는 수업에서 이미지,

907
00:53:55,930 --> 00:53:59,840
여러 개의 컨볼루션, 샘플링 및

908
00:53:59,840 --> 00:54:01,970
완전 연결 작업을

909
00:54:01,970 --> 00:54:05,980
시작으로 세부 사항을 다룰 것입니다.

910
00:54:05,980 --> 00:54:08,770
그리고 컨볼루션 신경망을

911
00:54:08,770 --> 00:54:14,720
넘어, 우리는 순차 데이터에 대한 순환 신경망과

912
00:54:14,720 --> 00:54:19,670
변환기 및 주의 기반 프레임워크와

913
00:54:19,670 --> 00:54:24,140
같은 신경 아키텍처를 연구할 것입니다.

914
00:54:24,140 --> 00:54:29,180
다음으로, 우리는 이번 분기에 새롭게

915
00:54:29,180 --> 00:54:34,610
다룰 대규모 분산 훈련 주제를 다룰 것입니다.

916
00:54:34,610 --> 00:54:38,460
여러분 모두 대형 언어 모델, 대형 비전 모델 등에

917
00:54:38,460 --> 00:54:40,320
대해 들어보셨을 것입니다.

918
00:54:40,320 --> 00:54:44,480
우리는 이러한 모델이 실제로 어떻게 훈련되는지

919
00:54:44,480 --> 00:54:47,310
간략하게 논의할 것입니다.

920
00:54:47,310 --> 00:54:51,620
데이터와 데이터 세트가 모델을 확장하고 있다는 것을 알고 있습니다.

921
00:54:51,620 --> 00:54:56,430
그리고 모델은 점점 더 커지고 있습니다.

922
00:54:56,430 --> 00:54:59,820
이러한 모델을 훈련하기 위해 몇 가지 전략이

923
00:54:59,820 --> 00:55:02,360
있습니다. 예를 들어, 데이터 병렬화,

924
00:55:02,360 --> 00:55:04,470
모델 병렬화 등이 있으며,

925
00:55:04,470 --> 00:55:07,570
우리는 이 수업에서 이를 다룰 것입니다.

926
00:55:07,570 --> 00:55:11,170
하지만 그 외에도 이러한 모델과

927
00:55:11,170 --> 00:55:15,940
작업자 간의 동기화와 같은 많은 도전

928
00:55:15,940 --> 00:55:20,730
과제가 있으며, 이번 분기의 강의 중

929
00:55:20,730 --> 00:55:25,060
하나에서 여러 다른 측면도 다룰 것입니다.

930
00:55:25,060 --> 00:55:31,290
우리는 이러한 대규모 모델을 훈련하기 위한 몇 가지 트렌드에 대해서도

931
00:55:31,290 --> 00:55:33,070
살펴볼 것입니다.

932
00:55:33,070 --> 00:55:36,210
이 주제를 마친 후,

933
00:55:36,210 --> 00:55:44,010
다음으로는 자기 지도 학습으로 시작하는 생성적

934
00:55:44,010 --> 00:55:48,690
및 인터랙티브 비주얼 인텔리전스를

935
00:55:48,690 --> 00:55:52,030
살펴볼 것입니다.

936
00:55:52,030 --> 00:55:55,960
자기 지도 학습은 모델이 데이터 자체로부터

937
00:55:55,960 --> 00:56:00,580
훈련 신호를 받아 데이터를 이해하고 표현하는 방법을

938
00:56:00,580 --> 00:56:04,180
배우는 기계 학습의 한 분야입니다.

939
00:56:04,180 --> 00:56:06,385
이 주제를 다룰 것입니다.

940
00:56:06,385 --> 00:56:10,180
라벨이 필요 없는 방대한 양의

941
00:56:10,180 --> 00:56:15,340
데이터를 사용하여 대규모 모델 훈련을 가능하게

942
00:56:15,340 --> 00:56:18,880
한 접근 방식 중 하나입니다.

943
00:56:18,880 --> 00:56:23,200
그리고 이는 최근 컴퓨터 비전의 주요 돌파구에서

944
00:56:23,200 --> 00:56:26,200
중요한 역할을 했습니다.

945
00:56:26,200 --> 00:56:30,800
그리고 우리는 생성 모델에 대해 조금 이야기할 것입니다.

946
00:56:30,800 --> 00:56:33,710
그들은 인식을 넘어섭니다.

947
00:56:33,710 --> 00:56:35,860
실제로 생성합니다.

948
00:56:35,860 --> 00:56:39,340
이것은 스탠포드 캠퍼스 사진의

949
00:56:39,340 --> 00:56:44,380
내용으로, 반 고흐의 별이 빛나는 밤 스타일로 재구상된

950
00:56:44,380 --> 00:56:45,490
예입니다.

951
00:56:45,490 --> 00:56:49,990
이것은 스타일 전이로 알려져 있으며,

952
00:56:49,990 --> 00:56:54,370
신경 생성 기술의 고전적인 응용입니다.

953
00:56:54,370 --> 00:56:58,270
생성 모델은 이제 프롬프트에

954
00:56:58,270 --> 00:57:03,220
따라 언어를 이미지로 변환할 수 있습니다.

955
00:57:03,220 --> 00:57:07,290
Dall-E와 Dall-E 2와 같은 모델은 완전히 새로운

956
00:57:07,290 --> 00:57:09,060
이미지를 생성합니다.

957
00:57:09,060 --> 00:57:12,570
이는 생성적 비전 모델이 생성에서

958
00:57:12,570 --> 00:57:16,830
이해, 창의성 및 제어를 어떻게

959
00:57:16,830 --> 00:57:19,350
혼합하는지를 보여줍니다.

960
00:57:19,350 --> 00:57:22,590
최근에 확산 모델에

961
00:57:22,590 --> 00:57:26,620
대한 주제를 들었을 것입니다.

962
00:57:26,620 --> 00:57:33,180
이것은 이번 분기에서 다룰 또 다른 주제입니다.

963
00:57:33,180 --> 00:57:37,650
기본적으로 이미지를 생성하기 위해 점진적인 노이즈

964
00:57:37,650 --> 00:57:40,510
과정을 역전시키는 방법을 배웁니다.

965
00:57:40,510 --> 00:57:43,630
흥미롭게도, 과제 3에서는

966
00:57:43,630 --> 00:57:46,860
텍스트 입력에서 이모지를

967
00:57:46,860 --> 00:57:53,400
생성하는 생성 모델을 실제로 구현할 것입니다. 예를 들어,

968
00:57:53,400 --> 00:57:57,360
순수 노이즈에서 노이즈 제거된

969
00:57:57,360 --> 00:58:01,240
카우보이 모자를 쓴 얼굴입니다.

970
00:58:01,240 --> 00:58:06,530
비전 언어 모델은 우리가 다룰 다음

971
00:58:06,530 --> 00:58:08,890
관심 주제입니다.

972
00:58:08,890 --> 00:58:16,040
그들은 텍스트와 이미지를 공유 표현 공간에서 연결합니다.

973
00:58:16,040 --> 00:58:19,900
캡션이나 이미지가 주어지면

974
00:58:19,900 --> 00:58:24,290
모델은 해당 쌍을 검색하거나

975
00:58:24,290 --> 00:58:25,310
생성합니다.

976
00:58:25,310 --> 00:58:29,050
따라서 이 분야에는 많은 발전이 있습니다.

977
00:58:29,050 --> 00:58:32,170
우리는 몇 가지 주요 예를 다룰 것입니다.

978
00:58:32,170 --> 00:58:37,750
다시 말해, 이는 교차 모달 검색 또는 이해 및 시각적

979
00:58:37,750 --> 00:58:41,120
질문 응답 등에서 중요한 작업입니다.

980
00:58:41,120 --> 00:58:44,270
그래서 우리는 2강에서 그에 대해 다룰 것입니다.

981
00:58:44,270 --> 00:58:52,810
2D를 넘어, 모델은 이제 이미지를 기반으로 3D 표현을 재구성하고

982
00:58:52,810 --> 00:58:55,550
생성할 수 있습니다.

983
00:58:55,550 --> 00:59:00,980
여기에서 일부 복셀 기반 재구성, 형태

984
00:59:00,980 --> 00:59:06,770
완성 및 단일 뷰 이미지에서의 3D 객체

985
00:59:06,770 --> 00:59:09,600
감지를 볼 수 있습니다.

986
00:59:09,600 --> 00:59:14,810
따라서 3D 비전은 로봇 공학 및 AI VR 응용

987
00:59:14,810 --> 00:59:19,700
프로그램에 필수적인 보다 구체적인 이해를 가능하게

988
00:59:19,700 --> 00:59:20,400
합니다.

989
00:59:20,400 --> 00:59:26,900
마지막으로, 비전은 물리적 세계에서 행동하는

990
00:59:26,900 --> 00:59:30,680
구현된 에이전트를 강화합니다.

991
00:59:30,680 --> 00:59:35,280
따라서 이러한 모델은 지저분한 방을

992
00:59:35,280 --> 00:59:41,390
청소하든 인간의 시연에서 일반화하든 인식,

993
00:59:41,390 --> 00:59:44,880
계획 및 실행해야 합니다.

994
00:59:44,880 --> 00:59:50,210
이 모든 것과 함께 우리는 생성적 및 인터랙티브 비주얼

995
00:59:50,210 --> 00:59:53,970
인텔리전스에 관한 다양한 주제를 다룰 것입니다.

996
00:59:53,970 --> 01:00:00,760
마지막으로, 페이페이가 아주 잘 설명한 대로 인간 중심의

997
01:00:00,760 --> 01:00:05,990
응용 및 함의에 대해서도 다룰 것입니다.

998
01:00:05,990 --> 01:00:08,720
그래서 컴퓨터 비전이 있습니다.

999
01:00:08,720 --> 01:00:12,070
그리고 일반적으로 AI는 지난

1000
01:00:12,070 --> 01:00:16,070
몇 년 동안 많은 영향을 미쳤습니다.

1001
01:00:16,070 --> 01:00:18,280
인간 중심의 측면과 응용

1002
01:00:18,280 --> 01:00:21,230
프로그램을 이해하는 것이 매우 중요합니다.

1003
01:00:21,230 --> 01:00:24,160
이러한 영향 중 일부는

1004
01:00:24,160 --> 01:00:32,470
이 분야의 연구자들에게 수여되는 이러한 상으로 반영됩니다.

1005
01:00:32,470 --> 01:00:38,770
2018년 튜링 상에서 처음 인정받았으며, 이는 컴퓨팅에

1006
01:00:38,770 --> 01:00:41,440
대한 지속적인 중요성을 가진

1007
01:00:41,440 --> 01:00:45,400
주요 기여에 수여되는 가장 권위 있는

1008
01:00:45,400 --> 01:00:47,090
기술 상입니다.

1009
01:00:47,090 --> 01:00:50,890
제프리 힌턴, 요슈아 벤지오, 얀

1010
01:00:50,890 --> 01:00:54,850
르쿤은 심층 신경망을 컴퓨팅의 중요한

1011
01:00:54,850 --> 01:00:57,050
구성 요소로 만든 혁신적인

1012
01:00:57,050 --> 01:01:01,440
개념과 엔지니어링으로 상을 받았습니다.

1013
01:01:01,440 --> 01:01:06,200
그 외에도, 지난해인 2024년 제프리

1014
01:01:06,200 --> 01:01:11,090
힌턴은 존 홉필드와 함께 신경망에 대한

1015
01:01:11,090 --> 01:01:14,990
기초적인 기여로 물리학 노벨상을

1016
01:01:14,990 --> 01:01:17,460
공동 수상했습니다.

1017
01:01:17,460 --> 01:01:21,260
마지막으로, 이 수업의 학습

1018
01:01:21,260 --> 01:01:27,770
목표는 컴퓨터 비전 응용 프로그램을 작업으로

1019
01:01:27,770 --> 01:01:30,240
형식화하는 것입니다.

1020
01:01:30,240 --> 01:01:33,620
여기에서 일부 세부 사항을 보시다시피,

1021
01:01:33,620 --> 01:01:38,600
우리는 이미지와 시각 데이터에서 작동하는 비전 모델을

1022
01:01:38,600 --> 01:01:41,400
개발하고 훈련하고-- 이미지,

1023
01:01:41,400 --> 01:01:43,220
비디오 등-- 이

1024
01:01:43,220 --> 01:01:46,550
분야가 어디에 있고 어디로 향하고

1025
01:01:46,550 --> 01:01:48,990
있는지 이해하고자 합니다.

1026
01:01:48,990 --> 01:01:53,620
그래서 올해는 특별히 다루는

1027
01:01:53,620 --> 01:01:56,920
새로운 주제가 있습니다.

1028
01:01:56,920 --> 01:02:01,540
제가 앞서 언급한 네 가지 주제는

1029
01:02:01,540 --> 01:02:06,530
처음 몇 주 동안 기본을 다룰 것입니다.

1030
01:02:06,530 --> 01:02:09,220
이것들은 중요한 주제이므로 조금만 기다려 주세요.

1031
01:02:09,220 --> 01:02:12,860
먼저 모델을 처음부터 만드는 방법에 대한

1032
01:02:12,860 --> 01:02:15,110
세부 사항을 이해해야 합니다.

1033
01:02:15,110 --> 01:02:19,180
그런 다음 더 흥미롭고 신나는 주제인 컴퓨터

1034
01:02:19,180 --> 01:02:20,440
비전으로

1035
01:02:20,440 --> 01:02:21,770
넘어갈 것입니다.

1036
01:02:21,770 --> 01:02:27,970
마지막으로, 인간 중심 AI와 컴퓨터 비전에 대한 큰 강의를

1037
01:02:27,970 --> 01:02:30,550
하나 가질 것입니다.

1038
01:02:30,550 --> 01:02:33,040
다음 세션에서 다룰 내용을

1039
01:02:33,040 --> 01:02:34,790
남기고 싶습니다.

1040
01:02:34,790 --> 01:02:38,380
그것은 이미지 분류와 선형

1041
01:02:38,380 --> 01:02:43,720
분류기로, CS231n의 세계를 시작하는 데

1042
01:02:43,720 --> 01:02:45,910
도움이 될 것입니다.

1043
01:02:45,910 --> 01:02:47,970
감사합니다.
