1
00:00:05,510 --> 00:00:07,230
이것은 CS231n입니다.

2
00:00:07,230 --> 00:00:11,000
저는 컴퓨터 과학과의 Fei-Fei Li

3
00:00:11,000 --> 00:00:11,820
교수입니다.

4
00:00:11,820 --> 00:00:14,960
이번 학기에는 Ehsan Adeli

5
00:00:14,960 --> 00:00:19,320
교수님과 제 대학원생 Zane과 함께 공동 강의를 합니다.

6
00:00:19,320 --> 00:00:23,300
그래서 여러분은 그분들과 나중에 만나게 될 훌륭한 TA

7
00:00:23,300 --> 00:00:24,900
팀도 만나게 될 겁니다.

8
00:00:24,900 --> 00:00:28,250
그럼 바로 시작하겠습니다.

9
00:00:28,250 --> 00:00:32,030
제가 흥분하는 이유는 AI가 매우

10
00:00:32,030 --> 00:00:35,520
학제간 분야가 되었다는 점입니다. 이

11
00:00:35,520 --> 00:00:38,520
수업에서 배우는 내용은 물론

12
00:00:38,520 --> 00:00:40,530
매우 기술적입니다.

13
00:00:40,530 --> 00:00:42,750
컴퓨터 비전과 딥러닝에 관한 것입니다.

14
00:00:42,750 --> 00:00:44,600
하지만 여러분이 어떤

15
00:00:44,600 --> 00:00:48,590
분야에서 일하든, 열정을 가진 분야에 이 지식을 적용하길

16
00:00:48,590 --> 00:00:49,920
진심으로 바랍니다.

17
00:00:49,920 --> 00:00:52,800
우리는 AI 분야에 대해 많이 듣습니다.

18
00:00:52,800 --> 00:00:56,030
그렇다면 컴퓨터 비전과 이 수업의 범위를 어떻게

19
00:00:56,030 --> 00:00:57,920
위치시킬 수 있을까요?

20
00:00:57,920 --> 00:01:02,250
AI를 큰 거품으로 본다면, 컴퓨터

21
00:01:02,250 --> 00:01:07,350
비전은 AI의 필수적인 부분입니다.

22
00:01:07,350 --> 00:01:10,830
여러분 중 일부는 제가 비전이 지능의 일부일 뿐 아니라

23
00:01:10,830 --> 00:01:13,960
지능의 초석이라고 말하는 것을 들었을 겁니다.

24
00:01:13,960 --> 00:01:16,530
시각 지능의 신비를 푸는

25
00:01:16,530 --> 00:01:20,080
것은 지능의 신비를 푸는 것입니다.

26
00:01:20,080 --> 00:01:25,250
하지만 AI 문제를 푸는 가장 중요한 수학적 도구 중

27
00:01:25,250 --> 00:01:29,130
하나는 머신러닝, 또는 통계적 머신러닝이라고도

28
00:01:29,130 --> 00:01:31,060
불리는 것입니다.

29
00:01:31,060 --> 00:01:36,300
바로 이것이 우리가 이야기할 주제입니다.

30
00:01:36,300 --> 00:01:38,670
머신러닝 분야 내에서

31
00:01:38,670 --> 00:01:42,390
지난 10년 넘게 딥러닝이라는 큰 혁명이

32
00:01:42,390 --> 00:01:43,570
있었습니다.

33
00:01:43,570 --> 00:01:46,930
딥러닝이 무엇인지 조금 설명하겠습니다.

34
00:01:46,930 --> 00:01:50,640
딥러닝은 신경망이라는 알고리즘 계열을

35
00:01:50,640 --> 00:01:54,120
중심으로 구축된 알고리즘 기법들의

36
00:01:54,120 --> 00:01:55,540
집합입니다.

37
00:01:55,540 --> 00:02:02,040
이 수업의 범위를 정확히 말하자면, 컴퓨터 비전

38
00:02:02,040 --> 00:02:05,250
전체를 다루지는 않습니다.

39
00:02:05,250 --> 00:02:07,850
머신러닝이나 딥러닝 전체를

40
00:02:07,850 --> 00:02:09,030
다루지도 않습니다.

41
00:02:09,030 --> 00:02:12,410
하지만 이 두 분야의 핵심 교차점을 다룰

42
00:02:12,410 --> 00:02:13,290
것입니다.

43
00:02:13,290 --> 00:02:18,300
물론 AI 전체처럼 컴퓨터 비전도

44
00:02:18,300 --> 00:02:20,900
점점 더 학제간 분야가

45
00:02:20,900 --> 00:02:23,340
되고 있습니다.

46
00:02:23,340 --> 00:02:26,060
우리가 사용하는 많은 기술과

47
00:02:26,060 --> 00:02:28,310
다루는 문제들은 자연어

48
00:02:28,310 --> 00:02:31,280
처리, 음성 인식, 로보틱스

49
00:02:31,280 --> 00:02:37,850
등 다양한 분야와 교차합니다. AI 전체는 수학, 신경과학, 컴퓨터

50
00:02:37,850 --> 00:02:41,340
과학, 심리학, 물리학, 생물학,

51
00:02:41,340 --> 00:02:44,160
그리고 의학, 법률, 교육,

52
00:02:44,160 --> 00:02:46,430
비즈니스 등 다양한

53
00:02:46,430 --> 00:02:49,950
응용 분야와도 교차하는 분야입니다.

54
00:02:49,950 --> 00:02:55,170
이번 첫 강의에서는 컴퓨터 비전과 딥러닝의

55
00:02:55,170 --> 00:02:58,260
아주 간단한 역사를 소개할

56
00:02:58,260 --> 00:02:59,890
것입니다.

57
00:02:59,890 --> 00:03:05,310
그리고 Adeli 교수님이 이 강좌의 개요를

58
00:03:05,310 --> 00:03:08,130
설명하고 강좌 구성과

59
00:03:08,130 --> 00:03:11,670
기대 사항을 정리해 주실 겁니다.

60
00:03:11,670 --> 00:03:19,140
비전의 역사는 여러분이 태어났을 때나 인류가 태어났을 때 시작된

61
00:03:19,140 --> 00:03:20,980
것이 아닙니다.

62
00:03:20,980 --> 00:03:25,720
비전의 역사는 5억 4천만 년 전부터 시작되었습니다.

63
00:03:25,720 --> 00:03:29,920
여러분은 5억 4천만 년 전에 무슨 일이 있었냐고 물을 수 있습니다.

64
00:03:29,920 --> 00:03:34,230
왜 진화에서 비교적 구체적인 날짜나 연도를

65
00:03:34,230 --> 00:03:35,500
지목하냐고도요.

66
00:03:35,500 --> 00:03:37,830
그 이유는 많은 화석

67
00:03:37,830 --> 00:03:43,380
연구가 캄브리아기 폭발이라는 신비한 시기를

68
00:03:43,380 --> 00:03:45,550
보여주었기 때문입니다.

69
00:03:45,550 --> 00:03:49,200
화석 연구는 진화에서 매우 짧은 기간인 약

70
00:03:49,200 --> 00:03:52,440
천만 년 동안 동물 종의 폭발적 증가를

71
00:03:52,440 --> 00:03:53,810
보여주었습니다.

72
00:03:53,810 --> 00:03:58,340
즉, 캄브리아기 폭발 이전에는

73
00:03:58,340 --> 00:04:02,820
지구상의 생명체가 꽤 평온했다는

74
00:04:02,820 --> 00:04:05,220
뜻입니다.

75
00:04:05,220 --> 00:04:06,930
사실 그것은 물속에 있었습니다.

76
00:04:06,930 --> 00:04:10,320
아직 육지에는 동물이 없었습니다.

77
00:04:10,320 --> 00:04:13,770
동물들은 그냥 떠다니고 있었죠.

78
00:04:13,770 --> 00:04:18,240
그렇다면 동물 종 다양성의 폭발을 일으킨 원인은 무엇일까요?

79
00:04:18,240 --> 00:04:21,620
기후부터 해양의 화학 조성까지 여러

80
00:04:21,620 --> 00:04:23,190
이론이 있었습니다.

81
00:04:23,190 --> 00:04:29,360
하지만 가장 설득력 있는 이론 중 하나는 빙하기의 시작이었습니다.

82
00:04:29,360 --> 00:04:32,570
첫 번째 동물인 삼엽충은 광감지

83
00:04:32,570 --> 00:04:34,950
세포를 얻었습니다.

84
00:04:34,950 --> 00:04:37,310
우리가 말한 눈은 정교한

85
00:04:37,310 --> 00:04:41,010
렌즈와 망막, 신경 세포가 아니었습니다.

86
00:04:41,010 --> 00:04:44,520
그것은 문자 그대로 아주 단순한 핀홀 형태였습니다.

87
00:04:44,520 --> 00:04:47,340
그 핀홀이 빛을 모았습니다.

88
00:04:47,340 --> 00:04:53,550
빛을 모으기 시작하자 생명은 완전히 달라졌습니다.

89
00:04:53,550 --> 00:04:57,660
센서가 없으면 생명은 단순한 대사 작용입니다.

90
00:04:57,660 --> 00:04:59,410
아주 수동적이죠.

91
00:04:59,410 --> 00:05:01,180
그냥 대사 작용일 뿐입니다.

92
00:05:01,180 --> 00:05:02,530
왔다가 가는 거죠.

93
00:05:02,530 --> 00:05:06,690
센서가 있으면 환경의 일부가 되어

94
00:05:06,690 --> 00:05:08,980
환경을 바꾸려 하거나

95
00:05:08,980 --> 00:05:11,920
그 환경에서 실제로 살아남으려 합니다.

96
00:05:11,920 --> 00:05:16,170
어떤 동물이나 식물은 당신의 식사가 되고,

97
00:05:16,170 --> 00:05:18,070
당신도 누군가의 식사가 됩니다.

98
00:05:18,070 --> 00:05:24,120
그래서 진화적 힘은 센서의 출현,

99
00:05:24,120 --> 00:05:27,580
시각과 촉각 센서의

100
00:05:27,580 --> 00:05:31,530
출현 때문에 지능의 진화를

101
00:05:31,530 --> 00:05:33,220
이끕니다.

102
00:05:33,220 --> 00:05:38,080
이것들이 동물의 가장 오래된 센서들입니다.

103
00:05:38,080 --> 00:05:41,880
그래서 5억 4천만 년에 걸친 시각의

104
00:05:41,880 --> 00:05:46,510
진화 과정 전체가 지능의 진화인 셈입니다.

105
00:05:46,510 --> 00:05:49,850
동물의 주요 감각 중 하나인

106
00:05:49,850 --> 00:05:54,260
시각은 신경계와 지능 발달을

107
00:05:54,260 --> 00:05:55,320
촉진했습니다.

108
00:05:55,320 --> 00:05:59,450
오늘날 지구상의 거의 모든 동물은 시각을

109
00:05:59,450 --> 00:06:03,420
가지고 있거나 주요 감각으로 사용합니다.

110
00:06:03,420 --> 00:06:06,450
인간은 특히 시각적 동물입니다.

111
00:06:06,450 --> 00:06:08,810
우리 대뇌 피질 세포의 절반

112
00:06:08,810 --> 00:06:11,820
이상이 시각 처리에 관여합니다.

113
00:06:11,820 --> 00:06:15,930
그리고 우리는 매우 복잡하고 뒤얽힌 시각 시스템을 가지고 있습니다.

114
00:06:15,930 --> 00:06:19,800
이것이 제가 시각 분야에 뛰어들게 된 이유입니다.

115
00:06:19,800 --> 00:06:21,870
여러분도 흥미를 느끼시길 바랍니다.

116
00:06:21,870 --> 00:06:30,620
이제 캄브리아기 폭발에서 인간 문명까지 빠르게

117
00:06:30,620 --> 00:06:33,470
넘어가 보겠습니다.

118
00:06:33,470 --> 00:06:35,850
인간은 혁신을 합니다.

119
00:06:35,850 --> 00:06:37,610
그리고 단지 보는 것만이 아닙니다.

120
00:06:37,610 --> 00:06:40,050
우리는 보는 기계를 만들고자 합니다.

121
00:06:40,050 --> 00:06:44,850
여기 레오나르도 다 빈치가 그린 몇 장의 그림이 있습니다.

122
00:06:44,850 --> 00:06:48,540
그는 모든 것에 대해 끊임없이 호기심을

123
00:06:48,540 --> 00:06:49,540
가졌죠.

124
00:06:49,540 --> 00:06:56,740
그는 증기 기관을 만들기 위해 카메라 옵스큐라를 연구했습니다.

125
00:06:56,740 --> 00:07:01,830
사실 그보다 훨씬 이전, 고대 그리스와

126
00:07:01,830 --> 00:07:05,160
고대 중국에서도 사상가들과

127
00:07:05,160 --> 00:07:09,990
철학자들이 핀홀을 통해 물체를

128
00:07:09,990 --> 00:07:15,600
투사하고 물체의 이미지를 만드는 방법에 대해

129
00:07:15,600 --> 00:07:19,330
생각한 문서들이 있습니다.

130
00:07:19,330 --> 00:07:22,750
그리고 물론 현대 생활에서 카메라는

131
00:07:22,750 --> 00:07:25,990
정말 폭발적으로 발전했습니다.

132
00:07:25,990 --> 00:07:30,780
하지만 카메라만으로는 보는 것이 충분하지 않습니다. 눈만으로 보는 것이
충분하지

133
00:07:30,780 --> 00:07:31,720
않은 것처럼요.

134
00:07:31,720 --> 00:07:33,010
이것들은 장치일 뿐입니다.

135
00:07:33,010 --> 00:07:35,950
우리는 시각 지능이 어떻게 발생하는지 이해해야 합니다.

136
00:07:35,950 --> 00:07:38,590
그것이 바로 이 강의의 핵심입니다.

137
00:07:38,590 --> 00:07:45,670
그럼 딥러닝과 컴퓨터 비전이 만나는 이 지점에 이르게 한

138
00:07:45,670 --> 00:07:49,790
역사를 조금 이야기해 보겠습니다.

139
00:07:49,790 --> 00:07:57,160
1950년대로 돌아가 보겠습니다.

140
00:07:57,160 --> 00:08:03,370
1950년대에는 신경과학에서 매우 중요한 일련의 실험들이

141
00:08:03,370 --> 00:08:05,090
있었습니다.

142
00:08:05,090 --> 00:08:08,020
특히 Hubel과 Wiesel의

143
00:08:08,020 --> 00:08:10,630
획기적인 연구가

144
00:08:10,630 --> 00:08:11,990
있었습니다.

145
00:08:11,990 --> 00:08:18,410
그들은 마취된 살아있는 고양이에게 전극을 삽입했습니다.

146
00:08:18,410 --> 00:08:21,220
그리고 일차 시각 피질에

147
00:08:21,220 --> 00:08:25,760
있는 뉴런들의 수용 영역을 연구했습니다.

148
00:08:25,760 --> 00:08:28,910
그들이 놀랍게도 배운 두 가지 매우

149
00:08:28,910 --> 00:08:31,070
중요한 사실이 있습니다.

150
00:08:31,070 --> 00:08:38,740
하나는, primary visual cortex에서 시각을 담당하는 뉴런들이
각각

151
00:08:38,740 --> 00:08:41,860
고유한 receptive

152
00:08:41,860 --> 00:08:44,820
field를 가지고 있다는 점입니다.

153
00:08:44,820 --> 00:08:48,320
Receptive field란, 각

154
00:08:48,320 --> 00:08:52,590
뉴런마다 실제로 보는 공간의 일부가 있다는 뜻입니다.

155
00:08:52,590 --> 00:08:54,870
모든 공간을 보는 것은 아닙니다.

156
00:08:54,870 --> 00:08:55,800
그 크기도 매우 크지 않습니다.

157
00:08:55,800 --> 00:09:00,780
대개는 공간의 아주 제한된 영역을 보는 거죠.

158
00:09:00,780 --> 00:09:06,630
그리고 그 공간 내에서, 초기 시각

159
00:09:06,630 --> 00:09:12,320
경로에서 측정할 때는 단순한 패턴, 특화된

160
00:09:12,320 --> 00:09:15,470
패턴을 보게 됩니다.

161
00:09:15,470 --> 00:09:18,840
대체로 primary visual cortex,

162
00:09:18,840 --> 00:09:23,120
즉 머리 뒤쪽에 위치한 이 부분에서는, 방향성이

163
00:09:23,120 --> 00:09:27,210
있는 가장자리나 움직이는 방향성 가장자리를 봅니다.

164
00:09:27,210 --> 00:09:28,970
그래서 각 뉴런은 이런 가장자리를

165
00:09:28,970 --> 00:09:30,330
보는 뉴런도 있고,

166
00:09:30,330 --> 00:09:32,970
또 어떤 뉴런은 이런 가장자리나 저런 가장자리를 보는 뉴런도 있습니다.

167
00:09:32,970 --> 00:09:39,030
이것이 뇌에서 계산이 시작되는 방식입니다.

168
00:09:39,030 --> 00:09:42,370
두 번째로 알게 된 점은 시각 경로가 계층적이라는

169
00:09:42,370 --> 00:09:43,520
것입니다.

170
00:09:43,520 --> 00:09:47,150
시각 경로를 따라가면서 뉴런들이

171
00:09:47,150 --> 00:09:50,630
다른 뉴런으로 신호를 전달합니다.

172
00:09:50,630 --> 00:09:54,730
그리고 시각 계층의 더 높은 층이나 깊은 층에 있는

173
00:09:54,730 --> 00:09:57,460
뉴런들은 더 복잡한 receptive

174
00:09:57,460 --> 00:09:59,990
field를 가지고 있습니다.

175
00:09:59,990 --> 00:10:04,010
즉, 방향성이 있는 가장자리에서 시작하면, 코너를

176
00:10:04,010 --> 00:10:06,890
인식하는 뉴런으로 연결될 수 있고,

177
00:10:06,890 --> 00:10:10,400
또는 물체를 인식하는 뉴런으로 연결될 수 있습니다.

178
00:10:10,400 --> 00:10:12,200
제가 너무 단순화해서 설명하는 겁니다.

179
00:10:12,200 --> 00:10:16,360
하지만 개념은 뉴런들이 서로 연결된다는 것입니다.

180
00:10:16,360 --> 00:10:23,360
그리고 그것들이 큰 계산 네트워크를 만듭니다.

181
00:10:23,360 --> 00:10:25,720
물론 여기 앉아 계신 대부분

182
00:10:25,720 --> 00:10:27,850
분들은 제가 설명한

183
00:10:27,850 --> 00:10:30,670
방식이 시각 알고리즘의 신경망

184
00:10:30,670 --> 00:10:36,020
모델링에 깊은 영향을 미칠 것이라고 이미 생각하고 계실 겁니다.

185
00:10:36,020 --> 00:10:37,070
계속 진행해 보겠습니다.

186
00:10:37,070 --> 00:10:40,260
1959년입니다.

187
00:10:40,260 --> 00:10:43,500
시각에 관한 아주 초기 연구입니다.

188
00:10:43,500 --> 00:10:48,290
참고로, 약 30년 후—정확히는 아닐 수도

189
00:10:48,290 --> 00:10:50,970
있지만—20대 후반쯤에,

190
00:10:50,970 --> 00:10:54,770
Hubel과 Wiesel이 이

191
00:10:54,770 --> 00:10:59,840
연구로 시각 처리 원리를 밝혀내어 노벨

192
00:10:59,840 --> 00:11:01,790
의학상을 받았습니다.

193
00:11:01,790 --> 00:11:05,780
컴퓨터 비전 초기 역사에서 또 다른 이정표는 첫

194
00:11:05,780 --> 00:11:09,180
번째 컴퓨터 비전 박사학위 논문입니다.

195
00:11:09,180 --> 00:11:13,040
대부분 사람들은 1963년에 Larry

196
00:11:13,040 --> 00:11:17,880
Roberts가 형태만 연구한 첫 박사 논문을 썼다고 봅니다.

197
00:11:17,880 --> 00:11:21,350
이것은 세계를 매우, 매우 특징적으로 표현한

198
00:11:21,350 --> 00:11:22,260
것입니다.

199
00:11:22,260 --> 00:11:26,090
그리고 아이디어는, 이런 형태를 보고

200
00:11:26,090 --> 00:11:30,560
그 표면과 모서리, 특징들을 이해할 수

201
00:11:30,560 --> 00:11:32,210
있느냐는 겁니다.

202
00:11:32,210 --> 00:11:34,230
인간이 그렇게 한다는 것은 직관적입니다.

203
00:11:34,230 --> 00:11:39,350
그래서 전체 박사 논문이 이 주제에 할애되었습니다.

204
00:11:39,350 --> 00:11:44,980
이것이 컴퓨터 비전의 시작입니다.

205
00:11:44,980 --> 00:11:52,870
그리고 그 무렵인 1966년에 MIT 교수 한 분이 MIT에서

206
00:11:52,870 --> 00:11:56,710
여름 프로젝트를 만들고, 아주

207
00:11:56,710 --> 00:12:03,830
똑똑한 학부생 몇 명을 고용해 시각을 연구하도록 했습니다.

208
00:12:03,830 --> 00:12:07,120
목표는 한 여름 동안 컴퓨터 비전을 해결하거나

209
00:12:07,120 --> 00:12:09,400
시각 문제를 해결하는 것이었습니다.

210
00:12:09,400 --> 00:12:13,280
물론, AI 역사의 나머지 부분과 마찬가지로,

211
00:12:13,280 --> 00:12:18,310
우리는 짧은 시간 안에 할 수 있는 것에 대해 지나치게

212
00:12:18,310 --> 00:12:20,330
낙관적인 경향이 있습니다.

213
00:12:20,330 --> 00:12:24,530
그래서 그 여름 동안 비전 문제는 해결되지 않았습니다.

214
00:12:24,530 --> 00:12:29,800
사실, 이 분야는 놀라운 컴퓨터 과학 분야로

215
00:12:29,800 --> 00:12:30,710
발전했습니다.

216
00:12:30,710 --> 00:12:33,830
지금 매년 열리는 우리 연례 학회에 가보면

217
00:12:33,830 --> 00:12:36,420
1만 명이 넘는 사람들이 참석합니다.

218
00:12:36,420 --> 00:12:43,880
하지만 1960년대가 바로 Larry Roberts의 박사 논문과 이런
종류의

219
00:12:43,880 --> 00:12:48,500
프로젝트 사이에서, 우리 분야가 컴퓨터 비전

220
00:12:48,500 --> 00:12:51,830
분야의 시작으로 간주하는 시기입니다.

221
00:12:51,830 --> 00:12:55,620
1970년대에 David Marr가 쓴 중요한 책이 있습니다만,

222
00:12:55,620 --> 00:12:58,470
그는 안타깝게도 너무 일찍 세상을 떠났습니다.

223
00:12:58,470 --> 00:13:01,940
그는 비전을 체계적으로 연구하고 시각 처리

224
00:13:01,940 --> 00:13:05,790
과정이 어떻게 일어나는지 고려하기 시작했습니다.

225
00:13:05,790 --> 00:13:07,640
비록 명시적으로 언급되지는

226
00:13:07,640 --> 00:13:10,310
않았지만, 신경과학과

227
00:13:10,310 --> 00:13:12,930
인지과학에서 많은 영감을 받았습니다.

228
00:13:12,930 --> 00:13:20,070
그는 입력 이미지를 받으면 우리가 어떻게 시각적으로 처리하고

229
00:13:20,070 --> 00:13:23,580
이해하는지에 대해 생각했습니다.

230
00:13:23,580 --> 00:13:28,730
아마도 첫 번째 층은 우리가 본 것처럼 가장자리와 비슷할 겁니다.

231
00:13:28,730 --> 00:13:30,630
그는 이것을 primal sketch라고 부릅니다.

232
00:13:30,630 --> 00:13:37,890
그리고 2와 1/2D 스케치가 있는데, 이는 이미지 내

233
00:13:37,890 --> 00:13:42,910
객체들의 서로 다른 깊이를 구분합니다.

234
00:13:42,910 --> 00:13:45,060
그래서 공은 전경 객체입니다.

235
00:13:45,060 --> 00:13:47,860
그리고 여기 잔디-- 아, 아니네요,

236
00:13:47,860 --> 00:13:48,820
잔디가 아닙니다.

237
00:13:48,820 --> 00:13:51,520
여기 땅이 배경입니다.

238
00:13:51,520 --> 00:13:53,920
그래서 그는 이런 2와 1/2D 스케치를 만듭니다.

239
00:13:53,920 --> 00:14:01,440
그리고 마지막으로, David Marr는 시각 문제를 완전히 해결하는

240
00:14:01,440 --> 00:14:06,660
궁극적인 목표가 전체 3D 표현을 아는 것이라고

241
00:14:06,660 --> 00:14:07,960
믿습니다.

242
00:14:07,960 --> 00:14:12,880
그리고 그것이 사실 시각에서 가장 어려운 문제입니다.

243
00:14:12,880 --> 00:14:15,130
잠시 20초만 딴 얘기를 하겠습니다.

244
00:14:15,130 --> 00:14:20,950
모든 동물의 시각을 생각해보면, 이 문제는 잘

245
00:14:20,950 --> 00:14:23,350
정의되지 않은 문제입니다.

246
00:14:23,350 --> 00:14:27,390
초기 삼엽충들이 수중에서 빛을

247
00:14:27,390 --> 00:14:30,660
모았을 때, 빛—즉

248
00:14:30,660 --> 00:14:35,810
광자를 통해 본 세계는 대체로 2D

249
00:14:35,810 --> 00:14:38,070
표면에 투영됩니다.

250
00:14:38,070 --> 00:14:40,880
그 당시에는 동물의 어떤 부분에

251
00:14:40,880 --> 00:14:42,060
불과했죠.

252
00:14:42,060 --> 00:14:45,470
하지만 지금 우리에게는 그것이 망막입니다.

253
00:14:45,470 --> 00:14:47,910
하지만 실제 세계는 3D입니다.

254
00:14:47,910 --> 00:14:55,610
그래서 2D 이미지에서 전체 3D 정보를 복원하는 것이 자연이

255
00:14:55,610 --> 00:15:00,230
해결해야 했고 컴퓨터 비전도 해결해야 하는

256
00:15:00,230 --> 00:15:02,730
근본적인 문제입니다.

257
00:15:02,730 --> 00:15:05,840
그리고 수학적으로도 그것은 잘 정의되지 않은 문제입니다.

258
00:15:05,840 --> 00:15:07,940
그럼 우리는 나중에 무엇을 했을까요?

259
00:15:07,940 --> 00:15:09,745
누구든지 대충 추측해보시겠습니까?

260
00:15:14,900 --> 00:15:17,300
깊이를 위해 두 개의 눈을 개발했습니다.

261
00:15:17,300 --> 00:15:18,800
맞습니다.

262
00:15:18,800 --> 00:15:22,200
자연이 한 트릭은 여러 개의 눈, 주로 두 개의 눈을 개발한

263
00:15:22,200 --> 00:15:22,700
것입니다.

264
00:15:22,700 --> 00:15:25,260
어떤 동물은 두 개 이상을 가지고 있기도 합니다.

265
00:15:25,260 --> 00:15:28,110
그리고 나서 정보를 삼각측량합니다.

266
00:15:28,110 --> 00:15:29,740
하지만 두 개의 눈만으로는 충분하지 않습니다.

267
00:15:29,740 --> 00:15:33,250
실제로 대응 관계를 이해해야 하고 그런 것들이 필요합니다.

268
00:15:33,250 --> 00:15:35,050
이 주제들 중 일부를 다룰 것입니다.

269
00:15:35,050 --> 00:15:38,880
하지만 Stanford에서 제공하는 다른 컴퓨터 비전

270
00:15:38,880 --> 00:15:42,090
수업들도 3D 비전에 대해 구체적으로 다룹니다.

271
00:15:42,090 --> 00:15:45,660
하지만 요점은 이것이 매우 어려운 문제라는 것입니다.

272
00:15:45,660 --> 00:15:47,590
그리고 우리는 이것을 해결해야 합니다.

273
00:15:47,590 --> 00:15:48,790
자연은 이 문제를 해결했습니다.

274
00:15:48,790 --> 00:15:53,110
인간도 해결했지만 극도의 정밀도는 아닙니다.

275
00:15:53,110 --> 00:15:55,750
사실 인간은 그렇게 정밀하지 않습니다.

276
00:15:55,750 --> 00:15:58,510
저는 대략 3D 형태를 압니다.

277
00:15:58,510 --> 00:16:03,430
하지만 모든 형태의 기하학적 정밀도를 가지고 있지는 않습니다.

278
00:16:03,430 --> 00:16:06,780
그래서 이 문제의 어려움을 고려하고

279
00:16:06,780 --> 00:16:08,620
이해하는 것이 중요합니다.

280
00:16:08,620 --> 00:16:12,420
컴퓨터 비전과 언어가 매우 다른

281
00:16:12,420 --> 00:16:15,480
또 다른 점은 철학적으로

282
00:16:15,480 --> 00:16:17,370
미묘한 부분입니다.

283
00:16:17,370 --> 00:16:20,170
언어는 자연에 존재하지 않습니다.

284
00:16:20,170 --> 00:16:24,340
무언가를 가리키면서 '저것이 언어다'라고 할 수 없습니다.

285
00:16:24,340 --> 00:16:30,090
언어는 순전히 생성된 것입니다.

286
00:16:30,090 --> 00:16:31,860
어떤 단어를 써야 할지조차 모르겠습니다.

287
00:16:31,860 --> 00:16:35,460
그것은 우리 뇌를 통해 나옵니다.

288
00:16:35,460 --> 00:16:37,290
생성되는 거죠.

289
00:16:37,290 --> 00:16:38,580
1차원입니다.

290
00:16:38,580 --> 00:16:40,310
순차적입니다.

291
00:16:40,310 --> 00:16:44,450
그래서 이것은 최신 GenAI 알고리즘

292
00:16:44,450 --> 00:16:47,510
물결에 깊은 영향을 미칩니다.

293
00:16:47,510 --> 00:16:50,420
이것이 바로 이 수업 범위를 벗어난

294
00:16:50,420 --> 00:16:54,890
LLM들이 매우 강력한 이유인데, 우리는 언어를 그렇게

295
00:16:54,890 --> 00:16:56,760
모델링할 수 있기 때문입니다.

296
00:16:56,760 --> 00:16:58,650
하지만 비전은 생성되지 않습니다.

297
00:16:58,650 --> 00:17:01,670
물리 법칙과 재료 등

298
00:17:01,670 --> 00:17:05,839
실제 물리적 세계가 존재합니다.

299
00:17:05,839 --> 00:17:06,510
실제 물리적 세계가 존재합니다.

300
00:17:06,510 --> 00:17:09,420
그래서 비전은 매우 다른 과제를 가집니다.

301
00:17:09,420 --> 00:17:14,089
그래서 언어와 비전의 차이를 이해하고, 솔직히

302
00:17:14,089 --> 00:17:17,450
자연이 이 문제를 어떻게 해결했는지

303
00:17:17,450 --> 00:17:19,880
감탄했으면 합니다.

304
00:17:19,880 --> 00:17:21,060
계속 진행하겠습니다.

305
00:17:21,060 --> 00:17:28,150
1970년대, 컴퓨터 비전의 초기 개척자들은 데이터도, 강력한

306
00:17:28,150 --> 00:17:32,320
컴퓨터도, 오늘날 우리가 보는 수학적

307
00:17:32,320 --> 00:17:36,970
발전도 없이 이미 컴퓨터 비전의 어려운

308
00:17:36,970 --> 00:17:40,290
문제들, 예를 들어 객체

309
00:17:40,290 --> 00:17:43,780
인식을 해결하기 시작했습니다.

310
00:17:43,780 --> 00:17:48,120
스탠포드에서는 Rodney Brooks와 Tom Binford가

311
00:17:48,120 --> 00:17:52,140
generalized cylinders라는 선구적인 연구를

312
00:17:52,140 --> 00:17:52,900
했습니다.

313
00:17:52,900 --> 00:17:58,650
아이러니하게도 Rodney Brooks는 오늘 캠퍼스에서

314
00:17:58,650 --> 00:18:03,520
로봇공학 컨퍼런스에서 강연을 하고 있습니다.

315
00:18:03,520 --> 00:18:05,760
그는 우리 시대의 가장 위대한

316
00:18:05,760 --> 00:18:10,080
로봇공학자 중 한 명이 되었고, Roomba와 여러 다른

317
00:18:10,080 --> 00:18:11,770
로봇들의 창립자였습니다.

318
00:18:11,770 --> 00:18:16,530
그리고 우리와 멀지 않은 Palo

319
00:18:16,530 --> 00:18:24,760
Alto의 다른 지역에서는 연구자들이 인간 몸과 물체의 구성

320
00:18:24,760 --> 00:18:27,860
모델에 대해 연구했습니다.

321
00:18:27,860 --> 00:18:34,250
그리고 1980년대에 디지털 사진이 등장하기 시작했습니다.

322
00:18:34,250 --> 00:18:37,220
적어도 사진이 등장하기 시작했습니다.

323
00:18:37,220 --> 00:18:39,680
사람들은 그것을 어느 정도 디지털화할 수 있었습니다.

324
00:18:39,680 --> 00:18:43,940
그리고 에지 검출에 관한 훌륭한 연구들이 있었습니다.

325
00:18:43,940 --> 00:18:48,190
이 모든 것을 보면 아마

326
00:18:48,190 --> 00:18:50,900
실망감을 느낄 것입니다.

327
00:18:50,900 --> 00:18:55,540
사실, 스케치와 에지를 얻는 것은 꽤 사소한 일입니다.

328
00:18:55,540 --> 00:18:58,460
그리고 그것이 크게 발전하지 못했습니다.

329
00:18:58,460 --> 00:19:02,060
그 당시 컴퓨터 비전이 바로 그렇게 작동했습니다.

330
00:19:02,060 --> 00:19:03,980
사실, 당신이 틀린 것은 아닙니다.

331
00:19:03,980 --> 00:19:07,660
그것은 여러분 중 많은 분들이 태어나기

332
00:19:07,660 --> 00:19:10,280
전쯤인 AI 겨울 시기였습니다.

333
00:19:10,280 --> 00:19:15,250
그 분야는 AI 연구에 대한 열정과 자금 지원이 크게

334
00:19:15,250 --> 00:19:18,530
줄어들면서 AI 겨울에 접어들었습니다.

335
00:19:18,530 --> 00:19:20,510
많은 것들이 기대에 미치지 못했습니다.

336
00:19:20,510 --> 00:19:22,270
컴퓨터 비전도 기대에 미치지 못했습니다.

337
00:19:22,270 --> 00:19:24,460
전문가 시스템도 기대에 미치지 못했습니다.

338
00:19:24,460 --> 00:19:26,520
로보틱스는 기대에 미치지 못했습니다.

339
00:19:26,520 --> 00:19:32,310
하지만 이 겨울 동안 컴퓨터 비전, NLP, 로보틱스

340
00:19:32,310 --> 00:19:34,530
같은 다양한 분야에서

341
00:19:34,530 --> 00:19:37,510
많은 연구가 시작되었습니다.

342
00:19:37,510 --> 00:19:40,380
그래서 컴퓨터 비전에 깊은

343
00:19:40,380 --> 00:19:43,290
영향을 준 또 다른 연구 분야인

344
00:19:43,290 --> 00:19:45,270
인지과학과 신경과학도

345
00:19:45,270 --> 00:19:46,960
살펴보겠습니다.

346
00:19:46,960 --> 00:19:49,320
특히 컴퓨터 비전 분야에서

347
00:19:49,320 --> 00:19:52,480
중요한 점은 인지과학과 신경과학이 우리가

348
00:19:52,480 --> 00:19:55,800
집중해야 할 북극성 문제들을 제시하기

349
00:19:55,800 --> 00:19:57,490
시작했다는 겁니다.

350
00:19:57,490 --> 00:20:00,030
예를 들어, 심리학자들은

351
00:20:00,030 --> 00:20:02,620
자연을 보고 실제 세상을

352
00:20:02,620 --> 00:20:06,360
보는 것에 특별한 점이 있다고 말합니다.

353
00:20:06,360 --> 00:20:09,210
이것은 Irv Biederman의

354
00:20:09,210 --> 00:20:13,980
연구로, 이미지가 섞였는지 여부에

355
00:20:13,980 --> 00:20:18,820
따라 자전거 인식이 달라진다는 것을 보여줍니다.

356
00:20:18,820 --> 00:20:19,570
생각해 보세요.

357
00:20:19,570 --> 00:20:22,090
광학적으로 보면 이 두

358
00:20:22,090 --> 00:20:26,630
자전거는 망막의 같은 위치에 맺히죠.

359
00:20:26,630 --> 00:20:28,720
하지만 이미지의

360
00:20:28,720 --> 00:20:39,080
나머지 부분이 관찰자가 목표 객체를 보는 데 영향을 미칩니다.

361
00:20:39,080 --> 00:20:41,440
즉, 전체 숲이나 세상을

362
00:20:41,440 --> 00:20:44,170
보는 것이 객체 인식 방식에

363
00:20:44,170 --> 00:20:46,730
영향을 준다는 것을 알려줍니다.

364
00:20:46,730 --> 00:20:49,820
또한 시각 처리가 매우 빠르다는 것도 알려줍니다.

365
00:20:49,820 --> 00:20:55,340
여기 객체를 얼마나 빠르게 인식하는지 직접 측정한 또 다른 예가 있습니다.

366
00:20:55,340 --> 00:21:00,670
1970년대 초 실험으로 사람들에게

367
00:21:00,670 --> 00:21:03,061
비디오를 보여줍니다.

368
00:21:03,061 --> 00:21:07,630
피험자의 과제는 프레임 중 하나에서 사람을

369
00:21:07,630 --> 00:21:09,170
인식하는 것입니다.

370
00:21:09,170 --> 00:21:11,920
여러분 모두 그 프레임에서 사람을 보셨을

371
00:21:11,920 --> 00:21:13,250
거라 생각합니다.

372
00:21:13,250 --> 00:21:15,520
하지만 이 비디오를 본 적이 없는데도

373
00:21:15,520 --> 00:21:19,080
여러분의 눈과 뇌가 얼마나 놀라운지 생각해 보세요.

374
00:21:19,080 --> 00:21:22,610
어떤 프레임에 목표 객체가 나타날지 말씀드리지

375
00:21:22,610 --> 00:21:23,160
않았습니다.

376
00:21:23,160 --> 00:21:24,980
목표 객체가 어떻게 생겼는지,

377
00:21:24,980 --> 00:21:28,860
어디에 있는지, 어떤 제스처를 하는지 등도 말씀드리지 않았습니다.

378
00:21:28,860 --> 00:21:31,690
그런데도 인간을 감지하는 데 아무 문제가 없으시죠.

379
00:21:34,570 --> 00:21:37,670
게다가 이 프레임들은 10 헤르츠로

380
00:21:37,670 --> 00:21:39,860
재생되기 때문에, 각

381
00:21:39,860 --> 00:21:43,800
프레임을 겨우 100밀리초 동안만 보게 됩니다.

382
00:21:43,800 --> 00:21:47,880
이것이 바로 우리의 시각 시스템이 얼마나 놀라운지 보여주는 겁니다.

383
00:21:47,880 --> 00:21:53,700
사실, 또 다른 인지 신경과학자인 Simon Thorpe가 그

384
00:21:53,700 --> 00:21:55,410
속도를 측정했습니다.

385
00:21:55,410 --> 00:21:58,430
사람들에게 EEG 캡을 씌우고

386
00:21:58,430 --> 00:22:01,770
복잡한 자연 장면을 보여준 뒤,

387
00:22:01,770 --> 00:22:05,870
동물이 있는 것과 없는 것을 구분하도록

388
00:22:05,870 --> 00:22:07,970
요청했습니다.

389
00:22:07,970 --> 00:22:10,260
수백 장의 사진을

390
00:22:10,260 --> 00:22:11,310
보여주면서요.

391
00:22:11,310 --> 00:22:13,290
그리고 뇌파를 측정했습니다.

392
00:22:13,290 --> 00:22:18,910
결과는, 사진을 본 지 150밀리초 만에 뇌가

393
00:22:18,910 --> 00:22:22,540
이미 구분 신호를 만들어낸다는

394
00:22:22,540 --> 00:22:24,020
것이었습니다.

395
00:22:24,020 --> 00:22:25,990
그리 대단하지 않다고 생각할 수도 있습니다.

396
00:22:25,990 --> 00:22:29,870
오늘날 GPU나 최신 칩과 비교하면

397
00:22:29,870 --> 00:22:34,550
150밀리초는 훨씬 느린 속도이니까요.

398
00:22:34,550 --> 00:22:37,210
하지만 감탄할 수밖에 없습니다.

399
00:22:37,210 --> 00:22:40,780
우리의 생물학적 시스템, 즉 뇌와 뉴런은

400
00:22:40,780 --> 00:22:43,370
트랜지스터만큼 빠르게 작동하지 않습니다.

401
00:22:43,370 --> 00:22:46,610
150밀리초는 사실 매우 빠른 속도입니다.

402
00:22:46,610 --> 00:22:49,310
신경 처리 관점에서 보면 뇌에서

403
00:22:49,310 --> 00:22:51,520
몇 단계만 거친 셈이니까요.

404
00:22:51,520 --> 00:22:53,950
다시 말해, 이것은 인간이

405
00:22:53,950 --> 00:22:59,990
사물을 보고 분류하는 데 정말 뛰어나다는 것을 알려줍니다.

406
00:22:59,990 --> 00:23:02,560
사실 우리는 물체를 보고

407
00:23:02,560 --> 00:23:05,830
분류하는 데 매우 뛰어날 뿐만 아니라,

408
00:23:05,830 --> 00:23:10,060
얼굴이나 장소, 신체 부위를 인식하는 전문적인 능력을

409
00:23:10,060 --> 00:23:13,100
가진 뇌 영역도 발달시켰습니다.

410
00:23:13,100 --> 00:23:19,040
이것들은 1990년대와 21세기 초 MIT 신경생리학자들의

411
00:23:19,040 --> 00:23:21,120
발견입니다.

412
00:23:21,120 --> 00:23:26,090
이 모든 연구들은 단순히 문자 모양이나

413
00:23:26,090 --> 00:23:30,020
이미지 스케치만 연구해서는

414
00:23:30,020 --> 00:23:33,660
안 된다는 것을 알려줍니다.

415
00:23:33,660 --> 00:23:38,750
우리는 시각 지능을 이끄는 중요한 근본 문제를 정말로

416
00:23:38,750 --> 00:23:40,770
추구해야 합니다.

417
00:23:40,770 --> 00:23:43,340
그리고 모든 연구가 말해주는

418
00:23:43,340 --> 00:23:46,100
그 문제 중 하나가

419
00:23:46,100 --> 00:23:49,830
바로 자연 환경에서의 물체 인식입니다.

420
00:23:49,830 --> 00:23:52,950
세상에는 정말 많은 물체들이 존재합니다.

421
00:23:52,950 --> 00:23:57,740
이것을 연구하는 것이 시각 지능을 여는 열쇠

422
00:23:57,740 --> 00:24:00,300
중 하나가 될 것입니다.

423
00:24:00,300 --> 00:24:01,550
바로 그 일을 우리가 했습니다.

424
00:24:01,550 --> 00:24:04,670
이 분야는 전경 물체와 배경 물체를

425
00:24:04,670 --> 00:24:08,210
어떻게 분리할 수 있는지 연구하는

426
00:24:08,210 --> 00:24:09,960
것부터 시작했습니다.

427
00:24:09,960 --> 00:24:14,570
이것을 1990년대에는 그룹화에 의한 인식이라고 불렀습니다.

428
00:24:14,570 --> 00:24:16,850
기억하세요, 그때는 아직 AI 겨울기였습니다.

429
00:24:16,850 --> 00:24:20,090
하지만 연구는 실제로 진행되고 있었습니다.

430
00:24:20,090 --> 00:24:24,560
그리고 특징(feature)에 대한 연구도 있었습니다.

431
00:24:24,560 --> 00:24:27,550
여러분 중 일부는 아직도 SIFT 특징과

432
00:24:27,550 --> 00:24:29,780
매칭을 기억할 수 있을 겁니다.

433
00:24:29,780 --> 00:24:33,610
제가 대학원에 들어갔을 때 가장 흥미로웠던 것은 얼굴

434
00:24:33,610 --> 00:24:34,790
인식이었습니다.

435
00:24:34,790 --> 00:24:37,280
대학원 첫 해에 이 논문이

436
00:24:37,280 --> 00:24:39,380
발표된 것을 기억합니다.

437
00:24:39,380 --> 00:24:42,550
그리고 5년 후, 최초의 디지털

438
00:24:42,550 --> 00:24:49,030
카메라가 이 논문의 알고리즘을 사용해 얼굴 인식 자동 초점

439
00:24:49,030 --> 00:24:51,260
기능을 제공했습니다.

440
00:24:51,260 --> 00:24:56,560
그래서 기술이 작동하기 시작했고 산업계로 넘어갔습니다.

441
00:24:56,560 --> 00:25:01,190
그리고 21세기 초쯤에 매우 중요한

442
00:25:01,190 --> 00:25:04,810
일이 일어났는데, 바로 인터넷이

443
00:25:04,810 --> 00:25:06,820
시작된 것입니다.

444
00:25:06,820 --> 00:25:12,600
인터넷이 시작되면서 데이터가 폭발적으로 늘어나기 시작했습니다.

445
00:25:12,600 --> 00:25:16,970
디지털 카메라와 인터넷의 결합이 컴퓨터

446
00:25:16,970 --> 00:25:19,850
비전 분야에 연구할 데이터를

447
00:25:19,850 --> 00:25:22,050
제공하기 시작했습니다.

448
00:25:22,050 --> 00:25:26,420
초기에는 수천 장 또는 수만 장의

449
00:25:26,420 --> 00:25:30,470
이미지로 시각 인식 문제나 물체 인식

450
00:25:30,470 --> 00:25:32,880
문제를 연구했습니다.

451
00:25:32,880 --> 00:25:36,350
그래서 Pascal Visual Object

452
00:25:36,350 --> 00:25:40,760
Challenge나 Caltech 101 같은 데이터셋이 있었습니다.

453
00:25:40,760 --> 00:25:43,610
여기서 잠시 멈추겠습니다.

454
00:25:43,610 --> 00:25:50,060
이것이 컴퓨터 비전의 첫 번째 흐름이 발전하기 시작한

455
00:25:50,060 --> 00:25:51,060
지점입니다.

456
00:25:51,060 --> 00:25:54,420
왜 제가 잠시 멈추는지 궁금할 수 있습니다.

457
00:25:54,420 --> 00:25:57,300
곧 다시 돌아와서 딥러닝에 대해 이야기할 거기 때문입니다.

458
00:25:57,300 --> 00:26:03,170
이 시각 분야가 신경생리학에서 컴퓨터 비전,

459
00:26:03,170 --> 00:26:06,980
인지 신경과학, 다시 컴퓨터

460
00:26:06,980 --> 00:26:11,490
비전으로 발전하는 동안, 별도의

461
00:26:11,490 --> 00:26:14,980
노력이 병행되고 있었습니다.

462
00:26:14,980 --> 00:26:17,380
그것이 결국 딥러닝이 되었습니다.

463
00:26:17,380 --> 00:26:22,870
딥러닝은 초기 신경망 연구, 예를 들어 퍼셉트론 같은 것에서

464
00:26:22,870 --> 00:26:24,270
시작되었습니다.

465
00:26:24,270 --> 00:26:29,800
Rumelhart 같은 사람들이 연구를 시작했고,

466
00:26:29,800 --> 00:26:32,140
물론 Jeff Hinton도

467
00:26:32,140 --> 00:26:35,400
초기에는 소수의 인공

468
00:26:35,400 --> 00:26:41,010
뉴런으로 정보 처리와 학습이 어떻게 가능한지 연구했습니다.

469
00:26:41,010 --> 00:26:48,270
그리고 여러분은 Marvin Minsky 같은 위대한 학자들과 그의

470
00:26:48,270 --> 00:26:52,620
동료들이 이 지각의 다양한 측면을 연구하는 것을

471
00:26:52,620 --> 00:26:54,550
들어보셨을 겁니다.

472
00:26:54,550 --> 00:27:02,850
하지만 Marvin Minsky는 퍼셉트론이 XOR 논리 함수를 학습할

473
00:27:02,850 --> 00:27:05,220
수 없다고 말했습니다.

474
00:27:05,220 --> 00:27:10,130
그것이 신경망 연구에 약간의 좌절을 가져왔죠.

475
00:27:10,130 --> 00:27:14,670
하지만 그 좌절에도 불구하고 연구는 계속 진행되었습니다.

476
00:27:14,670 --> 00:27:21,530
첫 번째 전환점 이전에 가장 중요한 연구 중 하나는 일본의
Fukushima가

477
00:27:21,530 --> 00:27:25,890
만든 neocognitron 작업입니다.

478
00:27:25,890 --> 00:27:31,980
Fukushima는 이렇게 생긴 신경망을 손수 설계했습니다.

479
00:27:31,980 --> 00:27:35,700
대략 다섯에서 여섯 개 층으로 구성되어 있습니다.

480
00:27:35,700 --> 00:27:41,780
그리고 각 층에 걸쳐 다른 기능들을 설계했는데, 여러분이

481
00:27:41,780 --> 00:27:43,700
더 배우게 될

482
00:27:43,700 --> 00:27:46,910
내용이며, 대체로 제가 설명한

483
00:27:46,910 --> 00:27:50,850
시각 경로에서 영감을 받았습니다.

484
00:27:50,850 --> 00:27:54,560
간단한 수용 영역에서 더 복잡한 수용 영역으로

485
00:27:54,560 --> 00:27:56,790
가는 고양이 실험을 기억하시죠?

486
00:27:56,790 --> 00:27:59,040
그가 바로 여기서 그런 작업을 한 겁니다.

487
00:27:59,040 --> 00:28:01,830
초기 층들은 단순한 기능을 가지고 있습니다.

488
00:28:01,830 --> 00:28:03,270
그리고 나중 층들은

489
00:28:03,270 --> 00:28:05,490
더 복잡한 기능을 가지고 있죠.

490
00:28:05,490 --> 00:28:08,680
단순한 기능은 컨볼루션이라고 부를 수 있습니다.

491
00:28:08,680 --> 00:28:10,710
혹은 그가 컨볼루션 함수를 사용했습니다.

492
00:28:10,710 --> 00:28:13,620
더 복잡한 기능은 컨볼루션 층에서 정보를

493
00:28:13,620 --> 00:28:15,220
끌어오는 방식이었습니다.

494
00:28:15,220 --> 00:28:19,800
Neocognitron은 모든 파라미터가 손수

495
00:28:19,800 --> 00:28:24,795
설계되었기 때문에 정말 공학적인 업적이었습니다.

496
00:28:24,795 --> 00:28:26,170
수백 개의 파라미터가 있었죠.

497
00:28:26,170 --> 00:28:29,430
그는 이 작은 신경망이 숫자나

498
00:28:29,430 --> 00:28:32,610
글자를 인식할 수 있도록

499
00:28:32,610 --> 00:28:35,910
세심하게 조합해야 했습니다.

500
00:28:35,910 --> 00:28:41,130
진정한 돌파구는 1986년경에 나온

501
00:28:41,130 --> 00:28:43,180
학습 규칙입니다.

502
00:28:43,180 --> 00:28:45,580
그 학습 규칙은 역전파(backpropagation)라고 불립니다.

503
00:28:45,580 --> 00:28:47,580
이것은 우리의

504
00:28:47,580 --> 00:28:52,455
첫 수업 중 하나에서 다룰 내용인데,

505
00:28:52,455 --> 00:28:58,020
Rumelhart와 Jeff Hinton이

506
00:28:58,020 --> 00:29:04,260
신경망 구조에 오차 수정 목적 함수를

507
00:29:04,260 --> 00:29:07,400
도입했습니다. 입력을 넣고

508
00:29:07,400 --> 00:29:10,280
올바른 출력을 알 때,

509
00:29:10,280 --> 00:29:14,780
신경망 출력과 실제 정답 간의

510
00:29:14,780 --> 00:29:17,900
차이를 어떻게 계산하고,

511
00:29:17,900 --> 00:29:22,640
그 정보를 신경망 전체에 역전파하여

512
00:29:22,640 --> 00:29:28,590
파라미터를 개선할 수 있는지 보여줍니다.

513
00:29:28,590 --> 00:29:31,250
출력에서 신경망 전체로

514
00:29:31,250 --> 00:29:33,800
정보를 역전파하는 과정을

515
00:29:33,800 --> 00:29:35,850
역전파라고 합니다.

516
00:29:35,850 --> 00:29:39,180
이는 기본적인 미적분의 연쇄 법칙을 따릅니다.

517
00:29:39,180 --> 00:29:47,420
이것은 신경망 알고리즘에 있어 중대한 전환점이었습니다.

518
00:29:47,420 --> 00:29:50,970
물론 그때는 AI 겨울 한가운데였고,

519
00:29:50,970 --> 00:29:54,810
이 모든 연구는 대중적인 관심 없이 진행되었습니다.

520
00:29:54,810 --> 00:29:57,930
하지만 연구계에서는 매우 중요한

521
00:29:57,930 --> 00:29:59,650
이정표였습니다.

522
00:29:59,650 --> 00:30:03,720
역전파를 적용한 신경망의 가장 초기 응용 중

523
00:30:03,720 --> 00:30:07,020
하나는 Yann LeCun이 1990년대

524
00:30:07,020 --> 00:30:10,410
Bell Labs에서 만든 컨볼루션

525
00:30:10,410 --> 00:30:11,500
신경망입니다.

526
00:30:11,500 --> 00:30:15,970
그는 약 7층 정도 되는 조금 더 큰

527
00:30:15,970 --> 00:30:20,610
신경망을 만들었고, 훌륭한 공학 기술로 글자를

528
00:30:20,610 --> 00:30:25,120
인식할 수 있을 만큼 성능을 높였습니다.

529
00:30:25,120 --> 00:30:28,710
이 신경망은 실제로 미국 우체국과 은행의

530
00:30:28,710 --> 00:30:33,580
일부에 배포되어 숫자와 글자를 읽는 데 사용되었습니다.

531
00:30:33,580 --> 00:30:37,600
이것이 초기 신경망의 응용 사례였습니다.

532
00:30:37,600 --> 00:30:41,250
그리고 Jeff Hinton과 Yann LeCun은

533
00:30:41,250 --> 00:30:43,390
계속해서 신경망 연구를 이어갔습니다.

534
00:30:43,390 --> 00:30:45,720
그것은 크게 발전하지 못했습니다.

535
00:30:45,720 --> 00:30:52,050
이 신경망의 개선과 조정에도 불구하고,

536
00:30:52,050 --> 00:30:57,290
상황은 대체로 정체되었습니다.

537
00:30:57,290 --> 00:31:00,280
그들은 숫자와 글자의 큰 데이터 세트를 수집했습니다.

538
00:31:00,280 --> 00:31:03,730
숫자와 글자는 인식 측면에서 다소 부드러운

539
00:31:03,730 --> 00:31:05,090
편이었습니다.

540
00:31:05,090 --> 00:31:08,020
하지만 신경과학자들이 고양이, 개,

541
00:31:08,020 --> 00:31:11,500
전자레인지, 의자, 꽃 등을 인식하는

542
00:31:11,500 --> 00:31:14,470
데 사용한 디지털 사진을 시스템에

543
00:31:14,470 --> 00:31:17,180
넣으면 작동하지 않았습니다.

544
00:31:17,180 --> 00:31:22,550
이 문제의 큰 부분은 데이터 부족입니다.

545
00:31:22,550 --> 00:31:27,500
데이터 부족은 단순한 불편함이 아닙니다.

546
00:31:27,500 --> 00:31:29,990
이 알고리즘들은 높은

547
00:31:29,990 --> 00:31:36,430
용량의 알고리즘으로, 일반화 학습을 위해 많은

548
00:31:36,430 --> 00:31:39,850
데이터가 필요하기 때문에

549
00:31:39,850 --> 00:31:42,350
수학적인 문제입니다.

550
00:31:42,350 --> 00:31:45,010
일반화와 모델 과적합에

551
00:31:45,010 --> 00:31:48,380
관한 깊은 수학적 원리가

552
00:31:48,380 --> 00:31:49,210
존재합니다.

553
00:31:49,210 --> 00:31:52,660
대부분의 사람들이 아키텍처만 보고 있었기

554
00:31:52,660 --> 00:31:54,840
때문에 데이터의 중요성이

555
00:31:54,840 --> 00:31:56,560
과소평가되고 간과되었습니다.

556
00:31:56,560 --> 00:31:59,190
데이터가 머신러닝과 딥러닝에서

557
00:31:59,190 --> 00:32:02,070
1급 시민이라는 사실을 깨닫지

558
00:32:02,070 --> 00:32:03,490
못했습니다.

559
00:32:03,490 --> 00:32:08,340
이것은 2000년대 초반에 제 학생들과

560
00:32:08,340 --> 00:32:14,760
제가 수행한 연구의 일부로, 데이터의 중요성을

561
00:32:14,760 --> 00:32:15,640
인식했습니다.

562
00:32:15,640 --> 00:32:21,240
우리는 전체 분야가 데이터의 중요성을 과소평가하고

563
00:32:21,240 --> 00:32:24,520
있다고 가설을 세웠습니다.

564
00:32:24,520 --> 00:32:27,090
그래서 우리는 10억 개의 이미지를 정제한 후

565
00:32:27,090 --> 00:32:30,120
5천만 개의 이미지를 포함하는 ImageNet이라는

566
00:32:30,120 --> 00:32:32,260
거대한 데이터 세트를 수집했습니다.

567
00:32:32,260 --> 00:32:38,310
이 1,500만 개의 이미지는 22,000개의 객체 범주로

568
00:32:38,310 --> 00:32:39,310
분류되었습니다.

569
00:32:39,310 --> 00:32:43,110
우리는 인지과학과 심리학

570
00:32:43,110 --> 00:32:51,480
문헌을 많이 연구하여 22,000개의 범주가 인간이 어린

571
00:32:51,480 --> 00:32:54,880
시절에 인식하는 범주의

572
00:32:54,880 --> 00:32:58,510
수와 대략 비슷하다는 것을

573
00:32:58,510 --> 00:33:00,470
이해했습니다.

574
00:33:00,470 --> 00:33:02,180
그리고 우리는 이 데이터 세트를 오픈 소스로

575
00:33:02,180 --> 00:33:05,860
공개하고 Large Scale Visual Recognition
Challenge라는

576
00:33:05,860 --> 00:33:07,580
ImageNet 챌린지를 만들었습니다.

577
00:33:07,580 --> 00:33:12,700
우리는 ImageNet에서 백만 장 이상의 이미지와 1,

578
00:33:12,700 --> 00:33:16,870
000개의 객체 클래스로 구성된 하위 집합을

579
00:33:16,870 --> 00:33:21,430
선별했고, 여러 해 동안 국제 객체 인식 챌린지를

580
00:33:21,430 --> 00:33:22,040
진행했습니다.

581
00:33:22,040 --> 00:33:26,900
목표는 연구자들이 참여하도록 요청하는 것입니다.

582
00:33:26,900 --> 00:33:29,420
그리고 그들의 목표는 알고리즘을 만드는 것입니다.

583
00:33:29,420 --> 00:33:31,430
어떤 종류의 알고리즘인지는 중요하지 않습니다.

584
00:33:31,430 --> 00:33:35,650
그리고 그 알고리즘이 사진을 인식하는 능력을

585
00:33:35,650 --> 00:33:40,900
테스트해서 1,000개의 객체 클래스를 최대한 정확하게 맞출

586
00:33:40,900 --> 00:33:42,800
수 있는지 평가합니다.

587
00:33:42,800 --> 00:33:45,040
여기 오류들이 있습니다.

588
00:33:45,040 --> 00:33:53,070
첫해 이 대회를 진행했을 때, 가장 성능이 좋은 알고리즘의

589
00:33:53,070 --> 00:33:57,000
오류율은 거의 30%였습니다.

590
00:33:57,000 --> 00:34:00,860
사람은 3% 이하의 오류율을 보이기 때문에

591
00:34:00,860 --> 00:34:03,510
정말 형편없는 수준이었죠.

592
00:34:03,510 --> 00:34:07,260
2011년에는 그다지 흥미롭지 않았습니다.

593
00:34:07,260 --> 00:34:09,560
하지만 2012년에 무언가 일어났습니다.

594
00:34:09,560 --> 00:34:12,389
그 해가 가장 흥미로운 해였습니다.

595
00:34:12,389 --> 00:34:16,190
그 해에 Jeff Hinton과 그의 학생들이 convolutional

596
00:34:16,190 --> 00:34:18,650
neural network를 사용해

597
00:34:18,650 --> 00:34:20,340
이 챌린지에 참여했습니다.

598
00:34:20,340 --> 00:34:23,100
그리고 오류율을 거의 절반으로 줄였습니다.

599
00:34:23,100 --> 00:34:29,520
이것이 딥러닝 알고리즘의 힘을 진정으로 보여준 사례입니다.

600
00:34:29,520 --> 00:34:34,760
그래서 2012년 ImageNet 챌린지에 참가한 알고리즘은

601
00:34:34,760 --> 00:34:36,960
AlexNet이라고 불렸습니다.

602
00:34:36,960 --> 00:34:42,560
재미있는 점은, AlexNet을 보면 32년 전

603
00:34:42,560 --> 00:34:47,449
후쿠시마의 neocognitron과 크게 다르지

604
00:34:47,449 --> 00:34:49,580
않다는 겁니다.

605
00:34:49,580 --> 00:34:54,830
하지만 그 사이에 두 가지 중요한 일이 있었습니다.

606
00:34:54,830 --> 00:34:57,530
첫째는 backpropagation이 등장했다는 것입니다.

607
00:34:57,530 --> 00:35:01,270
이것은 수학적으로 엄밀한 학습 규칙으로,

608
00:35:01,270 --> 00:35:04,300
사람이 직접 파라미터를 조정할

609
00:35:04,300 --> 00:35:06,140
필요가 없게 해줍니다.

610
00:35:06,140 --> 00:35:09,410
이것이 이론적으로 큰 돌파구였습니다.

611
00:35:09,410 --> 00:35:14,180
또 다른 돌파구는 데이터였습니다.

612
00:35:14,180 --> 00:35:19,630
데이터에 대한 인식과 이해가 고용량 모델,

613
00:35:19,630 --> 00:35:23,200
결국에는 조 단위 파라미터를 가진

614
00:35:23,200 --> 00:35:26,110
모델을 가능하게 했고,

615
00:35:26,110 --> 00:35:34,831
당시에는 수백만 개 파라미터였지만, 이것이 딥러닝이 작동하게 하는 데

616
00:35:34,831 --> 00:35:36,410
결정적이었습니다.

617
00:35:36,410 --> 00:35:42,406
많은 사람들이 2012년과 ImageNet

618
00:35:42,406 --> 00:35:46,870
챌린지에서 우승한 AlexNet 알고리즘을

619
00:35:46,870 --> 00:35:51,020
현대 AI의 탄생 혹은 재탄생,

620
00:35:51,020 --> 00:35:54,410
딥러닝 혁명의 시작으로

621
00:35:54,410 --> 00:35:55,760
봅니다.

622
00:35:55,760 --> 00:35:59,540
그리고 물론 여러분이 이 자리에 있는 이유는

623
00:35:59,540 --> 00:36:04,320
그때부터 딥러닝 폭발 시대에 들어섰기 때문입니다.

624
00:36:04,320 --> 00:36:10,910
컴퓨터 비전을 보면, CVPR이라는 주요 연례 연구

625
00:36:10,910 --> 00:36:13,190
학회에서 논문 수가

626
00:36:13,190 --> 00:36:15,620
폭발적으로 증가했습니다.

627
00:36:15,620 --> 00:36:18,870
arXiv에 올라오는 논문 수도 폭발적으로 늘었습니다.

628
00:36:18,870 --> 00:36:22,730
그 이후로 ImageNet 챌린지에

629
00:36:22,730 --> 00:36:27,350
참여하기 위해 많은 새로운 알고리즘이 발명되었습니다.

630
00:36:27,350 --> 00:36:28,050
참여하기 위해 많은 새로운 알고리즘이 발명되었습니다.

631
00:36:28,050 --> 00:36:29,870
앞으로 몇 년간 우리는 이 알고리즘들

632
00:36:29,870 --> 00:36:31,740
중 일부를 공부할 것입니다.

633
00:36:31,740 --> 00:36:34,640
중요한 것은

634
00:36:34,640 --> 00:36:39,380
AlexNet을 넘어서 컴퓨터 비전

635
00:36:39,380 --> 00:36:43,610
분야의 발전과 응용에 깊은 영향을

636
00:36:43,610 --> 00:36:49,090
준 알고리즘들이 있다는 점입니다.

637
00:36:49,090 --> 00:36:52,720
많은 일이 일어났고,

638
00:36:52,720 --> 00:36:54,530
그중 일부를 다룰 예정입니다.

639
00:36:54,530 --> 00:36:57,340
컴퓨터 비전 분야는 고양이,

640
00:36:57,340 --> 00:37:01,510
개, 의자 같은 일상적인 물체를

641
00:37:01,510 --> 00:37:06,260
인식하는 알고리즘을 만드는 데 큰

642
00:37:06,260 --> 00:37:10,400
진전을 이루었을 뿐만 아니라, 2012년

643
00:37:10,400 --> 00:37:14,140
ImageNet 챌린지

644
00:37:14,140 --> 00:37:22,550
이후로 훨씬 더 복잡한 이미지를 인식하고, 이미지를 검색하며, 다중 객체

645
00:37:22,550 --> 00:37:27,470
탐지와 이미지 분할도 할 수 있는 알고리즘을

646
00:37:27,470 --> 00:37:30,560
빠르게 개발했습니다.

647
00:37:30,560 --> 00:37:34,360
이것들은 모두 시각 인식의 다양한 과제들로, 이 강의를

648
00:37:34,360 --> 00:37:36,220
통해 여러분이 익숙해지게

649
00:37:36,220 --> 00:37:38,690
될 내용입니다. 왜냐하면 비전은 단순히

650
00:37:38,690 --> 00:37:42,140
고양이와 개를 부르는 것만이 아니기 때문입니다.

651
00:37:42,140 --> 00:37:48,860
시각 인식에는 매우 미묘한 능력이 많이 포함되어 있습니다.

652
00:37:48,860 --> 00:37:52,830
그리고 물론, 비전은 정적인 이미지에만 국한되지 않습니다.

653
00:37:52,830 --> 00:37:57,500
비디오 분류, 인간 활동 인식 같은 연구도

654
00:37:57,500 --> 00:37:58,710
있습니다.

655
00:37:58,710 --> 00:38:00,930
이 개요를 보여드리는 이유는,

656
00:38:00,930 --> 00:38:04,775
여러분이 이 중 일부를 배우게 될 것이기 때문입니다.

657
00:38:04,775 --> 00:38:08,460
여기서 무슨 일이 일어나는지 정확히 이해할 필요는 없습니다.

658
00:38:08,460 --> 00:38:14,940
하지만 다양한 비전 과제들이 있다는 점을 이해하시길 바랍니다.

659
00:38:14,940 --> 00:38:20,870
의료 영상 분야에 계신 분들, 방사선학, 병리학, 혹은

660
00:38:20,870 --> 00:38:24,650
다른 의학 분야에서 오신 분들은 의료가

661
00:38:24,650 --> 00:38:28,260
매우 시각적인 분야임을 아실 겁니다.

662
00:38:28,260 --> 00:38:31,550
이것은 깊은 영향을 미칩니다.

663
00:38:31,550 --> 00:38:37,550
과학적 발견도 마찬가지입니다. 아마도 여러분이 기억하는

664
00:38:37,550 --> 00:38:41,700
최초의 블랙홀 사진 같은 중요한

665
00:38:41,700 --> 00:38:46,830
사진도 컴퓨터 비전과 계산 사진 기술을 많이

666
00:38:46,830 --> 00:38:47,980
활용했습니다.

667
00:38:47,980 --> 00:38:52,980
물론, 지속 가능성과 환경 분야에서도

668
00:38:52,980 --> 00:38:58,890
컴퓨터 비전이 큰 기여를 했습니다.

669
00:38:58,890 --> 00:39:02,310
그리고 2012년 그 순간 이후로

670
00:39:02,310 --> 00:39:07,450
이미지 캡셔닝 분야에서도 많은 진전을 이루었습니다.

671
00:39:07,450 --> 00:39:09,990
이것은 실제로 제 제자였던 Andrej

672
00:39:09,990 --> 00:39:13,800
Karpathy가 그의 논문 연구로 진행한 작업입니다.

673
00:39:13,800 --> 00:39:19,030
그리고 우리는 관계 이해에 관한 연구도 진행했습니다.

674
00:39:19,030 --> 00:39:22,710
시각 지능은 단순히 픽셀에 있는

675
00:39:22,710 --> 00:39:24,640
것을 보는 것뿐만

676
00:39:24,640 --> 00:39:26,860
아니라, 픽셀

677
00:39:26,860 --> 00:39:33,360
너머의 객체 간 관계나 스타일 전이까지 볼 수 있습니다.

678
00:39:33,360 --> 00:39:35,880
이 분야의 많은 연구는, 실제로

679
00:39:35,880 --> 00:39:39,000
이 강의에 게스트로 오실 Justin

680
00:39:39,000 --> 00:39:45,320
Johnson이 스타일 전이에 관한 그의 중요한 연구를 자세히 설명해 주실
겁니다.

681
00:39:45,320 --> 00:39:48,510
그리고 물론, 생성 AI 시대에는

682
00:39:48,510 --> 00:39:53,430
얼굴 생성 같은 정말 놀라운 결과들을 얻고 있습니다.

683
00:39:53,430 --> 00:39:59,240
이것은 Dall-E의 이미지 생성 초기 시절입니다. 이것이 초기
Dall-E라고

684
00:39:59,240 --> 00:40:03,380
생각합니다. 물론 지금은 Midjourney 등으로

685
00:40:03,380 --> 00:40:08,690
아보카도와 복숭아 의자를 넘어선 수준에 이르렀죠.

686
00:40:08,690 --> 00:40:14,780
하지만 정말로 우리는 AI 폭발의 가장 흥미로운 현대 시대에 정확히

687
00:40:14,780 --> 00:40:16,246
와 있습니다.

688
00:40:20,070 --> 00:40:25,370
계산 능력, 알고리즘, 데이터라는 세 가지

689
00:40:25,370 --> 00:40:29,720
힘이 이 분야를 완전히 다른 차원으로

690
00:40:29,720 --> 00:40:32,930
끌어올렸고, 이제 우리는 AI

691
00:40:32,930 --> 00:40:36,120
겨울을 완전히 벗어났습니다.

692
00:40:36,120 --> 00:40:40,260
저는 지금이 AI 지구 온난화 시기라고 말하고 싶습니다.

693
00:40:40,260 --> 00:40:46,050
그리고 좋은 이유든 나쁜 이유든 이 흐름이

694
00:40:46,050 --> 00:40:48,820
멈출 것 같지 않습니다.

695
00:40:48,820 --> 00:40:53,170
또한, 우리가 실리콘밸리에 있고

696
00:40:53,170 --> 00:40:58,050
Huang 빌딩과 NVIDIA 강의실에 있다는

697
00:40:58,050 --> 00:41:02,040
점에서, 하드웨어 발전과 그

698
00:41:02,040 --> 00:41:05,050
역할도 무시할 수 없습니다.

699
00:41:05,050 --> 00:41:14,080
여기 NVIDIA GPU의 달러당 FLOP 그래프가 있습니다.

700
00:41:14,080 --> 00:41:19,210
2020년 이전에는 발전이 꾸준했지만,

701
00:41:19,210 --> 00:41:22,800
딥러닝이 이 GPU와 칩을

702
00:41:22,800 --> 00:41:27,420
주도하기 시작하면서 GFLOPS가

703
00:41:27,420 --> 00:41:33,520
완전히 급증한 것을 볼 수 있습니다.

704
00:41:33,520 --> 00:41:40,610
어떤 기준으로 보든, 우리는 많은 계산 능력과 AI가

705
00:41:40,610 --> 00:41:45,360
가속화된 곡선 위에 있습니다.

706
00:41:45,360 --> 00:41:47,360
이 그래프들은 컴퓨터

707
00:41:47,360 --> 00:41:50,540
비전뿐 아니라 AI 전반에 걸친

708
00:41:50,540 --> 00:41:54,500
학회 참석자 수, 스타트업, 기업 응용 사례를

709
00:41:54,500 --> 00:41:55,710
보여줍니다.

710
00:41:55,710 --> 00:42:02,100
하지만 NLP와 다른 분야들도 폭발적으로 성장했습니다.

711
00:42:02,100 --> 00:42:06,300
아주 빠르게, 마지막으로, 정말 흥미로웠습니다.

712
00:42:06,300 --> 00:42:08,070
많은 성공 사례들이 있었습니다.

713
00:42:08,070 --> 00:42:11,310
하지만 컴퓨터 비전 분야에는 아직 할 일이 많습니다.

714
00:42:11,310 --> 00:42:14,330
이 문제는 아직 완전히 해결되지 않았습니다.

715
00:42:14,330 --> 00:42:19,970
훌륭한 도구에는 큰 책임도 따릅니다.

716
00:42:19,970 --> 00:42:24,450
그래서 컴퓨터 비전은 많은 긍정적인 일을 할 수 있습니다.

717
00:42:24,450 --> 00:42:26,040
하지만 동시에 해를 끼칠 수도 있습니다.

718
00:42:26,040 --> 00:42:28,730
예를 들어, 인간의 편향—오늘날

719
00:42:28,730 --> 00:42:32,360
모든 AI 알고리즘, 특히 대형 모델들은 데이터에

720
00:42:32,360 --> 00:42:33,880
의해 구동됩니다.

721
00:42:33,880 --> 00:42:38,550
그리고 데이터는 지구와 역사 속 인간

722
00:42:38,550 --> 00:42:40,360
활동의 산물입니다.

723
00:42:40,360 --> 00:42:43,900
많은 데이터가 우리의 편향을 담고 있습니다.

724
00:42:43,900 --> 00:42:47,200
이것이 AI 시스템에 그대로 반영됩니다.

725
00:42:47,200 --> 00:42:50,610
얼굴 인식 알고리즘들이 인간과 같은 편향을

726
00:42:50,610 --> 00:42:52,990
가진 사례를 많이 보았습니다.

727
00:42:52,990 --> 00:42:55,920
우리는 이것을 반드시 인식해야 합니다.

728
00:42:55,920 --> 00:43:01,450
AI를 이용해 인간의 삶에 긍정적인 영향을 줄 수도 있습니다.

729
00:43:01,450 --> 00:43:02,890
의료 영상 분야를 생각해 보십시오.

730
00:43:02,890 --> 00:43:05,200
하지만 몇 가지는 의문스럽습니다.

731
00:43:05,200 --> 00:43:09,300
만약 AI가 오로지 당신의 직업이나 금융 대출을 결정하는

732
00:43:09,300 --> 00:43:11,620
데만 관여한다면 어떻게 될까요?

733
00:43:11,620 --> 00:43:15,790
그래서 다시 말하지만, 완전히 나쁜 걸까요?

734
00:43:15,790 --> 00:43:17,050
완전히 좋은 걸까요?

735
00:43:17,050 --> 00:43:19,150
이 문제들은 매우 복잡합니다.

736
00:43:19,150 --> 00:43:23,490
이것이 바로 HMS, 법대, 교육대, 경영대 학생들이 제

737
00:43:23,490 --> 00:43:26,550
수업에 참석할 때마다 제가 항상 매우

738
00:43:26,550 --> 00:43:29,670
흥분하는 이유입니다. 모든 AI 문제들이 공학

739
00:43:29,670 --> 00:43:31,790
문제만은 아니기 때문입니다.

740
00:43:31,790 --> 00:43:36,560
우리는 많은 인간적 요소와 사회적 문제들을 해결해야 합니다.

741
00:43:36,560 --> 00:43:40,600
저는 특히 AI가 의학과 건강 관리에 사용되는 것에 매우 기대하고

742
00:43:40,600 --> 00:43:41,140
있습니다.

743
00:43:41,140 --> 00:43:43,960
이것은 제게 정말 소중한 분야입니다.

744
00:43:43,960 --> 00:43:46,120
이 강좌의 공동 강사인

745
00:43:46,120 --> 00:43:49,630
Adeli 교수님과 Zane 교수님과

746
00:43:49,630 --> 00:43:53,500
저는 고령 인구와 환자를 위한 AI 연구를

747
00:43:53,500 --> 00:43:59,050
하며 컴퓨터 비전을 이용해 사람들에게 돌봄을 제공하려 노력하고

748
00:43:59,050 --> 00:44:00,170
있습니다.

749
00:44:00,170 --> 00:44:01,820
그래서 이것은 좋은 활용 사례입니다.

750
00:44:01,820 --> 00:44:04,820
또한 기술 측면에서도 인간의

751
00:44:04,820 --> 00:44:07,190
시각은 놀랍습니다.

752
00:44:07,190 --> 00:44:10,670
오늘 수업뿐만 아니라 이 전체 강좌를

753
00:44:10,670 --> 00:44:14,240
통해 컴퓨터 비전이 아무리

754
00:44:14,240 --> 00:44:16,970
발전해도 인간의 시각에는 훨씬

755
00:44:16,970 --> 00:44:22,250
더 많은 뉘앙스, 미묘함, 풍부함, 복잡성, 그리고

756
00:44:22,250 --> 00:44:26,390
감정이 있다는 것을 이해하시길 바랍니다.

757
00:44:26,390 --> 00:44:29,370
이 아이들이 호기심이 이끄는 대로

758
00:44:29,370 --> 00:44:33,160
공부하는 모습이나 이 이미지 속 유머를 보세요.

759
00:44:33,160 --> 00:44:36,130
컴퓨터 비전이 아직 할 수 없는 것이 훨씬 더 많습니다.

760
00:44:36,130 --> 00:44:38,430
그래서 여러분이 계속해서 컴퓨터

761
00:44:38,430 --> 00:44:40,870
비전을 공부하도록 유도하길 바랍니다.

762
00:44:40,870 --> 00:44:45,690
이제 강단을 Adeli 교수님께 넘기겠습니다. 수업

763
00:44:45,690 --> 00:44:48,370
나머지 부분을 진행하실 겁니다.

764
00:44:48,370 --> 00:44:49,040
감사합니다.

765
00:44:49,040 --> 00:44:50,760
[박수]

766
00:44:50,760 --> 00:44:51,990
멋집니다.

767
00:44:51,990 --> 00:44:55,140
감사합니다, Fei-Fei.

768
00:44:55,140 --> 00:44:57,090
학기 시작을 이렇게 하게 되어 좋습니다.

769
00:44:57,090 --> 00:45:00,640
그리고 제 마이크가 제대로 작동하는 것 같아 다행입니다.

770
00:45:00,640 --> 00:45:01,390
좋습니다.

771
00:45:01,390 --> 00:45:05,730
고개를 끄덕이는 분들도 보이네요.

772
00:45:05,730 --> 00:45:13,080
여러분과 함께할 수 있어 매우 기쁩니다.

773
00:45:13,080 --> 00:45:18,630
그리고 훌륭한 핵심 강사진과 훌륭한

774
00:45:18,630 --> 00:45:23,160
조교들과 함께 재미있고 도전적인

775
00:45:23,160 --> 00:45:26,380
강좌가 되길 바랍니다.

776
00:45:26,380 --> 00:45:31,000
이 수업에서는 컴퓨터 비전과 이

777
00:45:31,000 --> 00:45:34,690
분야에서 딥러닝의 활용에 관한

778
00:45:34,690 --> 00:45:37,660
다양한 주제를 네 가지

779
00:45:37,660 --> 00:45:41,570
범주로 나누어 다룰 것입니다.

780
00:45:41,570 --> 00:45:45,230
우선 딥러닝 기초부터 시작하겠습니다.

781
00:45:45,230 --> 00:45:48,430
사실 간단한 질문부터 시작해

782
00:45:48,430 --> 00:45:52,010
보죠. 컴퓨터 비전이란 무엇일까요?

783
00:45:52,010 --> 00:45:57,610
본질적으로 기계가 이미지를 보고 이해할 수

784
00:45:57,610 --> 00:46:00,620
있게 하는 것입니다.

785
00:46:00,620 --> 00:46:09,340
기본적으로 이 분야에서 가장 근본적인 작업은

786
00:46:09,340 --> 00:46:13,390
이미지 분류입니다.

787
00:46:13,390 --> 00:46:17,060
모델에 고양이 사진 같은 이미지를 주면,

788
00:46:17,060 --> 00:46:21,550
그리고 모델은 고양이라는 라벨을 출력해야 합니다.

789
00:46:21,550 --> 00:46:23,740
그게 전부입니다.

790
00:46:23,740 --> 00:46:29,480
하지만 이 겉보기에는 단순한 작업이 자율주행부터

791
00:46:29,480 --> 00:46:32,040
의료 진단 등

792
00:46:32,040 --> 00:46:36,410
훨씬 복잡한 응용의 기초가 됩니다.

793
00:46:36,410 --> 00:46:40,430
그렇다면 기계에게 이것을 어떻게 가르칠까요?

794
00:46:40,430 --> 00:46:44,640
가장 간단한 방법 중 하나는 이 슬라이드에서 볼

795
00:46:44,640 --> 00:46:48,090
수 있듯이 선형 분류를 사용하는 것입니다.

796
00:46:48,090 --> 00:46:53,810
데이터 세트의 각 이미지가 그 공간에 점으로

797
00:46:53,810 --> 00:46:57,120
표시된다고 상상해 보세요.

798
00:46:57,120 --> 00:47:02,780
각 축은 이미지 자체에서 추출된 어떤

799
00:47:02,780 --> 00:47:05,280
특징을 나타냅니다.

800
00:47:05,280 --> 00:47:09,420
여기서는 단순화를 위해 2차원 공간을 보여주고 있습니다.

801
00:47:09,420 --> 00:47:12,470
하지만 선형 분류기의 임무는

802
00:47:12,470 --> 00:47:17,150
이 두 그룹, 예를 들어 고양이와

803
00:47:17,150 --> 00:47:23,470
개를 구분하는 초평면 또는 선형 함수를 찾는 것입니다.

804
00:47:23,470 --> 00:47:26,260
하지만 우리는 모두 선형 모델이 종종

805
00:47:26,260 --> 00:47:29,110
한계가 있다는 것을 알고 있습니다.

806
00:47:29,110 --> 00:47:32,350
데이터가 직선으로 깔끔하게 구분되지 않을 때

807
00:47:32,350 --> 00:47:33,800
어려움을 겪습니다.

808
00:47:33,800 --> 00:47:36,320
그렇다면 다음 단계는 무엇일까요?

809
00:47:36,320 --> 00:47:44,090
더 복잡한 패턴을 모델링하는 방법에 대해 다룰 것입니다.

810
00:47:44,090 --> 00:47:49,900
그리고 그렇게 할 때 우리는 과적합과

811
00:47:49,900 --> 00:47:54,220
과소적합이라는 문제에 직면하는데, 이는

812
00:47:54,220 --> 00:47:59,440
수업 초반 강의에서 다룰 주제입니다.

813
00:47:59,440 --> 00:48:05,110
적절한 균형을 맞추기 위해 정규화 같은

814
00:48:05,110 --> 00:48:08,320
기법을 사용해 모델

815
00:48:08,320 --> 00:48:14,110
복잡도를 조절하고 최적화를 통해 최적의 파라미터를

816
00:48:14,110 --> 00:48:16,060
찾습니다.

817
00:48:16,060 --> 00:48:21,080
이것들이 딥러닝과 모델 생성, 즉 데이터에

818
00:48:21,080 --> 00:48:26,660
맞출 뿐만 아니라 보지 못한 새로운 데이터에도

819
00:48:26,660 --> 00:48:31,320
일반화할 수 있는 모델을 훈련하는 핵심입니다.

820
00:48:31,320 --> 00:48:33,540
이제 재미있는 부분, 신경망이

821
00:48:33,540 --> 00:48:34,380
등장합니다.

822
00:48:34,380 --> 00:48:38,060
우리는 신경망에 대해 꽤 많이 이야기해 왔습니다.

823
00:48:38,060 --> 00:48:43,550
신경망은 선형 분류기와

824
00:48:43,550 --> 00:48:47,780
달리 여러 층의 연산을

825
00:48:47,780 --> 00:48:54,770
쌓아 비선형 함수를 모델링하여

826
00:48:54,770 --> 00:48:59,390
이미지 분류 같은 문제를

827
00:48:59,390 --> 00:49:04,490
해결할 수 있습니다.

828
00:49:04,490 --> 00:49:09,870
이 모델들은 Google Photos부터 시작해서

829
00:49:09,870 --> 00:49:13,430
이제는 모두가 익숙한 ChatGPT, ChatGPT의 비전

830
00:49:13,430 --> 00:49:15,440
모델 등 모든 것을 지원합니다.

831
00:49:15,440 --> 00:49:24,100
이 강의에서는 신경망이 어떻게 작동하는지, 어떻게 훈련되는지 자세히

832
00:49:24,100 --> 00:49:26,300
다룰 것입니다.

833
00:49:26,300 --> 00:49:31,090
그리고 디버깅과 개선 방법도 살펴볼 것입니다.

834
00:49:31,090 --> 00:49:35,030
딥러닝 기초를 본 후에는

835
00:49:35,030 --> 00:49:39,280
시각 세계를 인지하고 이해하는

836
00:49:39,280 --> 00:49:44,620
주제를 다룰 텐데, 이는 방대한 시각

837
00:49:44,620 --> 00:49:49,880
정보를 해석하는 복잡한 과정입니다.

838
00:49:49,880 --> 00:49:52,330
이를 위해 우리는 종종 특정

839
00:49:52,330 --> 00:49:56,740
도전 과제나 문제를 가리키는 작업을 먼저 정의합니다.

840
00:49:56,740 --> 00:49:59,150
우리가 해결하려는 작업의 예로는

841
00:49:59,150 --> 00:50:02,180
객체 검출, 장면 이해, 움직임

842
00:50:02,180 --> 00:50:03,620
감지 등이 있습니다.

843
00:50:03,620 --> 00:50:10,540
이 작업들을 해결하기 위해 우리는 시각 시스템이 이러한 작업을

844
00:50:10,540 --> 00:50:13,930
수행하는 방식을 모방하거나

845
00:50:13,930 --> 00:50:17,780
설명하기 위해 개발한 계산적, 이론적

846
00:50:17,780 --> 00:50:22,350
프레임워크인 다양한 모델을 사용합니다.

847
00:50:22,350 --> 00:50:25,610
이러한 모델의 예 중 하나가

848
00:50:25,610 --> 00:50:27,730
신경망입니다.

849
00:50:30,260 --> 00:50:36,150
모델과 작업을 일치시킴으로써 우리는 주변

850
00:50:36,150 --> 00:50:41,030
세계를 보고 해석할 수 있는 시스템을

851
00:50:41,030 --> 00:50:43,730
만들 수 있습니다.

852
00:50:43,730 --> 00:50:48,740
작업 얘기가 나왔으니 이미지 분류, 즉

853
00:50:48,740 --> 00:50:53,240
전체 이미지에 대해 단일 라벨을

854
00:50:53,240 --> 00:50:56,990
예측하는 주제로 돌아가 보겠습니다.

855
00:50:56,990 --> 00:50:59,360
하지만 실제 세계의 컴퓨터

856
00:50:59,360 --> 00:51:02,340
비전은 이보다 훨씬 풍부합니다.

857
00:51:02,340 --> 00:51:05,240
분류를 넘어서는 몇 가지 작업을

858
00:51:05,240 --> 00:51:06,870
살펴보겠습니다.

859
00:51:06,870 --> 00:51:13,340
먼저, semantic segmentation입니다. 여기서는 단순히

860
00:51:13,340 --> 00:51:17,520
고양이나 나무 같은 객체나 전체 이미지를

861
00:51:17,520 --> 00:51:19,740
라벨링하는 것이 아닙니다.

862
00:51:19,740 --> 00:51:25,020
여기서는 이미지의 모든 픽셀마다 라벨을 찾는

863
00:51:25,020 --> 00:51:25,810
것입니다.

864
00:51:25,810 --> 00:51:30,670
그래서 모든 픽셀이 잔디, 고양이, 나무, 하늘 중 하나로 분류됩니다.

865
00:51:30,670 --> 00:51:34,960
하지만 개별 객체를 구분하지는 않습니다.

866
00:51:34,960 --> 00:51:38,280
다음으로 object detection이

867
00:51:38,280 --> 00:51:45,580
있습니다. 여기서는 이미지에 무엇이 있는지 말하는 것뿐만 아니라 위치도

868
00:51:45,580 --> 00:51:47,440
정확히 찾아야 합니다.

869
00:51:47,440 --> 00:51:49,860
그래서 객체 주위에

870
00:51:49,860 --> 00:51:54,670
바운딩 박스를 만들고 특정 라벨과 연결합니다.

871
00:51:54,670 --> 00:51:58,270
마지막으로 instance segmentation이 있습니다.

872
00:51:58,270 --> 00:52:01,140
가장 세분화된 instance

873
00:52:01,140 --> 00:52:04,410
segmentation에 대해 설명하겠습니다.

874
00:52:04,410 --> 00:52:08,280
이것은 detection과 segmentation의 아이디어를

875
00:52:08,280 --> 00:52:09,130
결합한 것입니다.

876
00:52:09,130 --> 00:52:13,040
각 객체 인스턴스마다 고유한 마스크가 부여됩니다.

877
00:52:13,040 --> 00:52:20,090
이 작업들은 이미지에 대한 훨씬 더 깊은 공간적 이해를

878
00:52:20,090 --> 00:52:21,060
요구합니다.

879
00:52:21,060 --> 00:52:23,810
그리고 모델이 단순히 카테고리를

880
00:52:23,810 --> 00:52:27,860
인식하는 것 이상을 하도록 만듭니다.

881
00:52:27,860 --> 00:52:30,660
복잡성은 정적인 이미지에서 멈추지 않습니다.

882
00:52:30,660 --> 00:52:33,270
이제 시간적 차원을 살펴보겠습니다.

883
00:52:33,270 --> 00:52:36,270
Fei-Fei가 말한 것처럼, 비디오 분류

884
00:52:36,270 --> 00:52:40,430
작업이 있습니다. 여기서는 비디오에서 무슨 일이 일어나고

885
00:52:40,430 --> 00:52:42,350
있는지 이해하려고 합니다.

886
00:52:42,350 --> 00:52:47,210
누군가가 달리고 있는지, 점프하는지, 춤추는지 말이죠.

887
00:52:47,210 --> 00:52:51,630
멀티모달 비디오 이해라는 주제가 있는데, 이는

888
00:52:51,630 --> 00:52:56,630
시각, 소리, 그리고 다른 모달리티를 결합하는 것입니다.

889
00:52:56,630 --> 00:53:00,560
예를 들어, 이 예시에서는 사람이 비브라폰을 연주하고

890
00:53:00,560 --> 00:53:04,070
있는데, 여기서 무슨 일이 일어나고 있는지 진짜로

891
00:53:04,070 --> 00:53:05,040
이해하려면,

892
00:53:05,040 --> 00:53:08,210
시각적 특징과 오디오 특징을

893
00:53:08,210 --> 00:53:11,280
혼합해서 이해할 수 있어야 합니다.

894
00:53:11,280 --> 00:53:14,680
마지막으로, 이 수업에서

895
00:53:14,680 --> 00:53:19,330
다룰 시각화와 이해라는 주제가

896
00:53:19,330 --> 00:53:24,340
있는데, 이는 모델이 학습한 내용을

897
00:53:24,340 --> 00:53:31,270
해석하고, 모델이 올바른 분류를 위해 주목하는

898
00:53:31,270 --> 00:53:35,080
프레임이나 주의 맵을

899
00:53:35,080 --> 00:53:36,820
보는 것입니다.

900
00:53:36,820 --> 00:53:39,650
그리고 나서 우리는 작업을 넘어서 모델들을 살펴봅니다.

901
00:53:39,650 --> 00:53:41,740
모델들을 살펴보죠.

902
00:53:41,740 --> 00:53:46,510
첫 번째 주제는—소개해 드리자면—합성곱

903
00:53:46,510 --> 00:53:50,170
신경망, 즉

904
00:53:50,170 --> 00:53:51,230
CNN입니다.

905
00:53:51,230 --> 00:53:52,760
여러 가지 연산이 있습니다.

906
00:53:52,760 --> 00:53:55,930
수업에서 자세히 다룰 텐데,

907
00:53:55,930 --> 00:53:59,840
이미지에서 시작해서 여러 번의 합성곱,

908
00:53:59,840 --> 00:54:01,970
샘플링, 완전 연결 연산을

909
00:54:01,970 --> 00:54:05,980
거쳐 최종 출력을 만드는 과정입니다.

910
00:54:05,980 --> 00:54:08,770
그리고 합성곱 신경망을

911
00:54:08,770 --> 00:54:14,720
넘어서, 순차 데이터에 대한 순환 신경망과

912
00:54:14,720 --> 00:54:19,670
트랜스포머 및 어텐션 기반 구조 같은

913
00:54:19,670 --> 00:54:24,140
신경망 아키텍처도 공부할 것입니다.

914
00:54:24,140 --> 00:54:29,180
다음으로는 이번 학기에 새롭게 다루는

915
00:54:29,180 --> 00:54:34,610
대규모 분산 학습 주제를 살펴보겠습니다.

916
00:54:34,610 --> 00:54:38,460
여러분 모두 대형 언어 모델, 대형 비전 모델 등에

917
00:54:38,460 --> 00:54:40,320
대해 들어보셨을 겁니다.

918
00:54:40,320 --> 00:54:44,480
이 모델들이 실제로 어떻게 학습되는지

919
00:54:44,480 --> 00:54:47,310
간단히 논의할 것입니다.

920
00:54:47,310 --> 00:54:51,620
데이터와 데이터셋이 모델을 확장시키고,

921
00:54:51,620 --> 00:54:56,430
모델이 점점 더 커지고 있다는 것을 알고 있습니다.

922
00:54:56,430 --> 00:54:59,820
이런 모델을 학습하기 위해 데이터

923
00:54:59,820 --> 00:55:02,360
병렬화, 모델 병렬화

924
00:55:02,360 --> 00:55:04,470
같은 전략들이 있는데,

925
00:55:04,470 --> 00:55:07,570
이 수업에서 다룰 예정입니다.

926
00:55:07,570 --> 00:55:11,170
하지만 그 이상으로, 이러한 모델과

927
00:55:11,170 --> 00:55:15,940
작업자 간의 동기화 등 여러 도전 과제들이

928
00:55:15,940 --> 00:55:20,730
있을 것이며, 이번 학기 강의 중

929
00:55:20,730 --> 00:55:25,060
하나에서 다룰 여러 다른 측면들도 있습니다.

930
00:55:25,060 --> 00:55:31,290
또한 이러한 대규모 모델을 훈련하는 몇 가지 트렌드도

931
00:55:31,290 --> 00:55:33,070
살펴볼 것입니다.

932
00:55:33,070 --> 00:55:36,210
이 주제를 마친

933
00:55:36,210 --> 00:55:44,010
후에는 생성적이고 상호작용하는 시각 지능을 살펴볼

934
00:55:44,010 --> 00:55:48,690
텐데, 먼저 자기지도 학습부터

935
00:55:48,690 --> 00:55:52,030
시작할 것입니다.

936
00:55:52,030 --> 00:55:55,960
자기지도 학습은 모델이 데이터 자체에서

937
00:55:55,960 --> 00:56:00,580
훈련 신호를 얻어 데이터를 이해하고 표현하는

938
00:56:00,580 --> 00:56:04,180
법을 배우는 머신러닝의 한 분야입니다.

939
00:56:04,180 --> 00:56:06,385
이 주제를 다룰 것입니다.

940
00:56:06,385 --> 00:56:10,180
이 방법은 라벨이 필요 없는 방대한

941
00:56:10,180 --> 00:56:15,340
양의 비라벨 데이터로 대규모 모델을 훈련할 수

942
00:56:15,340 --> 00:56:18,880
있게 한 접근법 중 하나입니다.

943
00:56:18,880 --> 00:56:23,200
그리고 최근 컴퓨터 비전 분야의 돌파구에서

944
00:56:23,200 --> 00:56:26,200
중요한 역할을 했습니다.

945
00:56:26,200 --> 00:56:30,800
그리고 생성 모델에 대해서도 조금 이야기할 것입니다.

946
00:56:30,800 --> 00:56:33,710
이들은 인식을 넘어서서,

947
00:56:33,710 --> 00:56:35,860
실제로 무언가를 생성합니다.

948
00:56:35,860 --> 00:56:39,340
이것은 Stanford 캠퍼스 사진을

949
00:56:39,340 --> 00:56:44,380
반 고흐의 별이 빛나는 밤 스타일로 재구성한

950
00:56:44,380 --> 00:56:45,490
예시입니다.

951
00:56:45,490 --> 00:56:49,990
이것은 스타일 전이로 알려져 있으며,

952
00:56:49,990 --> 00:56:54,370
신경망 생성 기법의 고전적 응용입니다.

953
00:56:54,370 --> 00:56:58,270
생성 모델은 이제 프롬프트를

954
00:56:58,270 --> 00:57:03,220
주면 언어를 이미지로 번역할 수 있습니다.

955
00:57:03,220 --> 00:57:07,290
Dall-E, Dall-E 2 같은 모델은 완전히 새로운

956
00:57:07,290 --> 00:57:09,060
이미지를 생성합니다.

957
00:57:09,060 --> 00:57:12,570
이것은 생성 비전 모델이

958
00:57:12,570 --> 00:57:16,830
이해, 창의성, 제어를 어떻게

959
00:57:16,830 --> 00:57:19,350
결합하는지를 보여줍니다.

960
00:57:19,350 --> 00:57:22,590
최근에 확산 모델(diffusion

961
00:57:22,590 --> 00:57:26,620
models)이라는 주제를 들어보셨을 겁니다.

962
00:57:26,620 --> 00:57:33,180
이것도 이번 학기에 다룰 내용 중 하나입니다.

963
00:57:33,180 --> 00:57:37,650
이 모델들은 점진적인 노이즈 과정을 역으로

964
00:57:37,650 --> 00:57:40,510
학습해 이미지를 생성합니다.

965
00:57:40,510 --> 00:57:43,630
흥미롭게도, 과제 3에서는

966
00:57:43,630 --> 00:57:46,860
텍스트 입력, 예를 들어

967
00:57:46,860 --> 00:57:53,400
카우보이 모자를 쓴 얼굴 같은 프롬프트로부터 순수

968
00:57:53,400 --> 00:57:57,360
노이즈를 제거해 이모지를 생성하는

969
00:57:57,360 --> 00:58:01,240
생성 모델을 직접 구현할 것입니다.

970
00:58:01,240 --> 00:58:06,530
다음으로 다룰 관심 주제는 비전-언어

971
00:58:06,530 --> 00:58:08,890
모델입니다.

972
00:58:08,890 --> 00:58:16,040
이들은 텍스트와 이미지를 공유 표현 공간에서 연결합니다.

973
00:58:16,040 --> 00:58:19,900
캡션이나 이미지가 주어지면, 모델은

974
00:58:19,900 --> 00:58:24,290
해당하는 쌍을 검색하거나 생성합니다, 보시는

975
00:58:24,290 --> 00:58:25,310
것처럼요.

976
00:58:25,310 --> 00:58:29,050
이 분야에는 많은 발전이 있습니다.

977
00:58:29,050 --> 00:58:32,170
중요한 예시들을 다룰 것입니다.

978
00:58:32,170 --> 00:58:37,750
이것은 교차 모달 검색, 이해, 시각 질문

979
00:58:37,750 --> 00:58:41,120
응답 등에서 핵심 과제입니다.

980
00:58:41,120 --> 00:58:44,270
이 내용은 2강에서 다룰 예정입니다.

981
00:58:44,270 --> 00:58:52,810
2D를 넘어서, 이제 모델들은 이미지로부터 3D 표현을 재구성하고

982
00:58:52,810 --> 00:58:55,550
생성할 수 있습니다.

983
00:58:55,550 --> 00:59:00,980
여기서는 복셀 기반 재구성, 형태 완성,

984
00:59:00,980 --> 00:59:06,770
단일 뷰 이미지로부터 3D 객체 탐지 예시를

985
00:59:06,770 --> 00:59:09,600
볼 수 있습니다.

986
00:59:09,600 --> 00:59:14,810
3D 비전은 특히 로보틱스와 AI VR 응용에

987
00:59:14,810 --> 00:59:19,700
중요한, 더 기반이 확실한 이해를 가능하게

988
00:59:19,700 --> 00:59:20,400
합니다.

989
00:59:20,400 --> 00:59:26,900
마지막으로, 비전은 물리 세계에서 행동하는 구현된

990
00:59:26,900 --> 00:59:30,680
에이전트를 가능하게 합니다.

991
00:59:30,680 --> 00:59:35,280
이 모델들은 종종 어지러운 방을

992
00:59:35,280 --> 00:59:41,390
청소하거나 인간 시범에서 일반화하는 등 인지,

993
00:59:41,390 --> 00:59:44,880
계획, 실행을 해야 합니다.

994
00:59:44,880 --> 00:59:50,210
이 모든 주제를 통해 생성적이고 상호작용하는 시각 지능에

995
00:59:50,210 --> 00:59:53,970
관한 다양한 내용을 다룰 것입니다.

996
00:59:53,970 --> 01:00:00,760
마지막으로, Fei-Fei가 아주 잘 설명한 것처럼 인간

997
01:00:00,760 --> 01:00:05,990
중심의 응용과 그 함의에 대해 다루겠습니다.

998
01:00:05,990 --> 01:00:08,720
이것이 바로 컴퓨터 비전입니다.

999
01:00:08,720 --> 01:00:12,070
일반적으로 AI는 지난 몇

1000
01:00:12,070 --> 01:00:16,070
년간 많은 영향을 미쳐왔습니다.

1001
01:00:16,070 --> 01:00:18,280
인간 중심의 측면과 응용을

1002
01:00:18,280 --> 01:00:21,230
이해하는 것이 매우 중요합니다.

1003
01:00:21,230 --> 01:00:24,160
이러한 영향 중 일부는

1004
01:00:24,160 --> 01:00:32,470
이 분야 연구자들에게 수여되는 상들에 반영되어 있습니다.

1005
01:00:32,470 --> 01:00:38,770
가장 먼저 2018년 튜링상에서 인정받았는데, 이는 컴퓨팅에

1006
01:00:38,770 --> 01:00:41,440
지속적인 중요성을 가진

1007
01:00:41,440 --> 01:00:45,400
주요 공헌에 수여되는 가장 권위

1008
01:00:45,400 --> 01:00:47,090
있는 기술상입니다.

1009
01:00:47,090 --> 01:00:50,890
Geoffrey Hinton, Yoshua

1010
01:00:50,890 --> 01:00:54,850
Bengio, Yann LeCun은 딥 뉴럴

1011
01:00:54,850 --> 01:00:57,050
네트워크를 컴퓨팅의 핵심 요소로

1012
01:00:57,050 --> 01:01:01,440
만든 개념적·공학적 돌파구로 이 상을 받았습니다.

1013
01:01:01,440 --> 01:01:06,200
더 나아가, 작년인 2024년에는 Geoffrey

1014
01:01:06,200 --> 01:01:11,090
Hinton이 John Hopfield와

1015
01:01:11,090 --> 01:01:14,990
함께 신경망의 기초적 공헌으로 노벨 물리학상을

1016
01:01:14,990 --> 01:01:17,460
공동 수상했습니다.

1017
01:01:17,460 --> 01:01:21,260
마지막으로, 이 수업의 학습

1018
01:01:21,260 --> 01:01:27,770
목표를 간단히 말씀드리면 컴퓨터 비전 응용을 과제로

1019
01:01:27,770 --> 01:01:30,240
공식화하는 것입니다.

1020
01:01:30,240 --> 01:01:33,620
여기 보시는 것처럼, 우리는

1021
01:01:33,620 --> 01:01:38,600
이미지와 시각 데이터를 다루는 비전

1022
01:01:38,600 --> 01:01:41,400
모델을 개발하고 훈련하며,

1023
01:01:41,400 --> 01:01:43,220
이 분야가

1024
01:01:43,220 --> 01:01:46,550
어디에 있고 어디로 향하는지

1025
01:01:46,550 --> 01:01:48,990
이해하고자 합니다.

1026
01:01:48,990 --> 01:01:53,620
그래서 올해는 특히 새로운

1027
01:01:53,620 --> 01:01:56,920
주제들도 다루고 있습니다.

1028
01:01:56,920 --> 01:02:01,540
앞서 말씀드린 네 가지 주제를 처음

1029
01:02:01,540 --> 01:02:06,530
몇 주 동안 기본부터 다룰 것입니다.

1030
01:02:06,530 --> 01:02:09,220
중요한 주제들이니 조금만 참고 따라와 주세요.

1031
01:02:09,220 --> 01:02:12,860
먼저 모델을 처음부터 어떻게 구축하는지

1032
01:02:12,860 --> 01:02:15,110
세부사항을 이해해야 합니다.

1033
01:02:15,110 --> 01:02:19,180
그다음에는 더 흥미롭고 신나는 오늘날의 컴퓨터

1034
01:02:19,180 --> 01:02:20,440
비전 주제로

1035
01:02:20,440 --> 01:02:21,770
넘어갈 것입니다.

1036
01:02:21,770 --> 01:02:27,970
마지막으로, 인간 중심 AI와 컴퓨터 비전에 관한 큰

1037
01:02:27,970 --> 01:02:30,550
강의를 진행할 예정입니다.

1038
01:02:30,550 --> 01:02:33,040
다음 시간에 다룰 내용을

1039
01:02:33,040 --> 01:02:34,790
간단히 말씀드리면,

1040
01:02:34,790 --> 01:02:38,380
이미지 분류와 선형

1041
01:02:38,380 --> 01:02:43,720
분류기로, CS231n의 세계를 시작하는

1042
01:02:43,720 --> 01:02:45,910
내용입니다.

1043
01:02:45,910 --> 01:02:47,970
감사합니다.
