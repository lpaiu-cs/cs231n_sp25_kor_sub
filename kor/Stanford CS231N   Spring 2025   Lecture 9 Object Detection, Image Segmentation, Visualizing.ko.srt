1
00:00:05,270 --> 00:00:06,470
좋아요.

2
00:00:06,470 --> 00:00:12,920
오늘은 핵심 컴퓨터 비전의 다양한 작업, 알고리즘 및

3
00:00:12,920 --> 00:00:19,110
작업, 탐지 및 분할에 대해 이야기할 것입니다.

4
00:00:19,110 --> 00:00:22,250
시각화 및 이해와 관련된 주제도

5
00:00:22,250 --> 00:00:23,700
다룰 것입니다.

6
00:00:23,700 --> 00:00:26,275
가장 중요한 것들을 다룰 것입니다.

7
00:00:28,820 --> 00:00:32,040
지난 강의와 마찬가지로,

8
00:00:32,040 --> 00:00:37,430
우리가 논의한 것은 시퀀스 모델에서 시퀀스

9
00:00:37,430 --> 00:00:43,940
모델로의 전환, RNN에서 트랜스포머로의 주제였습니다.

10
00:00:43,940 --> 00:00:47,570
우리는 트랜스포머가 다중

11
00:00:47,570 --> 00:00:52,520
헤드, 자기 주의 및 레이어 정규화가

12
00:00:52,520 --> 00:00:57,540
있는 여러 레이어를 가진 인코더를 가지고

13
00:00:57,540 --> 00:01:01,470
정의된다는 것을 보았습니다.

14
00:01:01,470 --> 00:01:06,500
그리고 이것은 궁극적으로 우리가 현재 시퀀스를 인코딩하는

15
00:01:06,500 --> 00:01:10,500
인코더라고 부르는 것으로 불렸습니다.

16
00:01:10,500 --> 00:01:16,100
그리고 이미지나 언어, 시퀀스를

17
00:01:16,100 --> 00:01:19,970
출력으로 디코딩해야 할

18
00:01:19,970 --> 00:01:27,210
경우, 유사한 유형의 아키텍처가 디코더에

19
00:01:27,210 --> 00:01:32,660
사용되어 인코더 토큰을 입력으로

20
00:01:32,660 --> 00:01:34,970
받아들이고, 그것을

21
00:01:34,970 --> 00:01:42,060
입력으로 받아 원하는 출력을 생성합니다.

22
00:01:42,060 --> 00:01:43,560
우리는 시퀀스를

23
00:01:43,560 --> 00:01:48,620
모델링하는 것의 차이에 대해 많이

24
00:01:48,620 --> 00:01:55,470
이야기했습니다. 재귀 신경망, RNN 및 우리가 지난주 화요일에

25
00:01:55,470 --> 00:01:59,210
논의한 변형들, 그리고 컨볼루션을

26
00:01:59,210 --> 00:02:04,940
또 다른 접근 방식으로 사용하는 것에 대해

27
00:02:04,940 --> 00:02:06,690
이야기했습니다.

28
00:02:06,690 --> 00:02:10,639
하지만 궁극적으로 우리는 요즘 많은

29
00:02:10,639 --> 00:02:17,910
응용 프로그램에서 작업하는 것이 자기 주의라는 것을 이야기했습니다.

30
00:02:17,910 --> 00:02:24,470
그들은 다른 두 가지보다 훨씬 더 잘 작동합니다.

31
00:02:24,470 --> 00:02:25,590
비용이 더 많이 듭니다.

32
00:02:25,590 --> 00:02:31,775
계산 및 메모리 요구 사항을 추가하지만, 이는

33
00:02:31,775 --> 00:02:36,650
시퀀스의 훨씬 더 나은 모델링과

34
00:02:36,650 --> 00:02:42,110
모든 작업에서 더 나은 결과를 가져옵니다.

35
00:02:42,110 --> 00:02:48,835
여기까지는 주로 자기 주의에 대해 이야기했습니다.

36
00:02:48,835 --> 00:02:50,210
우리는 교차

37
00:02:50,210 --> 00:02:55,050
주의 및 관련 주제에 대해서도 조금 이야기했습니다.

38
00:02:55,050 --> 00:02:59,750
그리고 우리는 현대 응용 프로그램, 컴퓨터 비전

39
00:02:59,750 --> 00:03:02,840
응용 프로그램에서 사용되는 핵심 모델

40
00:03:02,840 --> 00:03:06,290
중 하나인 비전 트랜스포머 주제로

41
00:03:06,290 --> 00:03:07,410
넘어갔습니다.

42
00:03:07,410 --> 00:03:17,330
우리는 지난 강의의 마지막 몇 분 동안 이 내용을 다루었습니다.

43
00:03:17,330 --> 00:03:18,300
우리는 지난 강의의 마지막 몇 분 동안 이 내용을 다루었습니다.

44
00:03:18,300 --> 00:03:21,030
그리고 이 주제를 다시 다루고 싶습니다.

45
00:03:21,030 --> 00:03:26,000
그 후에는 제가 지금까지 이야기한 과제와

46
00:03:26,000 --> 00:03:28,340
관련하여 질문이나 의견이

47
00:03:28,340 --> 00:03:30,830
있으면 듣겠습니다.

48
00:03:30,830 --> 00:03:33,320
우리는 트랜스포머로

49
00:03:33,320 --> 00:03:38,460
이미지를 처리할 때 우리가 하는 일이 이미지를

50
00:03:38,460 --> 00:03:48,440
패치로 나누는 것이라고 이야기했습니다. 기본적으로 시퀀스를 생성하는
것입니다.

51
00:03:48,440 --> 00:03:57,590
이미지는 S x S로 나누어지거나 이 경우 3 x 3 패치로

52
00:03:57,590 --> 00:03:59,760
나누어졌습니다.

53
00:03:59,760 --> 00:04:02,630
각 패치는 우리가 토큰이라고

54
00:04:02,630 --> 00:04:05,280
부르는 것으로 표현됩니다.

55
00:04:05,280 --> 00:04:10,610
토큰은 종종 이미지의

56
00:04:10,610 --> 00:04:17,810
재구성된 버전을 벡터로 선형 변환한

57
00:04:17,810 --> 00:04:20,100
것입니다.

58
00:04:20,100 --> 00:04:24,510
기본적으로 D차원 벡터이며, 이 슬라이드에서

59
00:04:24,510 --> 00:04:27,060
볼 수 있습니다.

60
00:04:27,060 --> 00:04:29,330
하지만 이미지를 패치로 나누었기 때문에

61
00:04:29,330 --> 00:04:32,210
중요한 것은 무엇입니까? 우리는 여기서

62
00:04:32,210 --> 00:04:33,540
무엇을 잃고 있습니까?

63
00:04:33,540 --> 00:04:36,390
기본적으로 우리는 이미지의 2D

64
00:04:36,390 --> 00:04:38,550
위치를 잃고 있습니다.

65
00:04:38,550 --> 00:04:43,970
그래서 우리는 종종 위치 임베딩이라고 부르는 것을

66
00:04:43,970 --> 00:04:46,110
생성하거나 추가합니다.

67
00:04:46,110 --> 00:04:49,080
이것을 수행하는 방법은 여러 가지가 있습니다.

68
00:04:49,080 --> 00:04:53,790
시퀀스를 생성하고 숫자를 1, 2, 3 등으로 나열할

69
00:04:53,790 --> 00:04:55,290
수 있습니다.

70
00:04:55,290 --> 00:05:02,250
또는 x 및 y 좌표의 2D 버전을 만들고 이 두 개를

71
00:05:02,250 --> 00:05:09,080
더하여 트랜스포머 레이어로 가는 새로운 토큰을

72
00:05:09,080 --> 00:05:12,350
생성합니다. 모든 자기 주의,

73
00:05:12,350 --> 00:05:15,020
레이어 정규화 및

74
00:05:15,020 --> 00:05:19,640
우리가 지난주에 이야기한 모든 것,

75
00:05:19,640 --> 00:05:24,680
MLP 등과 같은 방식으로 진행됩니다.

76
00:05:24,680 --> 00:05:29,000
그리고 출력 레이어는 우리를 위한 출력 벡터를

77
00:05:29,000 --> 00:05:29,615
생성합니다.

78
00:05:29,615 --> 00:05:32,280
이는 모든 응용 프로그램에 사용될 수 있습니다.

79
00:05:32,280 --> 00:05:35,270
컴퓨터 비전의 주요 응용 중

80
00:05:35,270 --> 00:05:36,960
하나는 분류입니다.

81
00:05:36,960 --> 00:05:39,120
우리는 이미지 분류로 시작했습니다.

82
00:05:39,120 --> 00:05:42,800
따라서 이미지 분류에서

83
00:05:42,800 --> 00:05:51,530
중요한 것은 클래스의 대표성을 갖는 출력을 인코딩하거나 생성할

84
00:05:51,530 --> 00:05:54,960
수 있는 방법입니다.

85
00:05:54,960 --> 00:06:00,380
우리가 하는 것은 종종 변환기에 하나의

86
00:06:00,380 --> 00:06:05,730
토큰, 특별한 추가 입력을 추가하는 것입니다.

87
00:06:05,730 --> 00:06:09,440
이는 동일한 차원을

88
00:06:09,440 --> 00:06:13,670
가지지만, 출력 공간에서 그것이

89
00:06:13,670 --> 00:06:19,590
나타내는 것은 클래스 확률 벡터로 변환됩니다.

90
00:06:19,590 --> 00:06:22,680
즉, 클래스 확률을 나타내는 C차원 벡터입니다.

91
00:06:22,680 --> 00:06:26,670
그리고 이것을 우리는 종종 클래스 토큰이라고 부릅니다.

92
00:06:26,670 --> 00:06:31,790
이것은 이미지 분류를 위해 ViTs, 비전

93
00:06:31,790 --> 00:06:35,360
변환기를 사용하는 가장

94
00:06:35,360 --> 00:06:39,830
기본적이고 표준적인 방법 중 하나입니다.

95
00:06:39,830 --> 00:06:42,810
하지만 변환기는 분류에만 사용되는

96
00:06:42,810 --> 00:06:45,200
것이 아니라, 오늘

97
00:06:45,200 --> 00:06:49,410
다룰 다른 많은 작업에도 사용될 수 있습니다.

98
00:06:49,410 --> 00:06:52,970
하지만 지난 주에는 변환기의 또 다른 변형에

99
00:06:52,970 --> 00:06:54,720
대해서도 이야기했습니다.

100
00:06:54,720 --> 00:06:56,250
다시 같은 토큰입니다.

101
00:06:56,250 --> 00:07:03,090
토큰에서 변환기 레이어로 진행합니다.

102
00:07:03,090 --> 00:07:05,600
지난 번에 여러 개의 변환기

103
00:07:05,600 --> 00:07:09,780
레이어에 대해 이야기한 것을 기억하신다면,

104
00:07:09,780 --> 00:07:13,890
제가 말했듯이, 위치 임베딩이 추가됩니다.

105
00:07:13,890 --> 00:07:20,130
그리고 여기서는 전체 이미지를 함께 보기 때문에, 언어에 대해 했던

106
00:07:20,130 --> 00:07:22,370
것처럼 마스킹을 할 필요가

107
00:07:22,370 --> 00:07:25,160
없습니다. 언어는 미래

108
00:07:25,160 --> 00:07:29,490
정보를 사용해서는 안 되는 시퀀스이기 때문입니다.

109
00:07:29,490 --> 00:07:33,650
그리고 궁극적으로 변환기는

110
00:07:33,650 --> 00:07:40,680
각 입력에 대해 벡터 패치를 출력합니다.

111
00:07:40,680 --> 00:07:44,210
변환기를 훈련하는 다른 옵션은 실제로

112
00:07:44,210 --> 00:07:48,150
별도의 클래스 토큰을 사용하는 대신, 출력을

113
00:07:48,150 --> 00:07:51,300
가져와 풀링 레이어를 실행한 다음,

114
00:07:51,300 --> 00:07:55,340
C개의 서로 다른 클래스에 대한 확률 벡터로

115
00:07:55,340 --> 00:07:57,360
변환하는 것입니다.

116
00:07:57,360 --> 00:08:00,810
그래서 저는 변환기의 두 가지 버전에 대해 이야기했습니다.

117
00:08:00,810 --> 00:08:03,540
그 중 하나는 클래스 토큰을 사용하는 것이었습니다.

118
00:08:03,540 --> 00:08:07,920
다른 하나는 모든 출력 토큰을 가져오는 것이었습니다.

119
00:08:07,920 --> 00:08:12,110
우리는 풀링을 적용하고 클래스 확률을 나타내는

120
00:08:12,110 --> 00:08:14,010
벡터로 투영합니다.

121
00:08:14,010 --> 00:08:15,960
우리는 이것을 어떻게 감독하나요?

122
00:08:15,960 --> 00:08:19,920
이것은 우리가 이전에 이야기한 것과 정확히 동일합니다.

123
00:08:19,920 --> 00:08:23,870
그리고 그것은 역전파, 손실 함수 정의,

124
00:08:23,870 --> 00:08:27,200
이진 교차 엔트로피, 소프트 로그,

125
00:08:27,200 --> 00:08:29,450
최대 손실 등을 포함합니다.

126
00:08:29,450 --> 00:08:33,230
그래서 이것이 ViTs입니다.

127
00:08:33,230 --> 00:08:35,103
이것이 ViTs의 요약입니다.

128
00:08:37,969 --> 00:08:41,840
수년 동안, 이러한 유형의 아키텍처는 다양한

129
00:08:41,840 --> 00:08:46,490
응용 프로그램에 대해 동일하게 유지되었습니다.

130
00:08:46,490 --> 00:08:53,300
현재 많은 현대 아키텍처는 여기에서 제시한 것과 매우 유사한

131
00:08:53,300 --> 00:08:56,550
많은 구성 요소를 사용합니다.

132
00:08:56,550 --> 00:09:00,320
하지만 지난 주 슬라이드에서 언급한

133
00:09:00,320 --> 00:09:03,110
몇 가지 최적화가

134
00:09:03,110 --> 00:09:10,170
있으며, 저는 그것들에 대해 빠르게 몇 분만 할애할 것입니다.

135
00:09:10,170 --> 00:09:12,290
하지만 더 나은 성능을

136
00:09:12,290 --> 00:09:18,200
위한 다양한 조정과 최적화가 있으며, 변환기의 훈련을

137
00:09:18,200 --> 00:09:21,740
조금 더 안정적으로 만드는 것도

138
00:09:21,740 --> 00:09:23,870
이해하시길 바랍니다.

139
00:09:23,870 --> 00:09:28,710
그 중 하나는 실제로 잔여 연결입니다.

140
00:09:28,710 --> 00:09:33,900
이 레이어 정규화는 기본적으로 잔여 연결 외부에

141
00:09:33,900 --> 00:09:38,890
있습니다. 즉, 여기서 얻은 것을 정규화합니다.

142
00:09:38,890 --> 00:09:42,860
그래서 이것은 우리가 더 이상 어떤 형태의 항등 함수를 복제할

143
00:09:42,860 --> 00:09:46,190
수 없다는 것을 의미하지 않습니다. 그것이

144
00:09:46,190 --> 00:09:47,610
정말로 원하는 것입니다.

145
00:09:47,610 --> 00:09:50,030
그래서 그 해결책은 레이어

146
00:09:50,030 --> 00:09:53,160
정규화를 도입하는 것입니다.

147
00:09:53,160 --> 00:09:56,210
우리는 종종 자기 주의 이전과 MLP

148
00:09:56,210 --> 00:09:59,370
레이어 이전에 그것을 배치합니다.

149
00:09:59,370 --> 00:10:01,320
그래서 정규화가 존재합니다.

150
00:10:01,320 --> 00:10:05,030
하지만 우리는 또한 정체성 함수를 보존합니다.

151
00:10:05,030 --> 00:10:09,180
정규화하는 다른 방법들도 있습니다.

152
00:10:09,180 --> 00:10:13,070
이 RMSNorm, 즉 제곱근

153
00:10:13,070 --> 00:10:19,820
평균 제곱 정규화는 사실 매우 기본적인 정규화 유형입니다.

154
00:10:19,820 --> 00:10:21,620
각 특성에 대해 정규화를

155
00:10:21,620 --> 00:10:25,590
위해 특성의 평균 값을 사용하지 않습니다.

156
00:10:25,590 --> 00:10:29,610
하지만 이것은 훈련을 조금 더 안정적으로 만듭니다.

157
00:10:29,610 --> 00:10:38,390
다시 말해, 이것들은 모두 경험적으로 더 나은 옵션으로 나타났습니다.

158
00:10:38,390 --> 00:10:40,490
그들이 잘 작동하는 이유에 대한

159
00:10:40,490 --> 00:10:42,040
몇 가지 정당화가 있지만,

160
00:10:42,040 --> 00:10:46,065
대부분의 경우 이러한 방법을

161
00:10:46,065 --> 00:10:53,290
채택하는 이유는 훈련을 더 안정적으로 만들기 때문입니다.

162
00:10:53,290 --> 00:10:58,380
다른 옵션은 간단한 MLP 대신 SwiGLU

163
00:10:58,380 --> 00:11:05,190
MLP를 사용하는 것입니다. 여기서 우리는 실제로 일부-- 이것을

164
00:11:05,190 --> 00:11:08,530
게이트 비선형성이라고 부릅니다.

165
00:11:08,530 --> 00:11:13,720
두 개의 가중치 벡터, W1과 W2 행렬 대신 세 번째인

166
00:11:13,720 --> 00:11:16,750
1, 2, 3을 추가합니다.

167
00:11:16,750 --> 00:11:22,710
하지만 여기서 우리는 게이트 비선형성을 만듭니다.

168
00:11:22,710 --> 00:11:36,390
기본적으로 그것이 하는 것은 더 많은 학습 가능한 매개변수를 얻는 것이며,
단순히 학습 가능한 매개변수뿐만

169
00:11:36,390 --> 00:11:38,700
아니라 작은 아키텍처에

170
00:11:38,700 --> 00:11:42,210
더 나은 비선형성을 만드는

171
00:11:42,210 --> 00:11:43,750
것입니다.

172
00:11:43,750 --> 00:11:50,250
숨겨진 레이어 값을 8을 3으로 나눈 값으로

173
00:11:50,250 --> 00:11:53,790
선택하더라도, 매개변수 수

174
00:11:53,790 --> 00:11:56,200
측면에서 네트워크의

175
00:11:56,200 --> 00:12:04,540
크기를 유지하지만, 그 레이어에서 더 높은 차원의 비선형성을

176
00:12:04,540 --> 00:12:05,950
학습합니다.

177
00:12:05,950 --> 00:12:09,540
마지막 요소는 요즘 매우 현대적인

178
00:12:09,540 --> 00:12:13,590
아키텍처에서도 자주 사용되는 전문가

179
00:12:13,590 --> 00:12:14,530
혼합입니다.

180
00:12:14,530 --> 00:12:17,770
하나의 MLP 레이어 세트 대신 여러 세트의

181
00:12:17,770 --> 00:12:20,560
MLP 레이어를 가질 수 있습니다.

182
00:12:20,560 --> 00:12:22,720
각각은 전문가가 됩니다.

183
00:12:22,720 --> 00:12:28,930
우리가 하는 것은 라우터를 통해 토큰이 E명의

184
00:12:28,930 --> 00:12:34,630
전문가 중 A로 라우팅되는 것입니다.

185
00:12:34,630 --> 00:12:40,360
이런 식으로 우리는 실제로 A명의 활성 전문가를 갖게 됩니다.

186
00:12:40,360 --> 00:12:43,110
하지만 다시 말해,

187
00:12:43,110 --> 00:12:48,220
이것은 매개변수 수를 증가시키고, 너무

188
00:12:48,220 --> 00:12:55,200
많은 계산을 증가시키지 않으면서 더 강력한 모델을 학습하는

189
00:12:55,200 --> 00:12:57,850
데 도움이 됩니다.

190
00:12:57,850 --> 00:13:01,240
그리고 이것들은 다시 모두 병렬 MLP입니다.

191
00:13:01,240 --> 00:13:05,290
그래서 우리는 병렬로 여러 전문가를 가질 수 있습니다.

192
00:13:05,290 --> 00:13:08,430
말했듯이, 요즘 모든 LLM,

193
00:13:08,430 --> 00:13:10,260
대형 언어

194
00:13:10,260 --> 00:13:15,420
모델에서 사용되며, 우리가 알고 있는 모든 현대

195
00:13:15,420 --> 00:13:20,860
LLM은 이러한 유형의 조정을 사용하고 있습니다.

196
00:13:20,860 --> 00:13:23,520
그리고 이것은 제가 방금 언급한

197
00:13:23,520 --> 00:13:25,740
모든 조정의 요약입니다.

198
00:13:25,740 --> 00:13:28,805
이것은 [? 편향. ?] 아니요.

199
00:13:28,805 --> 00:13:32,010
이것은 스스로 학습 가능한

200
00:13:32,010 --> 00:13:37,500
매개변수로, 피드포워드 네트워크이거나 단순히 확률

201
00:13:37,500 --> 00:13:42,420
벡터로 변환하기 위한 선형 프로젝션입니다.

202
00:13:42,420 --> 00:13:45,570
그래서 이것은 [?] 그냥 편향입니다.

203
00:13:45,570 --> 00:13:47,550
그리고 다시 말하지만,

204
00:13:47,550 --> 00:13:54,370
여기에는 많은 자기 주의 네트워크와 레이어가 있다는 것을 기억하세요.

205
00:13:54,370 --> 00:13:56,250
이 자기 주의 레이어는

206
00:13:56,250 --> 00:13:59,050
기본적으로 정보를 융합하고 모든

207
00:13:59,050 --> 00:14:02,190
토큰과 이 클래스 토큰 간의 주의를

208
00:14:02,190 --> 00:14:02,830
생성합니다.

209
00:14:02,830 --> 00:14:05,260
그래서 여기서 감독을 하면 손실

210
00:14:05,260 --> 00:14:06,700
함수가 들어옵니다.

211
00:14:06,700 --> 00:14:13,860
이것은 클래스 확률 벡터를 나타냅니다.

212
00:14:13,860 --> 00:14:16,800
질문은, 좋은 직관이 있다면, 서로

213
00:14:16,800 --> 00:14:19,920
다른 전문가들이 무엇을 하고 있는가입니다.

214
00:14:19,920 --> 00:14:21,930
정말 좋은 질문입니다.

215
00:14:21,930 --> 00:14:24,930
그들은 병렬로 훈련되고

216
00:14:24,930 --> 00:14:27,700
서로 다르게 초기화되기

217
00:14:27,700 --> 00:14:33,630
때문에, 종종 하나의 측면이나 관련된, 때로는 매우

218
00:14:33,630 --> 00:14:36,220
관련된 측면을 배우려고

219
00:14:36,220 --> 00:14:43,510
합니다. 하지만 이는 단순히 더 많은 계산과 더 많은

220
00:14:43,510 --> 00:14:47,760
매개변수를 추가하여 네트워크가 여러

221
00:14:47,760 --> 00:14:51,160
개념을 배울 수 있도록 합니다.

222
00:14:51,160 --> 00:14:54,660
예를 들어, 여러 확률 분포를 다루어야

223
00:14:54,660 --> 00:14:57,400
한다면, 이러한 MLP를 사용하여

224
00:14:57,400 --> 00:15:02,260
데이터의 모드를 분리할 수 있는 힘이 종종 있습니다.

225
00:15:02,260 --> 00:15:06,150
질문은 전문가의 수가

226
00:15:06,150 --> 00:15:09,370
하이퍼파라미터인지 아닌가입니다.

227
00:15:09,370 --> 00:15:11,800
네, 확실히 하이퍼파라미터입니다.

228
00:15:11,800 --> 00:15:15,780
제가 아는 한, 이는 종종 미리 정의됩니다.

229
00:15:15,780 --> 00:15:18,910
반드시 과도하게 미세 조정할 필요는 없습니다.

230
00:15:18,910 --> 00:15:21,553
하지만 네, 모두 하이퍼파라미터입니다.

231
00:15:21,553 --> 00:15:22,470
그것들은 또한 학습됩니다.

232
00:15:22,470 --> 00:15:23,490
네.

233
00:15:23,490 --> 00:15:25,050
그리고 그것들은 학습됩니다.

234
00:15:25,050 --> 00:15:30,450
그렇다면 레이어 정규화를 이동하는 것이 왜 정체성 변환을

235
00:15:30,450 --> 00:15:33,160
배우는 데 도움이 될까요?

236
00:15:33,160 --> 00:15:35,110
이 아키텍처를 보세요.

237
00:15:35,110 --> 00:15:38,470
어떤 형태의 정체성을 만들 수 있을까요?

238
00:15:38,470 --> 00:15:41,680
잔여 연결 바로 뒤에서 특징 값이 변경되기

239
00:15:41,680 --> 00:15:44,490
때문에 정체성을 가질 수 없습니다. 정규화가

240
00:15:44,490 --> 00:15:45,900
있기 때문입니다.

241
00:15:45,900 --> 00:15:48,990
특징에서 정체성을 가질 수 없습니다.

242
00:15:48,990 --> 00:15:53,880
왜냐하면 그 직후에 레이어 정규화를 보게 되기 때문입니다.

243
00:15:53,880 --> 00:15:57,570
그래서 우리가 하는 것은 그것을 가져오는 것입니다.

244
00:15:57,570 --> 00:16:04,750
컴퓨터 비전에는 꽤 많은 다양한 작업이 있습니다.

245
00:16:04,750 --> 00:16:09,990
그리고 이것들은 수년 동안 컴퓨터 비전 응용 프로그램에 대한

246
00:16:09,990 --> 00:16:13,360
핵심적이고 가장 중요한 작업이었습니다.

247
00:16:13,360 --> 00:16:16,900
비록 요즘에는 훨씬 더 어려운 작업을 해결하고 있지만.

248
00:16:16,900 --> 00:16:19,320
그리고 이제는 한 줄의 코드로 객체 감지를

249
00:16:19,320 --> 00:16:22,510
할 수 있기 때문에 아무도 신경 쓰지 않습니다.

250
00:16:22,510 --> 00:16:25,470
하지만 지난 10, 15년 동안 많은

251
00:16:25,470 --> 00:16:27,000
발전이 있었습니다.

252
00:16:27,000 --> 00:16:31,230
그리고 오늘 그 중 일부를 정말 다루고

253
00:16:31,230 --> 00:16:32,290
싶습니다.

254
00:16:32,290 --> 00:16:35,640
그래서 만약 당신이 새로운 것을 설계해야

255
00:16:35,640 --> 00:16:40,960
한다면, 어디를 보고 모델을 어떻게 설계해야 할지 알 수 있습니다.

256
00:16:40,960 --> 00:16:43,230
그리고 궁극적으로 시각화와

257
00:16:43,230 --> 00:16:47,310
이해라는 주제가 있습니다. 이는 많은 응용

258
00:16:47,310 --> 00:16:49,510
프로그램에서 매우 중요합니다.

259
00:16:49,510 --> 00:16:52,360
예를 들어, 의료 데이터를 다룰 때

260
00:16:52,360 --> 00:16:54,330
시각화 이해가 분류

261
00:16:54,330 --> 00:16:57,150
자체나 종양 탐지보다 더 중요할 때가

262
00:16:57,150 --> 00:16:58,895
많습니다. 예를 들어,

263
00:16:58,895 --> 00:17:02,075
어디서, 왜, 등을 알고 싶다면요.

264
00:17:06,480 --> 00:17:11,670
수업을 시작한 방식과 이 슬라이드는 아마 모든 사람에게

265
00:17:11,670 --> 00:17:18,030
매우 익숙할 것입니다. 우리는 다양한 작업에 대해 이야기했습니다.

266
00:17:18,030 --> 00:17:23,290
객체 분류와 분류 작업에 대해

267
00:17:23,290 --> 00:17:24,579
이야기했습니다.

268
00:17:24,579 --> 00:17:29,610
우리는 처음 몇 강의에서 이미지를 픽셀에서

269
00:17:29,610 --> 00:17:33,540
레이블로 분류하는 분류기를 만드는

270
00:17:33,540 --> 00:17:37,990
방법에 대해 많은 시간을 보냈습니다.

271
00:17:37,990 --> 00:17:45,750
하지만 비슷하게 중요한 다른 작업 중 하나는 의미론적

272
00:17:45,750 --> 00:17:48,130
분할입니다.

273
00:17:48,130 --> 00:17:50,110
의미론적 분할

274
00:17:50,110 --> 00:17:56,520
내에서 우리가 중요하게 여기는 것은

275
00:17:56,520 --> 00:18:01,110
이미지 내의 모든 픽셀에 레이블을

276
00:18:01,110 --> 00:18:08,235
할당하는 것입니다. 각 픽셀을 해당 객체나

277
00:18:08,235 --> 00:18:12,630
장면의 레이블로 변환합니다.

278
00:18:12,630 --> 00:18:15,600
기본적으로, 우리가 이렇게 하는 모델을

279
00:18:15,600 --> 00:18:19,890
훈련할 때, 테스트 시에는 이미지를 가져와서

280
00:18:19,890 --> 00:18:23,130
동일한 맵을 출력으로 생성하고 싶습니다.

281
00:18:23,130 --> 00:18:24,910
어떻게 해야 할까요?

282
00:18:24,910 --> 00:18:26,650
여러 가지 옵션이 있습니다.

283
00:18:26,650 --> 00:18:31,140
예를 들어, 각 픽셀, 모든 픽셀을

284
00:18:31,140 --> 00:18:36,330
살펴보고 그 픽셀의 값이나 레이블이

285
00:18:36,330 --> 00:18:40,360
무엇이어야 하는지 말할 수 있습니다.

286
00:18:40,360 --> 00:18:43,270
아주 기본적인 형태로, 여기서 볼 수

287
00:18:43,270 --> 00:18:46,120
있듯이, 사실상 매우 불가능합니다.

288
00:18:46,120 --> 00:18:52,650
특정 픽셀이 어떤 객체를 나타내는지 말하기

289
00:18:52,650 --> 00:18:57,360
어렵습니다. 픽셀 자체만 보면

290
00:18:57,360 --> 00:19:00,430
맥락이 없기 때문입니다.

291
00:19:00,430 --> 00:19:04,270
그래서 맥락이 중요합니다.

292
00:19:04,270 --> 00:19:06,900
우리는 주변 영역을 봅니다.

293
00:19:09,475 --> 00:19:13,920
그리고 이 패치와 중앙의 픽셀, 주변 영역을

294
00:19:13,920 --> 00:19:16,270
가져오면, 이제 우리는 출력을

295
00:19:16,270 --> 00:19:19,920
위한 레이블을 생성하는 합성곱 신경망이나

296
00:19:19,920 --> 00:19:23,300
어떤 네트워크를 훈련할 수 있습니다.

297
00:19:23,300 --> 00:19:25,170
우리가 분기 동안

298
00:19:25,170 --> 00:19:28,090
이야기한 동일한 아키텍처입니다.

299
00:19:28,090 --> 00:19:30,660
이미지 분류에 사용한 것 중에서

300
00:19:30,660 --> 00:19:32,500
아무거나 선택할 수 있습니다.

301
00:19:32,500 --> 00:19:35,140
이제 전체 이미지를 분류하고 있기 때문입니다.

302
00:19:35,140 --> 00:19:38,250
CNN일 수도 있고, ResNet일 수도

303
00:19:38,250 --> 00:19:40,290
있고, ViT일 수도 있습니다.

304
00:19:40,290 --> 00:19:44,880
이것은 정말 시간이 많이 걸립니다. 이미지의

305
00:19:44,880 --> 00:19:50,200
모든 픽셀에 대해 전체 네트워크를 실행하려면 세그멘테이션

306
00:19:50,200 --> 00:19:55,050
맵으로 변환하는 데 영원히 걸릴 것입니다.

307
00:19:55,050 --> 00:19:58,380
우리가 사용할 수 있는 다른

308
00:19:58,380 --> 00:20:05,080
옵션은 모든 픽셀에 대해 하나의 네트워크를 실행하는 대신,

309
00:20:05,080 --> 00:20:07,860
이미지를 입력으로 받고

310
00:20:07,860 --> 00:20:13,770
전체 픽셀 맵, 세그멘테이션 맵을 출력하는 신경망을

311
00:20:13,770 --> 00:20:17,380
훈련하는 것입니다. 단일 레이블이

312
00:20:17,380 --> 00:20:20,640
아니라 레이블의 행렬입니다.

313
00:20:20,640 --> 00:20:28,150
그 경우, 우리는 세그멘테이션 작업을 해결할 수 있습니다.

314
00:20:28,150 --> 00:20:32,070
이를 위해서는 입력의 레이어가

315
00:20:32,070 --> 00:20:36,960
이미지와 동일한 크기여야 합니다.

316
00:20:36,960 --> 00:20:39,720
출력에서도 어떤 형태의 팽창된

317
00:20:39,720 --> 00:20:42,220
레이어가 필요합니다.

318
00:20:42,220 --> 00:20:47,970
완전 연결 레이어로 갈 수는 없습니다. 이제 이미지를

319
00:20:47,970 --> 00:20:50,080
생성하고 있기 때문입니다.

320
00:20:50,080 --> 00:20:57,695
그렇기 때문에 네트워크를 팽창된 상태로 유지해야 합니다.

321
00:20:57,695 --> 00:21:03,180
그래서 우리는 종종 완전 합성곱 신경망

322
00:21:03,180 --> 00:21:06,600
또는 FCN이라고 부릅니다.

323
00:21:06,600 --> 00:21:10,725
완전 합성곱 신경망으로서, 이것은

324
00:21:10,725 --> 00:21:13,780
확실히 훌륭한 아이디어입니다.

325
00:21:13,780 --> 00:21:15,130
하지만 단점이 있습니다.

326
00:21:15,130 --> 00:21:16,240
문제가 있습니다.

327
00:21:16,240 --> 00:21:18,100
이 이미지는 큽니다.

328
00:21:18,100 --> 00:21:24,210
그리고 이러한 네트워크, 이러한 레이어는 매우 커질 것입니다.

329
00:21:24,210 --> 00:21:26,550
그리고 최적화해야 할 매개변수가

330
00:21:26,550 --> 00:21:28,620
너무 많아져서, 특히

331
00:21:28,620 --> 00:21:31,300
강력한 GPU가 없었던 초기에는

332
00:21:31,300 --> 00:21:34,950
이것이 병목 현상, 문제, 훈련 알고리즘의

333
00:21:34,950 --> 00:21:37,210
도전 과제가 되었습니다.

334
00:21:37,210 --> 00:21:40,980
그래서 알고리즘은 전체 크기의

335
00:21:40,980 --> 00:21:46,530
이미지에서 시작하여 해상도를 낮추고,

336
00:21:46,530 --> 00:21:49,680
합성곱을 통해 공간

337
00:21:49,680 --> 00:21:53,790
해상도를 점점 더 작게 만드는

338
00:21:53,790 --> 00:21:56,650
방향으로 발전했습니다.

339
00:21:56,650 --> 00:21:59,100
그리고 중간 어딘가에서 우리는

340
00:21:59,100 --> 00:22:02,490
낮은 해상도를 가지지만 채널 수는

341
00:22:02,490 --> 00:22:05,165
두꺼운 상태가 될 것입니다.

342
00:22:05,165 --> 00:22:08,370
그리고 거기서 우리는 출력 픽셀을

343
00:22:08,370 --> 00:22:10,740
생성하기 위해 이미지의

344
00:22:10,740 --> 00:22:13,800
동일한 크기로 다시 올라갑니다.

345
00:22:13,800 --> 00:22:19,860
이를 위해 우리는 다운샘플링을 수행하는 방법을 알고 있습니다.

346
00:22:19,860 --> 00:22:21,250
다운샘플링은 쉬웠습니다.

347
00:22:21,250 --> 00:22:22,420
우리는 그것에 대해 이야기했습니다.

348
00:22:22,420 --> 00:22:26,500
우리는 풀링 연산, 스트라이드

349
00:22:26,500 --> 00:22:35,460
합성곱, 그리고 여기서 사용할 수 있는 여러 다른 단계나 연산에

350
00:22:35,460 --> 00:22:37,980
대해 이야기했습니다.

351
00:22:37,980 --> 00:22:41,880
하지만 업샘플링 측면에서는

352
00:22:41,880 --> 00:22:46,770
풀링이나 역 풀링 또는 역 스트라이드

353
00:22:46,770 --> 00:22:55,135
합성곱이 없기 때문에 업샘플링을 수행하는 방법을 잘 모릅니다.

354
00:22:55,135 --> 00:22:57,990
그 때문에 우리는

355
00:22:57,990 --> 00:23:04,750
다운샘플링을 스스로 역전시키는 새로운 연산을 발명해야 했습니다.

356
00:23:04,750 --> 00:23:09,900
하지만 업샘플링으로 넘어가기 전에

357
00:23:09,900 --> 00:23:12,870
업샘플링이 무엇인지

358
00:23:12,870 --> 00:23:21,160
정의하기 전에, 간단히 질문을 드리고 싶습니다.

359
00:23:21,160 --> 00:23:24,100
이 네트워크는 어떻게 훈련된다고 생각하십니까?

360
00:23:24,100 --> 00:23:27,540
지금 우리는 이미지에서 시작하여 이미지로 끝나는

361
00:23:27,540 --> 00:23:29,440
네트워크를 가지고 있습니다.

362
00:23:29,440 --> 00:23:33,570
그리고 이 네트워크를 훈련시키기 위해

363
00:23:33,570 --> 00:23:37,560
우리가 가진 도구는 손실 함수입니다.

364
00:23:37,560 --> 00:23:41,400
이 네트워크를 훈련시키거나 손실 함수를 정의하는

365
00:23:41,400 --> 00:23:44,370
가장 좋은 방법은 무엇이라고 생각하십니까?

366
00:23:44,370 --> 00:23:47,130
우리는 소프트맥스 손실에 대해 이야기했습니다.

367
00:23:47,130 --> 00:23:51,300
우리는 회귀 손실과 SVM 손실에 대해서도

368
00:23:51,300 --> 00:23:53,170
조금 이야기했습니다.

369
00:23:53,170 --> 00:23:58,650
하지만 소프트맥스 손실 함수를 사용하고 싶다고 가정할 때, 이

370
00:23:58,650 --> 00:24:02,730
네트워크를 어떻게 정의하거나 훈련할 수 있을까요?

371
00:24:02,730 --> 00:24:04,680
목표는 무엇일까요?

372
00:24:04,680 --> 00:24:09,670
그래서 당신은 각 픽셀에 대한 평균 분류 손실이라고 말했습니다.

373
00:24:09,670 --> 00:24:11,950
그것은 맞습니다.

374
00:24:11,950 --> 00:24:16,690
각 픽셀에 대한 손실 함수를 추가할 수 있습니다. 왜냐하면

375
00:24:16,690 --> 00:24:20,200
각 픽셀이 분류를 수행하고 있기 때문입니다.

376
00:24:20,200 --> 00:24:24,370
그래서 이미지의 모든 픽셀에 대해 시그마를 가질 것입니다.

377
00:24:24,370 --> 00:24:28,720
손실 함수는 단순한 소프트맥스입니다.

378
00:24:28,720 --> 00:24:30,970
그리고 나서 역전파를 수행할 수 있습니다.

379
00:24:30,970 --> 00:24:33,810
그것이 당신이 필요한 전체 손실 함수입니다.

380
00:24:33,810 --> 00:24:37,680
질문은 훈련을 위해 우리가 부르는 '그라운드

381
00:24:37,680 --> 00:24:39,340
트루스'가 필요한가입니다.

382
00:24:39,340 --> 00:24:41,920
그래서 그것은 실제로 세분화의 그라운드 트루스입니다.

383
00:24:41,920 --> 00:24:44,280
네, 이러한 유형의 알고리즘에는

384
00:24:44,280 --> 00:24:46,060
완전 감독이 필요하기

385
00:24:46,060 --> 00:24:49,290
때문에 그라운드 트루스 레이블 맵이 필요합니다.

386
00:24:49,290 --> 00:24:52,470
초기에는 이러한 알고리즘을

387
00:24:52,470 --> 00:24:57,030
훈련시키기 위해 픽셀을 수동으로 레이블링하는

388
00:24:57,030 --> 00:24:59,530
많은 작업이 있었습니다.

389
00:24:59,530 --> 00:25:00,720
네.

390
00:25:00,720 --> 00:25:04,180
요즘 우리는 도구가 있기 때문에 그게 필요하지 않습니다.

391
00:25:04,180 --> 00:25:07,540
하지만 초기에는 이러한 알고리즘을 훈련시키기 위해 실제

392
00:25:07,540 --> 00:25:08,990
데이터를 필요로 했습니다.

393
00:25:13,530 --> 00:25:17,260
간단히 말해, 업샘플링에서 우리가 하는 일을 말씀드리겠습니다.

394
00:25:17,260 --> 00:25:19,660
업샘플링은 사실 그렇게 어렵지 않습니다.

395
00:25:19,660 --> 00:25:22,720
우리는 언풀링 작업을 사용할 수 있습니다.

396
00:25:22,720 --> 00:25:24,730
이를 수행하는 방법은 여러 가지가 있습니다.

397
00:25:24,730 --> 00:25:26,440
하나는 최근접 이웃입니다.

398
00:25:26,440 --> 00:25:32,080
예를 들어 2x2 행렬에서 4x4로

399
00:25:32,080 --> 00:25:34,000
가고 싶다면,

400
00:25:34,000 --> 00:25:39,070
각각의 데이터를 복사하고, 낮은 해상도에서

401
00:25:39,070 --> 00:25:42,360
최근접 이웃을 가져오면 됩니다.

402
00:25:42,360 --> 00:25:45,300
또는 침대의 못처럼 업샘플링된

403
00:25:45,300 --> 00:25:48,810
버전에서 그 중 하나를 선택합니다.

404
00:25:48,810 --> 00:25:53,850
그 중 하나, 모서리에 있는 것을 선택합니다.

405
00:25:53,850 --> 00:25:57,880
데이터를 복사하고 나머지는 모두 0으로 대체합니다.

406
00:25:57,880 --> 00:26:00,240
그리고 여러 층의

407
00:26:00,240 --> 00:26:05,250
컨볼루션을 통해 이러한 값들이 나타나기 시작합니다.

408
00:26:05,250 --> 00:26:11,550
네트워크에서 맥스 풀링을 사용하면,

409
00:26:11,550 --> 00:26:15,120
인코딩 측면에서

410
00:26:15,120 --> 00:26:20,220
우리는 선택된 맥스의 위치를

411
00:26:20,220 --> 00:26:25,500
저장하고, 언풀링 맥스

412
00:26:25,500 --> 00:26:34,930
단계에서 그 위치에 데이터를 복사할 수 있습니다.

413
00:26:34,930 --> 00:26:37,980
기본적으로 우리는 위치를 저장합니다.

414
00:26:37,980 --> 00:26:40,350
인코딩 부분과 디코딩

415
00:26:40,350 --> 00:26:46,950
부분의 업샘플링 단계에서 우리는 저장된 좌표를 재사용합니다.

416
00:26:46,950 --> 00:26:51,750
다른 옵션은 학습된 업샘플링을 하는 것입니다.

417
00:26:51,750 --> 00:26:55,660
제가 보여준 모든 것은 학습할 매개변수가 없습니다.

418
00:26:55,660 --> 00:26:57,370
그냥 작업일 뿐입니다.

419
00:26:57,370 --> 00:27:01,440
하지만 학습된 업샘플링도 가능합니다.

420
00:27:01,440 --> 00:27:05,040
아주 간단하게, 컨볼루션을 다시 살펴보겠습니다.

421
00:27:05,040 --> 00:27:07,260
컨볼루션 층에서 우리는

422
00:27:07,260 --> 00:27:10,860
픽셀에 컨볼루션 필터를 적용하고

423
00:27:10,860 --> 00:27:13,860
출력을 생성하며, 모든 픽셀에

424
00:27:13,860 --> 00:27:16,620
대해 이를 반복했습니다.

425
00:27:16,620 --> 00:27:20,400
그리고 다운샘플링을 하고 싶을 때,

426
00:27:20,400 --> 00:27:23,610
우리는 보폭이 1이

427
00:27:23,610 --> 00:27:27,220
아닌 2인 스트라이드 컨볼루션을

428
00:27:27,220 --> 00:27:31,720
사용하여 단계별로 출력을 생성했습니다.

429
00:27:31,720 --> 00:27:34,888
이 부분이 기억나지 않으면 강의로 돌아가세요.

430
00:27:34,888 --> 00:27:35,680
우리가 이야기했습니다.

431
00:27:35,680 --> 00:27:36,638
세 번째 강의였던 것 같습니다.

432
00:27:39,275 --> 00:27:44,590
그리고 우리는 업샘플링 과정에서도 동일하게 복제할 수 있습니다.

433
00:27:44,590 --> 00:27:51,400
그래서 이 부분은 업샘플링된 이미지에서 이 영역을 나타냅니다.

434
00:27:51,400 --> 00:27:53,670
그리고 우리는 이를 출력 맵에

435
00:27:53,670 --> 00:27:57,550
매핑하기 위해 여기에서 일부 가중치를 정의합니다.

436
00:27:57,550 --> 00:27:59,830
그리고 다음 것도 같은 이야기지만,

437
00:27:59,830 --> 00:28:01,480
겹치는 부분이 있을 것입니다.

438
00:28:01,480 --> 00:28:04,840
겹치는 부분에 대해서는 종종 값을 합산합니다.

439
00:28:04,840 --> 00:28:08,320
출력에 대해 합산하는 예를 드리겠습니다.

440
00:28:08,320 --> 00:28:09,940
예를 들어 보겠습니다.

441
00:28:09,940 --> 00:28:14,680
그리고 그것은 간단한 1D 함수로 이루어져 있습니다.

442
00:28:14,680 --> 00:28:18,810
입력이 A와 B의 두 값뿐이라면,

443
00:28:18,810 --> 00:28:24,450
우리는 그 필터가 더 높은 해상도의 출력으로 매핑되도록

444
00:28:24,450 --> 00:28:26,206
학습합니다.

445
00:28:26,206 --> 00:28:30,000
이를 위해 각 값에 필터를

446
00:28:30,000 --> 00:28:34,980
적용하고 출력을 여기에 기록합니다.

447
00:28:34,980 --> 00:28:38,550
겹치는 부분은 합산입니다.

448
00:28:38,550 --> 00:28:46,306
두 위치에서 오는 것의 합입니다.

449
00:28:49,380 --> 00:28:58,575
우리는 완전 합성곱 신경망과 그것이 어떻게 사용되는지에 대해

450
00:28:58,575 --> 00:29:00,160
이야기했습니다.

451
00:29:00,160 --> 00:29:07,500
이들은 실제로 세분화에 가장 기본적이고 널리

452
00:29:07,500 --> 00:29:11,670
사용되는 알고리즘 중 일부입니다.

453
00:29:11,670 --> 00:29:15,300
또한, 널리 사용되는 네트워크

454
00:29:15,300 --> 00:29:21,040
유닛 중 하나를 빠르게 강조하고 싶습니다.

455
00:29:21,040 --> 00:29:23,700
보시다시피, U 형태는 제가 여기서

456
00:29:23,700 --> 00:29:26,020
보여준 것과 동일한 구조입니다.

457
00:29:26,020 --> 00:29:31,900
그냥 U 형태와 유사하게 그려봅시다.

458
00:29:31,900 --> 00:29:35,520
제가 이것을 강조하는 이유는 오늘날에도

459
00:29:35,520 --> 00:29:40,770
세분화 작업을 수행하는 일부 의료 응용

460
00:29:40,770 --> 00:29:44,560
프로그램이 세분화 알고리즘을 사용하고

461
00:29:44,560 --> 00:29:53,040
있으며, 여전히 이 유닛 또는 그 변형이 최첨단 결과를 생성하기 때문입니다.
기초

462
00:29:53,040 --> 00:29:56,490
모델을 사용하고 싶지 않다면요.

463
00:29:56,490 --> 00:30:01,080
그것이 하는 일은 우리가 설명한 것과 정확히 같습니다.

464
00:30:01,080 --> 00:30:05,340
시야를 넓히고 일부 공간 정보를

465
00:30:05,340 --> 00:30:08,380
잃는 다운샘플링 단계와

466
00:30:08,380 --> 00:30:12,570
이미지 해상도로 돌아가는 업샘플링

467
00:30:12,570 --> 00:30:14,560
단계입니다.

468
00:30:14,560 --> 00:30:16,440
U-Net의

469
00:30:16,440 --> 00:30:20,370
유일한 차이점은 세분화를 위해

470
00:30:20,370 --> 00:30:24,480
사용되기 때문에 디코더 측에서 공간

471
00:30:24,480 --> 00:30:32,230
정보를 유지해야 한다는 이해가 있다는 것입니다. 다운샘플링할 때

472
00:30:32,230 --> 00:30:35,500
해상도를 잃기 때문입니다.

473
00:30:35,500 --> 00:30:38,770
그리고 업샘플링할 때 정보가 없다면

474
00:30:38,770 --> 00:30:40,930
조금 어려울 것입니다.

475
00:30:40,930 --> 00:30:45,610
때때로 경계가 흐릿해지는 경우가 있습니다.

476
00:30:45,610 --> 00:30:53,220
인코더 측의 피처 맵이 디코더 레이어의 입력으로

477
00:30:53,220 --> 00:30:58,570
실제로 복사되지 않도록 합니다.

478
00:30:58,570 --> 00:31:03,900
이런 방식으로 이미지 내의 구조적 정보를

479
00:31:03,900 --> 00:31:06,600
유지하고 훨씬 선명한

480
00:31:06,600 --> 00:31:09,070
출력을 생성합니다.

481
00:31:09,070 --> 00:31:14,050
그래서 이것이 U-Net의 아이디어였습니다. 제가

482
00:31:14,050 --> 00:31:17,560
말했듯이, 실제로 꽤 자주 사용됩니다.

483
00:31:17,560 --> 00:31:21,390
오늘 이야기한 의미 분할 요약 -

484
00:31:21,390 --> 00:31:24,840
완전 합성곱 신경망에 대해

485
00:31:24,840 --> 00:31:26,580
이야기했습니다.

486
00:31:26,580 --> 00:31:32,010
여기에서 다운샘플링을 위해 사용했던 것과 동일한

487
00:31:32,010 --> 00:31:34,100
필터가 있습니다.

488
00:31:42,780 --> 00:31:45,630
시간을 절약하기 위해 이 부분의 슬라이드를

489
00:31:45,630 --> 00:31:46,690
일부 제거했습니다.

490
00:31:46,690 --> 00:31:48,370
슬라이드 뒷부분에 있습니다.

491
00:31:48,370 --> 00:31:49,510
확인해 보세요.

492
00:31:49,510 --> 00:31:51,330
이것은 역변환입니다.

493
00:31:51,330 --> 00:31:54,130
이것은 전치 합성곱입니다.

494
00:31:54,130 --> 00:31:57,220
여기에는 3x3 행렬이 있습니다.

495
00:31:57,220 --> 00:32:03,040
입력 이미지, 입력 데이터에 대해 합성곱을 수행하는

496
00:32:03,040 --> 00:32:05,530
대신, 입력의

497
00:32:05,530 --> 00:32:09,410
전치 버전에서 합성곱을 적용합니다.

498
00:32:09,410 --> 00:32:12,590
그 결과 더 큰 출력을 생성합니다.

499
00:32:12,590 --> 00:32:16,690
그래서 이것이 전치 합성곱입니다.

500
00:32:16,690 --> 00:32:20,510
정규 합성곱의 역입니다.

501
00:32:20,510 --> 00:32:21,760
하지만 왜 전치했나요?

502
00:32:21,760 --> 00:32:25,850
추가 슬라이드를 확인해 보시길 권장합니다.

503
00:32:25,850 --> 00:32:28,640
그래서 질문은 필터가 훈련되었는가입니다.

504
00:32:28,640 --> 00:32:29,140
네.

505
00:32:29,140 --> 00:32:31,338
다른 합성곱 층과 매우 유사합니다.

506
00:32:31,338 --> 00:32:32,630
모든 필터가 훈련됩니다.

507
00:32:32,630 --> 00:32:33,100
네.

508
00:32:33,100 --> 00:32:33,600
네.

509
00:32:38,860 --> 00:32:40,120
좋습니다.

510
00:32:40,120 --> 00:32:45,920
이것은 의미 분할의 주제였습니다.

511
00:32:45,920 --> 00:32:51,860
우리가 이 주제에 대해 이야기할 때, 우리는 픽셀에 대한 레이블만 얻습니다.

512
00:32:51,860 --> 00:32:55,570
하지만 같은 객체의 두 인스턴스가 있다면, 우리는

513
00:32:55,570 --> 00:32:58,885
어떤 것이 어떤 것인지 알 수 없습니다.

514
00:32:58,885 --> 00:33:07,960
왜냐하면 이것은 단지 픽셀 레이블을 생성하거나 출력하는 것이기 때문입니다.

515
00:33:07,960 --> 00:33:13,040
이것은 인스턴스 분할의 주제로 이어지며,

516
00:33:13,040 --> 00:33:18,410
이제 우리는 픽셀 클래스뿐만 아니라 이 픽셀들이

517
00:33:18,410 --> 00:33:23,050
개의 한 인스턴스에 속한다는 것을

518
00:33:23,050 --> 00:33:24,800
알고 싶습니다.

519
00:33:24,800 --> 00:33:29,442
그리고 다음 것은 실제로 다른 개입니다.

520
00:33:29,442 --> 00:33:37,430
이를 위해서는 이미지 내 여러 객체를 이해해야 하며,

521
00:33:37,430 --> 00:33:41,200
이는 객체 탐지의 주제로

522
00:33:41,200 --> 00:33:43,430
이어집니다.

523
00:33:43,430 --> 00:33:49,030
객체 탐지는 이미지 분류 이후 또는

524
00:33:49,030 --> 00:33:51,280
그와 함께

525
00:33:51,280 --> 00:33:58,020
핵심 컴퓨터 비전 문제 및 작업 중

526
00:33:58,020 --> 00:33:59,350
하나였습니다.

527
00:33:59,350 --> 00:34:03,240
수년 동안, 객체 탐지 작업을

528
00:34:03,240 --> 00:34:09,520
수행하기 위해 많은 다양한 알고리즘이 제안되었습니다.

529
00:34:09,520 --> 00:34:11,940
우리는 그 중 일부를 간략히 살펴보고

530
00:34:11,940 --> 00:34:15,040
몇 가지 중요한 것들을 강조할 것입니다.

531
00:34:15,040 --> 00:34:20,280
하지만 다시 말하지만, 여기서 다루지

532
00:34:20,280 --> 00:34:22,590
않는 많은

533
00:34:22,590 --> 00:34:30,239
연구가 있으며, 심층 학습 문헌에서도 마찬가지입니다.

534
00:34:30,239 --> 00:34:35,170
우리는 어떻게 이 문제를 해결할 수 있을까요?

535
00:34:35,170 --> 00:34:40,330
단일 객체라면, 우리는 분류를 수행하고

536
00:34:40,330 --> 00:34:42,810
레이블 클래스

537
00:34:42,810 --> 00:34:46,739
점수를 생성하며, 경계 상자의

538
00:34:46,739 --> 00:34:50,350
좌표를 얻어야 합니다.

539
00:34:50,350 --> 00:34:52,650
그래서 우리는 상자의 x, y

540
00:34:52,650 --> 00:34:58,360
좌표와 h, w를 출력으로 필요로 하며, 그것이 어떤 클래스인지도
필요합니다.

541
00:34:58,360 --> 00:35:01,630
이것이 바로 객체 탐지의 작업입니다.

542
00:35:01,630 --> 00:35:03,190
우리는 이것을 어떻게 해결할 수 있을까요?

543
00:35:03,190 --> 00:35:04,440
매우 간단합니다.

544
00:35:04,440 --> 00:35:11,410
클래스 점수에 대한 소프트맥스 손실 함수를 정의할 수 있습니다.

545
00:35:11,410 --> 00:35:15,210
그리고 박스 좌표에 대한 간단한

546
00:35:15,210 --> 00:35:20,910
거리 메트릭인 L2 손실 함수를 정의할 수

547
00:35:20,910 --> 00:35:21,790
있습니다.

548
00:35:21,790 --> 00:35:27,580
이 두 가지를 정의하면, 우리는 다중 작업 손실을 가지게 됩니다.

549
00:35:27,580 --> 00:35:30,640
우리는 두 작업을 동시에 해결하고 있습니다.

550
00:35:30,640 --> 00:35:34,110
이를 위해 우리는 다시

551
00:35:34,110 --> 00:35:40,420
손실 값을 더하고, 여기서 볼 수 있는 복합

552
00:35:40,420 --> 00:35:43,920
손실 함수를 생성합니다.

553
00:35:43,920 --> 00:35:46,480
그래서 이것은 간단합니다.

554
00:35:46,480 --> 00:35:47,760
할 수 있습니다.

555
00:35:47,760 --> 00:35:54,780
하나의 객체만 있다면, 제가 이야기한 이 아키텍처를 사용하여 이

556
00:35:54,780 --> 00:35:56,880
문제를 확실히 해결할 수

557
00:35:56,880 --> 00:35:58,060
있습니다.

558
00:35:58,060 --> 00:36:00,420
하지만 장면에 여러 객체가

559
00:36:00,420 --> 00:36:02,620
있다면 그렇게 쉽지 않습니다.

560
00:36:02,620 --> 00:36:07,270
세 개의 객체가 있을 경우, 12개의 출력 숫자를 생성해야 합니다.

561
00:36:07,270 --> 00:36:09,540
더 많아지면 생성해야

562
00:36:09,540 --> 00:36:12,820
할 숫자가 너무 많아질 것입니다.

563
00:36:12,820 --> 00:36:15,995
그래서 이 알고리즘은 정말로 확장 가능하지 않습니다.

564
00:36:15,995 --> 00:36:17,970
단순히 분류를 일부 객체

565
00:36:17,970 --> 00:36:20,560
탐지로 확장하는 것인데, 괜찮지만

566
00:36:20,560 --> 00:36:23,040
정말로 확장 가능하지는 않습니다.

567
00:36:23,040 --> 00:36:28,270
여러 객체가 있을 때, 한 가지

568
00:36:28,270 --> 00:36:35,310
해결책은 전체 이미지를 입력으로 받는 대신 바운딩

569
00:36:35,310 --> 00:36:38,970
박스를 보는 것입니다.

570
00:36:38,970 --> 00:36:44,800
각 바운딩 박스에 대해 우리는 하나의 레이블만 가지고, 그것이

571
00:36:44,800 --> 00:36:49,470
고양이인지 개인지 배경인지 말할 수 있습니다.

572
00:36:49,470 --> 00:36:56,460
이 바운딩 박스를 분류하는 방법이 있다면, 슬라이딩 윈도우를

573
00:36:56,460 --> 00:36:59,140
사용할 수 있습니다.

574
00:36:59,140 --> 00:37:01,060
이 바운딩 박스를

575
00:37:01,060 --> 00:37:06,300
생성하고, 좌표 0, 0에서 모든 x, y, h, w 조합으로

576
00:37:06,300 --> 00:37:10,740
이미지를 슬라이드하여 객체를 감지할 수 있는지

577
00:37:10,740 --> 00:37:12,670
확인할 수 있습니다.

578
00:37:12,670 --> 00:37:16,080
단계별로, 각 객체의

579
00:37:16,080 --> 00:37:18,090
최대 확률을 가진

580
00:37:18,090 --> 00:37:23,070
바운딩 박스를 찾을 수 있습니다.

581
00:37:23,070 --> 00:37:26,140
하지만 여기에는 큰 문제가 있습니다.

582
00:37:26,140 --> 00:37:29,400
다시 말해, 사용할 수 있는 바운딩

583
00:37:29,400 --> 00:37:31,740
박스의 조합이 너무 많습니다.

584
00:37:31,740 --> 00:37:35,820
그리고 다시, 이 알고리즘은 확장 가능하지 않습니다.

585
00:37:35,820 --> 00:37:39,875
문헌에서 우리가 해왔던 것처럼,

586
00:37:39,875 --> 00:37:43,660
초기 몇 년 동안,

587
00:37:43,660 --> 00:37:46,230
이 기사가 발표된

588
00:37:46,230 --> 00:37:52,300
연도를 보면 2014년 이전에 객체가

589
00:37:52,300 --> 00:37:58,750
있을 확률이 높은 영역을 찾는 연구가 많이

590
00:37:58,750 --> 00:38:00,560
있었습니다.

591
00:38:00,560 --> 00:38:02,540
그래서 지역 제안입니다.

592
00:38:02,540 --> 00:38:07,190
그리고 지역 제안을 찾는 방법이 있다면,

593
00:38:07,190 --> 00:38:10,940
그건 실제로 쉬운 문제일 것입니다.

594
00:38:10,940 --> 00:38:14,740
앞서 설명한 것과 같은 방식으로 할 수 있습니다.

595
00:38:14,740 --> 00:38:19,490
이미지의 경우, 지역 제안이 있다면,

596
00:38:19,490 --> 00:38:23,800
그 부분, 패치를 떼어내어 그

597
00:38:23,800 --> 00:38:29,620
패치에서 CNN, 즉 합성곱 신경망을 실행하고

598
00:38:29,620 --> 00:38:31,820
분류할 수 있습니다.

599
00:38:31,820 --> 00:38:33,460
그리고-- 심지어

600
00:38:33,460 --> 00:38:37,810
경계 상자를 정제할 수 있습니다.

601
00:38:37,810 --> 00:38:44,680
그래서 분류한 후, 물체가 감지되도록

602
00:38:44,680 --> 00:38:48,620
경계 상자를 정제합니다.

603
00:38:48,620 --> 00:38:51,610
상자를 분류하고 경계 상자를 정제할

604
00:38:51,610 --> 00:38:53,470
수 있습니다. 좌표를

605
00:38:53,470 --> 00:38:55,840
조금 변경해야 할 경우입니다.

606
00:38:55,840 --> 00:39:01,450
이것이 R-CNN 알고리즘이라고 불리는 것입니다.

607
00:39:01,450 --> 00:39:09,010
작동은 하지만, 다시 말해, 이것은 2014년까지의

608
00:39:09,010 --> 00:39:12,860
초기 알고리즘 중 하나입니다.

609
00:39:12,860 --> 00:39:17,120
이것들은 매우 느립니다. 왜냐하면 이러한 각 상자에 대해

610
00:39:17,120 --> 00:39:20,920
전체 합성곱 신경망을 실행하고 있기 때문입니다.

611
00:39:20,920 --> 00:39:26,500
하지만 한 가지 단점이 있습니다.

612
00:39:26,500 --> 00:39:34,780
각 상자에서 합성곱 신경망을 실행하는 대신,

613
00:39:34,780 --> 00:39:39,500
합성곱 연산이 공간 정보를

614
00:39:39,500 --> 00:39:41,710
보존하기 때문에.

615
00:39:41,710 --> 00:39:45,020
그들은 다운샘플링하거나 업샘플링합니다.

616
00:39:45,020 --> 00:39:50,230
우리는 항상 픽셀 공간에서 그들이 어디에 있는지 추적할 수 있는 방법이

617
00:39:50,230 --> 00:39:51,115
있습니다.

618
00:39:51,115 --> 00:39:56,380
그런 경우, 패치에서 합성곱 신경망을

619
00:39:56,380 --> 00:40:02,920
실행하는 대신, 전체 이미지에서 하나의

620
00:40:02,920 --> 00:40:06,680
큰 합성곱을 실행합니다.

621
00:40:06,680 --> 00:40:09,460
그리고 이제 우리는 전체 이미지에 해당하는

622
00:40:09,460 --> 00:40:11,900
특징 맵에서 그 지역을 갖게 됩니다.

623
00:40:11,900 --> 00:40:13,990
그 지역을 살펴봅시다.

624
00:40:13,990 --> 00:40:18,040
이제 그 위에 더 작은 CNN을

625
00:40:18,040 --> 00:40:24,490
실행하고 제가 원하는 두 출력에 대한 출력을

626
00:40:24,490 --> 00:40:25,370
생성하세요.

627
00:40:25,370 --> 00:40:27,580
먼저, 박스 오프셋입니다.

628
00:40:27,580 --> 00:40:30,010
바운딩 박스를 조금 이동해야 할까요?

629
00:40:30,010 --> 00:40:34,070
아니면 객체 카테고리는 무엇인가요?

630
00:40:34,070 --> 00:40:37,700
이것은 R-CNN의 빠른 버전입니다. 우리는

631
00:40:37,700 --> 00:40:40,600
객체, 그들의 바운딩 박스 등을

632
00:40:40,600 --> 00:40:44,570
감지하기 위해 합성곱 신경망을 사용할 수 있는 몇

633
00:40:44,570 --> 00:40:46,390
가지 기본 알고리즘입니다.

634
00:40:46,390 --> 00:40:49,480
질문은 제안된 영역의 수가 미리

635
00:40:49,480 --> 00:40:51,760
정의되어 있는가입니다.

636
00:40:51,760 --> 00:40:53,720
그에 대한 간단한 대답은 예입니다.

637
00:40:53,720 --> 00:40:57,360
저는 지역 제안 네트워크가 하는 일에 대해 간단히 이야기할 것입니다.

638
00:41:00,550 --> 00:41:03,260
그래서 쉬운 알고리즘입니다.

639
00:41:03,260 --> 00:41:07,360
하나는 제안된 영역의 바운딩 박스를 이미지 아래에

640
00:41:07,360 --> 00:41:08,530
놓습니다.

641
00:41:08,530 --> 00:41:12,650
하나는 ConvNet의 특징 맵에 놓습니다.

642
00:41:12,650 --> 00:41:16,460
그리고 이 두 가지 모두 출력 클래스

643
00:41:16,460 --> 00:41:21,160
레이블과 감지된 객체의 위치를 개선하는

644
00:41:21,160 --> 00:41:22,960
오프셋을 생성합니다.

645
00:41:22,960 --> 00:41:26,620
하지만 이는 먼저 바운딩 박스

646
00:41:26,620 --> 00:41:35,000
지역 제안을 수행해야 하며, 이미지에서 어디를 찾아야 하는지 알려주는

647
00:41:35,000 --> 00:41:37,720
지역 제안 네트워크가

648
00:41:37,720 --> 00:41:40,970
필요하다는 것을 의미합니다.

649
00:41:40,970 --> 00:41:46,480
그리고 지역 제안 네트워크(RPN)를 구축하는 연구가

650
00:41:46,480 --> 00:41:47,980
있었습니다.

651
00:41:47,980 --> 00:41:53,900
여기서 우리는 단순히 CNN으로 무작위로 시작합니다.

652
00:41:53,900 --> 00:41:59,200
우리는 이미지의 서로 다른 위치에서 무작위로 시작하려고

653
00:41:59,200 --> 00:42:00,130
합니다.

654
00:42:00,130 --> 00:42:03,250
그리고 합성곱 층을 통해, 우리는

655
00:42:03,250 --> 00:42:09,370
객체가 있을 확률이 높은 지역을 정제합니다. 왜냐하면

656
00:42:09,370 --> 00:42:12,190
우리는 객체 레이블과 위치를

657
00:42:12,190 --> 00:42:14,600
가지고 있기 때문입니다.

658
00:42:14,600 --> 00:42:17,210
그래서 우리는 이를 최적화할 수 있고, 감독할 수 있습니다.

659
00:42:17,210 --> 00:42:21,500
그리고 각 박스도 박스 좌표를 정제합니다.

660
00:42:21,500 --> 00:42:26,920
기본적으로 지역 제안

661
00:42:26,920 --> 00:42:32,770
네트워크가 하는 일은 높은 확률로

662
00:42:32,770 --> 00:42:36,010
객체가 있는

663
00:42:36,010 --> 00:42:42,160
각 박스를 정제하는 것입니다.

664
00:42:42,160 --> 00:42:43,340
박스 수정입니다.

665
00:42:43,340 --> 00:42:47,260
다시 말하지만, 좌표와 이러한 차원에 대한 모든 세부

666
00:42:47,260 --> 00:42:50,110
사항은 나중에 확인할 수 있도록

667
00:42:50,110 --> 00:42:52,930
남겨두겠습니다. 왜냐하면 너무 많은 시간이

668
00:42:52,930 --> 00:42:54,200
걸리기 때문입니다.

669
00:42:54,200 --> 00:42:57,140
그리고 우리는 이 알고리즘에 너무 많은 시간을 할애하고 싶지 않습니다.

670
00:42:57,140 --> 00:43:01,160
하지만 여기서 중요한 것은 질문으로

671
00:43:01,160 --> 00:43:05,560
돌아가서, 우리는 종종 객체가 있을

672
00:43:05,560 --> 00:43:08,380
확률이 가장 높은 상위 K를

673
00:43:08,380 --> 00:43:12,320
이 이미지의 제안으로 선택합니다.

674
00:43:12,320 --> 00:43:18,230
이것은 간단한 이미지이며 단 하나의 객체만 있습니다.

675
00:43:18,230 --> 00:43:21,730
그래서 대부분의 영역은 그 단일 객체를 중심으로

676
00:43:21,730 --> 00:43:23,480
형성되어 있습니다.

677
00:43:23,480 --> 00:43:25,280
하지만 일반적으로 그렇지 않습니다.

678
00:43:25,280 --> 00:43:29,590
따라서 많은 설정에서 우리는 서로 다른 설정에서

679
00:43:29,590 --> 00:43:33,640
사용되는 지역 제안이 있을 수 있습니다.

680
00:43:33,640 --> 00:43:37,870
우리는 더 높은 확률로 서로 다른 객체를 얻을 수 있습니다.

681
00:43:37,870 --> 00:43:42,040
그것과 함께, R-CNN과 마스크 R-CNN에

682
00:43:42,040 --> 00:43:46,970
대해 조금 이야기한 후, 다시 말하지만, 여러분에게는 세부

683
00:43:46,970 --> 00:43:49,940
사항을 살펴보는 것이 중요합니다.

684
00:43:49,940 --> 00:43:55,640
그리고 스스로 계산하는 데 시간을 할애할 수 있다면

685
00:43:55,640 --> 00:43:57,410
매우 좋습니다.

686
00:43:57,410 --> 00:44:01,110
하지만 이러한 유형의 알고리즘인 R-CNN, 마스크

687
00:44:01,110 --> 00:44:04,570
R-CNN은 현재 더 이상 사용되지 않습니다.

688
00:44:04,570 --> 00:44:07,300
왜냐하면 계산적으로 매우 무겁기 때문입니다.

689
00:44:07,300 --> 00:44:09,700
이 지점에 도달한 과정을

690
00:44:09,700 --> 00:44:11,960
이해하는 것이 중요합니다.

691
00:44:11,960 --> 00:44:15,860
하지만 그 이유는 여러 가지입니다.

692
00:44:15,860 --> 00:44:19,510
그 이유 중 하나는 두 개의 별도 네트워크가 필요하다는

693
00:44:19,510 --> 00:44:25,180
것입니다. 하나는 지역 제안 네트워크이고, 다른 하나는 분류 및 박스

694
00:44:25,180 --> 00:44:26,480
정제 네트워크입니다.

695
00:44:26,480 --> 00:44:32,176
그래서 각 이미지에서 객체를 감지하기 위해 최소 두

696
00:44:32,176 --> 00:44:35,080
번의 패스가 필요합니다.

697
00:44:35,080 --> 00:44:38,950
그래서 단일 단계 객체 탐지기,

698
00:44:38,950 --> 00:44:45,800
SSD를 사용한 후 발전이 있었습니다. 가장 인기 있는

699
00:44:45,800 --> 00:44:50,080
것 중 하나는 YOLO라고 불립니다.

700
00:44:50,080 --> 00:44:55,090
YOLO는 아마도 어떤 컴퓨터 비전 문제를 다루든, 오늘날까지도

701
00:44:55,090 --> 00:44:58,880
YOLO에 대해 들어본 적이 있을 것입니다.

702
00:44:58,880 --> 00:45:04,090
비록 오늘날에는 컨볼루션이 많은 네트워크이지만,

703
00:45:04,090 --> 00:45:07,450
적어도 초기 버전에서는 그렇습니다.

704
00:45:07,450 --> 00:45:10,520
많은 산업 응용 프로그램에서

705
00:45:10,520 --> 00:45:16,240
YOLO는 빠른 객체 탐지기이기 때문에 객체 탐지의

706
00:45:16,240 --> 00:45:19,220
기반으로 사용되고 있습니다.

707
00:45:19,220 --> 00:45:25,100
그리고 객체를 감지하는 데 매우 뛰어납니다.

708
00:45:25,100 --> 00:45:30,040
YOLO가 하는 일을 간단히 말씀드리고

709
00:45:30,040 --> 00:45:31,130
싶습니다.

710
00:45:31,130 --> 00:45:34,270
기본적으로 이미지를 한 번만 보고 한 번의 패스로

711
00:45:34,270 --> 00:45:35,150
처리합니다.

712
00:45:35,150 --> 00:45:38,750
모든 경계 상자를 생성합니다.

713
00:45:38,750 --> 00:45:48,640
그 방법은 이미지를 S x S 그리드로 나누는 것입니다. 이

714
00:45:48,640 --> 00:45:52,430
예에서는 7 x 7입니다.

715
00:45:52,430 --> 00:45:56,930
무슨 일이 일어나냐면, 그 그리드의

716
00:45:56,930 --> 00:46:02,260
각 상자에 대해, 객체가 그 위치에

717
00:46:02,260 --> 00:46:07,660
있을 확률과 경계 상자의 정제를 출력하는

718
00:46:07,660 --> 00:46:12,770
완전 컨볼루션 네트워크를 생성합니다.

719
00:46:12,770 --> 00:46:16,510
그래서 B 개의 경계 상자를 생성하고, 새로운

720
00:46:16,510 --> 00:46:20,740
하이퍼파라미터인 경계 B 상자를 생성하는데, 이는 그 상자에

721
00:46:20,740 --> 00:46:22,370
있는 객체의 정제입니다.

722
00:46:22,370 --> 00:46:27,640
또한 클래스 확률, 객체 클래스 확률도

723
00:46:27,640 --> 00:46:28,760
생성합니다.

724
00:46:28,760 --> 00:46:33,560
이 경우, 예를 들어 B가 2일 경우, 서로

725
00:46:33,560 --> 00:46:35,860
다른 확률을 가진 두 개의

726
00:46:35,860 --> 00:46:38,380
경계 상자를 생성합니다.

727
00:46:38,380 --> 00:46:43,580
모든 상자에 대해 동시에 이 작업을 수행합니다.

728
00:46:43,580 --> 00:46:45,910
기본적으로, 이 네트워크는

729
00:46:45,910 --> 00:46:49,900
이러한 각 경계 상자에 대한 출력을

730
00:46:49,900 --> 00:46:52,790
생성하는 동일한 네트워크입니다.

731
00:46:52,790 --> 00:46:59,662
그리고 객체에 대한 여러 가지 다른 옵션을

732
00:46:59,662 --> 00:47:00,950
생성합니다.

733
00:47:00,950 --> 00:47:03,490
그리고 말씀드린 것처럼, 각 상자는

734
00:47:03,490 --> 00:47:05,660
확률과 연결되어 있습니다.

735
00:47:05,660 --> 00:47:07,600
이 예에서는

736
00:47:07,600 --> 00:47:13,640
확률이 각 상자의 가장자리 가중치로 표시됩니다.

737
00:47:13,640 --> 00:47:17,470
이 많은 다양한 경계 상자와 객체 확률에

738
00:47:17,470 --> 00:47:21,050
대해 이제 임계값 처리를 할 수 있습니다.

739
00:47:21,050 --> 00:47:29,300
또한, 그들이 논문에서 사용하는 알고리즘이 있습니다.

740
00:47:29,300 --> 00:47:31,750
다시 말하지만, 세부

741
00:47:31,750 --> 00:47:37,570
사항에 들어가고 싶지 않습니다. 비최대 억제와 임계값 처리가

742
00:47:37,570 --> 00:47:41,800
포함된 일부 알고리즘이 가장 높은 확률을

743
00:47:41,800 --> 00:47:44,450
가진 것을 식별합니다.

744
00:47:44,450 --> 00:47:48,460
그래서 이것은 객체

745
00:47:48,460 --> 00:47:55,550
탐지의 간단한 구현 또는 사용입니다.

746
00:47:55,550 --> 00:47:58,930
다시 말하지만, 이것은 매우 유용한 것입니다.

747
00:47:58,930 --> 00:48:02,360
시간이 있다면, YOLO의 저장소와 함께 시간을 보내는 것이 좋습니다.

748
00:48:02,360 --> 00:48:05,800
의학, 로봇 공학 및 많은 산업

749
00:48:05,800 --> 00:48:10,730
응용 프로그램에서 사용되는 많은 새로운

750
00:48:10,730 --> 00:48:13,490
YOLO 버전이 있습니다.

751
00:48:13,490 --> 00:48:16,900
그래서 질문은, 이 두 번째 이미지를 어떻게 얻느냐는 것입니다.

752
00:48:16,900 --> 00:48:18,870
그리고 그 뒤에 있는 직관은 무엇인가요?

753
00:48:18,870 --> 00:48:20,680
말씀드린 것처럼, 각

754
00:48:20,680 --> 00:48:23,560
그리드에 대해 경계 상자를 생성합니다.

755
00:48:23,560 --> 00:48:27,310
이번에는 두 개를 생성했고, 다른 모든 경우에도

756
00:48:27,310 --> 00:48:28,900
두 개를 생성합니다.

757
00:48:28,900 --> 00:48:32,980
이 벌은 다시 확률 벡터이며, 각 상자는

758
00:48:32,980 --> 00:48:36,670
그 안에 객체가 존재할 확률과 연결되어

759
00:48:36,670 --> 00:48:37,970
있습니다.

760
00:48:37,970 --> 00:48:41,500
그리고 모든 패치를 위해 이들을 함께 모으면

761
00:48:41,500 --> 00:48:43,390
많은 상자가 생깁니다.

762
00:48:43,390 --> 00:48:47,300
이제 각 상자는 확률과 연결되어 있습니다.

763
00:48:51,654 --> 00:48:54,765
완벽합니다. 다음으로

764
00:48:55,630 --> 00:48:56,595
넘어갑시다.

765
00:49:00,340 --> 00:49:05,980
객체 탐지를 위한 최근 접근 방식 중

766
00:49:05,980 --> 00:49:09,500
하나는 탐지 변환기입니다.

767
00:49:09,500 --> 00:49:15,070
이는 순전히 변환기에 기반하며, 우리가 지난주에

768
00:49:15,070 --> 00:49:17,240
논의한 주제입니다.

769
00:49:17,240 --> 00:49:21,100
또한 오늘 시작한 것처럼, 같은

770
00:49:21,100 --> 00:49:25,390
유형의 자기 주의 및 교차 주의

771
00:49:25,390 --> 00:49:30,880
모듈이 객체 탐지 및 경계 상자를 생성할 수

772
00:49:30,880 --> 00:49:32,080
있습니다.

773
00:49:32,080 --> 00:49:33,920
이것은 어떻게 작동하나요?

774
00:49:33,920 --> 00:49:36,640
이 논문은 사실 그리 오래되지 않은

775
00:49:36,640 --> 00:49:39,230
2020년의 논문으로, 거의 5년 전입니다.

776
00:49:39,230 --> 00:49:41,930
비록 지금은 더 이상 사용되지 않습니다.

777
00:49:41,930 --> 00:49:45,430
실제 애플리케이션에서는 아무도 사용하지 않습니다.

778
00:49:45,430 --> 00:49:48,340
하지만 변환기를 객체 탐지에

779
00:49:48,340 --> 00:49:51,440
사용하는 좋은 예입니다.

780
00:49:51,440 --> 00:49:55,600
여기서 우리가 하는 일은 기본적으로 이전에 설명한

781
00:49:55,600 --> 00:49:57,260
것과 유사합니다.

782
00:49:57,260 --> 00:50:01,280
이미지를 패치로 변환할 수 있습니다.

783
00:50:01,280 --> 00:50:04,480
그런 다음 이 패치들은 CNN을

784
00:50:04,480 --> 00:50:06,530
통과하여 토큰을 생성합니다.

785
00:50:06,530 --> 00:50:09,490
그 후, 패치에 설명한 것과 같은

786
00:50:09,490 --> 00:50:12,710
방식으로 위치 인코딩을 추가합니다.

787
00:50:12,710 --> 00:50:17,260
이것들이 입력에 대한 토큰을 정의하며,

788
00:50:17,260 --> 00:50:22,250
이는 변환기 인코더의 입력입니다. 변환기

789
00:50:22,250 --> 00:50:25,570
인코더는 다시 자기 주의 레이어

790
00:50:25,570 --> 00:50:28,040
정규화 또는 기타 정규화와

791
00:50:28,040 --> 00:50:31,720
MLP 레이어로 구성되어 있으며,

792
00:50:31,720 --> 00:50:38,860
여러 레이어의 변환기 인코더 후에 출력 토큰을 생성합니다.

793
00:50:38,860 --> 00:50:42,950
그런 다음 경계 상자를 생성하기 위해,

794
00:50:42,950 --> 00:50:45,220
이 알고리즘의 스마트한

795
00:50:45,220 --> 00:50:49,900
부분은 인코더 출력 토큰을 변환기 디코더의

796
00:50:49,900 --> 00:50:52,640
입력으로 사용하지만,

797
00:50:52,640 --> 00:50:57,250
우리는 또한 쿼리를 정의합니다. 이 쿼리는

798
00:50:57,250 --> 00:50:59,800
스스로 학습 가능한 매개변수로,

799
00:50:59,800 --> 00:51:05,830
예를 들어 쿼리로 5개를 추가하면, 10개 또는

800
00:51:05,830 --> 00:51:08,900
20개의 쿼리를 입력으로 추가하면,

801
00:51:08,900 --> 00:51:14,840
이미지에서 최대 20개의 객체를 탐지하려고 합니다.

802
00:51:14,840 --> 00:51:17,500
그리고 다시, 이

803
00:51:17,500 --> 00:51:24,230
변환기 디코더의 시작 부분에서 자기 주의

804
00:51:24,230 --> 00:51:30,860
레이어와 인코더 출력과의 교차 주의의

805
00:51:30,860 --> 00:51:32,780
조합을 통해.

806
00:51:32,780 --> 00:51:39,235
따라서 교차 주의 및 자기 주의 네트워크 레이어가 각

807
00:51:39,235 --> 00:51:44,600
쿼리에 대한 출력 값을 생성하며, 이는

808
00:51:44,600 --> 00:51:48,980
FNN, 피드 포워드 네트워크를 통해

809
00:51:48,980 --> 00:51:56,670
전달되어 클래스 레이블과 경계 상자를 생성합니다. 이는 우리가

810
00:51:56,670 --> 00:52:01,760
이전에 논의한 것과 매우 유사하며, 경우에

811
00:52:01,760 --> 00:52:05,150
따라 탐지할 객체가 없다고

812
00:52:05,150 --> 00:52:07,495
말하기도 합니다.

813
00:52:07,495 --> 00:52:10,640
마지막으로, 우리는 경계 상자와

814
00:52:10,640 --> 00:52:16,190
경계 상자와 연결된 클래스가 출력으로 있습니다.

815
00:52:16,190 --> 00:52:19,428
질문은, 모든 가능한 상자를 변환기에 입력하고

816
00:52:19,428 --> 00:52:20,220
있나요?

817
00:52:20,220 --> 00:52:20,930
아니요.

818
00:52:20,930 --> 00:52:23,500
여기 입력은 삼각형

819
00:52:23,500 --> 00:52:30,370
매개변수로, 이는 실제로 이 입력 쿼리의 자리에

820
00:52:30,370 --> 00:52:34,345
객체가 존재하길 원하는 질문을

821
00:52:34,345 --> 00:52:37,280
하는 쿼리입니다.

822
00:52:37,280 --> 00:52:40,840
따라서 입력으로 상자나 다른 것은 없습니다.

823
00:52:40,840 --> 00:52:43,480
이는 클래스 레이블과 상자

824
00:52:43,480 --> 00:52:46,780
좌표를 생성하는 출력의 일부입니다.

825
00:52:46,780 --> 00:52:51,520
질문은, 쿼리가 우리가 찾고자 하는 것과

826
00:52:51,520 --> 00:52:56,740
이미지에서 어디에 있는지를 실제로 나타내는 방식으로

827
00:52:56,740 --> 00:52:58,480
형성되었는가입니다.

828
00:52:58,480 --> 00:53:02,410
이 경우, 우리가 찾고 있는 것은 미리

829
00:53:02,410 --> 00:53:06,670
정의된 클래스 레이블로 정의되며, 이는

830
00:53:06,670 --> 00:53:08,810
출력의 일부입니다.

831
00:53:08,810 --> 00:53:10,970
따라서 우리의 감독은 클래스 레이블을 기반으로 합니다.

832
00:53:10,970 --> 00:53:13,140
우리는 클래스 확률 벡터를 가지고 있습니다.

833
00:53:13,140 --> 00:53:15,920
다른 알고리즘에 대해 정의한 것과 같은 방식입니다.

834
00:53:15,920 --> 00:53:20,650
그래서 알고리즘이 어떤 종류의 클래스를 찾아야 하는지 아는

835
00:53:20,650 --> 00:53:21,650
방법입니다.

836
00:53:21,650 --> 00:53:25,390
그리고 출력 측면에서, 다시

837
00:53:25,390 --> 00:53:28,310
말해 이 출력은 감독됩니다.

838
00:53:28,310 --> 00:53:31,090
L2 노름, 즉 실제 박스의

839
00:53:31,090 --> 00:53:35,110
L2 손실을 기반으로 기억하신다면.

840
00:53:35,110 --> 00:53:41,500
쿼리 부분에서 어떤 객체를 어떻게 또는 어디서 찾아야

841
00:53:41,500 --> 00:53:45,740
할지 아무것도 지시하지 않습니다.

842
00:53:45,740 --> 00:53:49,450
훈련, 즉 과정 자체는 역전파입니다.

843
00:53:49,450 --> 00:53:52,310
손실이나 오류가 있으면

844
00:53:52,310 --> 00:53:55,640
출력을 역전파합니다.

845
00:53:55,640 --> 00:54:00,340
기본적으로 우리는 처음이나 이 부분에서

846
00:54:00,340 --> 00:54:02,920
아무것도 결정하지 않습니다.

847
00:54:02,920 --> 00:54:09,040
질문은 쿼리가 최대 아홉 개의 객체를 요청하는 것이었습니다.

848
00:54:09,040 --> 00:54:14,510
네, 기본적으로 그 의미입니다.

849
00:54:14,510 --> 00:54:19,010
자기 주의와 교차 주의를 통해 출력

850
00:54:19,010 --> 00:54:22,600
토큰을 생성하려고 하며, 이는 그

851
00:54:22,600 --> 00:54:25,960
FNN 작업을 통해 클래스

852
00:54:25,960 --> 00:54:29,380
및 박스 좌표로 변환됩니다.

853
00:54:29,380 --> 00:54:33,640
당신의 질문은 쿼리가 저기 있다면, 그것들이 이미지

854
00:54:33,640 --> 00:54:35,900
패치인지 아닌지입니다.

855
00:54:35,900 --> 00:54:38,480
아니요, 그것들은 이미지 패치가 아닙니다.

856
00:54:38,480 --> 00:54:44,270
그것들은 학습 가능한 매개변수에 대한 쿼리입니다.

857
00:54:44,270 --> 00:54:47,200
출력을 생성하기 위해 그것들을 넣습니다.

858
00:54:47,200 --> 00:54:51,850
각 입력에 대해 출력으로서 값을 얻습니다.

859
00:54:51,850 --> 00:54:55,810
그 값은 클래스 및 박스 좌표로 변환됩니다.

860
00:54:55,810 --> 00:54:58,130
다시 질문은 객체 쿼리가 무엇인지입니다.

861
00:54:58,130 --> 00:55:00,980
그것들은 학습 가능한 매개변수입니다.

862
00:55:00,980 --> 00:55:02,980
그래서 그것들을 초기화합니다.

863
00:55:02,980 --> 00:55:06,550
네트워크가 그에 대한 최적의 값을 찾습니다.

864
00:55:06,550 --> 00:55:09,010
그리고 그것이 출력으로 얻는 것입니다.

865
00:55:09,010 --> 00:55:12,040
질문은 어떤 직관이 있는지, 어떤

866
00:55:12,040 --> 00:55:14,710
FNN이 어떤 박스를 얻는지입니다.

867
00:55:14,710 --> 00:55:19,720
짧은 대답은, 아니요, 네트워크가

868
00:55:19,720 --> 00:55:22,280
여러 개를

869
00:55:22,280 --> 00:55:24,940
생성하는 것을

870
00:55:24,940 --> 00:55:28,430
막는 것은 없습니다.

871
00:55:28,430 --> 00:55:32,320
하지만 그곳에 많은 자기 주의 및

872
00:55:32,320 --> 00:55:34,930
교차 주의 레이어가

873
00:55:34,930 --> 00:55:38,875
있어 서로 상호작용하며 각 쿼리가

874
00:55:38,875 --> 00:55:41,380
출력 레이어 중 하나와

875
00:55:41,380 --> 00:55:43,730
일치하게 만듭니다.

876
00:55:43,730 --> 00:55:46,880
그래서 출력과 정확히 같은 것을 생성하는 것은 아닙니다.

877
00:55:46,880 --> 00:55:52,930
그리고 우리는 이러한 FNN을 감독하는 것에 대한 제어도 가지고 있습니다.

878
00:55:52,930 --> 00:55:57,580
그래서 당신의 질문은 훈련의 일환으로 이미지 분할,

879
00:55:57,580 --> 00:56:00,490
픽셀 수준 분할이 있는지입니다.

880
00:56:00,490 --> 00:56:08,040
이 알고리즘은 픽셀 수준 분할을 요구하지 않습니다.

881
00:56:08,040 --> 00:56:11,930
클래스 레이블과 경계 상자에 기반하여 감독됩니다.

882
00:56:11,930 --> 00:56:15,410
하지만 픽셀 수준 분할이 있다면, 항상

883
00:56:15,410 --> 00:56:17,560
픽셀 수준 분할을 경계

884
00:56:17,560 --> 00:56:20,980
상자로 변환하여 이 알고리즘을 훈련할 수

885
00:56:20,980 --> 00:56:24,130
있지만, 반드시 필요하지는 않습니다.

886
00:56:24,130 --> 00:56:26,860
그래서 질문은 보지 못한

887
00:56:26,860 --> 00:56:29,890
객체를 일반화할 수 있는지입니다.

888
00:56:29,890 --> 00:56:32,545
보지 못한 객체란 새로운 클래스 레이블을 의미합니까?

889
00:56:32,545 --> 00:56:34,360
네.

890
00:56:34,360 --> 00:56:39,170
이러한 알고리즘은 완전히 감독되기 때문에, 클래스 확률

891
00:56:39,170 --> 00:56:41,320
벡터를 생성하고 있기 때문에

892
00:56:41,320 --> 00:56:43,040
방법이 없습니다.

893
00:56:43,040 --> 00:56:45,100
다른 클래스가 있다는

894
00:56:45,100 --> 00:56:52,225
것을 미리 알지 못하면 새로운 클래스에 대해 끝에 무언가를 추가할

895
00:56:52,225 --> 00:56:53,810
수 없습니다.

896
00:56:53,810 --> 00:56:58,010
그래서 완전히 감독된 네트워크에서는 종종 새로운 객체가 없습니다.

897
00:56:58,010 --> 00:57:00,320
배경 객체가 있거나 객체가 없을 수 있습니다.

898
00:57:00,320 --> 00:57:03,080
보시다시피, 우리는 객체가 없다는 레이블을 가지고 있습니다.

899
00:57:03,080 --> 00:57:07,030
하지만 제로샷 학습에 사용되는 이러한 유형의

900
00:57:07,030 --> 00:57:08,620
알고리즘과 혼합 확장

901
00:57:08,620 --> 00:57:10,930
알고리즘이 많이 있습니다.

902
00:57:10,930 --> 00:57:13,990
제로샷은 훈련 데이터에 예제가 없이 새로운

903
00:57:13,990 --> 00:57:16,940
것을 찾는 것을 이해하는 것을 의미합니다.

904
00:57:16,940 --> 00:57:19,640
하지만 이 주제를 넘어섭니다.

905
00:57:19,640 --> 00:57:25,150
장면에 쿼리로 넣은 것보다 더 많은 객체가

906
00:57:25,150 --> 00:57:27,910
있으면 어떻게 됩니까?

907
00:57:27,910 --> 00:57:29,900
그래서 좋은 질문입니다.

908
00:57:29,900 --> 00:57:34,300
종종 객체에 대한 신뢰도가 가장 높은 것을 생성하므로,

909
00:57:34,300 --> 00:57:36,490
신뢰도가 가장 높은

910
00:57:36,490 --> 00:57:38,030
바운딩 박스입니다.

911
00:57:38,030 --> 00:57:40,240
그런 경우에는 더 많은 객체를

912
00:57:40,240 --> 00:57:44,220
얻기 위해 더 많은 쿼리를 추가하고 싶습니다.

913
00:57:47,050 --> 00:57:48,580
수업 후에 질문이

914
00:57:48,580 --> 00:57:50,840
있으면 여기에서 답변하겠습니다.

915
00:57:50,840 --> 00:57:54,890
하지만 다루어야 할 다른 주제가 많고, 그것들을

916
00:57:54,890 --> 00:57:57,080
꼭 살펴보고 싶습니다.

917
00:57:57,080 --> 00:58:01,250
최소한 주제에 익숙해지도록 하세요.

918
00:58:01,250 --> 00:58:04,750
그래서 객체 감지와 관련하여, 이전에

919
00:58:04,750 --> 00:58:07,250
질문받았던 것에 다시 돌아가면,

920
00:58:07,250 --> 00:58:10,240
이러한 유형의 알고리즘을 인스턴스

921
00:58:10,240 --> 00:58:13,130
분할에 어떻게 사용할 수 있을까요?

922
00:58:13,130 --> 00:58:15,140
사실 그렇게 어렵지 않습니다.

923
00:58:15,140 --> 00:58:18,640
이미지에서 CNN을 실행하는 R-CNN

924
00:58:18,640 --> 00:58:24,440
알고리즘에 대해 이야기했을 때 이 이야기를 했습니다.

925
00:58:24,440 --> 00:58:27,430
그런 다음 바운딩 박스를 제공하는 지역

926
00:58:27,430 --> 00:58:29,450
제안 네트워크가 있습니다.

927
00:58:29,450 --> 00:58:35,560
그리고 그 바운딩 박스는 클래스 레이블과 바운딩

928
00:58:35,560 --> 00:58:38,750
박스 수정으로 변환됩니다.

929
00:58:38,750 --> 00:58:43,970
그래서 지금까지 R-CNN에 대해 이야기한 내용입니다.

930
00:58:43,970 --> 00:58:46,840
이제 이것을 마스크 R-CNN으로

931
00:58:46,840 --> 00:58:49,960
변환하여 마스크도 생성할 수 있습니다.

932
00:58:49,960 --> 00:58:54,680
기본적으로, 우리가 이전에 이야기했던 것과 같은 아키텍처입니다.

933
00:58:54,680 --> 00:59:01,450
이제 하나의 출력을 더 추가하여 다중 작업으로 만들고 마스크

934
00:59:01,450 --> 00:59:04,700
예측을 생성할 수 있습니다.

935
00:59:04,700 --> 00:59:07,570
우리가 이전에 하던 것은 다시

936
00:59:07,570 --> 00:59:12,880
말해, 이미지, 지역 제안, CNN이 클래스 레이블과

937
00:59:12,880 --> 00:59:14,840
박스 좌표를 제공합니다.

938
00:59:14,840 --> 00:59:18,910
이제 우리는 해당 객체에 대한

939
00:59:18,910 --> 00:59:26,360
마스크를 픽셀 수준에서 생성하는 또 다른 합성곱 층을 추가합니다.

940
00:59:26,360 --> 00:59:28,990
그리고 그 마스크는 다시 입력

941
00:59:28,990 --> 00:59:35,450
및 이미지와 같은 크기일 수 있으며, 기본적으로 레이어 자체에서입니다.

942
00:59:35,450 --> 00:59:37,580
완전 합성곱 신경망을 사용하면,

943
00:59:37,580 --> 00:59:40,000
우리가 종종 출력으로 얻는 것입니다.

944
00:59:40,000 --> 00:59:44,390
각 객체에 대해 그 작은 박스가 있을 때, 우리는 항상

945
00:59:44,390 --> 00:59:47,630
그에 대한 마스크를 얻을 수 있습니다.

946
00:59:47,630 --> 00:59:52,430
상자 자체의 다양한 설정에서 의자,

947
00:59:52,430 --> 00:59:58,460
다른 상자가 있는 경우 침대와 인간,

948
00:59:58,460 --> 01:00:00,740
이미지의 아기.

949
01:00:00,740 --> 01:00:04,700
그리고 이것은 우리가 마스크 R-CNN이라고 부르는

950
01:00:04,700 --> 01:00:07,420
R-CNN 알고리즘의 확장입니다.

951
01:00:07,420 --> 01:00:14,380
마스크 R-CNN을 사용하면 알고리즘을 훈련할 수 있는 다양한

952
01:00:14,380 --> 01:00:21,850
객체, 즉 서로 다른 알려진 객체를 탐지하는 데 매우 좋은 결과를

953
01:00:21,850 --> 01:00:23,780
얻을 수 있습니다.

954
01:00:23,780 --> 01:00:29,920
그리고 탐색할 수 있는 많은 API와 오픈

955
01:00:29,920 --> 01:00:34,670
소스 객체 탐지기 버전이 있습니다.

956
01:00:34,670 --> 01:00:37,460
여기 몇 가지 링크와

957
01:00:37,460 --> 01:00:40,870
리소스가 있지만, 이것은 우리가

958
01:00:40,870 --> 01:00:45,727
다루고자 했던 작업들을 요약하고 정리한 것입니다.

959
01:00:45,727 --> 01:00:47,560
이 작업들을 이해하는 것이

960
01:00:47,560 --> 01:00:49,190
여러분에게 매우 중요합니다.

961
01:00:49,190 --> 01:00:52,400
이들은 핵심 컴퓨터 비전 작업이었습니다.

962
01:00:52,400 --> 01:00:56,570
요즘 컴퓨터 비전은 훨씬 더 발전했습니다.

963
01:00:56,570 --> 01:00:59,270
이 작업들에 국한되지 않습니다.

964
01:00:59,270 --> 01:01:03,430
하지만 산업 응용 프로그램이 있다면, 예를

965
01:01:03,430 --> 01:01:09,310
들어 산업 파이프라인에서 썩은 토마토와 좋은 토마토를 분리하는

966
01:01:09,310 --> 01:01:12,380
품질 관리 같은 경우입니다.

967
01:01:12,380 --> 01:01:14,050
그렇다면 컴퓨터 비전을

968
01:01:14,050 --> 01:01:15,880
통해 객체를 탐지하고

969
01:01:15,880 --> 01:01:19,780
이를 좋거나 나쁜 것으로 분류할 수 있어야 합니다.

970
01:01:19,780 --> 01:01:22,540
그래서 이러한 단계와 파이프라인을 이해하고

971
01:01:22,540 --> 01:01:26,510
실시간으로 수행하는 방법을 아는 것이 여전히 중요합니다.

972
01:01:26,510 --> 01:01:29,170
하지만 이제 여러분이 모두 익숙한

973
01:01:29,170 --> 01:01:31,660
대규모 모델이 있습니다.

974
01:01:31,660 --> 01:01:36,340
이것은 제가 이야기하고 싶었던 첫 번째 부분, 컴퓨터 비전 작업을

975
01:01:36,340 --> 01:01:37,610
요약한 것입니다.

976
01:01:37,610 --> 01:01:40,480
마지막으로 10분 정도

977
01:01:40,480 --> 01:01:46,330
할애하고 싶은 부분은 시각화와 이해에 관한 것입니다.

978
01:01:46,330 --> 01:01:50,320
다시 말해, 이것은 그 자체로 큰 강의였습니다.

979
01:01:50,320 --> 01:01:57,040
2050년, 60년대, 2020년대까지 컴퓨터 주제, 심지어

980
01:01:57,040 --> 01:02:01,810
2014년, 2013년 이전부터 신경망 시각화

981
01:02:01,810 --> 01:02:06,755
주제가 매우 뜨거웠고, 네트워크가 학습하는

982
01:02:09,840 --> 01:02:12,560
내용을 이해하는 데 큰 도움이

983
01:02:12,560 --> 01:02:14,040
되었습니다.

984
01:02:14,040 --> 01:02:16,500
여기서 여러분의 응용

985
01:02:16,500 --> 01:02:20,285
프로그램에서 필요할 수 있는 가장 중요한

986
01:02:20,285 --> 01:02:22,470
것들을 요약하겠습니다.

987
01:02:22,470 --> 01:02:26,660
하지만 그 전에 우리가 이야기했던 선형

988
01:02:26,660 --> 01:02:28,760
분류기로 돌아가겠습니다.

989
01:02:28,760 --> 01:02:33,240
우리는 선형 분류기에 꽤 많은 시간을 보냈습니다.

990
01:02:33,240 --> 01:02:37,710
선형 분류기와 함께, 우리는 결국 선형 함수에서

991
01:02:37,710 --> 01:02:43,100
네트워크가 학습하는 내용을 보면 각 클래스에 대한

992
01:02:43,100 --> 01:02:46,472
템플릿을 가질 수 있다고 말했습니다.

993
01:02:46,472 --> 01:02:47,930
예를 들어, 이 자동차의

994
01:02:47,930 --> 01:02:52,310
경우 항상 정면을 향한 자동차를 템플릿으로 볼 수 있습니다.

995
01:02:52,310 --> 01:02:55,100
신경망에서도 같은 작업을 할 수 있습니다.

996
01:02:55,100 --> 01:02:57,630
필터 중 하나를 시각화하면,

997
01:02:57,630 --> 01:03:01,740
여기서 우리는 선형 함수의 가중치를 시각화합니다.

998
01:03:01,740 --> 01:03:03,300
그것은 시각적 관점이었습니다.

999
01:03:03,300 --> 01:03:06,140
신경망의 필터를

1000
01:03:06,140 --> 01:03:11,700
시각화하는 것과 같은 작업을 할 수 있습니다.

1001
01:03:11,700 --> 01:03:15,080
각 필터에 대해

1002
01:03:15,080 --> 01:03:20,510
네트워크는 기본적으로 기본 형태,

1003
01:03:20,510 --> 01:03:25,980
방향 또는 간단한 형태를 학습하고

1004
01:03:25,980 --> 01:03:28,040
있습니다.

1005
01:03:28,040 --> 01:03:32,720
이 시각화는 채널 수가 적은 레이어에 대해서만 수행할

1006
01:03:32,720 --> 01:03:33,950
수 있습니다.

1007
01:03:33,950 --> 01:03:36,150
예를 들어, 세 개의 채널이 있다면

1008
01:03:36,150 --> 01:03:39,330
RGB 이미지로 배치하고 시각화할 수 있습니다.

1009
01:03:39,330 --> 01:03:42,690
하지만 기억하듯이, CNN에서는 그렇지 않았습니다.

1010
01:03:42,690 --> 01:03:50,420
CNN에서는 중간 레이어에 때때로 꽤 많은 채널이 있었기 때문에, 우리가 볼

1011
01:03:50,420 --> 01:03:53,660
수 있는 것으로 시각화하기가

1012
01:03:53,660 --> 01:03:55,050
쉽지 않았습니다.

1013
01:03:55,050 --> 01:03:57,770
하지만 기본적으로 여러분이 보는 것입니다.

1014
01:03:57,770 --> 01:04:00,570
채널 수가 적은 초기 레이어에서는 이를 시각화하고

1015
01:04:00,570 --> 01:04:03,590
네트워크가 실제로 어떤 패턴을 학습하고 있는지

1016
01:04:03,590 --> 01:04:04,800
볼 수 있습니다.

1017
01:04:04,800 --> 01:04:06,920
그래서 패턴 학습을 시작합니다.

1018
01:04:06,920 --> 01:04:14,960
그리고 나중 단계에서는 더 전체적이고 큰 패턴을 가지게 되며,

1019
01:04:14,960 --> 01:04:21,200
우리가 '유도 역전파'라고 부르는 것을

1020
01:04:21,200 --> 01:04:26,130
실행하면 이러한 것들을 시각화할 수 있지만,

1021
01:04:26,130 --> 01:04:30,560
이처럼 간단하지는 않습니다.

1022
01:04:30,560 --> 01:04:34,310
신경망을 이해하고 시각화하는 몇

1023
01:04:34,310 --> 01:04:39,350
가지 방법을 강조하고 싶습니다. 이는 실제로

1024
01:04:39,350 --> 01:04:41,190
중요합니다.

1025
01:04:41,190 --> 01:04:47,060
하나의 개념은 주목도입니다.

1026
01:04:47,060 --> 01:04:50,330
많은 응용 프로그램에서 어떤 픽셀이

1027
01:04:50,330 --> 01:04:53,070
중요한지 아는 것이 매우 중요합니다.

1028
01:04:53,070 --> 01:04:55,200
예를 들어, 의료 응용

1029
01:04:55,200 --> 01:04:58,890
프로그램에서 종양과 비종양을 분류할 때,

1030
01:04:58,890 --> 01:05:01,550
이미지의 어떤 부분이 실제로

1031
01:05:01,550 --> 01:05:03,540
종양인지 보고 싶습니다.

1032
01:05:03,540 --> 01:05:05,850
왜냐하면 이를 자동화하고 싶다면, 종양이

1033
01:05:05,850 --> 01:05:09,090
있는지 없는지 아는 것은 아무도 신경 쓰지 않기 때문입니다.

1034
01:05:09,090 --> 01:05:12,500
모두가 이미지에서 종양이 어디에 있는지에 관심이 있습니다.

1035
01:05:12,500 --> 01:05:17,210
그래서 이를 위해 가장 간단한 응용 프로그램은

1036
01:05:17,210 --> 01:05:21,890
네트워크를 훈련시키는 것입니다. 피드포워드 신경망이

1037
01:05:21,890 --> 01:05:26,040
값을 생성하거나 클래스 레이블을 생성합니다.

1038
01:05:26,040 --> 01:05:31,940
하지만 우리가 할 수 있는 것은, 사실 제가 그걸

1039
01:05:31,940 --> 01:05:35,670
보여주기 전에, 이 경우 이 네트워크를

1040
01:05:35,670 --> 01:05:38,450
훈련시키기 위해 우리가

1041
01:05:38,450 --> 01:05:45,660
한 것은 항상 신경망의 도함수, 즉 손실 또는 클래스 점수의

1042
01:05:45,660 --> 01:05:50,000
가중치에 대한 도함수를 취하여 가중치를

1043
01:05:50,000 --> 01:05:53,204
업데이트하는 것이었습니다.

1044
01:05:53,204 --> 01:05:56,340
이제 제가 필요한 것은 각

1045
01:05:56,340 --> 01:06:03,380
픽셀에 대해 픽셀 값을 변경하면 개 점수에 얼마나 영향을

1046
01:06:03,380 --> 01:06:06,740
미치는지 보고 싶습니다.

1047
01:06:06,740 --> 01:06:07,830
이게 무슨 뜻인가요?

1048
01:06:07,830 --> 01:06:12,950
제가 설명한 것은 변동의 의미입니다.

1049
01:06:12,950 --> 01:06:19,080
즉, 기본적으로 기울기의 의미입니다.

1050
01:06:19,080 --> 01:06:23,000
그래서 이제 네트워크 가중치가 아니라

1051
01:06:23,000 --> 01:06:26,000
픽셀 값에 대한 점수의 기울기를

1052
01:06:26,000 --> 01:06:30,680
취하면, 그 기울기를 시각화할 수 있습니다.

1053
01:06:30,680 --> 01:06:33,650
그리고 그 기울기를 시각화한다는 것은 이

1054
01:06:33,650 --> 01:06:36,000
픽셀들이 중요하다는 것을 의미합니다.

1055
01:06:36,000 --> 01:06:40,020
이 이미지에서 개를 분류하기 위해서는 이

1056
01:06:40,020 --> 01:06:41,700
픽셀들이 중요합니다.

1057
01:06:41,700 --> 01:06:44,840
그래서 이 픽셀들의 값을

1058
01:06:44,840 --> 01:06:48,590
변경하면 개 점수가 변경됩니다.

1059
01:06:48,590 --> 01:06:52,280
다시 말해, 이것이 우리가 이야기한 기울기의

1060
01:06:52,280 --> 01:06:53,970
기본 의미와 정의입니다.

1061
01:06:53,970 --> 01:06:56,160
그래서 이것이 하나의 방법입니다.

1062
01:06:56,160 --> 01:06:59,630
이것을 네트워크에서 훈련한

1063
01:06:59,630 --> 01:07:02,700
다양한 객체에

1064
01:07:02,700 --> 01:07:07,220
대해 실행하면, 이렇게 됩니다.

1065
01:07:07,220 --> 01:07:12,080
그래서 이것이 주목도를 이해하는 한 가지 방법입니다.

1066
01:07:12,080 --> 01:07:14,790
그리고 많은 경우에 매우 효과적입니다.

1067
01:07:14,790 --> 01:07:19,790
하지만 때때로 픽셀 값만으로는

1068
01:07:19,790 --> 01:07:21,810
충분하지 않습니다.

1069
01:07:21,810 --> 01:07:25,640
각 클래스에 대해 활성화가 어떻게

1070
01:07:25,640 --> 01:07:28,770
작용하는지 보고 싶습니다.

1071
01:07:28,770 --> 01:07:32,330
이것이 클래스 활성화 맵 또는 CAM

1072
01:07:32,330 --> 01:07:37,010
알고리즘, 클래스 활성화 매핑, CAM 또는

1073
01:07:37,010 --> 01:07:40,760
Grad-CAM으로 이어지며, 이는 CNN을

1074
01:07:40,760 --> 01:07:44,900
이해하는 데 가장 널리 사용되는 알고리즘

1075
01:07:44,900 --> 01:07:47,430
중 하나이며, 다른

1076
01:07:47,430 --> 01:07:49,950
아키텍처에도 사용할 수 있습니다.

1077
01:07:49,950 --> 01:07:53,360
하지만 변환기에서는 이를 이해하는 훨씬

1078
01:07:53,360 --> 01:07:56,900
더 나은 방법이 있으며, 이는 지난

1079
01:07:56,900 --> 01:07:59,090
강의에서 이야기했습니다.

1080
01:07:59,090 --> 01:08:04,100
무슨 일이 일어나는지는 각 합성곱 층에 대해 우리는 종종

1081
01:08:04,100 --> 01:08:06,200
풀링을 수행한다는 것입니다.

1082
01:08:06,200 --> 01:08:08,220
그리고 풀링은 특징 맵을 생성합니다.

1083
01:08:08,220 --> 01:08:11,400
그 특징 맵은 점수로 변환됩니다.

1084
01:08:11,400 --> 01:08:20,134
그리고 그 점수는 가중치의 값과 함께 사용됩니다.

1085
01:08:20,134 --> 01:08:24,950
수학을 확장하면, 기본적으로 우리는 클래스

1086
01:08:24,950 --> 01:08:29,430
점수를 가중 합 형태로 강조할 수 있습니다.

1087
01:08:29,430 --> 01:08:35,359
그리고 이는 클래스 예측을 특징 맵으로 거슬러 올라가 특정

1088
01:08:35,359 --> 01:08:39,500
공간의 위치까지 추적할 수 있음을

1089
01:08:39,500 --> 01:08:42,060
의미합니다. 왜냐하면 합성곱

1090
01:08:42,060 --> 01:08:44,630
층은 항상 이미지 공간의

1091
01:08:44,630 --> 01:08:47,379
공간에 매핑되기 때문입니다.

1092
01:08:47,379 --> 01:08:52,850
우리는 모든 작업에서 공간적 일관성이 이미지 공간까지 추적하는

1093
01:08:52,850 --> 01:08:55,729
데 도움이 될 수 있기 때문에

1094
01:08:55,729 --> 01:08:58,140
컨볼루션을 수행합니다.

1095
01:08:58,140 --> 01:09:02,180
어쨌든, 우리는 피처 맵을 보고 각

1096
01:09:02,180 --> 01:09:04,890
클래스의 활성화가 이미지의

1097
01:09:04,890 --> 01:09:06,859
해당 위치에 실제로

1098
01:09:06,859 --> 01:09:11,040
어떻게 영향을 미치는지 볼 수 있습니다.

1099
01:09:11,040 --> 01:09:16,880
그리고 이제, 피처 값 위에 우리가 학습한

1100
01:09:16,880 --> 01:09:21,470
가중치와의 곱셈을 수행하면

1101
01:09:21,470 --> 01:09:26,160
일부 클래스 활성화를 생성합니다.

1102
01:09:26,160 --> 01:09:31,100
이는 내가 이미지 공간으로 돌아갈 수 있는 방법이

1103
01:09:31,100 --> 01:09:33,810
있다는 것을 의미합니다.

1104
01:09:33,810 --> 01:09:36,080
왜냐하면 내가

1105
01:09:36,080 --> 01:09:41,060
컨볼루션 공간에 있는 한, 이미지로 돌아가서 각

1106
01:09:41,060 --> 01:09:46,850
클래스인 궁전, 돔, 교회, 제단, 수도원에 대한 서로

1107
01:09:46,850 --> 01:09:52,529
다른 클래스 활성화 맵을 생성할 수 있기 때문입니다.

1108
01:09:52,529 --> 01:09:54,270
이것들이 가중치입니다.

1109
01:09:54,270 --> 01:09:57,380
이것들은 특정 클래스의

1110
01:09:57,380 --> 01:10:01,220
점수를 유도한 컨볼루션

1111
01:10:01,220 --> 01:10:06,260
레이어의 픽셀 또는 영역입니다.

1112
01:10:06,260 --> 01:10:09,920
다른 것들, 즉 서로 다른 이미지에서 단일

1113
01:10:09,920 --> 01:10:14,000
객체에 대한 클래스 활성화 맵도 마찬가지입니다.

1114
01:10:14,000 --> 01:10:15,780
하지만 여기에는 문제가 있습니다.

1115
01:10:15,780 --> 01:10:18,050
그 문제는 우리가 마지막 컨볼루션

1116
01:10:18,050 --> 01:10:21,090
레이어에만 이를 적용할 수 있다는 것입니다. 이것이

1117
01:10:21,090 --> 01:10:23,910
우리가 할 수 있는 유일한 방법이기 때문입니다.

1118
01:10:23,910 --> 01:10:26,550
우리는 마지막 컨볼루션 레이어로만 갈 수 있습니다.

1119
01:10:26,550 --> 01:10:29,550
여기서 우리가 계산한 방식입니다.

1120
01:10:29,550 --> 01:10:32,390
그 문제를 해결하기 위해

1121
01:10:32,390 --> 01:10:34,640
Grad-CAM이라는 알고리즘의

1122
01:10:34,640 --> 01:10:38,990
변형이 있습니다. 즉, 그래디언트 가중 클래스 활성화

1123
01:10:38,990 --> 01:10:40,170
맵입니다.

1124
01:10:40,170 --> 01:10:43,040
기본적으로 같은 알고리즘입니다.

1125
01:10:43,040 --> 01:10:46,850
우리는 활성화를 생성한

1126
01:10:46,850 --> 01:10:52,160
레이어 중 하나에 대해 가중치를

1127
01:10:52,160 --> 01:10:54,900
계산해야 합니다.

1128
01:10:54,900 --> 01:10:59,130
클래스 수준에서 우리는 그래디언트를 계산합니다.

1129
01:10:59,130 --> 01:11:03,170
단순히 W와 피처 간의 곱셈을 계산하는

1130
01:11:03,170 --> 01:11:04,760
대신에 말입니다.

1131
01:11:04,760 --> 01:11:07,640
우리는 그래디언트를 통해 완전히

1132
01:11:07,640 --> 01:11:11,180
돌아가고 그래디언트를 기반으로 가중치를

1133
01:11:11,180 --> 01:11:15,900
생성한 다음, 그것이 가중치 대신 사용됩니다. 이는

1134
01:11:15,900 --> 01:11:17,810
특정 레이어까지 모든

1135
01:11:17,810 --> 01:11:20,700
가중치와 그래디언트의 집합입니다.

1136
01:11:20,700 --> 01:11:24,960
그리고 우리는 그것으로 가중치를 부여합니다.

1137
01:11:24,960 --> 01:11:32,850
그리고 우리는 또한 양수 값을 통과시키기 위해 ReLU를 사용합니다.

1138
01:11:32,850 --> 01:11:36,170
그리고 그것은 이미지 공간에서도

1139
01:11:36,170 --> 01:11:38,910
모두 보여질 수 있습니다.

1140
01:11:38,910 --> 01:11:43,820
그래서 나는 CAM에 대해 이야기했는데, 이는 마지막 컨볼루션

1141
01:11:43,820 --> 01:11:45,600
레이어에만 적용되었습니다.

1142
01:11:45,600 --> 01:11:47,260
하지만 이것은

1143
01:11:47,260 --> 01:11:51,660
대부분의 CNN 알고리즘에서 마지막에 단일

1144
01:11:51,660 --> 01:11:55,990
컨볼루션 레이어가 없기 때문에 불가능합니다.

1145
01:11:55,990 --> 01:11:59,860
우리는 항상 완전 연결된 작업 등이 있습니다.

1146
01:11:59,860 --> 01:12:03,870
그래서 중간에 다른 것이 있을 경우, 이

1147
01:12:03,870 --> 01:12:06,390
클래스 활성화를 컨볼루션

1148
01:12:06,390 --> 01:12:10,230
레이어로 전달할 수 있도록 우리는 종종

1149
01:12:10,230 --> 01:12:17,560
그래디언트를 사용하고 기본적으로 그래디언트 집합으로 맵에 가중치를
부여합니다.

1150
01:12:17,560 --> 01:12:20,410
그런 다음 우리는 실제로 시각화를 수행할 수 있습니다.

1151
01:12:20,410 --> 01:12:24,060
그들은 각 객체에 대한 이러한 히트 맵을 생성합니다.

1152
01:12:24,060 --> 01:12:26,980
그래서 이것은 CNN에 관한 것이었습니다.

1153
01:12:26,980 --> 01:12:32,310
하지만 우리는 지난 주 마지막 강의에서 변환기에 대해 이야기했는데,

1154
01:12:32,310 --> 01:12:37,270
그것들은 본질적으로 활성화 맵을 가지고 있습니다.

1155
01:12:37,270 --> 01:12:41,610
저스틴이 보여준 언어 행렬을 기억하십니까?

1156
01:12:41,610 --> 01:12:45,660
각 출력 단어에 대해 입력에 대한 주의

1157
01:12:45,660 --> 01:12:47,820
가중치가 있습니다.

1158
01:12:47,820 --> 01:12:50,610
우리는 픽셀에 대해서도 같은 작업을 수행할 수 있습니다.

1159
01:12:50,610 --> 01:12:54,140
각 출력에 대해 우리는 픽셀 공간에서

1160
01:12:54,140 --> 01:13:00,110
이러한 맵을 생성하고 ViTs의 특징을 시각화할 수

1161
01:13:00,110 --> 01:13:01,020
있습니다.

1162
01:13:01,020 --> 01:13:03,140
기본적으로 ViTs와 변환기를 사용하면

1163
01:13:03,140 --> 01:13:04,410
이것이 훨씬 쉬워집니다.

1164
01:13:04,410 --> 01:13:09,080
우리는 이미 주의와 가중치를 시각화하는

1165
01:13:09,080 --> 01:13:11,730
방법을 가지고 있습니다.

1166
01:13:11,730 --> 01:13:16,880
하지만 CNN을 사용할 때는 Grad-CAM이나 이러한

1167
01:13:16,880 --> 01:13:19,830
유형의 알고리즘을 자주 사용합니다.

1168
01:13:19,830 --> 01:13:24,530
그렇긴 하지만, 제가 오늘 이야기하고 싶었던

1169
01:13:24,530 --> 01:13:29,180
주제를 완료하는 이 작업을 할 수 있을 것이라고

1170
01:13:29,180 --> 01:13:31,350
생각하지 않았습니다.

1171
01:13:31,350 --> 01:13:35,000
다음 세션에서는 비디오 이해에 관한 강의를

1172
01:13:35,000 --> 01:13:36,810
진행할 것입니다.

1173
01:13:36,810 --> 01:13:38,740
감사합니다.
