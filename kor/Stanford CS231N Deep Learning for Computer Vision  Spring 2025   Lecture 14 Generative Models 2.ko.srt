1
00:00:05,480 --> 00:00:08,392
지난 시간에는 생성 모델에 대해 이야기했습니다.

2
00:00:08,392 --> 00:00:10,600
그리고 생성 모델과 판별 모델에 대해

3
00:00:10,600 --> 00:00:13,308
논의하면서, 이 둘은 기본적으로 확률 모델의 다른

4
00:00:13,308 --> 00:00:15,822
형태라는 점을 기억하시고, 우리가 무엇을

5
00:00:15,822 --> 00:00:17,780
예측하려 하는지, 무엇을 조건으로 하는지,

6
00:00:17,780 --> 00:00:19,600
그리고 무엇을 정규화하는지가

7
00:00:19,600 --> 00:00:20,733
중요하다고 했습니다.

8
00:00:20,733 --> 00:00:22,400
그래서 우리는 데이터

9
00:00:22,400 --> 00:00:24,920
x를 조건으로 레이블 y를 예측하는

10
00:00:24,920 --> 00:00:27,280
판별 모델, 데이터 x에 대한 확률

11
00:00:27,280 --> 00:00:30,040
분포를 학습하는 생성 모델, 그리고

12
00:00:30,040 --> 00:00:32,040
사용자 입력 y나 레이블 y를

13
00:00:32,040 --> 00:00:37,080
조건으로 데이터 x를 모델링하는 조건부 생성 모델에 대해 이야기했습니다.

14
00:00:37,080 --> 00:00:39,200
이 모델들은 정규화하는

15
00:00:39,200 --> 00:00:42,320
대상이 다르다는 점에서 차이가

16
00:00:42,320 --> 00:00:46,777
있는데, 확률 분포는 정규화 효과를 도입해서

17
00:00:46,777 --> 00:00:49,360
서로 다른 것들이 확률 질량을

18
00:00:49,360 --> 00:00:51,840
놓고 경쟁해야 한다는

19
00:00:51,840 --> 00:00:54,080
제약이 있기 때문입니다.

20
00:00:54,080 --> 00:00:56,480
지난 시간에는 생성 모델의

21
00:00:56,480 --> 00:00:58,480
다양한 분류 체계도 살펴봤는데,

22
00:00:58,480 --> 00:01:00,740
생성 모델 분야는 오랫동안

23
00:01:00,740 --> 00:01:02,340
연구되어 왔고,

24
00:01:02,340 --> 00:01:03,820
문제 변형을 해결하기

25
00:01:03,820 --> 00:01:05,237
위한 여러

26
00:01:05,237 --> 00:01:07,240
방법들이 개발되어 왔습니다.

27
00:01:07,240 --> 00:01:09,980
그래서 우리는 생성 모델의 계보를

28
00:01:09,980 --> 00:01:14,020
살펴봤고, 지난 시간에는 모델이 x에 대한 어떤 값

29
00:01:14,020 --> 00:01:18,620
p를 출력하는 명시적 밀도 모델에 대해 이야기했는데,

30
00:01:18,620 --> 00:01:22,140
여기에는 계산 가능한 밀도 모델에서 정확한

31
00:01:22,140 --> 00:01:24,780
p(x)를 출력하는 경우와 근사

32
00:01:24,780 --> 00:01:27,060
밀도 모델에서 p(x)의 근사값을

33
00:01:27,060 --> 00:01:29,440
출력하는 경우가 있습니다.

34
00:01:29,440 --> 00:01:31,680
계산 가능한 밀도 모델의

35
00:01:31,680 --> 00:01:34,600
경우, 우리는 자기회귀 모델이라는 범주를

36
00:01:34,600 --> 00:01:36,072
보았고, 근사

37
00:01:36,072 --> 00:01:37,780
밀도를 제공하는 예로는

38
00:01:37,780 --> 00:01:40,180
변분 오토인코더를 보았습니다.

39
00:01:40,180 --> 00:01:42,420
자기회귀 모델을 기억해 보면,

40
00:01:42,420 --> 00:01:45,540
우리는 이미지나 일반적으로 다루는

41
00:01:45,540 --> 00:01:48,260
데이터를 시퀀스로 나누었습니다.

42
00:01:48,260 --> 00:01:50,040
이미지 데이터의 경우,

43
00:01:50,040 --> 00:01:52,980
보통 픽셀 값이나 심지어 서브픽셀 값의

44
00:01:52,980 --> 00:01:54,540
시퀀스로 처리합니다.

45
00:01:54,540 --> 00:01:56,440
그리고 이 값들은 보통 이산적이길 원합니다.

46
00:01:56,440 --> 00:02:00,000
그래서 픽셀 값을 0부터 255까지 값을 가질 수 있는

47
00:02:00,000 --> 00:02:01,780
8비트 정수로 취급합니다.

48
00:02:01,780 --> 00:02:05,620
이 정수들을 길게 나열한 시퀀스로 만들고,

49
00:02:05,620 --> 00:02:08,680
보통 RNN이나 트랜스포머 같은

50
00:02:08,680 --> 00:02:12,120
이산 자기회귀 시퀀스 모델로 모델링합니다.

51
00:02:12,120 --> 00:02:14,940
또한 변분 오토인코더도 보았는데,

52
00:02:14,940 --> 00:02:17,580
이것도 명시적 밀도

53
00:02:17,580 --> 00:02:19,400
모델이지만 정확한

54
00:02:19,400 --> 00:02:21,180
밀도를 계산하지

55
00:02:21,180 --> 00:02:24,800
않고, 특히 밀도의 하한을 근사합니다.

56
00:02:24,800 --> 00:02:27,480
이를 위해 우리는 데이터 x를 입력받아

57
00:02:27,480 --> 00:02:29,720
잠재 코드 z에 대한 분포를

58
00:02:29,720 --> 00:02:33,880
출력하는 인코더 네트워크와, 잠재 코드 z를 입력받아

59
00:02:33,880 --> 00:02:36,560
예측된 데이터 x를 출력하는 디코더

60
00:02:36,560 --> 00:02:39,360
네트워크를 공동으로 학습했습니다.

61
00:02:39,360 --> 00:02:41,160
이 두 네트워크를

62
00:02:41,160 --> 00:02:46,040
함께 학습하여 우도 함수에 대한

63
00:02:46,040 --> 00:02:48,120
변분 하한을

64
00:02:48,120 --> 00:02:49,960
최대화했습니다.

65
00:02:49,960 --> 00:02:52,160
최대 우도는 모든 생성

66
00:02:52,160 --> 00:02:54,480
모델링의 핵심 통찰 중

67
00:02:54,480 --> 00:02:57,700
하나로, 생성 모델을 학습할 때

68
00:02:57,700 --> 00:03:00,820
우리의 목표 함수는 관찰된 데이터의

69
00:03:00,820 --> 00:03:04,982
우도를 최대화하는 것이라는 점을 기억하세요.

70
00:03:04,982 --> 00:03:06,940
오늘은 생성 모델에 대한

71
00:03:06,940 --> 00:03:09,780
논의를 이어가면서, 계보의 다른 절반인

72
00:03:09,780 --> 00:03:12,380
암묵적 밀도 모델을 탐구할 것입니다.

73
00:03:12,380 --> 00:03:14,820
암묵적 밀도 모델에서는 더 이상

74
00:03:14,820 --> 00:03:18,100
실제 밀도 값 p(x)를 얻지 못하지만,

75
00:03:18,100 --> 00:03:21,300
이 모델들은 확률 분포를 암묵적으로

76
00:03:21,300 --> 00:03:22,160
모델링합니다.

77
00:03:22,160 --> 00:03:24,220
비록 어떤 데이터 x에 대해 밀도

78
00:03:24,220 --> 00:03:27,180
값 p(x)를 계산할 수 없지만, 이 모델들이

79
00:03:27,180 --> 00:03:29,757
학습한 분포에서 샘플을 뽑을 수 있습니다.

80
00:03:29,757 --> 00:03:32,340
즉, 실제 밀도 값을 출력하지 못해도

81
00:03:32,340 --> 00:03:35,940
학습된 분포에서 샘플을 생성할 수 있습니다.

82
00:03:35,940 --> 00:03:38,100
첫 번째로 살펴볼 모델은

83
00:03:38,100 --> 00:03:42,820
생성적 적대 신경망, 흔히 GAN이라고 부르는 모델입니다.

84
00:03:42,820 --> 00:03:45,860
GAN을 변분 오토인코더와 자기회귀 모델과

85
00:03:45,860 --> 00:03:48,220
대비해서 보는 것이 유용합니다.

86
00:03:48,220 --> 00:03:50,500
앞서 말했듯이, 자기회귀

87
00:03:50,500 --> 00:03:52,700
모델은 우도 기반 방법입니다.

88
00:03:52,700 --> 00:03:54,980
학습 목표는 최대 우도입니다.

89
00:03:54,980 --> 00:03:56,960
즉, 데이터 x에

90
00:03:56,960 --> 00:04:00,060
대한 매개변수화된 함수 P(x)를

91
00:04:00,060 --> 00:04:02,360
정의하고, 관찰한 데이터에

92
00:04:02,360 --> 00:04:04,820
대해 이를 최대화합니다.

93
00:04:04,820 --> 00:04:07,840
변분 오토인코더도 비슷한 아이디어를

94
00:04:07,840 --> 00:04:11,920
따르는데, p(x)에 대한 근사값을

95
00:04:11,920 --> 00:04:14,720
정의하고 이를 최대화합니다.

96
00:04:14,720 --> 00:04:16,560
반면 생성적 적대 신경망은

97
00:04:16,560 --> 00:04:18,268
조금 다르게 작동합니다.

98
00:04:18,268 --> 00:04:20,880
GAN은 p(x)를 직접 모델링하는

99
00:04:20,880 --> 00:04:23,280
것을 포기하지만, p(x)를

100
00:04:23,280 --> 00:04:26,100
명시적으로 모델링하거나 밀도 값을

101
00:04:26,100 --> 00:04:27,600
제공하지 않더라도,

102
00:04:27,600 --> 00:04:32,520
모델이 적합한 분포에서 샘플을 뽑을 수 있는 방법을 제공합니다.

103
00:04:32,520 --> 00:04:34,960
여기서 설정은, pdata라는

104
00:04:34,960 --> 00:04:38,240
진짜 데이터 분포에서 추출된

105
00:04:38,240 --> 00:04:41,120
유한한 데이터 샘플 Xi가

106
00:04:41,120 --> 00:04:42,240
주어지고,

107
00:04:42,240 --> 00:04:45,800
우리의 목표는 pdata에서 샘플을 뽑을 수 있는 것입니다.

108
00:04:45,800 --> 00:04:48,600
pdata는 우주의 진짜 분포와 같다고 생각할

109
00:04:48,600 --> 00:04:49,580
수 있습니다.

110
00:04:49,580 --> 00:04:52,400
이 분포는 우주가 여러분에게 데이터 샘플을

111
00:04:52,400 --> 00:04:53,640
제공하는 방식이며,

112
00:04:53,640 --> 00:04:55,920
아마도 매우 복잡한 분포일 것입니다.

113
00:04:55,920 --> 00:04:56,880
물리학이 관련되어 있습니다.

114
00:04:56,880 --> 00:04:58,080
역사가 관련되어 있습니다.

115
00:04:58,080 --> 00:05:00,803
사회정치적 제약도 관련될 수 있습니다.

116
00:05:00,803 --> 00:05:02,220
우주에서 일어나는 모든

117
00:05:02,220 --> 00:05:03,595
일에는 복잡한 요소가

118
00:05:03,595 --> 00:05:06,660
많아서 여러분이 보는 데이터가 생겨나는 거죠.

119
00:05:06,660 --> 00:05:10,300
그리고 우리는 어떻게든 그 진짜 데이터 분포에

120
00:05:10,300 --> 00:05:12,740
최대한 맞추려고 하는 근사 모델을

121
00:05:12,740 --> 00:05:14,380
맞추고, 그 모델에서

122
00:05:14,380 --> 00:05:16,820
원래 관찰한 데이터 샘플처럼 보이는

123
00:05:16,820 --> 00:05:20,005
새로운 샘플을 뽑아낼 수 있기를 원합니다.

124
00:05:20,005 --> 00:05:21,380
그래서 우리가 할

125
00:05:21,380 --> 00:05:24,385
방법은 잠재 변수 z를 도입하는 것입니다.

126
00:05:24,385 --> 00:05:26,260
이것은 변분 오토인코더에서

127
00:05:26,260 --> 00:05:28,880
본 잠재 변수 z와 비슷한데,

128
00:05:28,880 --> 00:05:31,900
이 잠재 변수 z가 우리가 직접

129
00:05:31,900 --> 00:05:34,740
쓰고 조절할 어떤 알려진 사전

130
00:05:34,740 --> 00:05:37,517
분포 p(z)를 따른다는 겁니다.

131
00:05:37,517 --> 00:05:39,100
보통은 단위 가우시안이나

132
00:05:39,100 --> 00:05:41,893
균등 분포가 되는데, 일반적으로는 단위

133
00:05:41,893 --> 00:05:44,060
가우시안으로, 우리가 샘플링하는

134
00:05:44,060 --> 00:05:45,518
방법과 해석적 특성을

135
00:05:45,518 --> 00:05:47,820
잘 아는 아주 단순한 분포입니다.

136
00:05:47,820 --> 00:05:49,460
이제 설정은 우리

137
00:05:49,460 --> 00:05:53,320
네트워크가 모델링할 어떤 데이터 생성 과정을 상상하는

138
00:05:53,320 --> 00:05:54,200
것입니다.

139
00:05:54,200 --> 00:05:58,520
여기서는 알려진 분포 p에서 z를 샘플링해서 샘플

140
00:05:58,520 --> 00:06:01,840
z를 얻고, 그 샘플 z를 생성기

141
00:06:01,840 --> 00:06:05,920
네트워크 g에 통과시키는 과정을 상상할 겁니다.

142
00:06:05,920 --> 00:06:09,480
그럼 그 x는 어떤 생성기 분포 PG에서 나온

143
00:06:09,480 --> 00:06:11,280
샘플이 될 것입니다.

144
00:06:11,280 --> 00:06:13,880
그리고 생성기 네트워크의

145
00:06:13,880 --> 00:06:16,580
파라미터나 구조, 학습 방식을 바꾸면,

146
00:06:16,580 --> 00:06:18,920
이 PG 분포에서

147
00:06:18,920 --> 00:06:21,600
샘플링하는 분포가 달라지게 됩니다.

148
00:06:21,600 --> 00:06:23,400
그래서 GAN 학습의 전체

149
00:06:23,400 --> 00:06:26,480
목표는 생성기 네트워크가 유도하는 이 PG 분포를 강제로

150
00:06:26,480 --> 00:06:27,820
조정하는 것입니다.

151
00:06:27,820 --> 00:06:30,520
우리는 그 PG 분포가 실제 데이터 분포 P 데이터와

152
00:06:30,520 --> 00:06:32,540
최대한 가깝게 일치하기를 원합니다.

153
00:06:32,540 --> 00:06:35,840
왜냐하면 두 분포가 일치하면, z를 샘플링해서

154
00:06:35,840 --> 00:06:38,160
생성기에 통과시키면, P

155
00:06:38,160 --> 00:06:40,200
데이터와 매우 비슷한 샘플

156
00:06:40,200 --> 00:06:43,127
데이터를 얻을 수 있기 때문입니다.

157
00:06:43,127 --> 00:06:45,460
이 과정을 그림으로 나타내면 다음과 같습니다.

158
00:06:45,460 --> 00:06:48,040
그리고 우리는 pz에서 z를 샘플링하여 구체적인

159
00:06:48,040 --> 00:06:51,220
잠재 변수 z를 얻고, 이를 생성기 G에 통과시켜 생성된

160
00:06:51,220 --> 00:06:53,260
이미지를 얻는다고 상상할 수 있습니다.

161
00:06:53,260 --> 00:06:55,100
그래서 생성기 네트워크는

162
00:06:55,100 --> 00:06:58,660
기본적으로 알려진 분포 z에서 샘플을 받아서 우리의

163
00:06:58,660 --> 00:07:01,620
데이터 분포 샘플로 변환하도록 훈련됩니다.

164
00:07:01,620 --> 00:07:04,720
그런데 이제 질문은, 어떻게 이 출력값들을 강제로 맞출 수 있을까요?

165
00:07:04,720 --> 00:07:07,620
어떻게 유도된 생성기 분포 PG를 강제로 맞출 수 있을까요?

166
00:07:07,620 --> 00:07:11,180
어떻게 이것을 데이터 분포 pdata와 일치하도록 강제할 수 있을까요?

167
00:07:11,180 --> 00:07:13,540
그리고 생성적 적대 신경망의 핵심은

168
00:07:13,540 --> 00:07:16,100
이 작업을 수행할 또 다른 신경망을

169
00:07:16,100 --> 00:07:17,580
도입한다는 점입니다.

170
00:07:17,580 --> 00:07:21,802
이전의 생성 모델링 방식인 VAE나 자기회귀 모델에서는,

171
00:07:21,802 --> 00:07:23,260
우리가 최소화할 목적

172
00:07:23,260 --> 00:07:24,802
함수를 직접 작성하여

173
00:07:24,802 --> 00:07:27,580
적합한 분포가 데이터 분포와 일치하도록

174
00:07:27,580 --> 00:07:29,120
강제하려고 했습니다.

175
00:07:29,120 --> 00:07:30,980
여기서는 그 통제를 포기하고,

176
00:07:30,980 --> 00:07:33,180
기본적으로 다른 신경망에게

177
00:07:33,180 --> 00:07:35,260
그 작업을 맡기게 됩니다.

178
00:07:35,260 --> 00:07:38,100
특히, 우리는 판별기라고 불리는 또

179
00:07:38,100 --> 00:07:40,740
다른 신경망 D를 훈련시킬 것입니다. 이 판별기는 입력으로 이미지를

180
00:07:40,740 --> 00:07:44,860
받는데, 때로는 진짜 이미지, 때로는 가짜

181
00:07:44,860 --> 00:07:46,800
이미지를 받습니다.

182
00:07:46,800 --> 00:07:49,840
그리고 그 이미지가 진짜인지 가짜인지

183
00:07:49,840 --> 00:07:51,280
분류하는 역할을 합니다.

184
00:07:51,280 --> 00:07:55,303
그리고 아이디어는 이 두 네트워크가 서로 경쟁한다는 것입니다.

185
00:07:55,303 --> 00:07:56,720
생성기는 판별기를

186
00:07:56,720 --> 00:07:58,095
속이려고 훈련되고,

187
00:07:58,095 --> 00:07:59,845
판별기는 진짜

188
00:07:59,845 --> 00:08:02,480
데이터와 가짜 데이터를 올바르게

189
00:08:02,480 --> 00:08:05,300
구분하는 분류 모델로 훈련됩니다.

190
00:08:05,300 --> 00:08:08,520
이 두 네트워크가 경쟁하면서, 이상적으로 판별기는

191
00:08:08,520 --> 00:08:10,580
점점 더 좋아질 것입니다.

192
00:08:10,580 --> 00:08:11,580
판별기는 정말 뛰어나게 될 것입니다.

193
00:08:11,580 --> 00:08:13,163
판별기는 진짜 데이터와 가짜

194
00:08:13,163 --> 00:08:16,318
데이터의 특징을 구분하는 데 매우 능숙해질 것입니다.

195
00:08:16,318 --> 00:08:18,360
그리고 판별기가 정말 능숙해지면,

196
00:08:18,360 --> 00:08:20,480
생성된 샘플이 진짜로

197
00:08:20,480 --> 00:08:23,220
분류되도록 속이기 위해 생성기 데이터는

198
00:08:23,220 --> 00:08:25,480
진짜 데이터처럼 보이는 샘플을

199
00:08:25,480 --> 00:08:28,257
점점 더 가까이 만들어야 합니다.

200
00:08:28,257 --> 00:08:30,840
이것이 바로 생성적 적대 신경망(GAN)의

201
00:08:30,840 --> 00:08:32,159
직관입니다.

202
00:08:32,159 --> 00:08:34,497
그럼 질문이, 생성기 네트워크가 판별기가

203
00:08:34,497 --> 00:08:36,080
올바르게 분류하는지에

204
00:08:36,080 --> 00:08:37,440
대한 피드백을 받나요?

205
00:08:37,440 --> 00:08:39,880
네, 그리고 이것이 이 전체 과정이 작동하는 데 매우 중요합니다.

206
00:08:39,880 --> 00:08:42,870
생성기가 받는 피드백의 종류는 그래디언트입니다.

207
00:08:42,870 --> 00:08:45,080
이 전체 시스템, 즉 생성기와

208
00:08:45,080 --> 00:08:47,140
판별기의 합성 시스템은 모두

209
00:08:47,140 --> 00:08:48,240
신경망입니다.

210
00:08:48,240 --> 00:08:50,157
우리는 이 신경망들을 통해 그래디언트를 계산하는

211
00:08:50,157 --> 00:08:52,440
방법을 알고 있고, 이들은 생성된 이미지를 통해 소통합니다.

212
00:08:52,440 --> 00:08:54,898
그래서 판별기에서 생성된 이미지,

213
00:08:54,898 --> 00:08:57,480
그리고 생성기로 역전파를 할 것입니다.

214
00:08:57,480 --> 00:08:59,355
이것이 생성기가 판별기로부터

215
00:08:59,355 --> 00:09:01,420
학습하는 방법입니다.

216
00:09:01,420 --> 00:09:03,380
그리고 좀 더 구체적으로,

217
00:09:03,380 --> 00:09:05,860
이 직관을 구체화하기 위해 실제

218
00:09:05,860 --> 00:09:08,580
방정식, 수학식을 적어야 합니다.

219
00:09:08,580 --> 00:09:10,660
특히, 우리는 생성기

220
00:09:10,660 --> 00:09:13,100
G와 판별기 D를 이 미니맥스

221
00:09:13,100 --> 00:09:15,820
게임으로 공동 훈련할 것입니다.

222
00:09:15,820 --> 00:09:17,880
이 방정식이 조금 복잡해 보일

223
00:09:17,880 --> 00:09:20,780
수 있으니 각 항목을 하나씩 살펴보겠습니다.

224
00:09:20,780 --> 00:09:22,500
여기서는 색깔 코드를

225
00:09:22,500 --> 00:09:25,200
사용해서 생성기는 파란색, 판별기는

226
00:09:25,200 --> 00:09:27,260
빨간색으로 표시하겠습니다.

227
00:09:27,260 --> 00:09:29,980
판별기는 데이터 x를 입력받아

228
00:09:29,980 --> 00:09:32,260
그 데이터가 진짜일 확률을

229
00:09:32,260 --> 00:09:34,340
출력하는 함수입니다.

230
00:09:34,340 --> 00:09:36,397
특히, D(x) = 0이면

231
00:09:36,397 --> 00:09:38,980
판별기가 데이터 x를 가짜로

232
00:09:38,980 --> 00:09:40,340
분류했다는 뜻입니다.

233
00:09:40,340 --> 00:09:43,300
D(x) = 1이면 판별기가 그 데이터를 진짜로

234
00:09:43,300 --> 00:09:44,835
분류했다는 뜻입니다.

235
00:09:44,835 --> 00:09:46,460
물론, 그것들은 극단적인 경우입니다.

236
00:09:46,460 --> 00:09:49,000
실제로 discriminator는

237
00:09:49,000 --> 00:09:53,960
두 결정 사이의 부드러운 버전을 제공하는 확률을 출력합니다.

238
00:09:53,960 --> 00:09:56,357
이제 generator G를 고정한다고 상상해 보세요.

239
00:09:56,357 --> 00:09:58,440
그리고 discriminator의 관점에서 이

240
00:09:58,440 --> 00:09:59,560
문제를 생각해 보세요.

241
00:09:59,560 --> 00:10:01,720
그래서 discriminator의 관점에서

242
00:10:01,720 --> 00:10:03,040
여기에는 두 가지 항이 있습니다.

243
00:10:03,040 --> 00:10:06,880
첫 번째 항은 discriminator가 실제 데이터에 대해

244
00:10:06,880 --> 00:10:09,140
D(x) = 1이 되길 원한다는 뜻입니다.

245
00:10:09,140 --> 00:10:11,920
D(x) = 1은 discriminator가 그것이 실제라고

246
00:10:11,920 --> 00:10:13,280
말하는 것을 의미합니다.

247
00:10:13,280 --> 00:10:15,880
이 기대값은 기본적으로 실제

248
00:10:15,880 --> 00:10:19,440
pdata 분포에서 데이터 샘플 x를 뽑는다는

249
00:10:19,440 --> 00:10:20,300
뜻입니다.

250
00:10:20,300 --> 00:10:22,500
그 샘플들을 discriminator에

251
00:10:22,500 --> 00:10:25,240
통과시키고 로그를 취하는데, 확률 작업 시 거의 항상 로그

252
00:10:25,240 --> 00:10:26,700
공간에서 작업하기 때문입니다.

253
00:10:26,700 --> 00:10:29,140
그리고 로그는 단조 함수라는 것을 기억하세요.

254
00:10:29,140 --> 00:10:34,000
그래서 로그 x를 최대화하는 것은 x를 최대화하는 것과 같습니다.

255
00:10:34,000 --> 00:10:37,720
따라서 이 경우는 실제 데이터에 대해 D(x)의

256
00:10:37,720 --> 00:10:40,920
로그를 최대화하고 싶다는 뜻이며, 이는 실제

257
00:10:40,920 --> 00:10:44,180
데이터에 대해 D(x) = 1과 같습니다.

258
00:10:44,180 --> 00:10:46,100
반면에 다른 쪽은 알려진

259
00:10:46,100 --> 00:10:49,540
prior p(z)에 따라

260
00:10:49,540 --> 00:10:50,740
latent z를

261
00:10:50,740 --> 00:10:52,980
샘플링하여 기대값을 취한다는

262
00:10:52,980 --> 00:10:54,180
뜻입니다.

263
00:10:54,180 --> 00:10:55,900
그 z들을 generator에

264
00:10:55,900 --> 00:10:58,660
통과시키면 생성된 데이터 샘플이

265
00:10:58,660 --> 00:11:01,100
나오고, 그 샘플을 discriminator에

266
00:11:01,100 --> 00:11:02,740
통과시킵니다.

267
00:11:02,740 --> 00:11:04,860
그리고 이제 discriminator는 이것들을

268
00:11:04,860 --> 00:11:06,267
가짜 샘플로 분류하고 싶어 합니다.

269
00:11:06,267 --> 00:11:08,100
그래서 discriminator는

270
00:11:08,100 --> 00:11:10,180
이것들을 가짜로 분류하고 싶기 때문에

271
00:11:10,180 --> 00:11:12,380
왼쪽 표현을 어떻게든 반대로 해야 합니다.

272
00:11:12,380 --> 00:11:15,880
여기서 우리는 D(x)가 0일 때 가짜라고 판단하기를 원합니다.

273
00:11:15,880 --> 00:11:19,820
이것을 표현하는 한 가지 방법은 log(1 - D(G(z)))를

274
00:11:19,820 --> 00:11:21,330
최대화하는 것입니다.

275
00:11:21,330 --> 00:11:23,580
오른쪽 항은 판별기가 가짜 데이터에 대해

276
00:11:23,580 --> 00:11:25,778
D(x)가 0이 되기를 원한다는 뜻입니다.

277
00:11:25,778 --> 00:11:27,820
왼쪽 항은 판별기가 진짜 데이터에 대해

278
00:11:27,820 --> 00:11:30,192
D(x)가 1이 되기를 원한다는 뜻입니다.

279
00:11:30,192 --> 00:11:32,400
네, 이것이 판별기가 하려는 일입니다.

280
00:11:32,400 --> 00:11:34,420
판별기는 생성된

281
00:11:34,420 --> 00:11:38,740
샘플과 실제 데이터 샘플을 올바르게

282
00:11:38,740 --> 00:11:40,360
분류하는

283
00:11:40,360 --> 00:11:43,560
작업을 수행하려고 합니다.

284
00:11:43,560 --> 00:11:47,280
이제 생성기의 관점에서 이것을 살펴봅시다.

285
00:11:47,280 --> 00:11:48,915
판별기를 고정하고

286
00:11:48,915 --> 00:11:51,040
생성기의 관점에서만 이 설정을

287
00:11:51,040 --> 00:11:53,640
바라보는 것을 상상해보세요.

288
00:11:53,640 --> 00:11:55,360
이 경우 첫 번째 항은 생성기와

289
00:11:55,360 --> 00:11:57,220
전혀 관련이 없습니다. 왜냐하면

290
00:11:57,220 --> 00:12:00,040
첫 번째 항은 판별기가 실제 데이터 샘플을

291
00:12:00,040 --> 00:12:02,760
올바르게 분류하는 것에 관한 것이기 때문입니다.

292
00:12:02,760 --> 00:12:06,320
그래서 생성기는 오른쪽 항만 신경 씁니다.

293
00:12:06,320 --> 00:12:08,360
직관적으로, 생성기는 판별기를 속여서

294
00:12:08,360 --> 00:12:10,040
자신의 샘플이 진짜라고

295
00:12:10,040 --> 00:12:11,560
생각하게 만들고 싶어합니다.

296
00:12:11,560 --> 00:12:14,200
즉, 생성기는 가짜 데이터에 대해

297
00:12:14,200 --> 00:12:16,600
D(x)가 1이 되기를 원합니다.

298
00:12:16,600 --> 00:12:17,880
항은 동일합니다.

299
00:12:17,880 --> 00:12:20,560
우리는 z를 p(z)에 따라 샘플링하고,

300
00:12:20,560 --> 00:12:22,945
생성기를 통과시켜 생성된 샘플을

301
00:12:22,945 --> 00:12:24,320
얻고, 그 샘플을

302
00:12:24,320 --> 00:12:26,920
판별기에 통과시켜 판별기가 예측한 확률을

303
00:12:26,920 --> 00:12:27,630
얻습니다.

304
00:12:30,180 --> 00:12:33,200
그리고 생성기는 D(x)가 1이 되기를 원한다는 점을 기억하세요.

305
00:12:33,200 --> 00:12:36,840
그래서 판별기가 최대화하려던

306
00:12:36,840 --> 00:12:39,360
것을 생성기는

307
00:12:39,360 --> 00:12:42,980
최소화하려고 시도합니다.

308
00:12:42,980 --> 00:12:45,500
그리고 이것이 우리에게 이 미니맥스 게임을 제공합니다.

309
00:12:45,500 --> 00:12:47,860
특히, 우리는 이 모든 수학을

310
00:12:47,860 --> 00:12:50,980
G와 D의 함수인 어떤 스칼라

311
00:12:50,980 --> 00:12:53,540
함수 v로 추상화할 수 있습니다. 그 다음에 판별자는 v를

312
00:12:53,540 --> 00:12:56,540
최대화하려 하고, 생성자는 v를

313
00:12:56,540 --> 00:12:59,060
최소화하려 하며, 이들이

314
00:12:59,060 --> 00:13:01,660
서로 싸우게 된다고 말합니다.

315
00:13:01,660 --> 00:13:04,780
그리고 이것을 최적화하기 위해, 우리는 기본적으로

316
00:13:04,780 --> 00:13:07,620
생성자와 판별자의 파라미터에 대해 번갈아 가며

317
00:13:07,620 --> 00:13:09,500
이 값을 최소화하고 최대화하는

318
00:13:09,500 --> 00:13:11,740
그래디언트 하강 루프를 돌릴 것입니다.

319
00:13:11,740 --> 00:13:14,460
그래서 무한 루프를 돌면서,

320
00:13:14,460 --> 00:13:18,700
먼저 D를 업데이트하는데, v를 D에 대해

321
00:13:18,700 --> 00:13:21,800
미분한 그래디언트를 따라 한 스텝

322
00:13:21,800 --> 00:13:24,400
올라갑니다. 판별자는 이 값을

323
00:13:24,400 --> 00:13:29,180
최대화하려 하므로, 그래디언트 상승을 하는 거죠.

324
00:13:29,180 --> 00:13:32,137
그 다음 판별자 가중치를 업데이트한

325
00:13:32,137 --> 00:13:34,220
후에는, 생성자

326
00:13:34,220 --> 00:13:38,700
가중치 G에 대해 v를 미분한 그래디언트를

327
00:13:38,700 --> 00:13:42,200
따라 한 스텝 내려갑니다. 생성자는

328
00:13:42,200 --> 00:13:46,320
이 목적함수를 최소화하려 하기 때문입니다.

329
00:13:46,320 --> 00:13:47,900
이것이 기본적으로 우리의 훈련 방법입니다.

330
00:13:47,900 --> 00:13:49,483
이것이 바로 우리가 생성적 적대

331
00:13:49,483 --> 00:13:50,840
신경망을 훈련하는 방식입니다.

332
00:13:50,840 --> 00:13:53,120
우리는 이 V라는 값을 가지고 있는데, 이것이

333
00:13:53,120 --> 00:13:54,755
우리의 미니맥스 게임의 값입니다.

334
00:13:54,755 --> 00:13:56,880
그리고 우리는 이 목적

335
00:13:56,880 --> 00:14:03,040
V에 대해 번갈아 가며 생성자와 판별자의 가중치를 그래디언트 상승과

336
00:14:03,040 --> 00:14:05,498
하강으로 업데이트합니다.

337
00:14:05,498 --> 00:14:07,040
생성적 적대 신경망을

338
00:14:07,040 --> 00:14:09,840
훈련할 때 정말 중요한 점은, 이

339
00:14:09,840 --> 00:14:12,640
V가 손실 함수가 아니라는 것입니다.

340
00:14:12,640 --> 00:14:16,240
즉, V의 절대값은 생성자와 판별자가 이 문제를

341
00:14:16,240 --> 00:14:18,840
얼마나 잘 해결하는지, 또는

342
00:14:18,840 --> 00:14:22,080
우리가 정말로 관심 있는 것은 유도된 PG

343
00:14:22,080 --> 00:14:23,840
분포가 데이터 분포와

344
00:14:23,840 --> 00:14:27,160
얼마나 잘 일치하는지에 대해 아무것도 알려주지

345
00:14:27,160 --> 00:14:28,020
않습니다.

346
00:14:28,020 --> 00:14:29,520
V의 값만 보는

347
00:14:29,520 --> 00:14:31,840
것으로는 그걸 알 수 없습니다.

348
00:14:31,840 --> 00:14:34,840
왜냐하면 V의 값은 판별자가 얼마나 좋은지에

349
00:14:34,840 --> 00:14:36,560
달려 있기 때문입니다.

350
00:14:36,560 --> 00:14:38,195
판별자가 매우 나쁘면,

351
00:14:38,195 --> 00:14:39,820
생성자가 쉽게 속여서

352
00:14:39,820 --> 00:14:42,200
좋은 값을 얻을 수 있고,

353
00:14:42,200 --> 00:14:43,920
판별자가 매우 좋으면 생성자도

354
00:14:43,920 --> 00:14:45,640
정말 잘해야 합니다.

355
00:14:45,640 --> 00:14:49,140
따라서 D와 G의 서로 다른 설정들이 동일한

356
00:14:49,140 --> 00:14:51,380
V 값을 낼 수 있습니다.

357
00:14:51,380 --> 00:14:54,100
이것이 생성적 적대 신경망이 종종

358
00:14:54,100 --> 00:14:57,220
훈련하기 어렵고, 훈련이 잘 되고 있는지 판단하기도

359
00:14:57,220 --> 00:14:58,985
어렵다는 의미입니다.

360
00:14:58,985 --> 00:15:01,360
보통 신경망을 훈련할 때는 손실(loss)이 있습니다.

361
00:15:01,360 --> 00:15:02,860
네트워크의 파라미터에 대해 손실을

362
00:15:02,860 --> 00:15:04,278
최소화하려고 하고, 훈련이

363
00:15:04,278 --> 00:15:05,820
진행됨에 따라 손실이 줄어드는

364
00:15:05,820 --> 00:15:07,380
것을 보고 싶어 하죠. 하지만

365
00:15:07,380 --> 00:15:09,680
생성적 적대 신경망(GAN)에서는 그렇지 않습니다.

366
00:15:09,680 --> 00:15:10,720
생성기(generator) 손실이 있고,

367
00:15:10,720 --> 00:15:12,053
판별기(discriminator) 손실이 있습니다.

368
00:15:12,053 --> 00:15:14,660
이것들을 그래프로 그려볼 수는 있지만, 일반적으로

369
00:15:14,660 --> 00:15:15,813
별 의미가 없습니다.

370
00:15:15,813 --> 00:15:17,480
그래서 GAN은

371
00:15:17,480 --> 00:15:19,540
훈련하기가 정말 어렵습니다.

372
00:15:19,540 --> 00:15:23,640
첫째, 이 목적 함수는 근본적으로 불안정합니다.

373
00:15:23,640 --> 00:15:26,340
네트워크의 서로 다른 파라미터 집합에

374
00:15:26,340 --> 00:15:29,408
대해 같은 값을 동시에 최대화하고

375
00:15:29,408 --> 00:15:31,700
최소화하려고 하니, 본질적으로 어려운

376
00:15:31,700 --> 00:15:33,080
최적화 문제입니다.

377
00:15:33,080 --> 00:15:35,420
더 나쁜 점은, 좋은 해답으로

378
00:15:35,420 --> 00:15:38,080
나아가고 있는지 알려줄 수 있는 값을 볼

379
00:15:38,080 --> 00:15:39,560
수 없다는 겁니다.

380
00:15:39,560 --> 00:15:41,400
그래서 GAN은

381
00:15:41,400 --> 00:15:44,000
효과적이긴 하지만 훈련하기도,

382
00:15:44,000 --> 00:15:48,200
튜닝하기도, 진전을 이루기도 정말 어렵습니다.

383
00:15:48,200 --> 00:15:52,340
이게 GAN에 대한 주요 요점입니다.

384
00:15:52,340 --> 00:15:55,120
GAN 훈련 시 생각해볼 만한

385
00:15:55,120 --> 00:15:57,800
작은 팁이 하나 있는데, 바로

386
00:15:57,800 --> 00:16:00,560
훈련 역학을 상상해보는 겁니다.

387
00:16:00,560 --> 00:16:03,040
훈련 초반을 상상해보면,

388
00:16:03,040 --> 00:16:05,300
생성기와 판별기가 모두 무작위로

389
00:16:05,300 --> 00:16:07,180
초기화되어 있습니다.

390
00:16:07,180 --> 00:16:08,200
무슨 일이 일어날까요?

391
00:16:08,200 --> 00:16:10,680
훈련 초반에 생성기는 완전히

392
00:16:10,680 --> 00:16:12,658
무작위 노이즈를 생성합니다.

393
00:16:12,658 --> 00:16:14,200
그 무작위 노이즈는 실제

394
00:16:14,200 --> 00:16:16,303
이미지와 매우 다르게 보일 겁니다.

395
00:16:16,303 --> 00:16:18,720
그래서 생성기가 형편없을 때,

396
00:16:18,720 --> 00:16:21,720
판별기는 아주 쉬운 문제를 갖게 됩니다.

397
00:16:21,720 --> 00:16:23,920
보통 몇 번의 반복만에

398
00:16:23,920 --> 00:16:25,720
판별기는 실제

399
00:16:25,720 --> 00:16:28,240
이미지와 완전 쓰레기 같은 무작위

400
00:16:28,240 --> 00:16:32,320
가짜 이미지를 바로 구분할 수 있습니다.

401
00:16:32,320 --> 00:16:35,603
즉, 훈련 초반에 판별기는

402
00:16:35,603 --> 00:16:37,020
실제와 가짜를

403
00:16:37,020 --> 00:16:41,180
꽤 높은 확률로 빠르게 분류하는

404
00:16:41,180 --> 00:16:43,060
법을 배웁니다.

405
00:16:43,060 --> 00:16:47,340
그래서 D(G(z))가 어떻게 변하는지 그래프로 그려보는 게 흥미롭습니다.

406
00:16:47,340 --> 00:16:52,740
죄송합니다, D(G(z)) 함수의 값이 어떻게 되는지 보는

407
00:16:52,740 --> 00:16:55,220
건데, 이게 생성기

408
00:16:55,220 --> 00:16:57,400
관점에서의 손실 함수입니다.

409
00:16:57,400 --> 00:17:00,060
그래서 생성기 관점에서

410
00:17:00,060 --> 00:17:02,420
보면, 훈련 초반은 여기

411
00:17:02,420 --> 00:17:04,220
쯤에 위치합니다.

412
00:17:04,220 --> 00:17:06,500
판별기는 생성된 샘플을

413
00:17:06,500 --> 00:17:09,609
가짜로 잘 분류하고 있어서,

414
00:17:09,609 --> 00:17:11,859
판별기 관점에서

415
00:17:11,859 --> 00:17:13,506
최적화하는

416
00:17:13,506 --> 00:17:15,339
손실 함수는 이런

417
00:17:15,339 --> 00:17:16,817
모양입니다.

418
00:17:16,817 --> 00:17:18,900
보시면, 이 손실 함수는

419
00:17:18,900 --> 00:17:21,819
생성기가 파라미터를 최적화하려는 지점에서

420
00:17:21,819 --> 00:17:24,720
거의 평평하거나 매우 평평합니다.

421
00:17:24,720 --> 00:17:27,660
즉, 실제로 이 단순한 목적 함수를

422
00:17:27,660 --> 00:17:29,905
사용해 GAN을 훈련하면,

423
00:17:29,905 --> 00:17:31,780
생성기는 훈련 초반에 배우기

424
00:17:31,780 --> 00:17:33,800
정말 어렵다는 뜻입니다.

425
00:17:33,800 --> 00:17:36,340
좋은 질문입니다, 데이터셋은 어떻게 구성하나요?

426
00:17:36,340 --> 00:17:40,080
유니콘이 존재하지 않는데 유니콘 사진을 어떻게 생성하나요?

427
00:17:40,080 --> 00:17:43,737
pdata는 여러분이 선택하는 pdata입니다.

428
00:17:43,737 --> 00:17:46,320
즉, 훈련 세트에서 어떤 데이터셋을

429
00:17:46,320 --> 00:17:48,480
모으느냐가 모델링하려는

430
00:17:48,480 --> 00:17:49,740
pdata를 결정합니다.

431
00:17:49,740 --> 00:17:51,960
일반적으로, 전에 본 적

432
00:17:51,960 --> 00:17:53,760
없는 전혀 다른 샘플을

433
00:17:53,760 --> 00:17:56,460
생성하고 싶다면, 불가능합니다.

434
00:17:56,460 --> 00:17:57,680
그런 일은 일어나지 않습니다.

435
00:17:57,680 --> 00:18:00,200
그래서 보통 샘플을 생성하려면,

436
00:18:00,200 --> 00:18:02,320
훈련 데이터셋에 그와 비슷한

437
00:18:02,320 --> 00:18:04,080
것이 있어야 합니다.

438
00:18:04,080 --> 00:18:07,360
그래서 모든 생성 모델과 모든 신경망은 실제로

439
00:18:07,360 --> 00:18:09,380
어느 정도 일반화합니다.

440
00:18:09,380 --> 00:18:11,800
그래서 희망하는 것은, 아마도

441
00:18:11,800 --> 00:18:14,800
산타 모자를 쓴 유니콘의 포토리얼리스틱

442
00:18:14,800 --> 00:18:17,920
이미지를 본 적은 없지만, 말의 포토리얼리스틱

443
00:18:17,920 --> 00:18:20,280
이미지, 산타 모자 이미지,

444
00:18:20,280 --> 00:18:22,300
유니콘 그림, 말 그림을

445
00:18:22,300 --> 00:18:24,600
본 적이 있어서, 정확히

446
00:18:24,600 --> 00:18:26,240
생성하고 싶은 속성 조합을

447
00:18:26,240 --> 00:18:28,400
본 적이 없더라도, 충분히

448
00:18:28,400 --> 00:18:30,200
비슷한 것을 많이 봐서

449
00:18:30,200 --> 00:18:32,180
모델이 일반화하여 새로운

450
00:18:32,180 --> 00:18:34,640
것을 만들어낼 수 있다는 겁니다.

451
00:18:34,640 --> 00:18:36,377
이게 항상 희망하는 바입니다.

452
00:18:36,377 --> 00:18:38,960
이걸 판별자의 관점에서 보면 어떨까요?

453
00:18:38,960 --> 00:18:41,180
그래서 만약 제가 산타 모자를

454
00:18:41,180 --> 00:18:43,740
쓴 포토리얼리스틱 유니콘

455
00:18:43,740 --> 00:18:46,118
이미지를 생성했다면, 모든 질감,

456
00:18:46,118 --> 00:18:48,160
조명, 그림자, 잎사귀가

457
00:18:48,160 --> 00:18:49,580
완벽해서 그 샘플

458
00:18:49,580 --> 00:18:53,020
자체만으로는 명백히 틀렸다고 말할 증거가

459
00:18:53,020 --> 00:18:54,553
없을 수도 있습니다.

460
00:18:54,553 --> 00:18:56,720
만약 판별자가 정말 똑똑하다면,

461
00:18:56,720 --> 00:18:58,220
유니콘이 실제로 존재하지

462
00:18:58,220 --> 00:18:59,975
않는다는 걸 알고, 완벽한

463
00:18:59,975 --> 00:19:02,100
포토리얼리스틱 이미지가 나올

464
00:19:02,100 --> 00:19:05,460
가능성이 낮다는 걸 알 수도 있겠지만, 그건 꽤 어려운

465
00:19:05,460 --> 00:19:06,740
의미론적 문제입니다.

466
00:19:06,740 --> 00:19:08,660
그래서 실제로 판별자는 그렇게

467
00:19:08,660 --> 00:19:10,660
똑똑하지 않은 경향이 있습니다.

468
00:19:10,660 --> 00:19:11,660
네, 좋은 질문입니다.

469
00:19:11,660 --> 00:19:13,758
왜 두 개의 곡선을 보지 않을까요?

470
00:19:13,758 --> 00:19:15,300
왜 판별자가 얼마나 좋은지 나타내는

471
00:19:15,300 --> 00:19:16,560
한 곡선만 보지 않을까요?

472
00:19:16,560 --> 00:19:18,102
왜 생성자가 얼마나 좋은지 나타내는

473
00:19:18,102 --> 00:19:19,280
한 곡선만 보지 않을까요?

474
00:19:19,280 --> 00:19:20,280
마음껏 그려보세요.

475
00:19:20,280 --> 00:19:22,140
그런데 보통은 정말 쓸모없어 보입니다.

476
00:19:22,140 --> 00:19:24,045
이 문제를 해결하고 GAN

477
00:19:24,045 --> 00:19:26,420
목적함수를 어떻게 조정할지 연구하는

478
00:19:26,420 --> 00:19:28,800
논문이 수백 편은 있을 겁니다.

479
00:19:28,800 --> 00:19:30,000
로그를 사용하지 않는 방법은?

480
00:19:30,000 --> 00:19:33,000
Wasserstein 뭔가, 뭐뭐를 사용하는 방법은?

481
00:19:33,000 --> 00:19:35,120
곡선을 더 해석하기 쉽게 만들기 위해

482
00:19:35,120 --> 00:19:37,000
온갖 복잡한 것들을 여기에 넣습니다.

483
00:19:37,000 --> 00:19:40,200
수백 편의 논문이 작성되었고, 수천 명의 사람들이 5년

484
00:19:40,200 --> 00:19:42,040
동안 연구했지만, 좋은 해결책을

485
00:19:42,040 --> 00:19:43,760
찾은 사람은 없다고 생각합니다.

486
00:19:43,760 --> 00:19:47,120
그래서 수백, 수천 편의 논문이 GAN을 학습시킨

487
00:19:47,120 --> 00:19:49,920
후에도 많은 사람들이 여전히 이 기본적인

488
00:19:49,920 --> 00:19:51,520
방식을 사용하는데,

489
00:19:51,520 --> 00:19:53,687
이렇게 나누어도 해석 가능한

490
00:19:53,687 --> 00:19:55,280
곡선을 얻기 어렵습니다.

491
00:19:55,280 --> 00:19:58,000
질문은 훈련 초기에 판별기가 어떻게 되는지가

492
00:19:58,000 --> 00:19:59,540
정말 중요한가 하는 것입니다.

493
00:19:59,540 --> 00:20:00,960
답은 아니오입니다. 왜냐하면 이것은

494
00:20:00,960 --> 00:20:02,520
우리가 이전에 본 어떤 분류 문제와도

495
00:20:02,520 --> 00:20:04,520
다르기 때문인데, 비정상 분포(non-stationary

496
00:20:04,520 --> 00:20:06,360
distribution)이기 때문입니다.

497
00:20:06,360 --> 00:20:08,720
ImageNet이나 CIFAR 같은 데이터셋으로

498
00:20:08,720 --> 00:20:10,840
이미지 분류기를 학습할 때는 데이터셋이

499
00:20:10,840 --> 00:20:12,640
고정되어 있고 모델은 그 정적인

500
00:20:12,640 --> 00:20:14,240
데이터셋을 잘 분류하려고 합니다.

501
00:20:14,240 --> 00:20:16,200
하지만 GAN 학습의 경우,

502
00:20:16,200 --> 00:20:18,560
학습 중에 맞추려는 데이터셋이

503
00:20:18,560 --> 00:20:20,960
계속 변하기 때문에, 초기에는 생성된

504
00:20:20,960 --> 00:20:23,520
이미지가 매우 형편없어서 문제를

505
00:20:23,520 --> 00:20:25,522
쉽게 해결할 수 있지만, 생성기가

506
00:20:25,522 --> 00:20:26,980
점점 좋아집니다.

507
00:20:26,980 --> 00:20:29,100
그래서 판별기가 구분하려는

508
00:20:29,100 --> 00:20:31,300
데이터셋이 학습 과정에서

509
00:20:31,300 --> 00:20:32,580
계속 변합니다.

510
00:20:32,580 --> 00:20:34,580
즉, 이것은 비정상

511
00:20:34,580 --> 00:20:38,100
문제이고 매우 복잡한 학습 역학을 가집니다.

512
00:20:38,100 --> 00:20:40,140
좋은 질문입니다.

513
00:20:40,140 --> 00:20:41,640
이것들이 지역 최솟값에 빠지나요?

514
00:20:41,640 --> 00:20:43,598
지역 최솟값에서 벗어나게 하는 방법이 있나요? 잠시

515
00:20:43,598 --> 00:20:45,060
학습하다가 벗어나게 하는 방법 말입니다.

516
00:20:45,060 --> 00:20:47,720
다시 말하지만, 수백, 수천 편의 논문과

517
00:20:47,720 --> 00:20:50,980
많은 휴리스틱이 있지만, 확실히 정착된 방법은 없습니다.

518
00:20:50,980 --> 00:20:53,722
맞습니다, 그래서 이걸 끝까지 학습시켜야 합니다.

519
00:20:53,722 --> 00:20:55,180
그래서 판별기로부터의

520
00:20:55,180 --> 00:20:58,540
그래디언트가 항상 생성기로 전달되는데, 특히 오른쪽

521
00:20:58,540 --> 00:21:00,000
항을 통해서입니다.

522
00:21:00,000 --> 00:21:02,220
즉, 생성기 파라미터에 그래디언트를

523
00:21:02,220 --> 00:21:04,100
얻는 유일한 방법은 실제로

524
00:21:04,100 --> 00:21:05,400
판별기를 통해서입니다.

525
00:21:05,400 --> 00:21:07,680
즉, 여기서 어떤 정규화 항이 있지 않는 한,

526
00:21:07,680 --> 00:21:09,237
생성자에게 무엇을 해야 하는지

527
00:21:09,237 --> 00:21:11,820
알려주는 보조 항은 없고, 판별기를 통과하는

528
00:21:11,820 --> 00:21:13,112
그래디언트만 있을 뿐입니다.

529
00:21:13,112 --> 00:21:15,500
그리고 이것이 다시 불안정한 학습 문제의

530
00:21:15,500 --> 00:21:16,860
일부로 이어집니다.

531
00:21:16,860 --> 00:21:18,860
맞습니다, pdata 분포는

532
00:21:18,860 --> 00:21:21,660
훈련 과정 내내 고정되어 있습니다.

533
00:21:21,660 --> 00:21:22,500
좋습니다.

534
00:21:22,500 --> 00:21:24,933
그래서 우리는 생성자가 훈련 과정에서 낮은

535
00:21:24,933 --> 00:21:26,600
그래디언트를 받는 문제가 있다고 말했죠.

536
00:21:26,600 --> 00:21:30,560
여기에는 작은 트릭이 있는데, 1 빼기 D(G(z))의

537
00:21:30,560 --> 00:21:33,460
로그를 최대화하려고 하기보다는 대신에

538
00:21:33,460 --> 00:21:36,667
-log(D(G(z)))를 최소화하는 방법입니다.

539
00:21:36,667 --> 00:21:39,000
오프라인에서 스스로 확인해보면 이 둘이 대략 동등하다는

540
00:21:39,000 --> 00:21:41,910
것을 알 수 있지만, 요약하자면 이 방법이 훈련 초기에 생성자가

541
00:21:41,910 --> 00:21:44,160
더 좋은 그래디언트를 받을 수 있도록 더 나은

542
00:21:44,160 --> 00:21:45,015
곡선을 제공합니다.

543
00:21:45,015 --> 00:21:46,140
그래서 이것이 정말 중요합니다.

544
00:21:46,140 --> 00:21:47,515
그리고 GAN을

545
00:21:47,515 --> 00:21:50,100
처음부터 이 로그 목적함수로 훈련할 때,

546
00:21:50,100 --> 00:21:53,880
생성자에 대해 수정된 손실 함수를 사용하는 이 트릭이

547
00:21:53,880 --> 00:21:55,500
실제로 매우 중요합니다.

548
00:21:55,500 --> 00:21:56,875
즉, 생성자에

549
00:21:56,875 --> 00:22:00,080
대해 계산하는 V와 판별기에

550
00:22:00,080 --> 00:22:02,240
대해 계산하는 V가

551
00:22:02,240 --> 00:22:04,880
실제로 다르다는 뜻입니다.

552
00:22:04,880 --> 00:22:06,480
좋습니다, 왜 이것이 좋은 목적함수일

553
00:22:06,480 --> 00:22:08,360
수 있는지에 대한 또 다른 질문이 있네요.

554
00:22:08,360 --> 00:22:11,600
예전에는 이 증명을 단계별로 설명하는 슬라이드가 있었지만,

555
00:22:11,600 --> 00:22:14,340
오늘은 시간이 없을 것 같아 요약만 드리겠습니다.

556
00:22:14,340 --> 00:22:16,720
그리고 오프라인에서 참고할

557
00:22:16,720 --> 00:22:21,320
자료를 알려드릴 수 있습니다만, 요약하자면 이 목적함수가

558
00:22:21,320 --> 00:22:24,940
좋은 이유는 최적 판별기를 쓸 수 있기

559
00:22:24,940 --> 00:22:25,720
때문입니다.

560
00:22:25,720 --> 00:22:28,980
이것은 내부에 D에 대한 최대화,

561
00:22:28,980 --> 00:22:30,860
외부에 G에 대한

562
00:22:30,860 --> 00:22:34,320
최소화가 있는 중첩 최적화 문제입니다. 조금 수학을 하면 이

563
00:22:34,320 --> 00:22:38,620
내부 최대화 문제를 풀고 최적

564
00:22:38,620 --> 00:22:43,323
판별기가 무엇인지 쓸 수 있습니다.

565
00:22:43,323 --> 00:22:44,740
이것이 바로

566
00:22:44,740 --> 00:22:46,448
특정 생성자

567
00:22:46,448 --> 00:22:49,447
G에 대한 최적 판별기입니다. 그리고 이것을 그냥 쓸 수 있죠.

568
00:22:49,447 --> 00:22:51,280
물론 쓸 수는 있지만 pdata에

569
00:22:51,280 --> 00:22:54,383
의존하기 때문에 실제로 계산할 수는 없습니다.

570
00:22:54,383 --> 00:22:56,300
pdata 밀도에 접근할 수

571
00:22:56,300 --> 00:22:58,600
있다면 이미 문제가 해결된 것이니까요.

572
00:22:58,600 --> 00:23:00,940
그래서 슬라이드나 종이에 방정식으로

573
00:23:00,940 --> 00:23:04,220
쓸 수는 있지만, 실제로 계산할 수는 없습니다.

574
00:23:04,220 --> 00:23:07,520
그리고 이 내부 목적을 최대화해서

575
00:23:07,520 --> 00:23:10,620
최적 판별기를 구한 후에는, 외부

576
00:23:10,620 --> 00:23:12,300
목적이 최소화되는 조건이

577
00:23:12,300 --> 00:23:14,660
PG(x)가 pdata와

578
00:23:14,660 --> 00:23:17,900
같을 때임을 증명할 수 있습니다.

579
00:23:17,900 --> 00:23:21,500
즉, 이론적으로는 판별기와 생성기의

580
00:23:21,500 --> 00:23:23,420
최적 상태가 PG가

581
00:23:23,420 --> 00:23:27,640
pdata와 같을 때 유일하게 발생합니다.

582
00:23:27,640 --> 00:23:29,880
이 점이 우리를 안심시키지만, 이

583
00:23:29,880 --> 00:23:32,360
이론적 결과에는 많은 단서가 있습니다.

584
00:23:32,360 --> 00:23:35,600
첫째, G와 D 모두 무한한 표현 능력을 가진다고

585
00:23:35,600 --> 00:23:39,240
가정한다는 점입니다. 즉, 생성기와 판별기가 원칙적으로

586
00:23:39,240 --> 00:23:41,120
어떤 함수든 표현할 수 있다고

587
00:23:41,120 --> 00:23:43,370
가정하는데, 실제로는 고정된 크기와

588
00:23:43,370 --> 00:23:46,120
용량의 신경망이기 때문에 불가능합니다.

589
00:23:46,120 --> 00:23:48,240
또한 이 결과는 우리가 이 해에 수렴할

590
00:23:48,240 --> 00:23:51,060
수 있을지에 대해서는 전혀 알려주지 않습니다.

591
00:23:51,060 --> 00:23:53,000
즉, 이 목적 함수에는

592
00:23:53,000 --> 00:23:55,840
최적점이 있지만, 유한한 데이터

593
00:23:55,840 --> 00:23:57,240
샘플과 함께 경사

594
00:23:57,240 --> 00:24:00,740
하강 및 상승법으로 그곳에 도달할 수

595
00:24:00,740 --> 00:24:04,400
있을지에 대해서는 아무런 보장을 주지 않습니다.

596
00:24:04,400 --> 00:24:08,040
그래서 GAN에 대한 이론적

597
00:24:08,040 --> 00:24:10,580
정당성이 어느 정도 있긴

598
00:24:10,580 --> 00:24:12,560
하지만, 실제로는

599
00:24:12,560 --> 00:24:16,040
강력한 보장을 제공하지 않습니다.

600
00:24:16,040 --> 00:24:19,440
실제로 GAN에서 생성기 G와

601
00:24:19,440 --> 00:24:21,320
판별기 D는 모두

602
00:24:21,320 --> 00:24:23,900
신경망으로 매개변수화됩니다.

603
00:24:23,900 --> 00:24:25,940
예전에는 CNN이었죠.

604
00:24:25,940 --> 00:24:27,860
GAN은 VIT가 인기를 얻기

605
00:24:27,860 --> 00:24:29,660
전에 인기가 떨어졌지만,

606
00:24:29,660 --> 00:24:31,900
VIT와도 잘 작동할 것이라 생각합니다.

607
00:24:31,900 --> 00:24:34,380
그리고 처음으로 의미 있는 결과를 낸

608
00:24:34,380 --> 00:24:37,100
GAN은 DC-GAN이라고 불리며, 5층

609
00:24:37,100 --> 00:24:39,420
ConvNet 아키텍처를 사용해 당시 꽤

610
00:24:39,420 --> 00:24:41,060
흥미로운 샘플을 만들었습니다.

611
00:24:41,060 --> 00:24:44,180
DC-GAN을 언급한 이유는 첫 번째 저자인 Alec Radford

612
00:24:44,180 --> 00:24:46,820
등 때문인데, 대부분의 사람들에게 DC-GAN은

613
00:24:46,820 --> 00:24:48,960
경력의 하이라이트였겠지만, Alec

614
00:24:48,960 --> 00:24:51,293
Radford에게는 충분하지 않았습니다. 왜냐하면

615
00:24:51,293 --> 00:24:55,060
DC-GAN 바로 다음에 그가 작업한 프로젝트가 무엇인지 아는 사람이
있나요?

616
00:24:55,060 --> 00:24:55,860
GPT입니다.

617
00:24:55,860 --> 00:24:57,020
GPT입니다.

618
00:24:57,020 --> 00:25:00,360
그래서 Alec Radford는 DC-GAN이 그의 경력에서 다소 저조한
시기였다고 할 수 있습니다.

619
00:25:00,360 --> 00:25:04,140
그는 이후에 GPT-1과 GPT-2를 개발했고, OpenAI에서 다른

620
00:25:04,140 --> 00:25:05,880
놀라운 연구들도 수행했습니다.

621
00:25:05,880 --> 00:25:08,540
그래서 이미지 생성 모델링을 하던

622
00:25:08,540 --> 00:25:10,840
사람들이 실제로는 이산 텍스트 데이터의

623
00:25:10,840 --> 00:25:12,540
생성 모델링으로

624
00:25:12,540 --> 00:25:14,582
넘어가서 중요한 연구를 했다는

625
00:25:14,582 --> 00:25:16,940
멋진 연결고리가 있다고 생각합니다.

626
00:25:16,940 --> 00:25:19,500
그리고 제가 강조할 유일한 다른 GAN 논문

627
00:25:19,500 --> 00:25:21,480
중 하나는 StyleGAN입니다.

628
00:25:21,480 --> 00:25:23,780
이 논문의 세부 내용을 자세히 설명하지는

629
00:25:23,780 --> 00:25:25,880
않겠지만, GAN의 최선의 실천법을

630
00:25:25,880 --> 00:25:28,900
알고 싶다면 읽어볼 만한 좋은 논문임을 알려드립니다.

631
00:25:28,900 --> 00:25:31,240
이들은 훨씬 더 복잡한 아키텍처를

632
00:25:31,240 --> 00:25:34,400
사용하지만, 실제로 꽤 좋은 결과를 얻습니다.

633
00:25:34,400 --> 00:25:36,120
그리고 GAN의 정말 좋은 점 중

634
00:25:36,120 --> 00:25:38,320
하나는 잠재 공간에서 실제로 부드러운 것을 학습하는

635
00:25:38,320 --> 00:25:39,500
경향이 있다는 겁니다.

636
00:25:39,500 --> 00:25:43,080
제가 말하는 것은, 만약 두 개의 잠재 벡터 Z0와

637
00:25:43,080 --> 00:25:45,740
Z1이 있고 그 사이를 보간한다면, 즉

638
00:25:45,740 --> 00:25:49,260
가우시안에서 샘플 Z0를 뽑고, 또 가우시안에서

639
00:25:49,260 --> 00:25:51,180
샘플 Z1을 뽑는다는 뜻입니다.

640
00:25:51,180 --> 00:25:54,540
그다음 Z0와 Z1 사이의 어떤 곡선을 보간합니다.

641
00:25:54,540 --> 00:25:56,040
그 곡선상의 모든

642
00:25:56,040 --> 00:26:00,067
점마다 생성기를 사용해 샘플을 생성합니다.

643
00:26:00,067 --> 00:26:02,400
그렇게 하면 잠재 공간을 통해 부드러운 보간이

644
00:26:02,400 --> 00:26:04,275
이루어지는 경향이 있는데, 이것이

645
00:26:04,275 --> 00:26:05,560
GAN의 정말 멋진 점입니다.

646
00:26:05,560 --> 00:26:08,480
여기 StyleGAN3 논문에서 나온 잠재

647
00:26:08,480 --> 00:26:10,600
공간 보간의 예가 있습니다.

648
00:26:10,600 --> 00:26:14,000
이 잠재 z를 부드럽게 변화시키고

649
00:26:14,000 --> 00:26:16,932
생성기에 통과시켜 다양한 샘플을

650
00:26:16,932 --> 00:26:18,640
생성한 것임을

651
00:26:18,640 --> 00:26:20,280
볼 수 있습니다.

652
00:26:20,280 --> 00:26:22,900
그리고 이 동물들이 서로 부드럽게 변형되는 모습을

653
00:26:22,900 --> 00:26:23,953
확인할 수 있습니다.

654
00:26:23,953 --> 00:26:25,620
즉, 모델이 어떤 식으로든

655
00:26:25,620 --> 00:26:27,700
유용한 구조를 발견해서

656
00:26:27,700 --> 00:26:29,940
잠재 공간에 담아냈다는 의미입니다.

657
00:26:29,940 --> 00:26:32,260
그거 참 멋지죠.

658
00:26:32,260 --> 00:26:35,420
예전에는 생성적 적대 신경망(GAN)에 대해 훨씬 더

659
00:26:35,420 --> 00:26:36,780
많이 이야기하곤 했습니다.

660
00:26:36,780 --> 00:26:39,020
장점은 기본적으로 매우 간단한 수식으로

661
00:26:39,020 --> 00:26:40,320
표현할 수 있다는 겁니다.

662
00:26:40,320 --> 00:26:43,400
그리고 StyleGAN3에서 봤듯이 잘 조정하면

663
00:26:43,400 --> 00:26:45,900
정말 멋진 결과, 아주 아름다운

664
00:26:45,900 --> 00:26:49,580
이미지, 고해상도, 아주 좋은 결과를 얻을 수 있습니다.

665
00:26:49,580 --> 00:26:52,220
하지만 단점은 우리가 이야기한 것처럼 훈련이 꽤

666
00:26:52,220 --> 00:26:53,583
불안정하다는 점입니다.

667
00:26:53,583 --> 00:26:55,000
볼 수 있는 손실 곡선이 없어요.

668
00:26:55,000 --> 00:26:56,480
훈련이 매우 불안정합니다.

669
00:26:56,480 --> 00:26:58,820
갑자기 폭발해서 모드 붕괴(mode

670
00:26:58,820 --> 00:27:02,102
collapse)가 발생하곤 합니다.

671
00:27:02,102 --> 00:27:03,560
갑자기 NaN이 나오기도 하고,

672
00:27:03,560 --> 00:27:05,200
무한대 값이 나오기도 합니다.

673
00:27:05,200 --> 00:27:07,200
판별기가 미쳐버리고,

674
00:27:07,200 --> 00:27:09,500
생성기는 계속 완전히 무작위인 쓰레기 같은

675
00:27:09,500 --> 00:27:10,320
결과물을 만들어내죠.

676
00:27:10,320 --> 00:27:13,340
이걸 진단할 수 있는 손실 곡선도 없고,

677
00:27:13,340 --> 00:27:14,500
정말 엉망인 상태입니다.

678
00:27:14,500 --> 00:27:16,380
그래서 GAN이 아주

679
00:27:16,380 --> 00:27:19,480
조심스럽게 조정하고 정규화, 샘플링 등 모든

680
00:27:19,480 --> 00:27:22,460
것을 철저히 통제하면 정말 좋은 결과를

681
00:27:22,460 --> 00:27:25,100
낼 수 있지만, 실제로는 매우 큰

682
00:27:25,100 --> 00:27:27,700
모델이나 대규모 데이터에 확장하기가

683
00:27:27,700 --> 00:27:29,120
꽤 어려웠습니다.

684
00:27:29,120 --> 00:27:31,680
그래서 GAN은 기본적으로

685
00:27:31,680 --> 00:27:36,940
2016년부터 2020년, 2021년쯤까지 대표적인 생성 모델

686
00:27:36,940 --> 00:27:38,160
카테고리였습니다.

687
00:27:38,160 --> 00:27:40,800
그 5년 동안 수천, 수만 편의 논문이

688
00:27:40,800 --> 00:27:43,200
나왔는데, 사람들은 다양한 GAN

689
00:27:43,200 --> 00:27:45,480
공식, 다양한 손실 함수, 다양한

690
00:27:45,480 --> 00:27:47,618
수학적 형식들을 시도했고, GAN을

691
00:27:47,618 --> 00:27:50,160
상상할 수 있는 모든 종류의 생성

692
00:27:50,160 --> 00:27:51,820
모델링 작업에 적용했습니다.

693
00:27:51,820 --> 00:27:54,600
그래서 이 기간 동안 GAN은 기본적으로 5~6년간

694
00:27:54,600 --> 00:27:57,080
대표적인 생성 모델링 프레임워크였던 거죠.

695
00:27:57,080 --> 00:27:59,460
그럼 우리는 이것을 그냥 당연하게 기대해야 할까요?

696
00:27:59,460 --> 00:28:02,040
이 부드러운 잠재 공간(latents)이 자연스럽게 나올 거라고 기대해야
하지 않을까요?

697
00:28:02,040 --> 00:28:04,800
저는 꼭 그렇지는 않다고 생각합니다. 왜냐하면 GAN에서

698
00:28:04,800 --> 00:28:08,240
일어날 수 있는 한 가지 현상은 생성기가 고정된 수의 데이터

699
00:28:08,240 --> 00:28:10,260
샘플만 암기할 수도 있기 때문입니다.

700
00:28:10,260 --> 00:28:12,920
만약 생성기가 잠재 변수 z를 무시하고 훈련

701
00:28:12,920 --> 00:28:15,160
데이터에서 10개의 샘플만 암기한다면

702
00:28:15,160 --> 00:28:16,017
어떻게 될까요?

703
00:28:16,017 --> 00:28:17,600
그리고 어떤 z를 넣어도 항상

704
00:28:17,600 --> 00:28:19,380
그 10개의 샘플 중 하나만

705
00:28:19,380 --> 00:28:20,900
출력하고 다른 것은 전혀 내놓지

706
00:28:20,900 --> 00:28:22,040
않는다면 말이죠.

707
00:28:22,040 --> 00:28:24,550
그 경우에는 생성기가 항상 실제 샘플 중

708
00:28:24,550 --> 00:28:26,300
하나와 비트 단위로 동일한

709
00:28:26,300 --> 00:28:28,460
것을 내놓기 때문에 판별기를 속일

710
00:28:28,460 --> 00:28:29,440
수 있습니다.

711
00:28:29,440 --> 00:28:30,940
그렇게 되면 생성기는

712
00:28:30,940 --> 00:28:34,020
사실상 몇 개의 유한한 샘플 근처에

713
00:28:34,020 --> 00:28:36,260
Dirac 델타 밀도를 쌓아놓고,

714
00:28:36,260 --> 00:28:39,420
다른 곳에는 확률 질량을 전혀 두지 않은

715
00:28:39,420 --> 00:28:40,400
셈이 됩니다.

716
00:28:40,400 --> 00:28:43,620
그래서 그게 생성기에게는 합법적인 해답이 될 수 있습니다.

717
00:28:43,620 --> 00:28:46,177
그리고 그 경우에는 절대 부드러운 잠재 공간을 얻을 수 없습니다.

718
00:28:46,177 --> 00:28:48,260
이것이 바로 이런 모델들이 우리가 원하는

719
00:28:48,260 --> 00:28:50,260
것과는 다른, 직관적이지 않은 해답으로

720
00:28:50,260 --> 00:28:51,860
붕괴할 수 있는 한 예입니다.

721
00:28:51,860 --> 00:28:52,820
아, 좋은 질문입니다.

722
00:28:52,820 --> 00:28:54,980
훈련 데이터셋과 잠재 변수 사이에는

723
00:28:54,980 --> 00:28:56,623
어떤 관계가 있을까요?

724
00:28:56,623 --> 00:28:58,540
이것은 GAN에 대해 매우

725
00:28:58,540 --> 00:29:00,120
근본적인 질문입니다.

726
00:29:00,120 --> 00:29:02,000
그래서 한 방향으로 매핑할 수 있습니다.

727
00:29:02,000 --> 00:29:03,500
그래서 생성기는 잠재 공간에서

728
00:29:03,500 --> 00:29:07,040
데이터 공간으로 매핑을 제공합니다. z에서 x로 매핑하죠.

729
00:29:07,040 --> 00:29:08,740
하지만 GAN에서는 일반적으로

730
00:29:08,740 --> 00:29:11,260
x에서 z로 다시 매핑할 방법이 없습니다.

731
00:29:11,260 --> 00:29:14,720
이 점이 GAN과 VAE의 아주 큰 차이점입니다.

732
00:29:14,720 --> 00:29:17,740
VAE는 x에서 z로 명시적인 매핑을 학습하지만,

733
00:29:17,740 --> 00:29:19,600
GAN에는 그런 것이 없습니다.

734
00:29:19,600 --> 00:29:21,200
역으로 계산하려고 시도할

735
00:29:21,200 --> 00:29:24,560
수는 있습니다—경사 하강법으로 수치적으로 역함수를

736
00:29:24,560 --> 00:29:25,660
구할 수도 있죠.

737
00:29:25,660 --> 00:29:28,080
그런 논문들도 있지만, 사실 x와

738
00:29:28,080 --> 00:29:31,440
z 사이에 명시적으로 강제된 관계는 없습니다.

739
00:29:31,440 --> 00:29:33,400
대신 판별기는 생성기에서

740
00:29:33,400 --> 00:29:35,837
나오는 출력들의 분포와 실제 데이터

741
00:29:35,837 --> 00:29:37,920
샘플들의 분포 사이의 분포

742
00:29:37,920 --> 00:29:40,040
정렬을 강제하려고 한다고

743
00:29:40,040 --> 00:29:42,082
생각할 수 있습니다. 명시적인

744
00:29:42,082 --> 00:29:43,120
감독 없이요.

745
00:29:43,120 --> 00:29:44,683
물론 GAN에 관해서라면, 아마도

746
00:29:44,683 --> 00:29:46,100
여러분이 생각하는 거의 모든 것에

747
00:29:46,100 --> 00:29:48,060
대해 최소한 열두 편 이상의 논문이 있을 겁니다.

748
00:29:48,060 --> 00:29:50,240
양방향 매핑을 모두 학습하려는 GAN

749
00:29:50,240 --> 00:29:52,700
변형에 관한 논문도 많지만, 그런

750
00:29:52,700 --> 00:29:54,840
시도들은 크게 성공하지 못했습니다.

751
00:29:54,840 --> 00:29:55,740
좋은 질문입니다.

752
00:29:55,740 --> 00:29:56,573
우리가 얻은 것은 무엇일까요?

753
00:29:56,573 --> 00:29:59,300
VAE로 넘어가면서 잠재 벡터를 얻었지만, 밀도

754
00:29:59,300 --> 00:30:00,420
추정은 포기했습니다.

755
00:30:00,420 --> 00:30:03,000
그리고 GAN에서는 우리가 제어할 수 있는 잠재 벡터를

756
00:30:03,000 --> 00:30:04,140
포기한 것처럼 보입니다.

757
00:30:04,140 --> 00:30:06,400
하지만 얻은 것은 훨씬 더 좋은 샘플입니다.

758
00:30:06,400 --> 00:30:09,280
VAE의 경우, VAE는 좋은 샘플을

759
00:30:09,280 --> 00:30:11,080
주지 않는 경향이 있습니다.

760
00:30:11,080 --> 00:30:14,280
VAE는 특징적으로 항상 흐릿합니다.

761
00:30:14,280 --> 00:30:16,220
그들은 결코 정말 좋아 보이지 않습니다.

762
00:30:16,220 --> 00:30:18,840
VAEs만으로는 절대 아주 깔끔하고

763
00:30:18,840 --> 00:30:21,243
선명한 샘플을 주지 않지만, GANs를

764
00:30:21,243 --> 00:30:22,660
사용하면 몇 가지

765
00:30:22,660 --> 00:30:28,220
예에서 보셨듯이 아주 선명하고 깔끔하며 좋은 샘플을 얻을 수 있습니다.
하지만

766
00:30:28,220 --> 00:30:30,260
이런 시스템을 조정하려고

767
00:30:30,260 --> 00:30:31,867
하면 정신을 잃게 됩니다.

768
00:30:31,867 --> 00:30:34,200
네, 추론 시에는 discriminator를 버리고

769
00:30:34,200 --> 00:30:35,325
generator만 사용합니다.

770
00:30:35,325 --> 00:30:38,942
그래서 추론할 때는 prior에서 샘플 z를 뽑아 generator에

771
00:30:38,942 --> 00:30:41,400
통과시키면 데이터에서 샘플을 얻을 수 있습니다.

772
00:30:41,400 --> 00:30:44,100
그래서 추론 시에는 매우, 매우 효율적입니다.

773
00:30:44,100 --> 00:30:44,600
좋습니다.

774
00:30:44,600 --> 00:30:46,340
GANs가 약 5~6년

775
00:30:46,340 --> 00:30:49,750
동안 생성 모델링의 대표적인 범주였다고

776
00:30:49,750 --> 00:30:50,780
말씀드렸죠.

777
00:30:50,780 --> 00:30:52,220
그럼 무엇이 그들을 대체했을까요?

778
00:30:52,220 --> 00:30:55,500
그것은 diffusion models라는 아주

779
00:30:55,500 --> 00:30:57,460
다른 범주의 모델이었습니다.

780
00:30:57,460 --> 00:31:00,300
여기서 몇 가지 주의사항을 말씀드려야 합니다.

781
00:31:00,300 --> 00:31:02,740
Diffusion model 관련 문헌은 정말 복잡합니다.

782
00:31:02,740 --> 00:31:05,500
논문을 읽으면 무슨 일이 일어나는지 알려주기

783
00:31:05,500 --> 00:31:07,600
전에 수학이 5페이지나 나옵니다.

784
00:31:07,600 --> 00:31:11,380
그리고 diffusion models로 이어지는 세 가지 서로

785
00:31:11,380 --> 00:31:13,240
다른 수학적 형식이 있는데, 모두

786
00:31:13,240 --> 00:31:14,660
수학적으로 매우 다릅니다.

787
00:31:14,660 --> 00:31:16,785
논문마다 표기법, 용어,

788
00:31:16,785 --> 00:31:18,960
수학적 형식이 매우

789
00:31:18,960 --> 00:31:20,100
다릅니다.

790
00:31:20,100 --> 00:31:23,080
그래서 이 분야는 정말 복잡한 하위 영역입니다.

791
00:31:23,080 --> 00:31:24,720
그래서 모든 diffusion

792
00:31:24,720 --> 00:31:28,225
model 변형과 그에 따른 수학적 형식을 완전히

793
00:31:28,225 --> 00:31:30,600
다루지 않을 것이라는 점을 크게 주의하셔야

794
00:31:30,600 --> 00:31:31,420
합니다.

795
00:31:31,420 --> 00:31:32,960
대신에, 제가 하려는 것은

796
00:31:32,960 --> 00:31:35,860
diffusion 모델에 대한 직관적인 개요와

797
00:31:35,860 --> 00:31:38,040
오늘날 가장 흔한 형태인 rectified

798
00:31:38,040 --> 00:31:40,540
flow 모델에 대한 직관적인

799
00:31:40,540 --> 00:31:42,480
기하학적 이해를 드리는 것입니다.

800
00:31:42,480 --> 00:31:45,212
diffusion 모델에 대해 많은 강의를

801
00:31:45,212 --> 00:31:47,920
할 수 있고 다양한 수학적 세부사항을

802
00:31:47,920 --> 00:31:51,280
다룰 수 있지만, 불행히도 한 강의의 2/3

803
00:31:51,280 --> 00:31:53,320
시간 안에 그럴 여유는 없습니다.

804
00:31:53,320 --> 00:31:56,200
그 점을 감안하고 나면, diffusion

805
00:31:56,200 --> 00:31:59,000
모델의 직관은 사실 쉽습니다.

806
00:31:59,000 --> 00:32:03,320
모든 생성 모델과 마찬가지로, 우리는 샘플을 뽑고 싶습니다.

807
00:32:03,320 --> 00:32:08,080
GAN처럼, 우리는 노이즈 분포 z에서 데이터 분포

808
00:32:08,080 --> 00:32:11,722
px로 샘플을 변환하고 싶지만, diffusion

809
00:32:11,722 --> 00:32:14,180
모델에서 그 방법은

810
00:32:14,180 --> 00:32:15,380
완전히 다릅니다.

811
00:32:15,380 --> 00:32:17,300
GAN은 생성기를 통해 z를

812
00:32:17,300 --> 00:32:20,122
직접 x로 매핑하는 결정론적 함수를 학습합니다.

813
00:32:20,122 --> 00:32:21,580
diffusion 모델에서는

814
00:32:21,580 --> 00:32:24,060
좀 더 암묵적이고 간접적인 방식을 사용합니다.

815
00:32:24,060 --> 00:32:26,700
먼저 diffusion 모델의 첫

816
00:32:26,700 --> 00:32:30,420
번째 제약은 z, 즉 노이즈 분포가 항상

817
00:32:30,420 --> 00:32:33,640
데이터와 같은 형태를 가져야 한다는 것입니다.

818
00:32:33,640 --> 00:32:36,560
그래서 이미지가 H 곱하기 W 곱하기 3이라면,

819
00:32:36,560 --> 00:32:38,060
노이즈 분포도 항상 H 곱하기

820
00:32:38,060 --> 00:32:39,840
W 곱하기 3이어야 합니다.

821
00:32:39,840 --> 00:32:42,220
모양이 정확히 같아야 합니다.

822
00:32:42,220 --> 00:32:45,940
이제 우리는 점점 더 많은 노이즈 수준으로 손상된

823
00:32:45,940 --> 00:32:49,393
데이터의 다양한 버전을 고려할 것입니다.

824
00:32:49,393 --> 00:32:51,060
여기서 데이터

825
00:32:51,060 --> 00:32:54,700
샘플이 고양이 사진이라면, t는 0에서

826
00:32:54,700 --> 00:32:58,420
1까지 범위의 노이즈 수준이 됩니다.

827
00:32:58,420 --> 00:33:00,920
t가 0이라는 것은 노이즈가 없다는 뜻입니다.

828
00:33:00,920 --> 00:33:03,260
즉, 완전히 깨끗한 데이터 샘플이라는 겁니다.

829
00:33:03,260 --> 00:33:06,000
t가 0.3이면 약간의 노이즈가 있다는 뜻입니다.

830
00:33:06,000 --> 00:33:08,560
노이즈 z를 일부 데이터

831
00:33:08,560 --> 00:33:11,240
x에 섞어서 넣는 거죠.

832
00:33:11,240 --> 00:33:14,210
t가 1까지 가면 완전한 노이즈가 됩니다.

833
00:33:14,210 --> 00:33:15,960
그것들은 노이즈 분포에서

834
00:33:15,960 --> 00:33:17,660
직접 뽑은 샘플이 될 겁니다.

835
00:33:17,660 --> 00:33:21,040
어떤 식으로든 이 t 파라미터가 데이터 분포와

836
00:33:21,040 --> 00:33:24,422
노이즈 분포 사이를 부드럽게 보간할 겁니다.

837
00:33:24,422 --> 00:33:25,880
그리고 이건 우리가 할

838
00:33:25,880 --> 00:33:27,720
수 있는 것이고, 노이즈

839
00:33:27,720 --> 00:33:30,760
분포는 거의 항상 Gaussian, 즉 우리가

840
00:33:30,760 --> 00:33:33,707
이해하고 샘플링할 수 있는 단순한 분포입니다.

841
00:33:33,707 --> 00:33:36,040
이제 신경망을 훈련시켜서 점진적으로

842
00:33:36,040 --> 00:33:38,440
노이즈를 제거하도록 할 겁니다.

843
00:33:38,440 --> 00:33:43,208
신경망은 중간 정도의 노이즈가 섞인 데이터

844
00:33:43,208 --> 00:33:45,000
샘플을

845
00:33:45,000 --> 00:33:46,662
입력으로 받습니다.

846
00:33:46,662 --> 00:33:48,120
그리고 신경망은

847
00:33:48,120 --> 00:33:50,340
그 노이즈를 조금

848
00:33:50,340 --> 00:33:52,360
제거하도록 훈련될 겁니다.

849
00:33:52,360 --> 00:33:53,960
훈련 목표는

850
00:33:53,960 --> 00:33:58,777
신경망이 노이즈가 섞인 이미지를 입력받아

851
00:33:58,777 --> 00:34:00,360
일부 노이즈를

852
00:34:00,360 --> 00:34:02,245
제거하는 것입니다.

853
00:34:02,245 --> 00:34:04,120
추론 시에는 노이즈

854
00:34:04,120 --> 00:34:06,480
분포 pz에서 직접 노이즈

855
00:34:06,480 --> 00:34:10,380
샘플을 뽑고, 신경망을 반복 적용해

856
00:34:10,380 --> 00:34:12,340
한 번에 조금씩

857
00:34:12,340 --> 00:34:15,500
노이즈를 제거하는 절차를 수행합니다.

858
00:34:15,500 --> 00:34:17,639
처음에는 완전한

859
00:34:17,639 --> 00:34:20,522
노이즈 샘플을 뽑습니다.

860
00:34:20,522 --> 00:34:21,980
그리고 신경망의 첫

861
00:34:21,980 --> 00:34:23,397
적용에서는 완전한

862
00:34:23,397 --> 00:34:26,225
노이즈에서 노이즈를 제거하려고 시도합니다.

863
00:34:26,225 --> 00:34:28,100
즉, 노이즈 속에서 아주

864
00:34:28,100 --> 00:34:31,620
작은 데이터 구조를 상상해내야 하는 거죠.

865
00:34:31,620 --> 00:34:34,617
조금 덜 노이즈가 섞인

866
00:34:34,617 --> 00:34:36,659
샘플이 되면

867
00:34:36,659 --> 00:34:39,380
다시 신경망에 넣어 조금

868
00:34:39,380 --> 00:34:43,630
더 노이즈를 제거하도록 합니다.

869
00:34:43,630 --> 00:34:45,380
점점 덜 노이즈가 섞이고,

870
00:34:45,380 --> 00:34:47,199
또 덜 노이즈가

871
00:34:47,199 --> 00:34:49,320
섞이고, 계속 그렇게 됩니다.

872
00:34:49,320 --> 00:34:52,080
모든 설정이 제대로 되면,

873
00:34:52,080 --> 00:34:53,739
완전한 노이즈

874
00:34:53,739 --> 00:34:56,020
샘플을 뽑고 신경망에

875
00:34:56,020 --> 00:34:57,700
노이즈를

876
00:34:57,700 --> 00:35:01,440
제거하도록 반복해서 결국 모든 노이즈를

877
00:35:01,440 --> 00:35:03,900
제거해 시스템에서 생성된

878
00:35:03,900 --> 00:35:07,160
샘플을 얻을 수 있습니다.

879
00:35:07,160 --> 00:35:09,040
이건 좀 이상한 설정입니다.

880
00:35:09,040 --> 00:35:11,960
이게 바로 diffusion 모델의

881
00:35:11,960 --> 00:35:13,280
직관입니다.

882
00:35:13,280 --> 00:35:15,940
스텝 수가 고정된 하이퍼파라미터인가요?

883
00:35:15,940 --> 00:35:16,620
그건 경우에 따라 다릅니다.

884
00:35:16,620 --> 00:35:18,840
이 슬라이드에서는

885
00:35:18,840 --> 00:35:22,600
일부러 매우 모호하게 설명했습니다.

886
00:35:22,600 --> 00:35:23,700
노이즈가 무엇인지,

887
00:35:23,700 --> 00:35:26,500
데이터를 노이즈로 오염시키는 게 무슨 의미인지,

888
00:35:26,500 --> 00:35:28,900
노이즈를 조금 제거하는 게 무슨 의미인지,

889
00:35:28,900 --> 00:35:32,263
추론 시 반복 적용하는 게 무슨 의미인지,

890
00:35:32,263 --> 00:35:34,680
diffusion에는 다양한

891
00:35:34,680 --> 00:35:36,840
형식과 변형이 많아서

892
00:35:36,840 --> 00:35:39,220
상황에 따라 의미가 다릅니다.

893
00:35:39,220 --> 00:35:41,480
이 슬라이드는 diffusion의 큰 그림을

894
00:35:41,480 --> 00:35:42,568
보여주기 위한 것입니다.

895
00:35:42,568 --> 00:35:44,360
그리고 diffusion

896
00:35:44,360 --> 00:35:46,920
모델의 구체적 구현마다 이

897
00:35:46,920 --> 00:35:49,840
용어들의 의미가 다를 수 있습니다.

898
00:35:49,840 --> 00:35:53,940
이 diffusion의 큰 그림이 이해가 되시나요?

899
00:35:53,940 --> 00:35:55,980
좋습니다, 그러면 좀 더 구체적으로 들어가 보겠습니다.

900
00:35:55,980 --> 00:35:59,400
이제 일반 diffusion 모델에서

901
00:35:59,400 --> 00:36:02,080
rectified flow 모델이라는 특정

902
00:36:02,080 --> 00:36:03,940
범주로 넘어가겠습니다.

903
00:36:03,940 --> 00:36:06,860
어떤 분들은 rectified flow가 diffusion이 아니라고

904
00:36:06,860 --> 00:36:07,793
주장할 수도 있습니다.

905
00:36:07,793 --> 00:36:09,960
어떤 분들은 둘이 다르다고 말할 수도 있죠.

906
00:36:09,960 --> 00:36:11,060
저는 별로 신경 쓰지 않습니다.

907
00:36:11,060 --> 00:36:13,800
저에게 rectified flow는 일종의 diffusion
model입니다.

908
00:36:13,800 --> 00:36:15,220
한번 싸워보시죠.

909
00:36:15,220 --> 00:36:18,260
그래서 rectified flow의 직관은 기본적으로 이렇습니다.

910
00:36:18,260 --> 00:36:19,720
우리는 같은 것을 가지고 있습니다.

911
00:36:19,720 --> 00:36:20,640
우리는 pnoise를 가지고 있습니다.

912
00:36:20,640 --> 00:36:21,560
우리는 pdata를 가지고 있습니다.

913
00:36:21,560 --> 00:36:23,310
그리고 저는 이것을 기하학적으로 그릴

914
00:36:23,310 --> 00:36:25,640
건데, 직관을 얻기에 좋은 방법이라고 생각합니다.

915
00:36:25,640 --> 00:36:28,140
특히 2차원에서 기하학적으로 그릴 텐데,

916
00:36:28,140 --> 00:36:29,960
그게 슬라이드에 다 들어가기

917
00:36:29,960 --> 00:36:32,377
때문입니다. 물론 실제로는 이

918
00:36:32,377 --> 00:36:34,300
이미지들과 가우시안은 매우

919
00:36:34,300 --> 00:36:37,140
고차원입니다. 2차원, 3차원에서 통하는 직관이

920
00:36:37,140 --> 00:36:39,560
고차원에서는 완전히 통하지 않기 때문에

921
00:36:39,560 --> 00:36:41,300
쉽게 오해할 수 있습니다.

922
00:36:41,300 --> 00:36:42,160
정말 안타깝죠.

923
00:36:42,160 --> 00:36:44,960
우리가 이렇게 저차원 우주에 살고 있다는

924
00:36:44,960 --> 00:36:47,380
게 안타깝습니다. 이 우주에서 만든

925
00:36:47,380 --> 00:36:50,200
직관이 100차원, 1000차원 공간에는 잘

926
00:36:50,200 --> 00:36:51,680
적용되지 않으니까요.

927
00:36:51,680 --> 00:36:54,040
항상 이 점을 유념하세요, 하지만 어쩔 수 없습니다.

928
00:36:54,040 --> 00:36:56,180
우리는 가진 우주에 갇혀 있습니다.

929
00:36:56,180 --> 00:36:58,060
그래서 rectified flow의

930
00:36:58,060 --> 00:37:01,840
설정은 pnoise 분포와 pdata 분포를 가지고 있다는 겁니다.

931
00:37:01,840 --> 00:37:03,320
pnoise는 우리가 이해하고

932
00:37:03,320 --> 00:37:06,020
샘플링할 수 있으며 적분도 계산할 수 있는 단순한 분포입니다.

933
00:37:06,020 --> 00:37:08,108
아주 친근한 분포죠. pdata는 다시 말해 복잡한

934
00:37:08,108 --> 00:37:08,900
분포입니다.

935
00:37:08,900 --> 00:37:12,240
우주가 우리에게 이미지를 주기 위해 사용하는 분포입니다.

936
00:37:12,240 --> 00:37:14,640
이제 매 학습 반복마다,

937
00:37:14,640 --> 00:37:18,800
우리는 prior 분포에서 z를 샘플링하고 데이터

938
00:37:18,800 --> 00:37:21,600
분포에서 x를 샘플링할 겁니다.

939
00:37:21,600 --> 00:37:23,440
pz는 우리가 제어하는 단순한

940
00:37:23,440 --> 00:37:26,100
분포이기 때문에 샘플을 해석적으로 그릴 수 있습니다.

941
00:37:26,100 --> 00:37:28,320
데이터 분포에서 샘플을 그린다는 건

942
00:37:28,320 --> 00:37:31,600
유한한 학습 세트에서 예제를 고르는 것을 의미합니다.

943
00:37:31,600 --> 00:37:34,640
그리고 0에서 1 사이에서 균등하게

944
00:37:34,640 --> 00:37:36,340
t를 선택할 겁니다.

945
00:37:36,340 --> 00:37:39,940
t는 노이즈 레벨로, t=0은 노이즈 없음,

946
00:37:39,940 --> 00:37:42,280
t=1은 완전 노이즈 상태입니다.

947
00:37:42,280 --> 00:37:44,840
이제 데이터 샘플 x에서

948
00:37:44,840 --> 00:37:48,720
노이즈 샘플 z로 향하는 선을 그릴

949
00:37:48,720 --> 00:37:49,600
겁니다.

950
00:37:49,600 --> 00:37:52,840
이 선, 즉 x에서 z로 향하는

951
00:37:52,840 --> 00:37:55,160
벡터를 v라고 부르겠습니다. 이것이 flow field의

952
00:37:55,160 --> 00:37:57,280
속도 벡터가 됩니다.

953
00:37:57,280 --> 00:38:01,860
그리고 xt는 이 선 위의 한 점으로, x와

954
00:38:01,860 --> 00:38:04,780
z 사이의 선형 보간입니다.

955
00:38:04,780 --> 00:38:06,860
그래서 이제 노이즈 샘플

956
00:38:06,860 --> 00:38:09,260
z, 데이터 샘플 x, 그 사이의

957
00:38:09,260 --> 00:38:12,580
속도 벡터 v, 그리고 노이즈 버전의

958
00:38:12,580 --> 00:38:15,140
데이터 xt를 갖게 되었습니다.

959
00:38:15,140 --> 00:38:19,458
이전 슬라이드에서 '노이즈가 있는 데이터 얻기'라고 했을 때,
rectified

960
00:38:19,458 --> 00:38:22,000
flow 모델에서는 이것이 의미하는 바입니다.

961
00:38:22,000 --> 00:38:24,180
데이터 샘플과 노이즈 샘플

962
00:38:24,180 --> 00:38:26,380
사이의 선형 보간입니다.

963
00:38:26,380 --> 00:38:28,880
이제 학습 목표는 매우 간단합니다.

964
00:38:28,880 --> 00:38:31,400
이제 학습 가능한 파라미터 theta를 가진

965
00:38:31,400 --> 00:38:33,540
신경망 f theta를 학습할 겁니다.

966
00:38:33,540 --> 00:38:36,860
그 신경망은 노이즈가 있는 샘플 xt와 노이즈 레벨

967
00:38:36,860 --> 00:38:38,580
t를 입력으로 받습니다.

968
00:38:38,580 --> 00:38:41,580
그리고 초록색 벡터 v를 예측하려고 합니다.

969
00:38:41,580 --> 00:38:42,480
그게 전부입니다.

970
00:38:42,480 --> 00:38:44,900
rectified flow에서 우리가 해야 할 일은 그것뿐입니다.

971
00:38:44,900 --> 00:38:47,180
이 코드가 매우 간단합니다.

972
00:38:47,180 --> 00:38:50,340
여기 논문을 읽으면 얼마나 난해한지

973
00:38:50,340 --> 00:38:51,640
깜짝 놀랄 겁니다.

974
00:38:51,640 --> 00:38:53,478
하지만 결국 이 아주 간단한 코드로 요약됩니다.

975
00:38:53,478 --> 00:38:55,020
많은 발표에서 이 부분이 더

976
00:38:55,020 --> 00:38:57,580
명확하게 설명되지 않는 게 정말 답답합니다.

977
00:38:57,580 --> 00:38:59,640
그래서 rectified flow의

978
00:38:59,640 --> 00:39:01,200
학습 루프는 매우 간단합니다.

979
00:39:01,200 --> 00:39:03,460
매 반복마다 데이터셋을 순회합니다.

980
00:39:03,460 --> 00:39:08,720
x와 같은 형태의 단위 가우시안 z를 얻습니다.

981
00:39:08,720 --> 00:39:11,980
0에서 1 사이의 균등 분포에서 노이즈 레벨 t를 선택합니다.

982
00:39:11,980 --> 00:39:14,600
x와 z 사이를 선형 보간하여 xt를

983
00:39:14,600 --> 00:39:15,720
계산합니다.

984
00:39:15,720 --> 00:39:18,040
xt와 t를 모델에 입력하고,

985
00:39:18,040 --> 00:39:20,040
손실은 이 실제값

986
00:39:20,040 --> 00:39:24,200
v와 모델 예측 간의 평균 제곱 오차입니다.

987
00:39:24,200 --> 00:39:24,900
그게 전부입니다.

988
00:39:24,900 --> 00:39:27,720
이것이 rectified flow 모델의 학습 목표입니다.

989
00:39:27,720 --> 00:39:29,320
GAN과 비교해 보겠습니다.

990
00:39:29,320 --> 00:39:31,440
정류 흐름 모델이나 사실상 모든 종류의

991
00:39:31,440 --> 00:39:33,200
확산 모델을 훈련할 때, 훈련 중에

992
00:39:33,200 --> 00:39:35,100
볼 수 있는 손실 함수가 있습니다.

993
00:39:35,100 --> 00:39:37,460
손실이 줄어들면 모델이 일반적으로 더 좋아집니다.

994
00:39:37,460 --> 00:39:40,360
그래서 GAN 광풍을 반년 넘게 겪은

995
00:39:40,360 --> 00:39:42,840
우리에게, 확산 모델을 처음 훈련하고

996
00:39:42,840 --> 00:39:45,660
손실을 볼 수 있다는 건, 와, 정말

997
00:39:45,660 --> 00:39:47,023
놀라운 일입니다.

998
00:39:47,023 --> 00:39:49,440
우리가 GAN 플롯을 몇 시간이나 봤는데,

999
00:39:49,440 --> 00:39:50,420
이런 모양이었죠?

1000
00:39:50,420 --> 00:39:51,300
그리고 전혀 알 수가 없었습니다.

1001
00:39:51,300 --> 00:39:52,880
모델이 잘 작동하는지 차잎을

1002
00:39:52,880 --> 00:39:54,140
읽는 것 같았습니다.

1003
00:39:54,140 --> 00:39:55,640
확산 모델을 훈련하면,

1004
00:39:55,640 --> 00:39:57,720
아름답고 부드러운

1005
00:39:57,720 --> 00:40:01,980
지수 손실 곡선을 얻어서 정말 기쁩니다. 정말 좋죠.

1006
00:40:01,980 --> 00:40:03,700
이게 확산 모델

1007
00:40:03,700 --> 00:40:05,420
훈련입니다.

1008
00:40:05,420 --> 00:40:09,417
그럼 추론 단계에서는 어떻게 할까요? GAN은 추론이

1009
00:40:09,417 --> 00:40:10,500
꽤 쉽습니다.

1010
00:40:10,500 --> 00:40:12,880
GAN은 그냥 z를 받아서 생성기에 통과시키면 됩니다.

1011
00:40:12,880 --> 00:40:13,977
데이터 샘플을 얻죠.

1012
00:40:13,977 --> 00:40:16,060
매우 간단합니다. 하지만 확산

1013
00:40:16,060 --> 00:40:19,300
모델이나 이 경우 정류 흐름 모델에서는 모델

1014
00:40:19,300 --> 00:40:21,180
출력 자체가 쓸모가 없습니다.

1015
00:40:21,180 --> 00:40:22,240
xt를 얻고,

1016
00:40:22,240 --> 00:40:24,160
v를 얻습니다. 이걸 가지고 무엇을 할까요?

1017
00:40:24,160 --> 00:40:25,220
그다지 명확하지 않습니다.

1018
00:40:25,220 --> 00:40:26,900
그래서 추론 시점에서

1019
00:40:26,900 --> 00:40:28,483
diffusion

1020
00:40:28,483 --> 00:40:31,700
모델은 GAN보다 좀 더 복잡해집니다.

1021
00:40:31,700 --> 00:40:34,780
추론 시에는 먼저 보통 고정된

1022
00:40:34,780 --> 00:40:36,980
상수인 단계 수

1023
00:40:36,980 --> 00:40:38,532
t를 정합니다.

1024
00:40:38,532 --> 00:40:40,240
rectified flow

1025
00:40:40,240 --> 00:40:43,120
모델의 경우 보통 t=50이 적당한 시작점입니다.

1026
00:40:43,120 --> 00:40:45,940
때로는 t=30까지 줄여도 괜찮습니다.

1027
00:40:45,940 --> 00:40:48,860
그다음에는 노이즈 분포에서 직접

1028
00:40:48,860 --> 00:40:50,320
x를 샘플링합니다.

1029
00:40:50,320 --> 00:40:52,862
이것은 알려진 노이즈 분포에서

1030
00:40:52,862 --> 00:40:54,500
샘플링한 순수 노이즈입니다.

1031
00:40:54,500 --> 00:40:56,880
그다음에는 t=1부터

1032
00:40:56,880 --> 00:40:59,663
루프를 돌립니다.

1033
00:40:59,663 --> 00:41:01,580
t=0까지 역순으로 진행합니다.

1034
00:41:01,580 --> 00:41:02,735
이것이 노이즈 레벨입니다.

1035
00:41:02,735 --> 00:41:04,360
이 간단한 버전에서는

1036
00:41:04,360 --> 00:41:07,920
완전 노이즈 1에서 완전 깨끗한

1037
00:41:07,920 --> 00:41:11,025
노이즈 0으로 선형적으로 진행합니다.

1038
00:41:11,025 --> 00:41:12,400
첫 번째 반복에서는

1039
00:41:12,400 --> 00:41:16,400
처음에 완전 노이즈였던 xt를 현재 노이즈 레벨과

1040
00:41:16,400 --> 00:41:18,880
함께 네트워크에 넣어 네트워크가

1041
00:41:18,880 --> 00:41:21,280
예측한 vt를 얻습니다.

1042
00:41:21,280 --> 00:41:23,180
rectified flow의 경우 이 vt가

1043
00:41:23,180 --> 00:41:24,520
무엇을 의미하는지 기억하세요.

1044
00:41:24,520 --> 00:41:28,840
이 v는 데이터 샘플에서 노이즈 샘플로 향하는

1045
00:41:28,840 --> 00:41:30,820
벡터여야 합니다.

1046
00:41:30,820 --> 00:41:32,480
그래서 rectified flow의

1047
00:41:32,480 --> 00:41:34,893
경우 기하학적으로 무엇을 해야 할지 명확합니다.

1048
00:41:34,893 --> 00:41:36,560
예측된 v 벡터를 따라 조금

1049
00:41:36,560 --> 00:41:40,440
이동해야 합니다. 문제는 이 rectified flow 모델의

1050
00:41:40,440 --> 00:41:42,560
v가 깨끗한 샘플까지 완전히 가리키지

1051
00:41:42,560 --> 00:41:43,810
않는다는 점입니다.

1052
00:41:43,810 --> 00:41:45,268
그저 시작점만 알려줄 뿐입니다.

1053
00:41:45,268 --> 00:41:46,840
깨끗한 샘플로 가는

1054
00:41:46,840 --> 00:41:48,458
경로를 설정해주는 거죠.

1055
00:41:48,458 --> 00:41:51,000
그래서 flow 모델이 예측한 v를

1056
00:41:51,000 --> 00:41:54,832
따라 조금 이동해 새로운 x2를 얻습니다. 이 x2는

1057
00:41:54,832 --> 00:41:56,540
모델이 노이즈를 조금

1058
00:41:56,540 --> 00:41:58,180
제거한 데이터 버전입니다.

1059
00:41:58,180 --> 00:41:59,480
그리고 이 과정을 반복합니다.

1060
00:41:59,480 --> 00:42:01,805
x2를 얻으면 다시 모델에

1061
00:42:01,805 --> 00:42:03,180
넣어 또

1062
00:42:03,180 --> 00:42:06,260
다른 예측된 v 벡터를 얻습니다.

1063
00:42:06,260 --> 00:42:10,740
v는 깨끗한 샘플에서 노이즈 샘플로 향하는 벡터여야 한다는

1064
00:42:10,740 --> 00:42:12,240
점을 기억하세요.

1065
00:42:12,240 --> 00:42:14,040
그래서 다시 이 예측된

1066
00:42:14,040 --> 00:42:15,780
v를 따라 조금

1067
00:42:15,780 --> 00:42:17,820
이동해 x1을 얻습니다.

1068
00:42:17,820 --> 00:42:19,820
이 과정을 반복합니다.

1069
00:42:19,820 --> 00:42:22,460
모델을 평가해 또 다른 예측된

1070
00:42:22,460 --> 00:42:25,940
v를 얻고, 이번에는 노이즈가

1071
00:42:25,940 --> 00:42:29,900
전혀 없는 끝점까지 이동해 x0를 얻습니다.

1072
00:42:29,900 --> 00:42:32,460
이 x0가 diffusion 모델에서의 샘플입니다.

1073
00:42:32,460 --> 00:42:34,940
그래서 여기서 보시는 추론

1074
00:42:34,940 --> 00:42:38,100
절차는 GAN보다 좀 더

1075
00:42:38,100 --> 00:42:41,360
복잡하지만, 얻은 것은 안정성입니다.

1076
00:42:41,360 --> 00:42:42,860
학습할 때 안정성을

1077
00:42:42,860 --> 00:42:45,960
되찾았고, 훨씬 더 좋은 샘플을

1078
00:42:45,960 --> 00:42:48,060
내며 대규모 데이터셋과

1079
00:42:48,060 --> 00:42:49,822
모델에도 잘 확장됩니다.

1080
00:42:49,822 --> 00:42:51,280
코드는 매우 간단합니다.

1081
00:42:51,280 --> 00:42:54,340
무작위 샘플을 완전히 랜덤하게

1082
00:42:54,340 --> 00:42:57,200
시작하고, t=1부터 0까지

1083
00:42:57,200 --> 00:42:59,520
역순으로 진행합니다.

1084
00:42:59,520 --> 00:43:01,558
각 노이즈 레벨에서

1085
00:43:01,558 --> 00:43:03,600
현재 샘플과 t를 입력으로

1086
00:43:03,600 --> 00:43:06,560
모델이 예측한 v를 얻습니다. 그다음 모델이 예측한 v에 대해 경사 하강법

1087
00:43:06,560 --> 00:43:09,680
스텝처럼 보이는 작은 이동을 하고 샘플을

1088
00:43:09,680 --> 00:43:11,840
업데이트하며 이 과정을 반복합니다.

1089
00:43:11,840 --> 00:43:14,240
그래서 결국 이 diffusion 모델들이 그렇게 무섭지

1090
00:43:14,240 --> 00:43:15,640
않다는 걸 알 수 있습니다.

1091
00:43:15,640 --> 00:43:17,880
사실 rectified flow

1092
00:43:17,880 --> 00:43:19,920
모델의 학습과 샘플링을 완전히 구현한

1093
00:43:19,920 --> 00:43:23,540
코드를 한 슬라이드에 몇 줄로 간단히 표현할 수 있는데,

1094
00:43:23,540 --> 00:43:26,360
저는 이 점이 아주 좋다고 생각합니다.

1095
00:43:26,360 --> 00:43:28,780
좋습니다, 그래서 아마 이런 질문을 받을 수도 있겠네요-- 꽤 괜찮습니다.

1096
00:43:28,780 --> 00:43:31,093
전체 구현까지 도달할 수 있어서 저는 꽤 만족스럽습니다-- 그리고

1097
00:43:31,093 --> 00:43:32,260
이 코드는 실제로 작동할 겁니다.

1098
00:43:32,260 --> 00:43:34,600
이 코드를 가져다가 적절한

1099
00:43:34,600 --> 00:43:37,560
모델 아키텍처에 적용하면 실제로 작동할

1100
00:43:37,560 --> 00:43:38,560
수 있습니다.

1101
00:43:38,560 --> 00:43:40,185
많은 경우에 이것이 합리적인

1102
00:43:40,185 --> 00:43:41,720
결과로 변환될 겁니다.

1103
00:43:41,720 --> 00:43:44,200
여러분이 지금 짚고 있는 부분이 바로 제가 지난 며칠간

1104
00:43:44,200 --> 00:43:46,120
이 슬라이드를 보면서 많이 고민했던

1105
00:43:46,120 --> 00:43:47,580
생성 모델링의 핵심 문제입니다.

1106
00:43:47,580 --> 00:43:49,320
생성 모델링의 핵심

1107
00:43:49,320 --> 00:43:51,740
문제는, 샘플링할 수 있는 prior

1108
00:43:51,740 --> 00:43:53,520
분포인 z가 있고,

1109
00:43:53,520 --> 00:43:55,103
생성하고자 하는 데이터 분포인

1110
00:43:55,103 --> 00:43:56,680
x가 있다는 점입니다.

1111
00:43:56,680 --> 00:43:58,700
그리고 생성 모델링의 핵심

1112
00:43:58,700 --> 00:44:01,600
문제는 z와 x를 어떻게 연관 짓느냐인데,

1113
00:44:01,600 --> 00:44:03,600
다양한 생성 모델링 방법들이

1114
00:44:03,600 --> 00:44:05,340
이를 다르게 해결합니다.

1115
00:44:05,340 --> 00:44:09,100
VAE에서는 모델이 z를 예측하고 그 다음 x를 예측하도록

1116
00:44:09,100 --> 00:44:11,460
하면서, 그 z가 샘플링할 수 있는 분포가

1117
00:44:11,460 --> 00:44:13,380
되도록 강제하는데, 이 방법은

1118
00:44:13,380 --> 00:44:15,420
그렇게 잘 작동하지 않습니다.

1119
00:44:15,420 --> 00:44:18,598
GAN에서는 그 관계를 감독하지 않습니다.

1120
00:44:18,598 --> 00:44:20,140
생성자는 discriminator가

1121
00:44:20,140 --> 00:44:23,107
주는 분포 매칭 목표를 통해 feedforward

1122
00:44:23,107 --> 00:44:24,940
방식으로 z에서 x로의

1123
00:44:24,940 --> 00:44:26,740
매핑을 스스로 찾아내는 거죠.

1124
00:44:26,740 --> 00:44:30,860
diffusion 모델에서는 결국 이 곡선들을

1125
00:44:30,860 --> 00:44:33,700
적분하는 방식으로 해결합니다.

1126
00:44:33,700 --> 00:44:37,580
그리고 이런 목표 함수들이 확률 분포를

1127
00:44:37,580 --> 00:44:40,060
합리적으로 맞추는 이유에 대해

1128
00:44:40,060 --> 00:44:41,900
여러 수학적 형식들이

1129
00:44:41,900 --> 00:44:43,220
존재합니다.

1130
00:44:43,220 --> 00:44:45,420
하지만 다시 말해, 핵심 문제는

1131
00:44:45,420 --> 00:44:48,180
prior에서 샘플링한 z와 데이터에서

1132
00:44:48,180 --> 00:44:51,280
샘플링한 x를 미리 짝지을 방법이

1133
00:44:51,280 --> 00:44:52,340
없다는 점입니다.

1134
00:44:52,340 --> 00:44:53,840
만약 우리가 그 쌍을 만드는

1135
00:44:53,840 --> 00:44:57,487
방법과 사전 분포에서 샘플링하는 방법을 안다면, 끝난 겁니다.

1136
00:44:57,487 --> 00:44:59,320
어떤 의미에서는, 이러한

1137
00:44:59,320 --> 00:45:01,040
다양한 형태의 생성 모델링이

1138
00:45:01,040 --> 00:45:02,720
모두 그 문제를 해결하고

1139
00:45:02,720 --> 00:45:06,960
z에서 x로의 연관성을 학습하며, 훈련 시점에 그 연관성이

1140
00:45:06,960 --> 00:45:08,680
없어도 z에서 샘플링할 수

1141
00:45:08,680 --> 00:45:11,210
있는 방법을 찾는 다양한 방식입니다.

1142
00:45:11,210 --> 00:45:12,960
이것에 대한 해석이

1143
00:45:12,960 --> 00:45:15,500
매우 복잡해질 수 있어서

1144
00:45:15,500 --> 00:45:19,040
저는 그런 부분은 피하려고 했습니다.

1145
00:45:19,040 --> 00:45:23,000
하지만 지난 강의에서 무조건적인 생성 모델링은 무의미하다고

1146
00:45:23,000 --> 00:45:26,320
했으니, 우리가 거의 항상 관심 있는 것은

1147
00:45:26,320 --> 00:45:28,260
조건부 생성 모델링입니다.

1148
00:45:28,260 --> 00:45:30,700
그리고 이것은 rectified flow에서 쉽게 적용할 수 있습니다.

1149
00:45:30,700 --> 00:45:32,820
조건부 rectified flow를

1150
00:45:32,820 --> 00:45:35,520
하려면, 데이터 분포에 여러 하위 부분이 있다고

1151
00:45:35,520 --> 00:45:36,320
상상하면 됩니다.

1152
00:45:36,320 --> 00:45:37,780
여기서는 범주형이라고 말하는 거죠.

1153
00:45:37,780 --> 00:45:40,320
우리 데이터가 실제로는 정사각형과 삼각형일 수도 있습니다.

1154
00:45:40,320 --> 00:45:43,520
그리고 전체 데이터 분포 pdata와 두

1155
00:45:43,520 --> 00:45:47,400
개의 하위 분포, 즉 y가 정사각형일 때의 pdata

1156
00:45:47,400 --> 00:45:51,583
x와 y가 삼각형일 때의 pdata x가 있습니다.

1157
00:45:51,583 --> 00:45:53,500
이것이 조건부 생성 모델링을

1158
00:45:53,500 --> 00:45:56,380
생각할 때 머릿속에 떠올려야 할 그림입니다.

1159
00:45:56,380 --> 00:45:57,820
그럼 rectified flow의

1160
00:45:57,820 --> 00:45:59,520
경우에는 이것을 매우 쉽게 적용할 수 있습니다.

1161
00:45:59,520 --> 00:46:02,740
데이터 세트에는 이제 x와 y 쌍이 있고,

1162
00:46:02,740 --> 00:46:05,380
모델은 y를 추가 보조 입력으로

1163
00:46:05,380 --> 00:46:06,300
받습니다.

1164
00:46:06,300 --> 00:46:09,860
샘플링할 때도 마찬가지입니다.

1165
00:46:09,860 --> 00:46:11,460
예측된 V들을 얻습니다.

1166
00:46:11,460 --> 00:46:14,840
모델은 이 추가 y를 입력으로 받고, 그것을 사용합니다.

1167
00:46:14,840 --> 00:46:16,500
이 모든 과정이 그대로 진행됩니다.

1168
00:46:16,500 --> 00:46:18,700
차이점은 이제 y가 실제로 사용자가

1169
00:46:18,700 --> 00:46:20,100
제어할 수 있는 어떤

1170
00:46:20,100 --> 00:46:21,553
조건부 신호라는 점입니다.

1171
00:46:21,553 --> 00:46:22,720
아마도 이것은 텍스트 프롬프트일 수 있습니다.

1172
00:46:22,720 --> 00:46:23,928
아마도 이것은 입력 이미지일 수 있습니다.

1173
00:46:23,928 --> 00:46:25,823
아마도 이것은 추론 시에 기대하는

1174
00:46:25,823 --> 00:46:27,740
어떤 사용자 입력일 수 있는데,

1175
00:46:27,740 --> 00:46:29,823
이것이 실제로 이 모델들을 제어

1176
00:46:29,823 --> 00:46:31,740
가능하고 실용적으로 만드는 겁니다.

1177
00:46:31,740 --> 00:46:34,326
하지만 또 다른 정말 흥미로운 질문이 있습니다.

1178
00:46:34,326 --> 00:46:37,140
모델이 조건 신호에 얼마나 집중할지

1179
00:46:37,140 --> 00:46:39,580
조절할 수 있는 노브가

1180
00:46:39,580 --> 00:46:40,240
있을까요?

1181
00:46:40,240 --> 00:46:42,368
알고 보니 이런 모델들을 단순히

1182
00:46:42,368 --> 00:46:44,660
훈련시키면, 원하는 만큼 조건 신호를

1183
00:46:44,660 --> 00:46:46,900
잘 따르지 않는 경우가 많습니다.

1184
00:46:46,900 --> 00:46:49,320
그래서 classifier free

1185
00:46:49,320 --> 00:46:54,040
guidance, 줄여서 CFG라는 트릭이 있는데, 이것은 우리의
diffusion 훈련

1186
00:46:54,040 --> 00:46:55,280
루프를 조금 바꿉니다.

1187
00:46:55,280 --> 00:46:56,480
그래서 우리가 할

1188
00:46:56,480 --> 00:46:58,647
일은 여전히 xt와 y를

1189
00:46:58,647 --> 00:47:03,900
입력으로 받는 조건부 diffusion 모델을 훈련시키되, 매 훈련 반복마다

1190
00:47:03,900 --> 00:47:05,360
동전을 던지는 겁니다.

1191
00:47:05,360 --> 00:47:08,040
동전이 앞면이면 조건 정보를

1192
00:47:08,040 --> 00:47:08,760
삭제합니다.

1193
00:47:08,760 --> 00:47:10,760
즉, 조건 정보를 0값이나

1194
00:47:10,760 --> 00:47:13,680
널 값으로 설정해서 50% 확률로

1195
00:47:13,680 --> 00:47:15,502
조건 정보를 없애는 거죠.

1196
00:47:15,502 --> 00:47:17,960
이 확률은 하이퍼파라미터가 될 수 있지만, 50%가

1197
00:47:17,960 --> 00:47:19,335
대부분 실무에서 좋은 값입니다.

1198
00:47:19,335 --> 00:47:20,585
그래서 동전을 던집니다.

1199
00:47:20,585 --> 00:47:23,047
동전이 앞면이면 조건 정보를 삭제합니다.

1200
00:47:23,047 --> 00:47:24,880
이 말은 모델이 개념적으로 두

1201
00:47:24,880 --> 00:47:27,610
가지 다른 속도 벡터를 배우도록 강제된다는

1202
00:47:27,610 --> 00:47:28,110
뜻입니다.

1203
00:47:32,640 --> 00:47:36,040
그래서 모델은 두 가지 다른 속도 벡터를

1204
00:47:36,040 --> 00:47:37,420
배우도록 강제됩니다.

1205
00:47:37,420 --> 00:47:42,240
그래서 y에 대해 조건 정보를 파괴한 null 값을

1206
00:47:42,240 --> 00:47:44,180
전달하는 경우에는, 이것이

1207
00:47:44,180 --> 00:47:46,880
기본적으로 무조건 생성 모델이

1208
00:47:46,880 --> 00:47:47,500
됩니다.

1209
00:47:47,500 --> 00:47:51,660
예측된 속도 벡터 v는 전체 데이터 분포

1210
00:47:51,660 --> 00:47:55,780
pdata의 중심을 향해야 하는데, 실제 조건

1211
00:47:55,780 --> 00:47:58,380
입력 y를 전달하면, 즉 파괴되지

1212
00:47:58,380 --> 00:48:01,620
않고 null도 0도 아닌 경우에는,

1213
00:48:01,620 --> 00:48:04,580
전체 데이터 분포가 아니라

1214
00:48:04,580 --> 00:48:07,973
우리가 관심 있는 조건 신호에 따른

1215
00:48:07,973 --> 00:48:10,140
조건부 데이터 분포를 향하는

1216
00:48:10,140 --> 00:48:11,890
조건부 속도

1217
00:48:11,890 --> 00:48:13,460
벡터를 얻는 겁니다.

1218
00:48:13,460 --> 00:48:15,620
그리고 간단한 트릭은

1219
00:48:15,620 --> 00:48:18,340
이 두 벡터의 선형 결합을

1220
00:48:18,340 --> 00:48:24,260
취해서 조건부 속도 벡터 쪽으로 더 밀어주는 겁니다.

1221
00:48:24,260 --> 00:48:26,860
특히 스칼라 하이퍼파라미터 w를 두고,

1222
00:48:26,860 --> 00:48:29,100
1+w 곱하기 vy에서 w

1223
00:48:29,100 --> 00:48:32,362
곱하기 v null을 뺀 선형 결합을 취합니다.

1224
00:48:32,362 --> 00:48:33,820
이렇게 하면

1225
00:48:33,820 --> 00:48:38,580
이제 데이터 분포보다 조건부 분포를 더 향하는

1226
00:48:38,580 --> 00:48:40,380
벡터가 됩니다.

1227
00:48:40,380 --> 00:48:44,498
그리고 샘플링할 때는 이제 모델이

1228
00:48:44,498 --> 00:48:46,040
예측한 원래

1229
00:48:46,040 --> 00:48:51,360
벡터 대신 이 v CFG 벡터에 따라 한 스텝씩

1230
00:48:51,360 --> 00:48:53,560
이동하는 겁니다.

1231
00:48:53,560 --> 00:48:57,000
그리고 여기서 w를 0으로 설정하면

1232
00:48:57,000 --> 00:48:59,800
정확히 조건부 1을

1233
00:48:59,800 --> 00:49:01,740
복원할 수 있습니다.

1234
00:49:01,740 --> 00:49:03,592
w가 클수록 조건 신호를 더

1235
00:49:03,592 --> 00:49:05,550
과도하게 강조하는 겁니다.

1236
00:49:08,120 --> 00:49:10,020
이 방법은 구현하기 꽤 쉽습니다.

1237
00:49:10,020 --> 00:49:13,560
그래서 추론 코드는 크게 바뀌지 않지만, 매

1238
00:49:13,560 --> 00:49:15,960
반복마다 모델을 두 번

1239
00:49:15,960 --> 00:49:18,120
평가해서 vy와 v0를 얻고,

1240
00:49:18,120 --> 00:49:20,320
그다음 이 선형 결합을 취해서 그에

1241
00:49:20,320 --> 00:49:22,280
따라 한 스텝 이동하는 겁니다.

1242
00:49:22,280 --> 00:49:25,792
이 방법을 classifier free라고 부르는데, 사실 좀 어처구니없는
이유 때문입니다.

1243
00:49:25,792 --> 00:49:28,000
이전에 classifier guidance라는 논문이 있었는데,

1244
00:49:28,000 --> 00:49:29,340
그건 자세히 다루고 싶지 않습니다.

1245
00:49:29,340 --> 00:49:31,040
그리고 나서 분류기를 제거했죠.

1246
00:49:31,040 --> 00:49:33,040
두 논문 사이에 9개월밖에 안 됐고 두 번째

1247
00:49:33,040 --> 00:49:35,700
논문이 나온 지 4년이 지났지만, 우리는 아직도 classifier

1248
00:49:35,700 --> 00:49:38,075
free guidance라는 이름을 쓰고 있습니다.

1249
00:49:38,075 --> 00:49:39,555
그냥 그런 겁니다.

1250
00:49:39,555 --> 00:49:41,680
좋습니다, 실제로 고품질 출력을

1251
00:49:41,680 --> 00:49:44,440
얻기 위해 매우 중요한 것이 바로 CFG입니다.

1252
00:49:44,440 --> 00:49:45,440
이것은 정말 중요합니다.

1253
00:49:45,440 --> 00:49:47,540
확산 모델 어디에서나 사용됩니다.

1254
00:49:47,540 --> 00:49:49,420
하지만 샘플링 비용이 두 배가

1255
00:49:49,420 --> 00:49:51,628
되는데, 매 반복마다 모델을 두 번

1256
00:49:51,628 --> 00:49:53,692
호출해야 하기 때문입니다. 이게 문제죠.

1257
00:49:53,692 --> 00:49:55,400
최적 예측에 관한 내용이 있습니다.

1258
00:49:55,400 --> 00:49:56,358
그 부분은 건너뛰겠습니다.

1259
00:49:56,358 --> 00:49:58,100
그다지 흥미롭지 않습니다.

1260
00:49:58,100 --> 00:50:01,880
흥미롭긴 한데 시간이 걱정되네요.

1261
00:50:01,880 --> 00:50:04,060
하지만 때때로 t

1262
00:50:04,060 --> 00:50:08,200
분포를 조정해야 할 때가 있습니다.

1263
00:50:08,200 --> 00:50:10,660
특히 원시 rectified

1264
00:50:10,660 --> 00:50:13,060
flow 모델에서 t를 균등 분포에

1265
00:50:13,060 --> 00:50:15,540
따라 샘플링하는 것을 봤습니다.

1266
00:50:15,540 --> 00:50:18,020
그런데 이 방식은 모든 노이즈

1267
00:50:18,020 --> 00:50:21,320
레벨에 균등한 비중을 둔다는 점입니다.

1268
00:50:21,320 --> 00:50:23,920
직관적으로, 노이즈가 가득한

1269
00:50:23,920 --> 00:50:26,740
상태에서는 문제가 매우 쉽습니다.

1270
00:50:26,740 --> 00:50:29,400
노이즈가 가득한 상태에서는 문제가 매우 쉽습니다.

1271
00:50:29,400 --> 00:50:31,697
그때 모델의 최적 예측은 기본적으로

1272
00:50:31,697 --> 00:50:33,780
데이터 분포의 평균을

1273
00:50:33,780 --> 00:50:34,860
가리키는 것입니다.

1274
00:50:34,860 --> 00:50:37,760
마찬가지로, 노이즈가 0일 때 최적

1275
00:50:37,760 --> 00:50:39,420
예측은 실제로 노이즈

1276
00:50:39,420 --> 00:50:42,300
분포의 평균을 가리키는 것입니다.

1277
00:50:42,300 --> 00:50:44,680
그래서 실제로 모델의 최적 예측은 노이즈가

1278
00:50:44,680 --> 00:50:48,240
가득한 상태와 데이터가 완전한 상태, 즉 노이즈가 없는 상태 모두

1279
00:50:48,240 --> 00:50:50,180
상대적으로 매우 쉬운 문제입니다.

1280
00:50:50,180 --> 00:50:53,080
그냥 두 분포의 평균을 배우면 됩니다.

1281
00:50:53,080 --> 00:50:55,180
하지만 중간 어딘가에 있을

1282
00:50:55,180 --> 00:50:57,890
때는 실제로 매우 어렵습니다. 왜냐하면

1283
00:50:57,890 --> 00:51:00,140
중간 어딘가에 있고 xt를 샘플링할

1284
00:51:00,140 --> 00:51:02,280
때, 그 같은 xt를 만들

1285
00:51:02,280 --> 00:51:06,420
수 있는 여러 쌍의 x와 z가 있을 수 있기 때문입니다.

1286
00:51:06,420 --> 00:51:07,920
그래서 네트워크는 기본적으로

1287
00:51:07,920 --> 00:51:09,600
이 기대값 문제를

1288
00:51:09,600 --> 00:51:11,960
해결해야 하고, 이 xt 지점에서 교차할

1289
00:51:11,960 --> 00:51:15,920
수 있는 모든 가능한 x와 z를 통합하는 최적의 예측 방향이

1290
00:51:15,920 --> 00:51:17,823
무엇인지 알아내야 합니다.

1291
00:51:17,823 --> 00:51:20,240
그래서 중간 지점의 포인트들은 직관적으로

1292
00:51:20,240 --> 00:51:24,320
네트워크가 해결하기 훨씬 더 어렵지만, 0부터 1까지

1293
00:51:24,320 --> 00:51:28,280
균일하게 샘플링하면 모든 노이즈 레벨에 동일한 중요도를

1294
00:51:28,280 --> 00:51:30,740
부여하게 되어 이 직관과 맞지 않습니다.

1295
00:51:30,740 --> 00:51:32,320
그래서 실제로는 종종 다른

1296
00:51:32,320 --> 00:51:34,040
노이즈 스케줄에서 샘플링합니다.

1297
00:51:34,040 --> 00:51:35,680
그리고 매우 인기 있는 방법 중

1298
00:51:35,680 --> 00:51:38,320
하나가 logit-normal 샘플링인데, 기본적으로

1299
00:51:38,320 --> 00:51:40,660
가우시안처럼 보이고 0과 1에는 상대적으로

1300
00:51:40,660 --> 00:51:43,683
적은 가중치를 두고 중간에 더 많은 가중치를 둡니다.

1301
00:51:43,683 --> 00:51:45,100
또 가끔 볼 수 있는 것은

1302
00:51:45,100 --> 00:51:47,100
비대칭적인 shifted noise

1303
00:51:47,100 --> 00:51:49,260
schedules로, 한쪽 방향으로 더

1304
00:51:49,260 --> 00:51:50,500
치우친 스케줄입니다.

1305
00:51:50,500 --> 00:51:53,118
이것들은 고해상도 데이터로 확장할 때 중요합니다.

1306
00:51:53,118 --> 00:51:55,660
직관적으로, 해상도가 매우 높은 이미지일 때는

1307
00:51:55,660 --> 00:51:57,220
인접한 픽셀들 간에 매우

1308
00:51:57,220 --> 00:51:59,138
강한 상관관계가 있을 수 있습니다.

1309
00:51:59,138 --> 00:52:00,680
해상도가 낮은 이미지일 때는

1310
00:52:00,680 --> 00:52:02,660
인접한 픽셀들 간의 상관관계가 더

1311
00:52:02,660 --> 00:52:03,820
작아지는 경향이 있습니다.

1312
00:52:03,820 --> 00:52:05,980
그래서 데이터 내 상관관계의

1313
00:52:05,980 --> 00:52:07,620
강도에 따라 적절하게

1314
00:52:07,620 --> 00:52:09,500
정보를 파괴하기 위해 필요한

1315
00:52:09,500 --> 00:52:12,300
노이즈 수준이 달라질 수 있습니다.

1316
00:52:12,300 --> 00:52:16,490
이런 것들은 단순히 해상도에 맞춰서 조정되지 않습니다.

1317
00:52:16,490 --> 00:52:18,740
사실 이런 diffusion

1318
00:52:18,740 --> 00:52:21,600
모델들의 큰 문제점 중 하나는, 매우 훌륭한

1319
00:52:21,600 --> 00:52:23,940
수식화이지만 고해상도 데이터에

1320
00:52:23,940 --> 00:52:26,180
단순 적용하기 어렵다는 점입니다.

1321
00:52:26,180 --> 00:52:28,100
그래서 실제로는—제가

1322
00:52:28,100 --> 00:52:30,620
diffusion 모델이 가장 인기 있는 생성

1323
00:52:30,620 --> 00:52:31,800
모델이라고 했는데,

1324
00:52:31,800 --> 00:52:34,092
그건 약간 과장된 말이고, 실제로 가장

1325
00:52:34,092 --> 00:52:36,140
인기 있는 것은 latent diffusion

1326
00:52:36,140 --> 00:52:39,840
모델이라 불리는 변형으로, 이게 사실상 어디서나 사용됩니다.

1327
00:52:39,840 --> 00:52:42,080
여기서는 다단계 절차가 진행될 것입니다.

1328
00:52:42,080 --> 00:52:45,280
그래서 우리가 할 일은 먼저 인코더 네트워크와 디코더 네트워크를

1329
00:52:45,280 --> 00:52:46,580
훈련하는 것입니다.

1330
00:52:46,580 --> 00:52:49,000
인코더 네트워크는 이미지를 잠재 공간으로

1331
00:52:49,000 --> 00:52:52,740
매핑하는 역할을 하며, 여기서는 보라색으로 표시했습니다.

1332
00:52:52,740 --> 00:52:55,160
이 잠재 공간은 이상적으로 이미지의

1333
00:52:55,160 --> 00:52:58,480
공간 해상도를 D배로 줄이고, 채널 수는

1334
00:52:58,480 --> 00:53:00,175
3개에서 C개로 변환합니다.

1335
00:53:00,175 --> 00:53:01,800
일반적인 설정은 공간

1336
00:53:01,800 --> 00:53:05,540
해상도를 8x8로 줄이고 채널 수를 16개로 늘리는 것입니다.

1337
00:53:05,540 --> 00:53:08,680
이것이 가장 흔한 인코더-디코더 구조 중 하나입니다.

1338
00:53:08,680 --> 00:53:11,460
이 인코더-디코더들은 보통 CNN과 어텐션을

1339
00:53:11,460 --> 00:53:15,440
결합한 형태지만, 최근 논문들은 VIT를 적용하기도 했습니다.

1340
00:53:15,440 --> 00:53:18,240
그다음에 하는 것은, 원본 이미지의 픽셀

1341
00:53:18,240 --> 00:53:20,180
공간이 아니라, 이 인코더-디코더

1342
00:53:20,180 --> 00:53:22,560
모델이 발견한 잠재 공간에서

1343
00:53:22,560 --> 00:53:24,420
확산 모델을 훈련하는 것입니다.

1344
00:53:24,420 --> 00:53:27,720
그래서 확산 모델 훈련 절차는, 이미지를

1345
00:53:27,720 --> 00:53:29,857
샘플링하고, 1단계에서 학습한

1346
00:53:29,857 --> 00:53:32,440
인코더를 통해 잠재 표현을 얻은

1347
00:53:32,440 --> 00:53:35,680
뒤, 그 잠재에 노이즈를 더하고, 확산

1348
00:53:35,680 --> 00:53:40,200
모델이 노이즈가 섞인 잠재를 복원하도록 훈련하는 방식입니다.

1349
00:53:40,200 --> 00:53:42,580
그리고 정말 중요한 점은, 인코더를

1350
00:53:42,580 --> 00:53:46,480
고정(freeze)해서 인코더 쪽으로는 그래디언트가 역전파되지 않도록 한다는
겁니다.

1351
00:53:46,480 --> 00:53:48,580
우리는 인코더가 학습한 잠재 공간(latent space)에서

1352
00:53:48,580 --> 00:53:50,413
직접 확산 모델(diffusion model)을

1353
00:53:50,413 --> 00:53:52,780
학습하기 위해 잠재 표현만 추출하는 데 인코더를 사용합니다.

1354
00:53:52,780 --> 00:53:55,240
그다음 추론 시에는, 학습이 모두 끝나면

1355
00:53:55,240 --> 00:53:57,180
무작위 잠재 벡터를 샘플링해서 확산

1356
00:53:57,180 --> 00:53:59,430
모델에 여러 번 통과시켜 모든 노이즈를

1357
00:53:59,430 --> 00:54:01,080
제거해 깨끗한 샘플을 얻는데,

1358
00:54:01,080 --> 00:54:04,260
그 깨끗한 샘플은 잠재 공간에서의 깨끗한 샘플입니다.

1359
00:54:04,260 --> 00:54:05,820
그래서 그 깨끗한 잠재 표현을

1360
00:54:05,820 --> 00:54:09,060
깨끗한 이미지로 변환하려면 디코더를 실행해야 합니다.

1361
00:54:09,060 --> 00:54:11,060
사실 이것이 요즘 대부분의

1362
00:54:11,060 --> 00:54:13,860
확산 모델에서 가장 일반적인 형태입니다.

1363
00:54:13,860 --> 00:54:16,300
그래서 여러분은 아마 이렇게 생각할 수 있겠죠, 좋아요,

1364
00:54:16,300 --> 00:54:18,560
우리는 이 확산 모델, 인코더-디코더를 다뤘는데,

1365
00:54:18,560 --> 00:54:20,160
그럼 인코더-디코더는 어떻게 학습할까요?

1366
00:54:20,160 --> 00:54:22,420
어떤 아이디어가 있나요?

1367
00:54:22,420 --> 00:54:25,020
인코더 디코더에 대해 배운 적 있나요?

1368
00:54:25,020 --> 00:54:26,837
변분 오토인코더는요?

1369
00:54:26,837 --> 00:54:29,420
실제로 잠재 확산 모델을 훈련할

1370
00:54:29,420 --> 00:54:31,700
때 이 인코더 디코더는

1371
00:54:31,700 --> 00:54:34,623
보통 변분 오토인코더인데, 변분

1372
00:54:34,623 --> 00:54:37,040
오토인코더의 큰 문제점은 출력이

1373
00:54:37,040 --> 00:54:38,582
흐릿하다는 거죠.

1374
00:54:38,582 --> 00:54:40,800
만약 이 인코더 디코더가 흐릿한

1375
00:54:40,800 --> 00:54:43,880
출력을 낸다면, 디코더에서 얻는 재구성

1376
00:54:43,880 --> 00:54:45,400
품질이 후속

1377
00:54:45,400 --> 00:54:47,520
확산 모델에서 생성되는 품질의

1378
00:54:47,520 --> 00:54:49,020
병목이 될 겁니다.

1379
00:54:49,020 --> 00:54:51,600
그래서 인코더 디코더가 흐릿하고 보기 안 좋은

1380
00:54:51,600 --> 00:54:54,220
재구성을 내면, 좋은 깨끗한 샘플을 얻을 수 없습니다.

1381
00:54:54,220 --> 00:54:56,360
그렇죠?

1382
00:54:56,360 --> 00:54:58,440
그렇다면 VAE의 샘플

1383
00:54:58,440 --> 00:55:01,600
품질을 개선할 방법이 있을까요?

1384
00:55:01,600 --> 00:55:04,840
특히 디코더 이후에 뭔가를 추가해서

1385
00:55:04,840 --> 00:55:07,640
GAN으로 만들 수 있습니다.

1386
00:55:07,640 --> 00:55:10,200
그래서 보통 이미지에서 잠재

1387
00:55:10,200 --> 00:55:12,960
공간으로 인코딩하는 인코더, 잠재

1388
00:55:12,960 --> 00:55:15,800
공간에서 이미지로 복원하는 디코더,

1389
00:55:15,800 --> 00:55:17,440
가짜 이미지와 진짜

1390
00:55:17,440 --> 00:55:20,560
이미지를 구분하는 판별기, 그리고

1391
00:55:20,560 --> 00:55:23,360
잠재 공간에서 생성하는 확산 모델을

1392
00:55:23,360 --> 00:55:24,820
함께 훈련합니다.

1393
00:55:24,820 --> 00:55:27,400
이런 다양한 생성 모델의 형태를

1394
00:55:27,400 --> 00:55:30,455
모두 살펴보는 이유가 바로 현대의 파이프라인을

1395
00:55:30,455 --> 00:55:32,580
이해하기 위해서입니다.

1396
00:55:32,580 --> 00:55:35,020
기본적으로 최신 생성 모델의 상태는

1397
00:55:35,020 --> 00:55:36,260
VAE인가요?

1398
00:55:36,260 --> 00:55:36,920
GAN인가요?

1399
00:55:36,920 --> 00:55:37,880
확산 모델인가요?

1400
00:55:37,880 --> 00:55:39,180
모두 다입니다.

1401
00:55:39,180 --> 00:55:40,120
모두 다입니다.

1402
00:55:40,120 --> 00:55:41,980
현대 생성 모델 파이프라인은

1403
00:55:41,980 --> 00:55:45,680
VAE, GAN, 확산 모델을 모두 훈련하는 것을 포함합니다.

1404
00:55:45,680 --> 00:55:46,280
죄송합니다.

1405
00:55:46,280 --> 00:55:47,820
정말 엉망입니다.

1406
00:55:47,820 --> 00:55:51,060
좋습니다, 그렇다면 여러분은 신경망이 실제로 내부에서 어떻게

1407
00:55:51,060 --> 00:55:52,820
생겼는지 궁금해할 수 있습니다.

1408
00:55:52,820 --> 00:55:55,180
다행히도 지난 몇 년간 어느

1409
00:55:55,180 --> 00:55:57,480
정도 일관성이 있었습니다.

1410
00:55:57,480 --> 00:55:59,940
상대적으로 단순한 transformers가 이

1411
00:55:59,940 --> 00:56:02,040
diffusion 모델에 적용될 수 있고, 매우 잘

1412
00:56:02,040 --> 00:56:03,500
작동한다는 것이 밝혀졌습니다.

1413
00:56:03,500 --> 00:56:06,760
이것들은 보통 diffusion transformers 또는

1414
00:56:06,760 --> 00:56:09,320
DiTs라고 불리지만, 기본적으로는 특별한 기술이

1415
00:56:09,320 --> 00:56:11,820
거의 없는 표준 diffusion 모델이나 표준

1416
00:56:11,820 --> 00:56:13,620
transformer 블록입니다.

1417
00:56:13,620 --> 00:56:15,180
몇 가지 질문이 있습니다.

1418
00:56:15,180 --> 00:56:17,740
아키텍처 측면에서 해결해야 할 주요 질문은 어떻게

1419
00:56:17,740 --> 00:56:20,460
conditioning 정보를 주입하느냐입니다.

1420
00:56:20,460 --> 00:56:22,060
특히 diffusion 모델은

1421
00:56:22,060 --> 00:56:24,038
이제 세 가지를 입력으로 받아야 합니다.

1422
00:56:24,038 --> 00:56:25,580
노이즈가 있는 이미지, 타임스탬프

1423
00:56:25,580 --> 00:56:26,982
t를 받아야 합니다.

1424
00:56:26,982 --> 00:56:28,940
또한 텍스트 같은

1425
00:56:28,940 --> 00:56:31,920
conditioning 신호도 받아야 합니다.

1426
00:56:31,920 --> 00:56:33,880
그리고 conditioning 신호를

1427
00:56:33,880 --> 00:56:36,520
transformer 블록에 주입하는 몇 가지

1428
00:56:36,520 --> 00:56:37,400
방법이 있습니다.

1429
00:56:37,400 --> 00:56:40,600
첫 번째는 diffusion 블록의 중간

1430
00:56:40,600 --> 00:56:42,360
활성화를 조절하는 데 사용할

1431
00:56:42,360 --> 00:56:45,385
scale과 shift를 예측하는 것입니다.

1432
00:56:45,385 --> 00:56:47,760
이것이 보통 diffusion 모델에

1433
00:56:47,760 --> 00:56:49,760
타임스탬프 정보를 주입하는 방법입니다.

1434
00:56:49,760 --> 00:56:51,950
또 다른 방법은 transformers가

1435
00:56:51,950 --> 00:56:54,200
시퀀스 모델이기 때문에 모든 것을

1436
00:56:54,200 --> 00:56:55,360
시퀀스에 넣는 것입니다.

1437
00:56:55,360 --> 00:56:57,220
타임스탬프를 시퀀스에 넣을 수 있습니다.

1438
00:56:57,220 --> 00:56:58,700
텍스트를 시퀀스에 넣을 수 있습니다.

1439
00:56:58,700 --> 00:57:00,658
원하는 어떤 것도 시퀀스에 넣고

1440
00:57:00,658 --> 00:57:03,440
transformer가 그 시퀀스 데이터를 함께 모델링하게

1441
00:57:03,440 --> 00:57:04,363
할 수 있습니다.

1442
00:57:04,363 --> 00:57:06,280
이것은 cross-attention이나 joint

1443
00:57:06,280 --> 00:57:09,420
attention을 통해 할 수 있고, 다양한 모델이 둘 다 사용합니다.

1444
00:57:09,420 --> 00:57:11,760
현대 diffusion DiTs에서는

1445
00:57:11,760 --> 00:57:14,520
보통 타임스탬프를 scale shift 메커니즘으로

1446
00:57:14,520 --> 00:57:15,300
주입합니다.

1447
00:57:15,300 --> 00:57:17,840
텍스트나 다른 conditioning 신호는 보통 시퀀스

1448
00:57:17,840 --> 00:57:20,440
연결, 주로 cross-attention을 통해

1449
00:57:20,440 --> 00:57:23,135
주입하지만 때로는 joint attention도 사용합니다.

1450
00:57:23,135 --> 00:57:24,760
그렇다면 이것을 어떻게 다양한

1451
00:57:24,760 --> 00:57:26,160
문제에 적용할 수 있을까요?

1452
00:57:26,160 --> 00:57:28,080
사람들이 많이 관심 갖는 작업 중

1453
00:57:28,080 --> 00:57:30,820
하나는 텍스트에서 이미지 생성하는 작업입니다.

1454
00:57:30,820 --> 00:57:32,802
여기서는 텍스트 프롬프트를 입력할 것입니다.

1455
00:57:32,802 --> 00:57:34,260
이것은 제가 어제 쓴 프롬프트입니다.

1456
00:57:34,260 --> 00:57:36,180
에펠탑 앞에서 호랑이와 악수하는

1457
00:57:36,180 --> 00:57:38,210
원숭이의 전문 다큐멘터리 사진입니다.

1458
00:57:38,210 --> 00:57:40,210
원숭이는 바나나로 만든 모자를 쓰고 있습니다.

1459
00:57:40,210 --> 00:57:42,300
호랑이는 두 발로 서서 정장을 입고 있습니다.

1460
00:57:42,300 --> 00:57:43,878
이것은 실제 샘플입니다.

1461
00:57:43,878 --> 00:57:45,420
이런 게 지금 작동한다니 정말

1462
00:57:45,420 --> 00:57:47,838
놀랍지만, 여러분도 이런 것들을 본 적 있을 겁니다.

1463
00:57:47,838 --> 00:57:49,380
작동하는 방식은 텍스트

1464
00:57:49,380 --> 00:57:51,620
프롬프트를 보통 사전 학습된 텍스트

1465
00:57:51,620 --> 00:57:53,260
인코더에 통과시키는 것입니다.

1466
00:57:53,260 --> 00:57:54,422
사실 제가 방금 거짓말을 했네요.

1467
00:57:54,422 --> 00:57:56,380
실제로 더 많은 모델을 학습해야 합니다.

1468
00:57:56,380 --> 00:57:58,140
인코더, 디코더, VAE,

1469
00:57:58,140 --> 00:57:59,915
디스크리미네이터 외에도, 이 모든 것이

1470
00:57:59,915 --> 00:58:01,540
작동하게 하려면 비밀리에

1471
00:58:01,540 --> 00:58:02,980
언어 모델도 학습해야 합니다.

1472
00:58:02,980 --> 00:58:05,272
그래서 보통은 사전 학습된 텍스트 인코더,

1473
00:58:05,272 --> 00:58:07,020
보통 T5나 CLIP 같은 걸

1474
00:58:07,020 --> 00:58:08,960
가져와서 텍스트 임베딩을 얻습니다.

1475
00:58:08,960 --> 00:58:10,920
그리고 보통 텍스트 인코더는 고정(frozen)됩니다.

1476
00:58:10,920 --> 00:58:13,740
그 다음 그 텍스트 임베딩과 노이즈가 있는 잠재

1477
00:58:13,740 --> 00:58:16,703
변수들을 함께 디퓨전 트랜스포머에 넣으면, 디퓨전

1478
00:58:16,703 --> 00:58:18,620
타임 스텝도 받아서 깨끗한

1479
00:58:18,620 --> 00:58:19,880
잠재 변수를 출력합니다.

1480
00:58:19,880 --> 00:58:22,120
이 과정은 반복적으로 진행됩니다.

1481
00:58:22,120 --> 00:58:24,100
그리고 그 결과를 VAE 디코더에

1482
00:58:24,100 --> 00:58:26,140
통과시켜 최종 이미지를 얻습니다.

1483
00:58:26,140 --> 00:58:28,640
좀 더 구체적으로 숫자를 들어보면, 현재

1484
00:58:28,640 --> 00:58:31,440
꽤 강력한 오픈소스 모델 중 하나가 FLUX1

1485
00:58:31,440 --> 00:58:32,860
dev라는 모델입니다.

1486
00:58:32,860 --> 00:58:34,500
이 모델은 T5와 CLIP 인코더를 사용합니다.

1487
00:58:34,500 --> 00:58:36,540
인코더는 8배 다운샘플링을 합니다.

1488
00:58:36,540 --> 00:58:38,800
12억 파라미터의 트랜스포머

1489
00:58:38,800 --> 00:58:41,000
모델을 학습하는데, 이 트랜스포머는

1490
00:58:41,000 --> 00:58:44,780
VAE 위에 추가 다운샘플링 레이어가 있어서

1491
00:58:44,780 --> 00:58:45,840
좀 복잡합니다.

1492
00:58:45,840 --> 00:58:50,320
그래서 최종적으로 1,024개의 이미지 토큰 시퀀스를 갖게 됩니다.

1493
00:58:50,320 --> 00:58:53,177
사람들이 많이 관심 가지는 또 다른 작업은 텍스트에서 비디오 생성입니다.

1494
00:58:53,177 --> 00:58:54,760
텍스트 프롬프트를 입력하면

1495
00:58:54,760 --> 00:58:57,740
그 텍스트에 맞는 비디오 픽셀을 출력하는 거죠.

1496
00:58:57,740 --> 00:59:00,578
파이프라인은 기본적으로 동일합니다.

1497
00:59:00,578 --> 00:59:03,120
사전 학습된 텍스트 인코더에 텍스트를 입력하고

1498
00:59:03,120 --> 00:59:04,980
노이즈가 있는 잠재 변수를 얻습니다.

1499
00:59:04,980 --> 00:59:07,400
중요한 차이점은 잠재 변수에

1500
00:59:07,400 --> 00:59:09,660
시간 차원이 추가된다는 겁니다.

1501
00:59:09,660 --> 00:59:12,040
즉, 공간적 차원 hw 외에 시간

1502
00:59:12,040 --> 00:59:14,040
차원이 잠재 변수에 포함되어 깨끗한

1503
00:59:14,040 --> 00:59:15,582
잠재 변수를 얻습니다.

1504
00:59:15,582 --> 00:59:17,520
그리고 디코더는 보통

1505
00:59:17,520 --> 00:59:19,860
시공간 오토인코더가 됩니다.

1506
00:59:19,860 --> 00:59:22,545
그래서 공간적, 시간적으로 다운샘플링을 합니다.

1507
00:59:22,545 --> 00:59:23,920
그 후 잠재 변수를

1508
00:59:23,920 --> 00:59:26,220
픽셀로 업샘플링해서

1509
00:59:26,220 --> 00:59:27,700
비디오를 생성합니다.

1510
00:59:27,700 --> 00:59:31,740
이것은 작년에 나온 Meta의 GOOVIGEN 논문에서

1511
00:59:31,740 --> 00:59:33,680
생성한 실제 비디오입니다.

1512
00:59:36,780 --> 00:59:39,340
여기에 구체적인 숫자도 나와

1513
00:59:39,340 --> 00:59:40,260
있습니다.

1514
00:59:40,260 --> 00:59:42,960
이 비디오 생성

1515
00:59:42,960 --> 00:59:45,460
모델들의 핵심은 시퀀스

1516
00:59:45,460 --> 00:59:47,620
길이 때문에

1517
00:59:47,620 --> 00:59:51,400
학습 비용이 매우 높다는

1518
00:59:51,400 --> 00:59:52,960
점입니다.

1519
00:59:52,960 --> 00:59:56,900
고해상도, 고프레임 비디오를 생성하려면

1520
00:59:56,900 --> 00:59:59,020
토큰 수가

1521
00:59:59,020 --> 01:00:02,100
엄청나게 많아지기 때문입니다.

1522
01:00:02,100 --> 01:00:03,960
앞서 말한 최첨단 텍스트-이미지

1523
01:00:03,960 --> 01:00:05,460
디퓨전 모델은

1524
01:00:05,460 --> 01:00:07,293
1,024개의 이미지

1525
01:00:07,293 --> 01:00:09,300
토큰 시퀀스를 처리했습니다.

1526
01:00:09,300 --> 01:00:13,273
텍스트-비디오 디퓨전 모델은 전체 구조는 비슷하지만

1527
01:00:13,273 --> 01:00:15,940
시퀀스 길이가 가장 큰

1528
01:00:15,940 --> 01:00:16,562
차이점입니다.

1529
01:00:16,562 --> 01:00:18,020
이 모델은 고해상도, 다수의

1530
01:00:18,020 --> 01:00:20,270
프레임을 가진 비디오를 생성하기 위해

1531
01:00:20,270 --> 01:00:23,020
76,000개의 비디오 토큰을 처리해야 합니다.

1532
01:00:23,020 --> 01:00:25,720
그래서 이 비디오 디퓨전 모델들의 비용이 많이

1533
01:00:25,720 --> 01:00:28,780
드는 이유는 바로 이렇게 긴 시퀀스를 처리하기 때문입니다.

1534
01:00:28,780 --> 01:00:33,843
지난 1년은 사실상 비디오 디퓨전 모델의

1535
01:00:33,843 --> 01:00:35,760
시대였다고 할

1536
01:00:35,760 --> 01:00:37,280
수 있습니다.

1537
01:00:37,280 --> 01:00:40,280
거의 매주 새로운 흥미로운 비디오 디퓨전

1538
01:00:40,280 --> 01:00:42,360
모델이 발표되고 있습니다.

1539
01:00:42,360 --> 01:00:44,800
이 모델들은 오픈소스 모델, 기술

1540
01:00:44,800 --> 01:00:47,362
보고서가 있는 모델, 그리고 아무 정보도

1541
01:00:47,362 --> 01:00:48,820
공개하지 않고 신용카드

1542
01:00:48,820 --> 01:00:49,880
결제만 받는

1543
01:00:49,880 --> 01:00:51,960
산업용 모델들이 혼합되어 있습니다.

1544
01:00:51,960 --> 01:00:55,622
그래서 이 모든 것을 하나하나 다 설명하지는 않겠지만,

1545
01:00:55,622 --> 01:00:57,080
지난 18개월 동안

1546
01:00:57,080 --> 01:01:01,680
이 주제가 정말 뜨거운 관심사였다는 점을 말씀드리고 싶었습니다.

1547
01:01:01,680 --> 01:01:04,160
특히 2024년 3월에 OpenAI에서 나온

1548
01:01:04,160 --> 01:01:06,760
Sora라는 매우 영향력 있는 블로그 글이

1549
01:01:06,760 --> 01:01:10,537
있었는데, 비디오에 대한 첫 번째 diffusion 모델은 아니었지만

1550
01:01:10,537 --> 01:01:13,120
정말, 정말, 정말 좋은 결과를 낸 첫

1551
01:01:13,120 --> 01:01:14,240
번째 모델이었습니다.

1552
01:01:14,240 --> 01:01:17,960
그들은 최신 diffusion transformer와 rectified

1553
01:01:17,960 --> 01:01:19,082
flow를 도입했습니다.

1554
01:01:19,082 --> 01:01:20,540
사실 Sora에서 rectified flow를

1555
01:01:20,540 --> 01:01:21,748
사용했는지는 잘 모르겠습니다.

1556
01:01:21,748 --> 01:01:24,180
그들이 말했는지 모르겠지만, 이 diffusion

1557
01:01:24,180 --> 01:01:26,660
transformer를 대규모로 확장해서 정말 잘 작동하게

1558
01:01:26,660 --> 01:01:28,320
만든 최초의 팀 중 하나였습니다.

1559
01:01:28,320 --> 01:01:31,020
그리고 그게 비디오 diffusion 모델에서 4분의 1마일

1560
01:01:31,020 --> 01:01:32,320
돌파 순간과 같았습니다.

1561
01:01:32,320 --> 01:01:34,653
그 후 다른 큰 회사들도 이를 주목하고 빠르게

1562
01:01:34,653 --> 01:01:36,420
Sora를 복제하려고 했습니다.

1563
01:01:36,420 --> 01:01:39,140
그래서 지난 1년 반 동안 거의 매주 새로운

1564
01:01:39,140 --> 01:01:41,260
최첨단 비디오 diffusion

1565
01:01:41,260 --> 01:01:43,660
모델이 나오는 것 같은 느낌이 들었습니다.

1566
01:01:43,660 --> 01:01:47,300
오늘도 예외는 아니어서, 오늘 오전

1567
01:01:47,300 --> 01:01:52,600
11시에 구글이 Veo 3를 발표했는데, 지금 당장 가장

1568
01:01:52,600 --> 01:01:55,100
뛰어난 비디오 생성 모델일

1569
01:01:55,100 --> 01:01:56,580
가능성이 큽니다.

1570
01:01:56,580 --> 01:01:58,740
저는 여기 오는 길 차 안에서

1571
01:01:58,740 --> 01:02:02,080
블로그 글을 읽었는데, 정말 멋져 보입니다.

1572
01:02:02,080 --> 01:02:04,780
여기 V3의 샘플 몇 개입니다.

1573
01:02:04,780 --> 01:02:07,460
이것들은 실제로 구글의 새 모델로 텍스트

1574
01:02:07,460 --> 01:02:10,760
프롬프트에서 생성된 비디오입니다, 꽤 놀랍죠.

1575
01:02:10,760 --> 01:02:13,660
또한 이 모델은 소리도 함께 모델링해서

1576
01:02:13,660 --> 01:02:17,540
비디오 프레임과 함께 오디오도 출력할 수 있습니다.

1577
01:02:17,540 --> 01:02:19,340
이것도 또 다른 생성된 예시인데,

1578
01:02:19,340 --> 01:02:21,600
텍스트로 원하는 내용을 말하면,

1579
01:02:21,600 --> 01:02:25,200
여기 위로 날아가고 정말 멋져 보입니다.

1580
01:02:25,200 --> 01:02:30,200
네, 새로운 것을 접목하는 게 재미있을 것 같아서 말씀드렸습니다.

1581
01:02:30,200 --> 01:02:32,920
좋습니다, diffusion의 큰 문제 중

1582
01:02:32,920 --> 01:02:35,460
하나는 샘플링할 때 정말 느리다는 점입니다.

1583
01:02:35,460 --> 01:02:37,660
우리는 샘플링이 반복적인 절차라고 말했죠.

1584
01:02:37,660 --> 01:02:39,140
그리고 이 모델들은 정말 클 수 있습니다.

1585
01:02:39,140 --> 01:02:40,600
이 모델들은 수십억 개의

1586
01:02:40,600 --> 01:02:42,960
파라미터를 가진 모델일 수 있고, 수만 개

1587
01:02:42,960 --> 01:02:45,360
이상의 시퀀스 길이에서 작동할 수 있습니다.

1588
01:02:45,360 --> 01:02:47,720
그래서 이런 것들은 추론 시에 정말

1589
01:02:47,720 --> 01:02:49,300
느려집니다. rectified

1590
01:02:49,300 --> 01:02:54,160
flow를 사용해도 추론 시에 수십 번의 반복이 필요하기 때문입니다.

1591
01:02:54,160 --> 01:02:56,640
그래서 해결책은 distillation이라고 불리는

1592
01:02:56,640 --> 01:02:59,057
알고리즘 범주인데, 시간 관계상 자세히 다루지는 않겠습니다.

1593
01:02:59,057 --> 01:03:01,098
여기 몇 가지 참고문헌을 넣어서 이런

1594
01:03:01,098 --> 01:03:03,460
기술들이 존재한다는 것을 알려드리고 싶었습니다.

1595
01:03:03,460 --> 01:03:05,520
distillation 알고리즘은

1596
01:03:05,520 --> 01:03:07,880
기본적으로 diffusion 모델이 추론

1597
01:03:07,880 --> 01:03:10,960
시 30, 50, 100번의 반복을 거쳐야 좋은

1598
01:03:10,960 --> 01:03:14,360
샘플을 얻을 수 있는데, 모델을 어떤 식으로든 수정해서

1599
01:03:14,360 --> 01:03:17,000
추론 시 훨씬 적은 단계로도 좋은 샘플을 얻을

1600
01:03:17,000 --> 01:03:18,560
수 있게 하는 방법입니다.

1601
01:03:18,560 --> 01:03:20,500
이들은 보통 샘플 품질을 어느 정도 희생합니다.

1602
01:03:20,500 --> 01:03:22,260
그래서 distillation

1603
01:03:22,260 --> 01:03:24,580
방법의 핵심은 추론 시 적은 단계로

1604
01:03:24,580 --> 01:03:26,300
샘플링하면서도 샘플 품질을 최대한

1605
01:03:26,300 --> 01:03:27,532
유지하는 것입니다.

1606
01:03:27,532 --> 01:03:29,740
어떤 distillation

1607
01:03:29,740 --> 01:03:32,320
방법은 단일 단계 샘플링까지

1608
01:03:32,320 --> 01:03:35,860
가능하게 하는데, 정말 멋지지만 그럴 때는

1609
01:03:35,860 --> 01:03:39,220
생성 품질이 꽤 떨어지는 경향이 있습니다.

1610
01:03:39,220 --> 01:03:40,840
이것들을 자세히 다루지는

1611
01:03:40,840 --> 01:03:42,420
않겠지만, distillation

1612
01:03:42,420 --> 01:03:44,100
관련 여러 논문들을

1613
01:03:44,100 --> 01:03:45,340
참고문헌으로 넣어두었습니다.

1614
01:03:45,340 --> 01:03:47,880
이 분야는 매우 활발하고 계속 발전하는 연구 영역입니다.

1615
01:03:47,880 --> 01:03:49,338
이 참고문헌들을 보면

1616
01:03:49,338 --> 01:03:52,180
2024년, 2025년 논문들이 포함되어 있습니다.

1617
01:03:52,180 --> 01:03:54,380
즉, 사람들이 지금도 더 나은

1618
01:03:54,380 --> 01:03:56,680
distillation 방법과

1619
01:03:56,680 --> 01:03:59,180
diffusion 모델의 추론 효율성을 높이는

1620
01:03:59,180 --> 01:04:01,580
방법을 연구하고 있다는 뜻입니다.

1621
01:04:01,580 --> 01:04:02,700
또 다른 점은요.

1622
01:04:02,700 --> 01:04:06,860
그래서 diffusion에는 수학의 블랙홀 같은 게 있어서 빠져들 수

1623
01:04:06,860 --> 01:04:08,318
있다고 말씀드렸습니다.

1624
01:04:08,318 --> 01:04:09,860
그리고 우리는 의도적으로

1625
01:04:09,860 --> 01:04:12,880
그 부분을 피해서 rectified flow 모델을

1626
01:04:12,880 --> 01:04:15,060
직관적으로 설명하며, 수학적으로

1627
01:04:15,060 --> 01:04:18,140
증명하는 대신 문제에 대한 기하학적 직관을 드렸습니다.

1628
01:04:18,140 --> 01:04:20,600
그래서 이런 형식들에 대해 간단히

1629
01:04:20,600 --> 01:04:22,600
소개해 드리려 하지만,

1630
01:04:22,600 --> 01:04:24,760
자세히 다루지는 않을 겁니다.

1631
01:04:24,760 --> 01:04:27,383
자, rectified flow 목표를 다시 말씀드리겠습니다.

1632
01:04:27,383 --> 01:04:28,800
훈련 중에는 데이터

1633
01:04:28,800 --> 01:04:31,280
분포에 따른 x와 노이즈 분포에

1634
01:04:31,280 --> 01:04:33,588
따른 z를 샘플링한다고 했습니다.

1635
01:04:33,588 --> 01:04:35,880
그리고 t는 우리가 선택한 분포 pt에서

1636
01:04:35,880 --> 01:04:38,840
샘플링하는데, 보통 uniform, logit-normal,

1637
01:04:38,840 --> 01:04:40,388
shifted 같은 분포입니다.

1638
01:04:40,388 --> 01:04:42,680
그다음 xt는 x와 z 사이의 선형

1639
01:04:42,680 --> 01:04:43,800
보간으로 설정합니다.

1640
01:04:43,800 --> 01:04:46,720
이 슬라이드에서는 조금 다르게

1641
01:04:46,720 --> 01:04:48,340
표현했습니다.

1642
01:04:48,340 --> 01:04:51,280
지금은 네트워크가 예측해야 하는 실제

1643
01:04:51,280 --> 01:04:54,160
속도 vgt를 z 빼기 x로 정의했습니다.

1644
01:04:54,160 --> 01:04:56,320
네트워크에 노이즈가 섞인

1645
01:04:56,320 --> 01:04:58,680
xt와 t를 넣어 예측된

1646
01:04:58,680 --> 01:05:01,400
v를 계산하고, vgt와 예측된

1647
01:05:01,400 --> 01:05:04,490
v 사이의 L2 손실을 최소화합니다.

1648
01:05:06,928 --> 01:05:09,220
다양한 형식과 종류의 diffusion이

1649
01:05:09,220 --> 01:05:11,840
있다고 했는데, 이들은

1650
01:05:11,840 --> 01:05:15,660
일반적으로 이 기본 설정에서 함수형 하이퍼파라미터를 다르게

1651
01:05:15,660 --> 01:05:16,880
설정하는 겁니다.

1652
01:05:16,880 --> 01:05:20,900
좀 더 일반화된 diffusion에서는 보통

1653
01:05:20,900 --> 01:05:23,883
pt 분포를 바꾸기도 합니다.

1654
01:05:23,883 --> 01:05:25,800
노이즈 분포는 보통 바꾸지 않는데, 연속 모델에서는 거의 항상
Gaussian입니다.

1655
01:05:25,800 --> 01:05:29,380
하지만 noisy xt를 어떻게

1656
01:05:29,380 --> 01:05:32,660
계산하느냐를 바꾸는데,

1657
01:05:32,660 --> 01:05:35,420
일반적으로 noisy xt는

1658
01:05:35,420 --> 01:05:38,420
x와 z의 선형 조합이며,

1659
01:05:38,420 --> 01:05:41,340
이 선형 조합의 가중치는 보통 t의 함수로

1660
01:05:41,340 --> 01:05:44,220
표현되지만, 정확한 함수는 diffusion

1661
01:05:44,220 --> 01:05:46,340
공식에 따라 다릅니다.

1662
01:05:46,340 --> 01:05:49,620
그럼 모델에게 예측하라고 하는 그 실제 정답

1663
01:05:49,620 --> 01:05:51,002
타깃도 달라집니다.

1664
01:05:51,002 --> 01:05:53,460
항상 데이터 샘플 x와

1665
01:05:53,460 --> 01:05:56,740
잠재 변수 z의 선형 결합일 겁니다.

1666
01:05:56,740 --> 01:05:58,960
그리고 다시 말하지만, 선형 결합

1667
01:05:58,960 --> 01:06:02,200
가중치는 어떤 공식에서는 t의 함수일 수 있습니다.

1668
01:06:02,200 --> 01:06:03,805
기본적으로 우리는 모델에게

1669
01:06:03,805 --> 01:06:05,180
노이즈가 섞인

1670
01:06:05,180 --> 01:06:08,240
xt와 t를 주고, y를 예측하게 할 겁니다.

1671
01:06:08,240 --> 01:06:10,640
그리고 항상 두 값 사이의 L2 손실을 계산합니다.

1672
01:06:10,640 --> 01:06:12,885
항상은 아니지만 보통 그렇습니다.

1673
01:06:12,885 --> 01:06:14,260
그리고 달라지는 것은 기본적으로

1674
01:06:14,260 --> 01:06:16,080
이 함수들의 다양한 형태입니다.

1675
01:06:16,080 --> 01:06:17,120
이 함수들이

1676
01:06:17,120 --> 01:06:19,160
네 군데 다른 위치에

1677
01:06:19,160 --> 01:06:21,120
들어가는 함수들인 거죠.

1678
01:06:21,120 --> 01:06:24,160
rectified flow의 경우는 꽤 간단합니다.

1679
01:06:24,160 --> 01:06:26,140
모두 아주 단순한 형태를 가집니다.

1680
01:06:26,140 --> 01:06:30,200
그리고 ct와 dt는 사실 상수입니다.

1681
01:06:30,200 --> 01:06:35,480
variance preserving이라는 다른 방식도 있는데, 여기서는 이

1682
01:06:35,480 --> 01:06:38,640
둘을 sigma(t)라는 하나의 스칼라

1683
01:06:38,640 --> 01:06:39,960
하이퍼파라미터로 합칩니다.

1684
01:06:39,960 --> 01:06:42,160
이제 이런 특정한 방식으로 선형

1685
01:06:42,160 --> 01:06:43,360
결합을 하게 됩니다.

1686
01:06:43,360 --> 01:06:46,200
x와 z가 독립이고 단위 분산을 가진다면, 출력도

1687
01:06:46,200 --> 01:06:48,400
단위 분산을 가지도록 보장하기 때문에

1688
01:06:48,400 --> 01:06:50,030
이렇게 선택하는 겁니다.

1689
01:06:50,030 --> 01:06:52,280
그래서 이 두 함수형 하이퍼파라미터를

1690
01:06:52,280 --> 01:06:54,040
하나의 노이즈 스케줄로

1691
01:06:54,040 --> 01:06:56,873
합치고, 그걸 어떻게든 선택해야 합니다.

1692
01:06:56,873 --> 01:06:58,540
variance preserving과

1693
01:06:58,540 --> 01:07:00,080
함께 variance exploding이라는

1694
01:07:00,080 --> 01:07:03,240
다른 방식도 있는데, 여기서는 at를 1로, bt를 다시

1695
01:07:03,240 --> 01:07:04,380
sigma(t)로 설정합니다.

1696
01:07:04,380 --> 01:07:06,640
그리고 나서 어떻게든 그것을 선택해야 합니다.

1697
01:07:06,640 --> 01:07:10,785
사람들이 선택하는 목표가 정말 다양합니다.

1698
01:07:10,785 --> 01:07:12,160
때로는 네트워크에게 깨끗한

1699
01:07:12,160 --> 01:07:13,510
데이터를 예측하라고 합니다.

1700
01:07:13,510 --> 01:07:15,260
때로는 모델에게 추가된 노이즈를

1701
01:07:15,260 --> 01:07:16,325
예측하라고 하기도 합니다.

1702
01:07:16,325 --> 01:07:17,700
때로는 두 가지의

1703
01:07:17,700 --> 01:07:20,100
선형 결합을 예측하라고 하기도 합니다.

1704
01:07:20,100 --> 01:07:22,200
rectified flow의

1705
01:07:22,200 --> 01:07:24,380
경우에는 데이터에서 노이즈로 직접 향하는

1706
01:07:24,380 --> 01:07:26,540
속도 벡터를 예측하는 것이지만,

1707
01:07:26,540 --> 01:07:30,060
다른 다양한 diffusion 방식에서는 이 모든

1708
01:07:30,060 --> 01:07:31,620
것이 달라질 수 있습니다.

1709
01:07:31,620 --> 01:07:34,580
하이퍼파라미터를 선택하는 것만 해도 충분히 어렵다고

1710
01:07:34,580 --> 01:07:35,830
생각할 수 있겠죠.

1711
01:07:35,830 --> 01:07:37,663
이제는 t의 함수인 하이퍼파라미터도

1712
01:07:37,663 --> 01:07:38,940
선택해야 합니다.

1713
01:07:38,940 --> 01:07:40,007
이건 정말 미친 짓입니다.

1714
01:07:40,007 --> 01:07:41,840
직관적으로 설정할 수 없으니

1715
01:07:41,840 --> 01:07:43,937
어떤 수학적 가이드가 필요합니다.

1716
01:07:43,937 --> 01:07:46,020
diffusion 모델을 훈련할 때

1717
01:07:46,020 --> 01:07:48,597
사람들이 생각하는 수학적 형식이 기본적으로

1718
01:07:48,597 --> 01:07:51,180
세 가지가 있는데, 실제로 다루지는

1719
01:07:51,180 --> 01:07:51,680
않겠습니다.

1720
01:07:51,680 --> 01:07:54,340
그저 존재한다는 것만 알아두시길 바랍니다.

1721
01:07:54,340 --> 01:07:57,460
첫 번째는 diffusion이 잠재 변수 모델이라는 점입니다.

1722
01:07:57,460 --> 01:07:59,680
깨끗한 데이터 샘플 x0가

1723
01:07:59,680 --> 01:08:01,460
있지만, 각 깨끗한

1724
01:08:01,460 --> 01:08:03,180
샘플에 대응하는

1725
01:08:03,180 --> 01:08:06,540
일련의 손상되거나 노이즈가 섞인 샘플들이

1726
01:08:06,540 --> 01:08:07,677
존재합니다.

1727
01:08:07,677 --> 01:08:08,760
우리는 그것들을 관찰할 수 없습니다.

1728
01:08:08,760 --> 01:08:10,140
무엇인지 모르지만 어떻게든

1729
01:08:10,140 --> 01:08:11,160
알아내야 합니다.

1730
01:08:11,160 --> 01:08:12,577
이것이 잠재 변수 모델입니다.

1731
01:08:12,577 --> 01:08:15,140
이것은 변분 오토인코더와 매우 비슷하게 보입니다.

1732
01:08:15,140 --> 01:08:17,700
기억하시죠, 변분 오토인코더에서는 z와 x가 있었고, z는 관찰하지
못했습니다.

1733
01:08:17,700 --> 01:08:18,779
어떻게든 이 모델을 훈련시키고 싶었죠.

1734
01:08:18,779 --> 01:08:21,040
그리고 변분 오토인코더에서 사용한 것과 매우 유사한 수학적 기법을 사용해
데이터의 우도에 대한 변분 하한을 최대화할 수 있습니다.

1735
01:08:21,040 --> 01:08:25,359
이것이 diffusion의

1736
01:08:25,359 --> 01:08:27,100
잠재 변수

1737
01:08:27,100 --> 01:08:28,840
모델 해석을

1738
01:08:28,840 --> 01:08:30,260
낳습니다.

1739
01:08:30,260 --> 01:08:32,359
diffusion에 대한 완전히 다른

1740
01:08:32,359 --> 01:08:35,441
해석은 score function을 모델링한다는 것입니다.

1741
01:08:35,441 --> 01:08:37,399
x의 분포 pdata가 주어지면, score function이라는

1742
01:08:37,399 --> 01:08:39,760
멋진 개념이 있는데, 이는 pdata(x)의 로그에 대해 x로 미분한
것입니다.

1743
01:08:39,760 --> 01:08:45,040
직관적으로 분포가 주어지면, score

1744
01:08:45,040 --> 01:08:47,479
function은 높은 확률

1745
01:08:47,479 --> 01:08:49,920
밀도 영역을 가리키는

1746
01:08:49,920 --> 01:08:52,040
벡터 필드입니다.

1747
01:08:52,040 --> 01:08:54,180
데이터 공간의 어떤 점에서든

1748
01:08:54,180 --> 01:08:55,920
score function은

1749
01:08:55,920 --> 01:09:00,319
높은 데이터 밀도 영역을 향하는 벡터가 됩니다.

1750
01:09:00,319 --> 01:09:02,785
또 다른 diffusion 해석은 diffusion이 데이터 분포의

1751
01:09:02,785 --> 01:09:04,160
score function을 학습한다는

1752
01:09:04,160 --> 01:09:08,240
것입니다. 사실, 데이터 분포에 노이즈가 섞인 다양한 수준에 대응하는
score function 집합을 학습합니다.

1753
01:09:08,240 --> 01:09:10,439
즉, diffusion은 점점 더 많은

1754
01:09:10,439 --> 01:09:12,939
알려진 노이즈로 진짜 데이터 분포를

1755
01:09:12,939 --> 01:09:14,660
손상시키는 노이즈 분포 계열에

1756
01:09:14,660 --> 01:09:16,740
대응하는 score function

1757
01:09:16,740 --> 01:09:19,725
계열을 학습하려는 시도라는 또 다른 해석이 있습니다.

1758
01:09:19,725 --> 01:09:21,100
이것은

1759
01:09:21,100 --> 01:09:22,725
완전히 다른

1760
01:09:22,725 --> 01:09:25,140
수학적 형식이지만

1761
01:09:25,140 --> 01:09:27,180
결국 매우 비슷한

1762
01:09:27,180 --> 01:09:29,700
알고리즘으로

1763
01:09:29,700 --> 01:09:31,080
이어집니다.

1764
01:09:31,080 --> 01:09:33,340
그리고 최근에 등장한 세 번째 해석은

1765
01:09:33,340 --> 01:09:36,837
diffusion을 확률 미분 방정식을 푸는 것으로 보는 것입니다.

1766
01:09:36,837 --> 01:09:39,420
솔직히 저도 이 부분은 완전히

1767
01:09:39,420 --> 01:09:41,620
이해하지 못해서 질문은

1768
01:09:41,620 --> 01:09:43,755
너무 많이 하지 마세요.

1769
01:09:43,755 --> 01:09:46,380
하지만 아이디어는

1770
01:09:46,380 --> 01:09:49,020
노이즈 분포에서

1771
01:09:49,020 --> 01:09:52,020
데이터 분포로 샘플을

1772
01:09:52,020 --> 01:09:55,260
미세하게 이동시키는

1773
01:09:55,260 --> 01:09:58,060
미분 방정식을 작성하는

1774
01:09:58,060 --> 01:10:00,040
것입니다.

1775
01:10:00,040 --> 01:10:02,220
그리고 추론 단계에서,

1776
01:10:02,220 --> 01:10:05,720
신경망은 기본적으로 우리가 쓸 수 있는 확률 미분

1777
01:10:05,720 --> 01:10:08,620
방정식에 대한 어떤 수치적 적분기를

1778
01:10:08,620 --> 01:10:09,940
배우는 겁니다.

1779
01:10:09,940 --> 01:10:12,683
이것은 확률 미분 방정식

1780
01:10:12,683 --> 01:10:14,600
관점에서 보면 추론 시점에

1781
01:10:14,600 --> 01:10:19,680
샘플링할 수 있는 완전히 다른 두 가지 방법 범주에

1782
01:10:19,680 --> 01:10:22,380
접근할 수 있게 해줍니다.

1783
01:10:22,380 --> 01:10:26,880
이 관점에서 보면, rectified flow에서 본

1784
01:10:26,880 --> 01:10:28,720
단순한 경사 하강법 방식은

1785
01:10:28,720 --> 01:10:31,320
확률 미분 방정식 위에서의 전진

1786
01:10:31,320 --> 01:10:33,682
오일러 적분기와 대응됩니다.

1787
01:10:33,682 --> 01:10:35,140
이 해석 아래에서는 점수

1788
01:10:35,140 --> 01:10:37,765
함수(score function)를 따라 더 잘 나아가기

1789
01:10:37,765 --> 01:10:40,440
위해 훨씬 복잡한 적분기를 사용할 수도 있다고 상상할

1790
01:10:40,440 --> 01:10:41,240
수 있습니다.

1791
01:10:41,240 --> 01:10:43,820
다시 말하지만, 이건 깊은 내용입니다.

1792
01:10:43,820 --> 01:10:46,400
이 모든 것에 대해 자세히 다룬

1793
01:10:46,400 --> 01:10:47,560
논문들이 있습니다.

1794
01:10:47,560 --> 01:10:49,040
제가 정말 좋아하는 블로그 글 중

1795
01:10:49,040 --> 01:10:52,203
하나는 Sander Dielman이 쓴 'perspectives

1796
01:10:52,203 --> 01:10:54,120
on diffusion'이라는 글로, 확산

1797
01:10:54,120 --> 01:10:56,812
모델을 생각하거나 보는 여덟 가지 다른 관점을 제시합니다.

1798
01:10:56,812 --> 01:10:58,020
정말 훌륭한 글입니다.

1799
01:10:58,020 --> 01:10:59,140
강력히 추천합니다.

1800
01:10:59,140 --> 01:11:00,280
사실 그가 확산 모델에

1801
01:11:00,280 --> 01:11:02,020
대해 쓴 모든 글을 강력히 추천합니다.

1802
01:11:02,020 --> 01:11:03,312
그의 모든 블로그 글이 훌륭합니다.

1803
01:11:05,800 --> 01:11:07,700
오토리그레시브 모델도 다시 등장합니다.

1804
01:11:07,700 --> 01:11:10,780
같은 방식으로 인코더-디코더에 오토리그레시브

1805
01:11:10,780 --> 01:11:12,940
모델을 붙일 수 있습니다.

1806
01:11:12,940 --> 01:11:16,560
마지막에 살짝 덧붙이자면, 확산 모델 외에 현대

1807
01:11:16,560 --> 01:11:19,620
생성 모델링의 또 다른 방법은 이산 변분

1808
01:11:19,620 --> 01:11:22,260
오토인코더로 계산된 이산 잠재

1809
01:11:22,260 --> 01:11:24,060
변수에 대해 오토리그레시브

1810
01:11:24,060 --> 01:11:26,060
모델을 훈련하는 것입니다.

1811
01:11:26,060 --> 01:11:30,860
그래서 우리가 생성 모델로 다룬 GAN, VAE,

1812
01:11:30,860 --> 01:11:33,220
오토리그레시브 모델, 확산

1813
01:11:33,220 --> 01:11:36,140
모델 모두가 현대 머신러닝 파이프라인에서

1814
01:11:36,140 --> 01:11:38,512
실제로 사용됩니다.

1815
01:11:38,512 --> 01:11:40,220
이게 오늘 내용의 요약입니다.

1816
01:11:40,220 --> 01:11:42,660
오늘은 두 가지 생성 모델 범주를 빠르게

1817
01:11:42,660 --> 01:11:43,720
훑어봤습니다.

1818
01:11:43,720 --> 01:11:46,137
생성적 적대 신경망과 확산 모델에 대해

1819
01:11:46,137 --> 01:11:46,880
이야기했습니다.

1820
01:11:46,880 --> 01:11:49,900
그리고 이들을 잠재 확산 모델에서 현대적인 전체 파이프라인으로

1821
01:11:49,900 --> 01:11:52,100
구현한 것을 봤습니다. 이게 생성

1822
01:11:52,100 --> 01:11:53,960
모델링 섹션을 잘 마무리하는 방법입니다.

1823
01:11:53,960 --> 01:11:56,252
왜냐하면 우리가 본 모든 생성 모델이

1824
01:11:56,252 --> 01:11:59,500
결국 다시 모여서 큰 현대 파이프라인을 형성하기 때문입니다.

1825
01:11:59,500 --> 01:12:03,690
감사합니다. 다음 시간에는 비전과 언어에 대해 이야기하겠습니다.
